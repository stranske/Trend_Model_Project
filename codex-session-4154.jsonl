{"type":"thread.started","thread_id":"019b85c6-42e3-7640-b1e4-8c090b8edc7d"}
{"type":"turn.started"}
{"type":"item.completed","item":{"id":"item_0","type":"reasoning","text":"**Assessing task requirements and planning**"}}
{"type":"item.started","item":{"id":"item_1","type":"command_execution","command":"/bin/bash -lc ls","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_1","type":"command_execution","command":"/bin/bash -lc ls","aggregated_output":"Agents.md\nCHANGELOG.md\nCLAUDE.md\nCODE_OF_CONDUCT.md\nCONTRIBUTING.md\nDEPENDENCY_QUICKSTART.md\nDOCKER_QUICKSTART.md\nDockerfile\nIssues.txt\nLICENSE\nMANIFEST.in\nMakefile\nREADME.md\nREADME_APP.md\nREADME_DATA.md\nSECURITY.md\nTrend Universe Data.csv\nagents\nanalysis\narchives\nassets\ncliff.toml\ncodex-prompt-4154.md\ncodex-session-4136.jsonl\ncodex-session-4138.jsonl\ncodex-session-4148.jsonl\ncodex-session-4150.jsonl\ncodex-session-4151.jsonl\ncodex-session-4154.jsonl\nconfig\ncoverage-summary.md\ndata\ndemo\ndocker-compose.yml\ndocs\nexamples\ngate-summary.md\nissues\nkeepalive_status.md\nman\nnotebooks\npackage-lock.json\npackage.json\nperf\npr_body.md\npyproject.toml\npytest.ini\nreports\nrequirements.lock\nretired\nscripts\nsrc\nstreamlit_app\ntests\ntools\ntrend_model.egg-info\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_2","type":"reasoning","text":"**Checking for AGENTS instructions**"}}
{"type":"item.started","item":{"id":"item_3","type":"command_execution","command":"/bin/bash -lc 'cat AGENTS.md'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_3","type":"command_execution","command":"/bin/bash -lc 'cat AGENTS.md'","aggregated_output":"cat: AGENTS.md: No such file or directory\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_4","type":"reasoning","text":"**Checking for Agents.md file**"}}
{"type":"item.started","item":{"id":"item_5","type":"command_execution","command":"/bin/bash -lc 'cat Agents.md'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_5","type":"command_execution","command":"/bin/bash -lc 'cat Agents.md'","aggregated_output":"# Agents.md\n\n> **Canonical implementation roadmap**: See [docs/phase-2/Agents.md](docs/phase-2/Agents.md) for the complete Phase-2 implementation spec and step-by-step guidance.\n\n## Mission\n\nConverge the scattered modules into one fully test-covered, vectorised pipeline that can be invoked from a single CLI entry-point. Never touch notebooks living under any directory whose name ends in `old/`.\n\n---\n\n## Quick Reference\n\n### Demo Pipeline\n\n```bash\n# 1. Bootstrap environment\n./scripts/setup_env.sh\n\n# 2. Generate demo dataset\npython scripts/generate_demo.py\n\n# 3. Run full demo pipeline\npython scripts/run_multi_demo.py\n\n# 4. Run test suite\n./scripts/run_tests.sh\n```\n\nSee [docs/DemoMaintenance.md](docs/DemoMaintenance.md) for the full checklist.\n\n### Key Entry Points\n\n| Purpose | Command |\n|---------|---------|\n| CLI analysis | `PYTHONPATH=\"./src\" python -m trend_analysis.run_analysis -c config/demo.yml` |\n| Streamlit app | `./scripts/run_streamlit.sh` |\n| Tests | `./scripts/run_tests.sh` |\n| Fast validation | `./scripts/dev_check.sh --fix` |\n\n---\n\n## Automation Entry Points\n\n### Agents 70 Orchestrator\n- **File**: `.github/workflows/agents-70-orchestrator.yml`\n- **Role**: Single automation front door for all agent operations\n- **Triggers**: 20-minute schedule sweep plus manual `workflow_dispatch`\n\n### Agents 63 Issue Intake\n- **File**: `.github/workflows/agents-63-issue-intake.yml`\n- **Role**: Bootstrap Codex PRs on `agent:codex` labeled issues\n- **Triggers**: Issue events (`opened`, `labeled`, `reopened`) plus manual dispatch\n\n### Agents 64 Verify Agent Assignment\n- **File**: `.github/workflows/agents-64-verify-agent-assignment.yml`\n- **Role**: Validates agent assignment before orchestrator proceeds\n\nLegacy consumer wrappers were retired. See [docs/archive/ARCHIVE_WORKFLOWS.md](docs/archive/ARCHIVE_WORKFLOWS.md).\n\n---\n\n## Canonical Module Locations\n\n| Layer / Concern | Canonical Location | Deprecated |\n|-----------------|-------------------|------------|\n| Data ingest & cleaning | `trend_analysis/data.py` | `data_utils.py`, notebook helpers |\n| Portfolio logic & metrics | `trend_analysis/metrics.py` | loops in `run_analysis.py` |\n| Export / I/O | `trend_analysis/export/` | root-level `exports.py` |\n| Domain kernels | `trend_analysis/core/` | standalone `core/` directory |\n| Pipeline orchestration | `trend_analysis/pipeline.py` | duplicated control flow |\n| CLI entry-point | `trend_analysis/cli.py` | bespoke `scripts/*.py` |\n| Config | `config/defaults.yml` via `trend_analysis.config.load()` | hard-coded constants |\n| Tests | `tests/` (pytest with coverage gate) | â€” |\n\n**Rule**: One concern â†’ one module. Replacements must delete or comment-out whatever they obsolete in the same PR.\n\n---\n\n## Guard-Rails\n\n### Communication\n- When a request contains multiple tasks, explicitly recap which items are complete and which remain before handing control back.\n- Call out any suggestion that is only a partial fix, and list the follow-up steps required for it to succeed.\n- Highlight assumptions about workflow or automation status and offer to pull the live data when needed.\n\n### Code Quality\n- **Vectorise first**: Falling back to for-loops requires a comment justifying why vectorisation is impossible or harmful.\n- **Public API**: Uses US-English snake_case; private helpers prefixed with `_`.\n- **No circular imports**: `pipeline.py` orchestrates; nothing imports it.\n- **Test fixtures**: Must be text-serialised (CSV/JSON); no binary formats in PRs.\n\n### Git Workflow\nBefore pushing, verify the target PR is still open:\n```bash\ngh pr view --json state,mergedAt,closed\n```\n- âŒ Never push to merged/closed PRs\n- âœ… Create a new branch and PR if the original is closed\n\n---\n\n## Export Guard-Rails\n\n> ðŸ›¡ï¸ Codex removed the pretty reporting layer once; it shall not happen again.\n\n1. **Call the canonical exporters**: After `pipeline.run()` completes, pipe results into exactly one of `export_to_excel`, `export_to_csv`, or `export_to_json`.\n\n2. **Excel format contract**:\n   - Bold title row\n   - `0.00%` for CAGR & Vol, `0.00` for Sharpe & Sortino\n   - Red numerals for MaxDD\n   - Freeze panes on header, auto-filter\n   - Column width = `max(len(header)) + 2`\n\n3. **Column order is law**: Tests must fail if column order mutates.\n\n4. **Back-compat**: Silent config = drop fully formatted Excel workbook into `outputs/` exactly as v1.0 did.\n\n---\n\n## Multi-Period Export (Phase-2)\n\nâœ… **Implemented**: Multi-period runs now emit Phase-1 style exports via:\n- `export_phase1_workbook()` - Excel with one sheet per period + summary tab\n- `export_phase1_multi_metrics()` - CSV/JSON with `*_periods.*` and `*_summary.*` files\n- `export_multi_period_metrics()` - General multi-period export helper\n\nHelper functions:\n- `workbook_frames_from_results()` - Builds sheet mapping\n- `period_frames_from_results()` - Converts result sequence to export format\n- `combined_summary_result()` - Aggregates portfolio returns across periods\n\n---\n\n## Feature Status\n\n### Implemented âœ…\n- Rank-based manager selection mode (`mode: rank`)\n- Blended scoring with z-score normalization\n- Scalar metric memoization (opt-in via `performance.cache.metrics: true`)\n- PR draft toggle for Codex bootstrap (`codex_pr_draft` input)\n- Multi-period Phase-1 style exports\n- Selector and weighting plugin classes\n\n### Backlog ðŸ“‹\n- Preview score frame in UI\n- Weight heatmap visualization\n- Expected shortfall metric\n- Diversification value metric\n- Export commit hash in outputs\n\n---\n\n## Debugging\n\n### Fund Selection Issues\n\nUse the debug script in `examples/`:\n```bash\npython examples/debug_fund_selection.py\n```\n\nThis reveals:\n- Which managers get filtered due to missing data\n- Available manager pool for selection\n- Actual ranking results\n\n### Common Pitfalls\n- Don't assume ranking is wrong without checking data completeness first\n- Both in-sample AND out-of-sample periods must have complete data\n- Verify configuration parameters match intended behavior\n\n---\n\n## Related Documentation\n\n- [docs/phase-2/Agents.md](docs/phase-2/Agents.md) - Complete implementation spec\n- [docs/DemoMaintenance.md](docs/DemoMaintenance.md) - Demo pipeline checklist\n- [docs/archive/ARCHIVE_WORKFLOWS.md](docs/archive/ARCHIVE_WORKFLOWS.md) - Retired workflows\n- [docs/metric_cache.md](docs/metric_cache.md) - Metric memoization details\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_6","type":"reasoning","text":"**Preparing to use plan tool**"}}
{"type":"item.started","item":{"id":"item_7","type":"todo_list","items":[{"text":"Inspect pipeline.py to identify preprocessing/selection/portfolio logic boundaries and dependent helpers","completed":false},{"text":"Create stages package and move preprocessing/selection/portfolio logic into new modules with tests","completed":false},{"text":"Refactor pipeline.py to orchestrate via stages, preserve public API, and add integration test + coverage checks","completed":false}]}}
{"type":"item.completed","item":{"id":"item_8","type":"reasoning","text":"**Examining pipeline.py file**"}}
{"type":"item.started","item":{"id":"item_9","type":"command_execution","command":"/bin/bash -lc 'rg -n \"preprocess|missing|align|inception|frequency|rank_select|score|metric|risk|weight|vol|portfolio\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_9","type":"command_execution","command":"/bin/bash -lc 'rg -n \"preprocess|missing|align|inception|frequency|rank_select|score|metric|risk|weight|vol|portfolio\" src/trend_analysis/pipeline.py'","aggregated_output":"15:from .core.rank_selection import (\n17:    get_window_metric_bundle,\n19:    rank_select_funds,\n21:from .data import identify_risk_free_fund, load_csv\n29:from .metrics import (\n35:    volatility,\n38:from .portfolio import apply_weight_policy\n40:from .risk import (\n43:    compute_constrained_weights,\n45:    realised_volatility,\n48:from .time_utils import align_calendar\n50:from .util.frequency import FrequencySummary, detect_frequency\n51:from .util.missing import MissingPolicyResult, apply_missing_policy\n52:from .weights.robust_config import weight_engine_params_from_robustness\n57:# column is eligible for risk-free fallback selection. This prevents sparse\n58:# series from being chosen and later propagating NaNs when aligned to the\n70:    \"\"\"Container for performance metrics.\n73:    requests the ``AvgCorr`` metric (Issue #1160). They remain ``None`` to\n79:    vol: float\n100:            and _equal(self.vol, other.vol)\n110:def _frequency_label(code: str) -> str:\n114:def _preprocessing_summary(\n115:    freq_code: str, *, normalised: bool, missing_summary: str | None\n117:    cadence = _frequency_label(freq_code)\n124:    if missing_summary:\n125:        parts.append(f\"Missing data: {missing_summary}\")\n134:    missing_result: MissingPolicyResult\n135:    preprocess_info: dict[str, object]\n136:    frequency_payload: dict[str, object]\n137:    missing_payload: Mapping[str, object]\n138:    alignment_info: Mapping[str, Any]\n163:    score_frame: pd.DataFrame\n164:    risk_free_override: pd.Series\n167:    missing_indices: list[str]\n172:    weights_series: pd.Series\n173:    risk_diagnostics: RiskDiagnostics\n174:    weight_engine_fallback: dict[str, Any] | None\n175:    weight_engine_diagnostics: dict[str, Any] | None\n190:    ew_weights: dict[str, float]\n191:    user_weights: dict[str, float]\n192:    score_frame: pd.DataFrame\n193:    weight_policy: dict[str, Any]\n198:def _prepare_preprocess_stage(\n201:    floor_vol: float | None,\n203:    missing_policy: str | Mapping[str, str] | None,\n204:    missing_limit: int | Mapping[str, int | None] | None,\n207:    allow_risk_free_fallback: bool | None,\n232:        df = align_calendar(\n235:            frequency=calendar_settings.get(\"frequency\"),\n250:    alignment_info = df.attrs.get(\"calendar_alignment\", {})\n253:        min_floor = float(floor_vol) if floor_vol is not None else 0.0\n267:    if allow_risk_free_fallback:\n270:    df_prepared, freq_summary, missing_result, normalised = _prepare_input_data(\n273:        missing_policy=missing_policy,\n274:        missing_limit=missing_limit,\n281:                \"missing_summary\": getattr(missing_result, \"summary\", None),\n282:                \"dropped_assets\": list(getattr(missing_result, \"dropped_assets\", ())),\n318:    frequency_payload = {\n328:    missing_payload = {\n329:        \"policy\": missing_result.default_policy,\n330:        \"policy_map\": missing_result.policy,\n331:        \"limit\": missing_result.default_limit,\n332:        \"limit_map\": missing_result.limit,\n333:        \"dropped_assets\": list(missing_result.dropped_assets),\n334:        \"filled_assets\": {asset: count for asset, count in missing_result.filled_cells},\n335:        \"total_filled\": missing_result.total_filled,\n338:    preprocess_info = {\n339:        \"input_frequency\": frequency_payload[\"code\"],\n340:        \"input_frequency_details\": frequency_payload,\n342:        \"missing\": missing_result,\n343:        \"missing_data_policy\": missing_payload,\n345:    preprocess_info[\"summary\"] = _preprocessing_summary(\n348:        missing_summary=missing_result.summary,\n350:    preprocess_info[\"calendar_alignment\"] = alignment_info\n356:        missing_result=missing_result,\n357:        preprocess_info=preprocess_info,\n358:        frequency_payload=frequency_payload,\n359:        missing_payload=missing_payload,\n360:        alignment_info=alignment_info,\n370:    preprocess: _PreprocessStage,\n386:            return pd.DatetimeIndex([], name=preprocess.date_col)\n389:    def _fill_missing_months(\n400:        configured missing-data policy is not \"drop\", we want windows to retain\n411:            # want to preserve calendar alignment for downstream diagnostics.\n424:            getattr(preprocess.missing_result, \"default_policy\", \"drop\") or \"drop\"\n429:        # Re-apply missing policy to fill any newly inserted rows.\n432:            policy_map = dict(getattr(preprocess.missing_result, \"policy\", {}) or {})\n434:                getattr(preprocess.missing_result, \"default_policy\", \"drop\") or \"drop\"\n443:            limit_map = dict(getattr(preprocess.missing_result, \"limit\", {}) or {})\n444:            default_limit = getattr(preprocess.missing_result, \"default_limit\", None)\n456:            reindexed, _ = apply_missing_policy(\n490:    date_series = preprocess.df[preprocess.date_col]\n498:    in_mask = (preprocess.df[preprocess.date_col] >= in_sdate) & (\n499:        preprocess.df[preprocess.date_col] <= in_edate\n501:    out_mask = (preprocess.df[preprocess.date_col] >= out_sdate) & (\n502:        preprocess.df[preprocess.date_col] <= out_edate\n504:    in_df_raw = preprocess.df.loc[in_mask].set_index(preprocess.date_col)\n505:    out_df_raw = preprocess.df.loc[out_mask].set_index(preprocess.date_col)\n513:    in_df = _fill_missing_months(\n519:    out_df = _fill_missing_months(\n552:        periods_per_year=preprocess.periods_per_year,\n553:        date_col=preprocess.date_col,\n558:    preprocess: _PreprocessStage,\n565:    custom_weights: dict[str, float] | None,\n571:    risk_free_column: str | None,\n572:    allow_risk_free_fallback: bool | None,\n576:    missing_indices: list[str] = []\n580:        missing_indices = [\n589:                missing_indices.append(idx)\n596:                    \"missing_indices\": missing_indices,\n610:        preprocess.date_col not in fallback_window.columns\n613:        fallback_window = fallback_window.rename(columns={\"index\": preprocess.date_col})\n614:    rf_col, fund_cols, rf_source = _resolve_risk_free_column(\n615:        preprocess.df,\n616:        date_col=preprocess.date_col,\n618:        risk_free_column=risk_free_column,\n619:        allow_risk_free_fallback=allow_risk_free_fallback,\n623:    if selection_mode == \"all\" and custom_weights is not None:\n624:        fund_cols = [c for c in fund_cols if c in custom_weights]\n625:        if not fund_cols and custom_weights:\n626:            fund_cols = list(custom_weights.keys())\n628:            custom_weights = None\n630:    # keep only funds that satisfy missing-data policy in both windows. The\n643:        max_missing = int(na_cfg.get(\"max_missing_per_window\", 0) or 0)\n648:            missing = int(series.isna().sum())\n649:            if missing == 0:\n651:            if missing > max_missing:\n668:        stats_cfg = RiskStatsConfig(risk_free=0.0)\n670:    risk_free_override = window.in_df[rf_col]\n676:        mask = (preprocess.df[preprocess.date_col] >= window.in_start) & (\n677:            preprocess.df[preprocess.date_col] <= window.in_end\n679:        sub = preprocess.df.loc[mask, fund_cols]\n690:            bundle = get_window_metric_bundle(window_key)\n694:        rank_result = rank_select_funds(\n698:            risk_free=risk_free_override,\n715:                \"universe_size\": len(preprocess.value_cols_all),\n719:    score_frame = single_period_run(\n720:        preprocess.df[[preprocess.date_col] + fund_cols],\n724:        risk_free=risk_free_override,\n731:        score_frame=score_frame,\n732:        risk_free_override=risk_free_override,\n735:        missing_indices=missing_indices,\n739:def _compute_weights_and_stats(\n740:    preprocess: _PreprocessStage,\n744:    target_vol: float | None,\n746:    custom_weights: dict[str, float] | None,\n747:    weighting_scheme: str | None,\n749:    risk_window: Mapping[str, Any] | None,\n750:    previous_weights: Mapping[str, float] | None,\n754:    weight_policy: Mapping[str, Any] | None,\n758:    weight_engine_params: Mapping[str, Any] | None,\n823:            scoped_cols = [preprocess.date_col, *fund_cols]\n827:            subset = preprocess.df[scoped_cols].copy()\n828:            signal_source = subset.set_index(preprocess.date_col)\n842:    custom_weights_input = custom_weights is not None\n843:    weight_engine_used = False\n844:    weight_engine_fallback: dict[str, Any] | None = None\n845:    weight_engine_diagnostics: dict[str, Any] | None = None\n847:        custom_weights is None\n848:        and weighting_scheme\n849:        and weighting_scheme.lower() != \"equal\"\n852:            from .plugins import create_weight_engine\n855:            engine = create_weight_engine(\n856:                weighting_scheme.lower(), **(weight_engine_params or {})\n858:            w_series = engine.weight(cov).reindex(fund_cols).fillna(0.0)\n859:            custom_weights = {c: float(w_series.get(c, 0.0) * 100.0) for c in fund_cols}\n860:            weight_engine_used = True\n861:            weight_engine_diagnostics = getattr(engine, \"diagnostics\", None)\n863:                weight_engine_diagnostics\n864:                and isinstance(weight_engine_diagnostics, Mapping)\n865:                and weight_engine_diagnostics.get(\"used_safe_mode\")\n867:                safe_mode = weight_engine_diagnostics.get(\"safe_mode\")\n868:                condition_number = weight_engine_diagnostics.get(\"condition_number\")\n869:                condition_threshold = weight_engine_diagnostics.get(\n872:                condition_source = weight_engine_diagnostics.get(\"condition_source\")\n873:                raw_condition_number = weight_engine_diagnostics.get(\n876:                shrunk_condition_number = weight_engine_diagnostics.get(\n879:                shrinkage_info = weight_engine_diagnostics.get(\"shrinkage\")\n880:                fallback_reason = weight_engine_diagnostics.get(\n883:                weight_engine_fallback = {\n884:                    \"engine\": str(weighting_scheme),\n892:                    weight_engine_fallback[\"raw_condition_number\"] = (\n896:                    weight_engine_fallback[\"shrunk_condition_number\"] = (\n900:                    weight_engine_fallback[\"shrinkage\"] = dict(shrinkage_info)\n907:                        weighting_scheme,\n916:                        weighting_scheme,\n920:                \"Successfully created %s weight engine\",\n921:                weighting_scheme,\n922:                extra={\"weight_engine\": weighting_scheme},\n926:                \"Weight engine '%s' failed (%s: %s); falling back to equal weights\"\n927:                % (weighting_scheme, type(e).__name__, e)\n931:                \"Weight engine creation failed, falling back to equal weights: %s\", e\n933:            weight_engine_fallback = {\n934:                \"engine\": str(weighting_scheme),\n939:            custom_weights = None\n941:    if custom_weights is None:\n942:        custom_weights = {c: 100 / len(fund_cols) for c in fund_cols}\n948:    raw_max_weight = constraints_cfg.get(\"max_weight\")\n950:        max_weight_val = float(raw_max_weight) if raw_max_weight is not None else None\n952:        max_weight_val = None\n976:        {c: float(custom_weights.get(c, 0.0)) / 100.0 for c in fund_cols},\n988:        if weight_engine_used:\n989:            source = f\"weight engine '{weighting_scheme}'\"\n990:        elif custom_weights_input:\n991:            source = \"custom weights\"\n993:            source = \"base weights\"\n996:            \"%s produced %d negative weights; long_only=%s so pipeline will %s.\",\n1003:    window_cfg = dict(risk_window or {})\n1033:        vol_adjust=False,\n1034:        vol_target=None,\n1035:        zscore=False,\n1044:        weights_series, risk_diagnostics = compute_constrained_weights(\n1048:            target_vol=target_vol,\n1050:            floor_vol=min_floor if min_floor > 0 else None,\n1052:            max_weight=max_weight_val,\n1054:            previous_weights=previous_weights,\n1062:            \"Risk controls failed; falling back to base weights: %s\", exc, exc_info=True\n1064:        weights_series = base_series.copy()\n1065:        asset_vol = realised_volatility(\n1070:        latest_vol = asset_vol.iloc[-1].reindex(fund_cols)\n1071:        latest_vol = latest_vol.ffill().bfill()\n1072:        positive = latest_vol[latest_vol > 0]\n1073:        fallback_vol = float(positive.min()) if not positive.empty else 1.0\n1074:        latest_vol = latest_vol.fillna(fallback_vol)\n1076:            latest_vol = latest_vol.clip(lower=min_floor)\n1077:        if target_vol is None:\n1081:                pd.Series(target_vol, index=fund_cols, dtype=float)\n1082:                .div(latest_vol)\n1087:        portfolio_returns = scaled_returns.mul(weights_series, axis=1).sum(axis=1)\n1088:        portfolio_vol = realised_volatility(\n1089:            portfolio_returns.to_frame(\"portfolio\"),\n1092:        )[\"portfolio\"]\n1093:        risk_diagnostics = RiskDiagnostics(\n1094:            asset_volatility=asset_vol,\n1095:            portfolio_volatility=portfolio_vol,\n1101:    policy_cfg = dict(weight_policy or {})\n1113:            aligned = signal_frame.reindex(columns=fund_cols)\n1114:            if target_index in aligned.index:\n1115:                signal_snapshot = aligned.loc[target_index]\n1116:            elif not aligned.empty:\n1117:                signal_snapshot = aligned.iloc[-1]\n1121:    weights_series = (\n1122:        apply_weight_policy(\n1123:            weights_series,\n1127:            previous=previous_weights,\n1132:    scale_factors = risk_diagnostics.scale_factors.reindex(fund_cols).fillna(0.0)\n1155:        reg = getattr(stats_cfg, \"metrics_to_run\", []) or []\n1200:    ew_weights = np.repeat(1.0 / len(fund_cols), len(fund_cols))\n1201:    ew_w_dict = {c: w for c, w in zip(fund_cols, ew_weights)}\n1202:    in_ew = calc_portfolio_returns(ew_weights, in_scaled)\n1203:    out_ew = calc_portfolio_returns(ew_weights, out_scaled)\n1204:    out_ew_raw = calc_portfolio_returns(ew_weights, window.out_df[fund_cols])\n1210:    user_w = weights_series.to_numpy(dtype=float, copy=False)\n1211:    user_w_dict = {c: float(weights_series[c]) for c in fund_cols}\n1213:    in_user = calc_portfolio_returns(user_w, in_scaled)\n1214:    out_user = calc_portfolio_returns(user_w, out_scaled)\n1215:    out_user_raw = calc_portfolio_returns(user_w, window.out_df[fund_cols])\n1224:        weights_series=weights_series,\n1225:        risk_diagnostics=risk_diagnostics,\n1226:        weight_engine_fallback=weight_engine_fallback,\n1227:        weight_engine_diagnostics=weight_engine_diagnostics,\n1242:        ew_weights=ew_w_dict,\n1243:        user_weights=user_w_dict,\n1244:        score_frame=selection.score_frame,\n1245:        weight_policy=policy_cfg,\n1252:    preprocess: _PreprocessStage,\n1259:    target_vol: float | None,\n1278:    out_user = calc_portfolio_returns(\n1279:        computation.weights_series.to_numpy(dtype=float, copy=False),\n1282:    out_user_raw = calc_portfolio_returns(\n1283:        computation.weights_series.to_numpy(dtype=float, copy=False), out_df[fund_cols]\n1285:    out_ew = calc_portfolio_returns(\n1288:    out_ew_raw = calc_portfolio_returns(\n1312:            ir_dict[\"equal_weight\"] = (\n1317:            ir_dict[\"user_weight\"] = (\n1331:        data=preprocess.df,\n1334:        risk_free=computation.rf_out,\n1336:        freq_code=preprocess.freq_summary.target,\n1341:        universe=preprocess.value_cols_all,\n1351:            \"target_vol\": target_vol,\n1352:            \"floor_vol\": min_floor if min_floor > 0 else None,\n1356:    metadata[\"frequency\"] = preprocess.frequency_payload\n1357:    metadata[\"missing_data\"] = preprocess.missing_payload\n1358:    metadata[\"risk_free_column\"] = rf_col\n1362:        \"missing\": selection.missing_indices,\n1368:            \"risk_free_column\": rf_col,\n1369:            \"risk_free_source\": selection.rf_source,\n1381:            \"ew_weights\": computation.ew_weights,\n1382:            \"fund_weights\": computation.user_weights,\n1385:            \"score_frame\": computation.score_frame,\n1386:            \"weight_engine_fallback\": computation.weight_engine_fallback,\n1387:            \"weight_engine_diagnostics\": computation.weight_engine_diagnostics,\n1388:            \"preprocessing\": preprocess.preprocess_info,\n1389:            \"preprocessing_summary\": preprocess.preprocess_info.get(\"summary\"),\n1390:            \"risk_diagnostics\": {\n1391:                \"asset_volatility\": computation.risk_diagnostics.asset_volatility,\n1392:                \"portfolio_volatility\": computation.risk_diagnostics.portfolio_volatility,\n1393:                \"turnover\": computation.risk_diagnostics.turnover,\n1394:                \"turnover_value\": computation.risk_diagnostics.turnover_value,\n1395:                \"scale_factors\": computation.risk_diagnostics.scale_factors,\n1396:                \"final_weights\": computation.weights_series,\n1446:def _resolve_target_vol(vol_adjust_cfg: Mapping[str, Any] | Any) -> float | None:\n1447:    enabled = _section_get(vol_adjust_cfg, \"enabled\")\n1450:    target_raw = _section_get(vol_adjust_cfg, \"target_vol\", 1.0)\n1462:# Default multiplier for reducing fund count/selection during risk-off regimes.\n1463:# Must match the value in config/defaults.yml regime.risk_off_fund_count_multiplier\n1468:    preprocess: _PreprocessStage,\n1508:        freq=preprocess.freq_summary.target,\n1513:    aligned = labels.reindex(window.in_df.index).ffill().bfill()\n1514:    if aligned.empty:\n1516:    return str(aligned.iloc[-1]), settings\n1529:    if regime_label != getattr(settings, \"risk_off_label\", \"Risk-Off\"):\n1535:    if \"risk_off_fund_count_multiplier\" in cfg:\n1537:            multiplier = float(cfg[\"risk_off_fund_count_multiplier\"])\n1580:def _apply_regime_weight_overrides(\n1582:    target_vol: float | None,\n1588:    if target_vol is None:\n1591:        return target_vol, constraints\n1592:    if regime_label != getattr(settings, \"risk_off_label\", \"Risk-Off\"):\n1593:        return target_vol, constraints\n1606:    updated_target = target_vol\n1607:    if \"risk_off_target_vol\" in cfg:\n1609:            cfg.get(\"risk_off_target_vol\"), target_vol\n1613:            cfg.get(\"risk_off_target_vol_multiplier\", 0.5), 0.5\n1615:        updated_target = float(target_vol) * multiplier\n1640:        \"risk_diagnostics\": {},\n1641:        \"fund_weights\": {},\n1647:    vol_adjust_cfg: Mapping[str, Any] | Any,\n1653:    the in-sample risk window).\n1659:    # the window from the risk window length rather than hardcoding 63.\n1690:    vol_adjust_default = bool(_section_get(vol_adjust_cfg, \"enabled\", False))\n1691:    vol_adjust_flag = bool(\n1692:        _signal_setting(\"vol_adjust\", \"trend_vol_adjust\", vol_adjust_default)\n1694:    vol_target_raw = _signal_setting(\"vol_target\", \"trend_vol_target\")\n1695:    if vol_target_raw is None and vol_adjust_flag:\n1696:        vol_target_raw = _section_get(vol_adjust_cfg, \"target_vol\")\n1698:        vol_target = float(vol_target_raw) if vol_target_raw is not None else None\n1699:        if vol_target is not None and vol_target <= 0:\n1700:            vol_target = None\n1702:        vol_target = None\n1704:    zscore_setting = _signal_setting(\"zscore\", \"trend_zscore\", False)\n1705:    if isinstance(zscore_setting, bool):\n1706:        zscore_flag: bool | float = zscore_setting\n1709:            zscore_value = float(zscore_setting)\n1711:            zscore_flag = False\n1713:            zscore_flag = zscore_value if np.isfinite(zscore_value) else False\n1714:            if isinstance(zscore_flag, float) and zscore_flag <= 0:\n1715:                zscore_flag = False\n1722:        vol_adjust=vol_adjust_flag,\n1723:        vol_target=vol_target,\n1724:        zscore=zscore_flag,\n1834:    missing = [key for key in required_keys if key not in resolved]\n1835:    if not missing:\n1873:    still_missing = [key for key in required_keys if key not in resolved]\n1874:    if still_missing:\n1876:            f\"Unable to derive sample split values for: {', '.join(still_missing)}\"\n1885:    missing_policy: str | Mapping[str, str] | None,\n1886:    missing_limit: int | Mapping[str, int | None] | None,\n1897:    freq_summary = detect_frequency(work[date_col])\n1913:    policy_spec: str | Mapping[str, str] | None = missing_policy or \"drop\"\n1925:    filled, missing_result = apply_missing_policy(\n1928:        limit=missing_limit,\n1931:    # Only drop rows that remain completely empty after the missing-data policy.\n1941:    return monthly_df, freq_summary, missing_result, normalised\n1944:def calc_portfolio_returns(\n1945:    weights: NDArray[Any], returns_df: pd.DataFrame\n1947:    \"\"\"Calculate weighted portfolio returns.\"\"\"\n1948:    return returns_df.mul(weights, axis=1).sum(axis=1)\n1951:def _resolve_risk_free_column(\n1956:    risk_free_column: str | None,\n1957:    allow_risk_free_fallback: bool | None,\n1960:    \"\"\"Select the risk-free column and investable funds.\n1965:        ``(risk_free_column, fund_columns, source)`` where ``source`` is\n1982:    configured_rf = (risk_free_column or \"\").strip()\n1989:            \"No numeric return columns were found in the requested window; cannot select risk-free series\"\n2000:        # Map observations to month-end dates at midnight so they align with\n2006:    except Exception:  # pragma: no cover - best-effort alignment\n2012:        # If the risk-free series is explicitly configured, compute coverage\n2028:        raise ValueError(\"Requested window is empty; cannot select risk-free series\")\n2030:    # Coverage threshold for selecting a risk-free proxy. Clamp to the window\n2043:                f\"Configured risk-free column '{configured_rf}' was not found in the dataset\"\n2047:                f\"Configured risk-free column '{configured_rf}' must be numeric\"\n2063:                \"Configured risk-free column '%s' has no coverage in the requested window; proceeding\",\n2069:                    f\"Configured risk-free column '{configured_rf}' has insufficient coverage \"\n2078:        # the requested windows. This keeps the fallback selection aligned with the\n2092:        # BREAKING CHANGE: The default behavior of allow_risk_free_fallback has changed.\n2097:        fallback_enabled = allow_risk_free_fallback is not False\n2098:        if fallback_enabled and allow_risk_free_fallback is None:\n2105:                \"Set data.risk_free_column or enable data.allow_risk_free_fallback to select a risk-free series.\"\n2112:        # With <2 observations, volatility is undefined (std = NaN), which can\n2135:                \"Using '%s' as risk-free (fallback short-window)\",\n2139:            detected = identify_risk_free_fund(window_df[probe_cols])\n2149:                \"Using lowest-volatility column '%s' as risk-free (fallback enabled)\",\n2163:    risk_free: float | pd.Series | None = None,\n2165:    \"\"\"Return a score frame of metrics for a single period.\n2179:        Table of metric values (index = fund code).  The frame is pure\n2183:    from .core.rank_selection import RiskStatsConfig, _compute_metric_series\n2214:    metrics = stats_cfg.metrics_to_run\n2215:    if not metrics:\n2216:        raise ValueError(\"stats_cfg.metrics_to_run must not be empty\")\n2219:        _compute_metric_series(\n2220:            window_no_all_nan, m, stats_cfg, risk_free_override=risk_free\n2222:        for m in metrics\n2224:    score_frame = pd.concat(parts, axis=1)\n2225:    score_frame.columns = metrics\n2226:    score_frame.attrs[\"insample_len\"] = len(window)\n2227:    score_frame.attrs[\"period\"] = (start, end)\n2228:    # Optional derived correlation metric (opt-in via stats_cfg.extra_metrics)\n2229:    extra = getattr(stats_cfg, \"extra_metrics\", [])\n2232:        and score_frame.shape[1] > 0\n2234:        and \"AvgCorr\" not in score_frame.columns\n2236:        from .core.rank_selection import compute_metric_series_with_cache\n2239:            avg_corr_series = compute_metric_series_with_cache(\n2243:                risk_free_override=risk_free,\n2254:        score_frame = pd.concat([score_frame, avg_corr_series], axis=1)\n2255:    return score_frame.astype(float)\n2272:            vol=float(volatility(df[col])),\n2289:    target_vol: float | None,\n2292:    floor_vol: float | None = None,\n2296:    custom_weights: dict[str, float] | None = None,\n2303:    weighting_scheme: str | None = None,\n2305:    missing_policy: str | Mapping[str, str] | None = None,\n2306:    missing_limit: int | Mapping[str, int | None] | None = None,\n2307:    risk_window: Mapping[str, Any] | None = None,\n2309:    previous_weights: Mapping[str, float] | None = None,\n2314:    weight_policy: Mapping[str, Any] | None = None,\n2315:    risk_free_column: str | None = None,\n2316:    allow_risk_free_fallback: bool | None = None,\n2317:    weight_engine_params: Mapping[str, Any] | None = None,\n2319:    preprocess_stage = _prepare_preprocess_stage(\n2321:        floor_vol=floor_vol,\n2323:        missing_policy=missing_policy,\n2324:        missing_limit=missing_limit,\n2327:        allow_risk_free_fallback=allow_risk_free_fallback,\n2329:    if isinstance(preprocess_stage, PipelineResult):\n2330:        return preprocess_stage\n2333:        preprocess_stage,\n2343:        preprocess_stage,\n2355:    target_vol, constraints = _apply_regime_weight_overrides(\n2356:        target_vol=target_vol,\n2364:        preprocess_stage,\n2370:        custom_weights=custom_weights,\n2376:        risk_free_column=risk_free_column,\n2377:        allow_risk_free_fallback=allow_risk_free_fallback,\n2382:    stats_cfg_obj = stats_cfg or RiskStatsConfig(risk_free=0.0)\n2383:    computation_stage = _compute_weights_and_stats(\n2384:        preprocess_stage,\n2387:        target_vol=target_vol,\n2389:        custom_weights=custom_weights,\n2390:        weighting_scheme=weighting_scheme,\n2392:        risk_window=risk_window,\n2393:        previous_weights=previous_weights,\n2397:        weight_policy=weight_policy,\n2398:        warmup=preprocess_stage.warmup,\n2399:        min_floor=preprocess_stage.min_floor,\n2401:        weight_engine_params=weight_engine_params,\n2405:        preprocess_stage,\n2411:        target_vol=target_vol,\n2413:        min_floor=preprocess_stage.min_floor,\n2423:    target_vol: float | None,\n2426:    floor_vol: float | None = None,\n2430:    custom_weights: dict[str, float] | None = None,\n2437:    weighting_scheme: str | None = None,\n2439:    missing_policy: str | Mapping[str, str] | None = None,\n2440:    missing_limit: int | Mapping[str, int | None] | None = None,\n2441:    risk_window: Mapping[str, Any] | None = None,\n2443:    previous_weights: Mapping[str, float] | None = None,\n2448:    weight_policy: Mapping[str, Any] | None = None,\n2449:    risk_free_column: str | None = None,\n2450:    allow_risk_free_fallback: bool | None = None,\n2451:    weight_engine_params: Mapping[str, Any] | None = None,\n2461:        target_vol,\n2463:        floor_vol=floor_vol,\n2467:        custom_weights=custom_weights,\n2474:        weighting_scheme=weighting_scheme,\n2476:        missing_policy=missing_policy,\n2477:        missing_limit=missing_limit,\n2478:        risk_window=risk_window,\n2480:        previous_weights=previous_weights,\n2485:        weight_policy=weight_policy,\n2486:        risk_free_column=risk_free_column,\n2487:        allow_risk_free_fallback=allow_risk_free_fallback,\n2488:        weight_engine_params=weight_engine_params,\n2518:    target_vol: float | None,\n2521:    floor_vol: float | None = None,\n2525:    custom_weights: dict[str, float] | None = None,\n2532:    weighting_scheme: str | None = None,\n2534:    missing_policy: str | Mapping[str, str] | None = None,\n2535:    missing_limit: int | Mapping[str, int | None] | None = None,\n2536:    risk_window: Mapping[str, Any] | None = None,\n2538:    previous_weights: Mapping[str, float] | None = None,\n2543:    calendar_frequency: str | None = None,\n2546:    weight_policy: Mapping[str, Any] | None = None,\n2547:    risk_free_column: str | None = None,\n2548:    allow_risk_free_fallback: bool | None = None,\n2549:    weight_engine_params: Mapping[str, Any] | None = None,\n2554:        for value in (calendar_frequency, calendar_timezone, holiday_calendar)\n2558:        if calendar_frequency is not None:\n2559:            calendar_settings[\"frequency\"] = calendar_frequency\n2571:        target_vol,\n2573:        floor_vol=floor_vol,\n2577:        custom_weights=custom_weights,\n2584:        weighting_scheme=weighting_scheme,\n2586:        missing_policy=missing_policy,\n2587:        missing_limit=missing_limit,\n2588:        risk_window=risk_window,\n2590:        previous_weights=previous_weights,\n2595:        weight_policy=weight_policy,\n2596:        risk_free_column=risk_free_column,\n2597:        allow_risk_free_fallback=allow_risk_free_fallback,\n2598:        weight_engine_params=weight_engine_params,\n2603:    preprocessing_section = _cfg_section(cfg, \"preprocessing\")\n2605:    data_frequency = _section_get(data_settings, \"frequency\")\n2607:    holiday_calendar = _section_get(preprocessing_section, \"holiday_calendar\")\n2609:        \"frequency\": data_frequency,\n2618:    preprocessing_section = _cfg_section(cfg, \"preprocessing\")\n2624:    missing_policy_cfg = _section_get(data_settings, \"missing_policy\")\n2625:    if missing_policy_cfg is None:\n2626:        missing_policy_cfg = _section_get(data_settings, \"nan_policy\")\n2627:    missing_limit_cfg = _section_get(data_settings, \"missing_limit\")\n2628:    if missing_limit_cfg is None:\n2629:        missing_limit_cfg = _section_get(data_settings, \"nan_limit\")\n2634:        missing_policy=missing_policy_cfg,\n2635:        missing_limit=missing_limit_cfg,\n2643:    metrics_section = _cfg_section(cfg, \"metrics\")\n2644:    metrics_list = _section_get(metrics_section, \"registry\")\n2646:    if metrics_list:\n2647:        from .core.rank_selection import RiskStatsConfig, canonical_metric_list\n2650:            metrics_to_run=canonical_metric_list(metrics_list),\n2651:            risk_free=0.0,\n2654:    missing_section = _section_get(preprocessing_section, \"missing_data\")\n2655:    if not isinstance(missing_section, Mapping):\n2656:        missing_section = None\n2658:        missing_section if isinstance(missing_section, Mapping) else None\n2661:    vol_adjust = _cfg_section(cfg, \"vol_adjust\")\n2663:    portfolio_cfg = _cfg_section(cfg, \"portfolio\")\n2664:    weighting_scheme = _section_get(portfolio_cfg, \"weighting_scheme\", \"equal\")\n2665:    robustness_cfg = _section_get(portfolio_cfg, \"robustness\")\n2668:    weight_engine_params = weight_engine_params_from_robustness(\n2669:        weighting_scheme, robustness_cfg\n2671:    trend_spec = _build_trend_spec(cfg, vol_adjust)\n2672:    lambda_tc_val = _section_get(portfolio_cfg, \"lambda_tc\", 0.0)\n2673:    risk_free_column = _section_get(data_settings, \"risk_free_column\")\n2674:    allow_risk_free_fallback = _section_get(data_settings, \"allow_risk_free_fallback\")\n2682:        _resolve_target_vol(vol_adjust),\n2684:        floor_vol=_section_get(vol_adjust, \"floor_vol\"),\n2685:        warmup_periods=int(_section_get(vol_adjust, \"warmup_periods\", 0) or 0),\n2686:        selection_mode=_section_get(portfolio_cfg, \"selection_mode\", \"all\"),\n2687:        random_n=_section_get(portfolio_cfg, \"random_n\", 8),\n2688:        custom_weights=_section_get(portfolio_cfg, \"custom_weights\"),\n2689:        rank_kwargs=_section_get(portfolio_cfg, \"rank\"),\n2690:        manual_funds=_section_get(portfolio_cfg, \"manual_list\"),\n2691:        indices_list=_section_get(portfolio_cfg, \"indices_list\"),\n2694:        weighting_scheme=weighting_scheme,\n2695:        constraints=_section_get(portfolio_cfg, \"constraints\"),\n2697:        missing_policy=policy_spec,\n2698:        missing_limit=limit_spec,\n2699:        risk_window=_section_get(vol_adjust, \"window\"),\n2700:        previous_weights=_section_get(portfolio_cfg, \"previous_weights\"),\n2702:        max_turnover=_section_get(portfolio_cfg, \"max_turnover\"),\n2705:        weight_policy=_section_get(portfolio_cfg, \"weight_policy\"),\n2706:        risk_free_column=risk_free_column,\n2707:        allow_risk_free_fallback=allow_risk_free_fallback,\n2708:        weight_engine_params=weight_engine_params,\n2734:                if k not in {\"equal_weight\", \"user_weight\"}\n2745:    preprocessing_section = _cfg_section(cfg, \"preprocessing\")\n2751:    missing_policy_cfg = _section_get(data_settings, \"missing_policy\")\n2752:    if missing_policy_cfg is None:\n2753:        missing_policy_cfg = _section_get(data_settings, \"nan_policy\")\n2754:    missing_limit_cfg = _section_get(data_settings, \"missing_limit\")\n2755:    if missing_limit_cfg is None:\n2756:        missing_limit_cfg = _section_get(data_settings, \"nan_limit\")\n2761:        missing_policy=missing_policy_cfg,\n2762:        missing_limit=missing_limit_cfg,\n2770:    metrics_section = _cfg_section(cfg, \"metrics\")\n2771:    metrics_list = _section_get(metrics_section, \"registry\")\n2773:    if metrics_list:\n2774:        from .core.rank_selection import RiskStatsConfig, canonical_metric_list\n2777:            metrics_to_run=canonical_metric_list(metrics_list),\n2778:            risk_free=0.0,\n2781:    missing_section = _section_get(preprocessing_section, \"missing_data\")\n2782:    if not isinstance(missing_section, Mapping):\n2783:        missing_section = None\n2785:        missing_section if isinstance(missing_section, Mapping) else None\n2788:    vol_adjust = _cfg_section(cfg, \"vol_adjust\")\n2790:    portfolio_cfg = _cfg_section(cfg, \"portfolio\")\n2791:    weighting_scheme = _section_get(portfolio_cfg, \"weighting_scheme\", \"equal\")\n2792:    robustness_cfg = _section_get(portfolio_cfg, \"robustness\")\n2795:    weight_engine_params = weight_engine_params_from_robustness(\n2796:        weighting_scheme, robustness_cfg\n2798:    risk_free_column = _section_get(data_settings, \"risk_free_column\")\n2799:    trend_spec = _build_trend_spec(cfg, vol_adjust)\n2800:    lambda_tc_val = _section_get(portfolio_cfg, \"lambda_tc\", 0.0)\n2801:    risk_free_column = _section_get(data_settings, \"risk_free_column\")\n2802:    allow_risk_free_fallback = _section_get(data_settings, \"allow_risk_free_fallback\")\n2810:        _resolve_target_vol(vol_adjust),\n2812:        floor_vol=_section_get(vol_adjust, \"floor_vol\"),\n2813:        warmup_periods=int(_section_get(vol_adjust, \"warmup_periods\", 0) or 0),\n2814:        selection_mode=_section_get(portfolio_cfg, \"selection_mode\", \"all\"),\n2815:        random_n=_section_get(portfolio_cfg, \"random_n\", 8),\n2816:        custom_weights=_section_get(portfolio_cfg, \"custom_weights\"),\n2817:        rank_kwargs=_section_get(portfolio_cfg, \"rank\"),\n2818:        manual_funds=_section_get(portfolio_cfg, \"manual_list\"),\n2819:        indices_list=_section_get(portfolio_cfg, \"indices_list\"),\n2822:        weighting_scheme=weighting_scheme,\n2823:        constraints=_section_get(portfolio_cfg, \"constraints\"),\n2825:        missing_policy=policy_spec,\n2826:        missing_limit=limit_spec,\n2827:        risk_window=_section_get(vol_adjust, \"window\"),\n2828:        previous_weights=_section_get(portfolio_cfg, \"previous_weights\"),\n2830:        max_turnover=_section_get(portfolio_cfg, \"max_turnover\"),\n2833:        weight_policy=_section_get(portfolio_cfg, \"weight_policy\"),\n2834:        risk_free_column=risk_free_column,\n2835:        allow_risk_free_fallback=allow_risk_free_fallback,\n2836:        weight_engine_params=weight_engine_params,\n2987:    \"calc_portfolio_returns\",\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_10","type":"reasoning","text":"**Inspecting pipeline and planning stages package**"}}
{"type":"item.started","item":{"id":"item_11","type":"command_execution","command":"/bin/bash -lc 'ls src/trend_analysis'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_11","type":"command_execution","command":"/bin/bash -lc 'ls src/trend_analysis'","aggregated_output":"__init__.py\n_autofix_probe.py\n_autofix_trigger_sample.py\n_autofix_violation_case2.py\n_autofix_violation_case3.py\n_ci_probe_faults.py\n_typing.py\napi.py\napi_server\nautomation_multifailure.py\nbacktesting\ncash_policy.py\ncli.py\nconfig\nconstants.py\ncore\ndata.py\ndiagnostics.py\nengine\nexport\ngui\nio\nlogging.py\nlogging_setup.py\nmetrics\nmulti_period\nperf\npipeline.py\nplugins\nportfolio\npresets.py\nproxy\nrebalancing\nrebalancing.py\nregimes.py\nreporting\nrisk.py\nrun_analysis.py\nrun_multi_analysis.py\nschedules.py\nscript_logging.py\nselector.py\nsignal_presets.py\nsignals.py\nstubs\ntime_utils.py\ntimefreq.py\ntyping.py\nui\nuniverse.py\nuniverse_catalog.py\nutil\nviz\nwalk_forward.py\nweighting.py\nweights\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_12","type":"reasoning","text":"**Preparing stages folder and inspecting pipeline**"}}
{"type":"item.started","item":{"id":"item_13","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,260p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_13","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,260p' src/trend_analysis/pipeline.py\"","aggregated_output":"from __future__ import annotations\n\nimport logging\nimport math\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Any, Mapping, cast\n\nimport numpy as np\nimport pandas as pd\nfrom numpy.typing import NDArray\n\nfrom analysis.results import build_metadata\nfrom trend.diagnostics import DiagnosticResult\n\nfrom .core.rank_selection import (\n    RiskStatsConfig,\n    get_window_metric_bundle,\n    make_window_key,\n    rank_select_funds,\n)\nfrom .data import identify_risk_free_fund, load_csv\nfrom .diagnostics import (\n    AnalysisResult,\n    PipelineReasonCode,\n    PipelineResult,\n    pipeline_failure,\n    pipeline_success,\n)\nfrom .metrics import (\n    annual_return,\n    information_ratio,\n    max_drawdown,\n    sharpe_ratio,\n    sortino_ratio,\n    volatility,\n)\nfrom .perf.rolling_cache import compute_dataset_hash, get_cache  # noqa: F401\nfrom .portfolio import apply_weight_policy\nfrom .regimes import build_regime_payload, compute_regimes, normalise_settings\nfrom .risk import (\n    RiskDiagnostics,\n    RiskWindow,\n    compute_constrained_weights,\n    periods_per_year_from_code,\n    realised_volatility,\n)\nfrom .signals import TrendSpec, compute_trend_signals\nfrom .time_utils import align_calendar\nfrom .timefreq import MONTHLY_DATE_FREQ\nfrom .util.frequency import FrequencySummary, detect_frequency\nfrom .util.missing import MissingPolicyResult, apply_missing_policy\nfrom .weights.robust_config import weight_engine_params_from_robustness\n\nlogger = logging.getLogger(__name__)\n\n# Require a minimum share of coverage within the requested windows before a\n# column is eligible for risk-free fallback selection. This prevents sparse\n# series from being chosen and later propagating NaNs when aligned to the\n# analysis windows.\n_MIN_FALLBACK_COVERAGE_RATIO = 0.6\n\nif TYPE_CHECKING:  # pragma: no cover - for static type checking only\n    from .config.models import ConfigProtocol as Config\n\ndel TYPE_CHECKING\n\n\n@dataclass\nclass _Stats:\n    \"\"\"Container for performance metrics.\n\n    AvgCorr fields are optional and only populated when the user explicitly\n    requests the ``AvgCorr`` metric (Issue #1160). They remain ``None`` to\n    preserve backward compatibility and avoid altering column order when the\n    feature is not in use.\n    \"\"\"\n\n    cagr: float\n    vol: float\n    sharpe: float\n    sortino: float\n    max_drawdown: float\n    information_ratio: float\n    is_avg_corr: float | None = None\n    os_avg_corr: float | None = None\n\n    def __eq__(self, other: object) -> bool:  # pragma: no cover - exercised via tests\n        if not isinstance(other, _Stats):\n            return NotImplemented\n\n        def _equal(a: float | None, b: float | None) -> bool:\n            if a is None or b is None:\n                return a is b\n            if a == b:\n                return True\n            return math.isnan(a) and math.isnan(b)\n\n        return (\n            _equal(self.cagr, other.cagr)\n            and _equal(self.vol, other.vol)\n            and _equal(self.sharpe, other.sharpe)\n            and _equal(self.sortino, other.sortino)\n            and _equal(self.max_drawdown, other.max_drawdown)\n            and _equal(self.information_ratio, other.information_ratio)\n            and _equal(self.is_avg_corr, other.is_avg_corr)\n            and _equal(self.os_avg_corr, other.os_avg_corr)\n        )\n\n\ndef _frequency_label(code: str) -> str:\n    return {\"D\": \"Daily\", \"W\": \"Weekly\", \"M\": \"Monthly\"}.get(code, code)\n\n\ndef _preprocessing_summary(\n    freq_code: str, *, normalised: bool, missing_summary: str | None\n) -> str:\n    cadence = _frequency_label(freq_code)\n    cadence_text = f\"Cadence: {cadence}\"\n    if normalised and freq_code != \"M\":\n        cadence_text += \" â†’ monthly\"\n    elif freq_code == \"M\":\n        cadence_text += \" (month-end)\"\n    parts = [cadence_text]\n    if missing_summary:\n        parts.append(f\"Missing data: {missing_summary}\")\n    return \"; \".join(parts)\n\n\n@dataclass(slots=True)\nclass _PreprocessStage:\n    df: pd.DataFrame\n    date_col: str\n    freq_summary: FrequencySummary\n    missing_result: MissingPolicyResult\n    preprocess_info: dict[str, object]\n    frequency_payload: dict[str, object]\n    missing_payload: Mapping[str, object]\n    alignment_info: Mapping[str, Any]\n    min_floor: float\n    warmup: int\n    value_cols_all: list[str]\n    df_original: pd.DataFrame\n    periods_per_year: float\n\n\n@dataclass(slots=True)\nclass _WindowStage:\n    in_df: pd.DataFrame\n    out_df: pd.DataFrame\n    in_start: pd.Timestamp\n    in_end: pd.Timestamp\n    out_start: pd.Timestamp\n    out_end: pd.Timestamp\n    periods_per_year: float\n    date_col: str\n\n\n@dataclass(slots=True)\nclass _SelectionStage:\n    fund_cols: list[str]\n    rf_col: str\n    rf_source: str\n    score_frame: pd.DataFrame\n    risk_free_override: pd.Series\n    indices_list: list[str]\n    requested_indices: list[str]\n    missing_indices: list[str]\n\n\n@dataclass(slots=True)\nclass _ComputationStage:\n    weights_series: pd.Series\n    risk_diagnostics: RiskDiagnostics\n    weight_engine_fallback: dict[str, Any] | None\n    weight_engine_diagnostics: dict[str, Any] | None\n    turnover_cap: float | None\n    in_scaled: pd.DataFrame\n    out_scaled: pd.DataFrame\n    rf_in: pd.Series\n    rf_out: pd.Series\n    in_stats: dict[str, _Stats]\n    out_stats: dict[str, _Stats]\n    out_stats_raw: dict[str, _Stats]\n    in_ew_stats: _Stats\n    out_ew_stats: _Stats\n    out_ew_stats_raw: _Stats\n    in_user_stats: _Stats\n    out_user_stats: _Stats\n    out_user_stats_raw: _Stats\n    ew_weights: dict[str, float]\n    user_weights: dict[str, float]\n    score_frame: pd.DataFrame\n    weight_policy: dict[str, Any]\n    signal_frame: pd.DataFrame\n    effective_signal_spec: TrendSpec\n\n\ndef _prepare_preprocess_stage(\n    df: pd.DataFrame | None,\n    *,\n    floor_vol: float | None,\n    warmup_periods: int,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    stats_cfg: RiskStatsConfig | None,\n    periods_per_year_override: float | None,\n    allow_risk_free_fallback: bool | None,\n) -> _PreprocessStage | PipelineResult:\n    if df is None:\n        return pipeline_failure(PipelineReasonCode.INPUT_NONE)\n\n    attrs_copy = dict(getattr(df, \"attrs\", {}))\n    if type(df) is not pd.DataFrame:  # noqa: E721 - intentional exact type check\n        df = pd.DataFrame(df)\n    if attrs_copy:\n        df.attrs = attrs_copy\n\n    date_col = \"Date\"\n    if date_col not in df.columns:\n        raise ValueError(\"DataFrame must contain a 'Date' column\")\n\n    calendar_settings = attrs_copy.get(\"calendar_settings\", {})\n\n    date_probe = pd.to_datetime(df[date_col], errors=\"coerce\")\n    if not date_probe.notna().any():\n        return pipeline_failure(\n            PipelineReasonCode.NO_VALID_DATES,\n            context={\"date_column\": date_col},\n        )\n\n    try:\n        df = align_calendar(\n            df,\n            date_col=date_col,\n            frequency=calendar_settings.get(\"frequency\"),\n            timezone=calendar_settings.get(\"timezone\", \"UTC\"),\n            holiday_calendar=calendar_settings.get(\"holiday_calendar\"),\n        )\n    except ValueError as exc:\n        message = str(exc)\n        if (\n            \"contains no valid timestamps\" in message\n            or \"All rows were removed\" in message\n        ):\n            return pipeline_failure(\n                PipelineReasonCode.CALENDAR_ALIGNMENT_WIPE,\n                context={\"error\": message},\n            )\n        raise\n    alignment_info = df.attrs.get(\"calendar_alignment\", {})\n\n    try:\n        min_floor = float(floor_vol) if floor_vol is not None else 0.0\n    except (TypeError, ValueError):  # pragma: no cover - defensive\n        min_floor = 0.0\n    if min_floor < 0:\n        min_floor = 0.0\n    try:\n        warmup = int(warmup_periods)\n    except (TypeError, ValueError):  # pragma: no cover - defensive\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_14","type":"reasoning","text":"**Continuing to examine input functions**"}}
{"type":"item.started","item":{"id":"item_15","type":"command_execution","command":"/bin/bash -lc \"sed -n '260,620p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_15","type":"command_execution","command":"/bin/bash -lc \"sed -n '260,620p' src/trend_analysis/pipeline.py\"","aggregated_output":"    except (TypeError, ValueError):  # pragma: no cover - defensive\n        warmup = 0\n    if warmup < 0:\n        warmup = 0\n\n    na_cfg = getattr(stats_cfg, \"na_as_zero_cfg\", None) if stats_cfg else None\n    enforce_complete = not (na_cfg and bool(na_cfg.get(\"enabled\", False)))\n    if allow_risk_free_fallback:\n        enforce_complete = False\n\n    df_prepared, freq_summary, missing_result, normalised = _prepare_input_data(\n        df,\n        date_col=date_col,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        enforce_completeness=enforce_complete,\n    )\n    if df_prepared.empty:\n        return pipeline_failure(\n            PipelineReasonCode.PREPARED_FRAME_EMPTY,\n            context={\n                \"missing_summary\": getattr(missing_result, \"summary\", None),\n                \"dropped_assets\": list(getattr(missing_result, \"dropped_assets\", ())),\n            },\n        )\n    initial_value_cols = [c for c in df_prepared.columns if c != date_col]\n    df_original = df_prepared.copy()\n    prepared_attrs = dict(getattr(df_prepared, \"attrs\", {}))\n    value_cols_all = [c for c in df_prepared.columns if c != date_col]\n\n    if not initial_value_cols or not value_cols_all:\n        reason = (\n            PipelineReasonCode.NO_VALUE_COLUMNS\n            if not initial_value_cols\n            else PipelineReasonCode.INSUFFICIENT_COLUMNS\n        )\n        return pipeline_failure(\n            reason,\n            context={\n                \"stage\": \"post-prep-column-check\",\n                \"initial_value_cols\": len(initial_value_cols),\n                \"post_probe_value_cols\": len(value_cols_all),\n            },\n        )\n\n    if not isinstance(df_original, pd.DataFrame):\n        df = pd.DataFrame(df_original)\n    else:\n        df = df_original\n    if prepared_attrs:\n        df.attrs = prepared_attrs\n\n    if df.empty or df.shape[1] <= 1:\n        return pipeline_failure(\n            PipelineReasonCode.INSUFFICIENT_COLUMNS,\n            context={\"columns\": df.shape[1], \"rows\": df.shape[0]},\n        )\n\n    frequency_payload = {\n        \"code\": freq_summary.code,\n        \"label\": freq_summary.label,\n        \"target\": freq_summary.target,\n        \"target_label\": freq_summary.target_label,\n        \"resampled\": freq_summary.resampled,\n    }\n    periods_per_year = periods_per_year_override or periods_per_year_from_code(\n        freq_summary.target\n    )\n    missing_payload = {\n        \"policy\": missing_result.default_policy,\n        \"policy_map\": missing_result.policy,\n        \"limit\": missing_result.default_limit,\n        \"limit_map\": missing_result.limit,\n        \"dropped_assets\": list(missing_result.dropped_assets),\n        \"filled_assets\": {asset: count for asset, count in missing_result.filled_cells},\n        \"total_filled\": missing_result.total_filled,\n    }\n\n    preprocess_info = {\n        \"input_frequency\": frequency_payload[\"code\"],\n        \"input_frequency_details\": frequency_payload,\n        \"resampled_to_monthly\": normalised,\n        \"missing\": missing_result,\n        \"missing_data_policy\": missing_payload,\n    }\n    preprocess_info[\"summary\"] = _preprocessing_summary(\n        freq_summary.code,\n        normalised=normalised,\n        missing_summary=missing_result.summary,\n    )\n    preprocess_info[\"calendar_alignment\"] = alignment_info\n\n    return _PreprocessStage(\n        df=df,\n        date_col=date_col,\n        freq_summary=freq_summary,\n        missing_result=missing_result,\n        preprocess_info=preprocess_info,\n        frequency_payload=frequency_payload,\n        missing_payload=missing_payload,\n        alignment_info=alignment_info,\n        min_floor=min_floor,\n        warmup=warmup,\n        value_cols_all=value_cols_all,\n        df_original=df_original,\n        periods_per_year=periods_per_year,\n    )\n\n\ndef _build_sample_windows(\n    preprocess: _PreprocessStage,\n    *,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n) -> _WindowStage | PipelineResult:\n    def _month_end(ts: pd.Timestamp) -> pd.Timestamp:\n        # Align arbitrary timestamps to month-end while preserving timezone.\n        return ts + pd.offsets.MonthEnd(0)\n\n    def _window_month_ends(start: pd.Timestamp, end: pd.Timestamp) -> pd.DatetimeIndex:\n        # Build an inclusive month-end index for the window.\n        start_me = _month_end(pd.Timestamp(start))\n        end_me = _month_end(pd.Timestamp(end))\n        if start_me > end_me:\n            return pd.DatetimeIndex([], name=preprocess.date_col)\n        return pd.date_range(start=start_me, end=end_me, freq=MONTHLY_DATE_FREQ)\n\n    def _fill_missing_months(\n        frame: pd.DataFrame,\n        *,\n        start: pd.Timestamp,\n        end: pd.Timestamp,\n        allow_empty_reindex: bool,\n    ) -> pd.DataFrame:\n        \"\"\"Ensure the frame contains every month-end between start and end.\n\n        Even after monthly resampling, certain upstream operations (e.g., strict\n        completeness enforcement) can remove entire month rows. When the\n        configured missing-data policy is not \"drop\", we want windows to retain\n        a contiguous monthly index so both in-sample and out-of-sample blocks\n        line up with the requested calendar.\n        \"\"\"\n\n        expected = _window_month_ends(start, end)\n        if expected.empty:\n            return frame\n        if frame.empty:\n            # Only reindex an empty slice when the caller explicitly allows it.\n            # This is used when one side of the sample split has data and we\n            # want to preserve calendar alignment for downstream diagnostics.\n            return frame.reindex(expected) if allow_empty_reindex else frame\n        if (\n            isinstance(frame.index, pd.DatetimeIndex)\n            and frame.index.tz is not None\n            and expected.tz is None\n        ):\n            # If the data is tz-aware, keep the expected range consistent.\n            expected = expected.tz_localize(frame.index.tz)\n\n        reindexed = frame.reindex(expected)\n\n        policy_default = str(\n            getattr(preprocess.missing_result, \"default_policy\", \"drop\") or \"drop\"\n        ).lower()\n        if policy_default == \"drop\":\n            return reindexed\n\n        # Re-apply missing policy to fill any newly inserted rows.\n        # Use a reconstructed mapping so per-column overrides remain intact.\n        try:\n            policy_map = dict(getattr(preprocess.missing_result, \"policy\", {}) or {})\n            default_policy = str(\n                getattr(preprocess.missing_result, \"default_policy\", \"drop\") or \"drop\"\n            )\n            overrides = {k: v for k, v in policy_map.items() if v != default_policy}\n            policy_spec: dict[str, str] | str = (\n                {\"default\": default_policy, **overrides}\n                if overrides\n                else default_policy\n            )\n\n            limit_map = dict(getattr(preprocess.missing_result, \"limit\", {}) or {})\n            default_limit = getattr(preprocess.missing_result, \"default_limit\", None)\n            limit_overrides = {\n                k: v\n                for k, v in limit_map.items()\n                if v is not None and default_limit is not None and v != default_limit\n            }\n            if default_limit is not None or limit_overrides:\n                limit_spec: dict[str, int | None] | int | None\n                limit_spec = {\"default\": default_limit, **limit_overrides}\n            else:\n                limit_spec = None\n\n            reindexed, _ = apply_missing_policy(\n                reindexed,\n                policy=policy_spec,\n                limit=limit_spec,\n                enforce_completeness=False,\n            )\n        except Exception:  # pragma: no cover - defensive\n            return reindexed\n        return reindexed\n\n    def _is_month_label(label: str) -> bool:\n        text = str(label).strip()\n        return len(text) == 7 and text.count(\"-\") == 1\n\n    def _resolve_bound(label: str, *, bound: str) -> pd.Timestamp:\n        text = str(label).strip()\n        if not text:\n            raise ValueError(\"Period label must be non-empty\")\n        try:\n            if _is_month_label(text):\n                period = pd.Period(text, freq=\"M\")\n                ts = period.start_time if bound == \"start\" else period.end_time\n            else:\n                ts = pd.to_datetime(text)\n        except Exception as exc:  # pragma: no cover - defensive\n            msg = f\"Failed to parse period label '{label}': {exc}\"\n            raise ValueError(msg) from exc\n        return pd.Timestamp(ts).normalize()\n\n    in_sdate = _resolve_bound(in_start, bound=\"start\")\n    in_edate = _resolve_bound(in_end, bound=\"end\")\n    out_sdate = _resolve_bound(out_start, bound=\"start\")\n    out_edate = _resolve_bound(out_end, bound=\"end\")\n\n    date_series = preprocess.df[preprocess.date_col]\n    if pd.DatetimeTZDtype.is_dtype(date_series.dtype):\n        tz = date_series.dt.tz\n        in_sdate = in_sdate.tz_localize(tz)\n        in_edate = in_edate.tz_localize(tz)\n        out_sdate = out_sdate.tz_localize(tz)\n        out_edate = out_edate.tz_localize(tz)\n\n    in_mask = (preprocess.df[preprocess.date_col] >= in_sdate) & (\n        preprocess.df[preprocess.date_col] <= in_edate\n    )\n    out_mask = (preprocess.df[preprocess.date_col] >= out_sdate) & (\n        preprocess.df[preprocess.date_col] <= out_edate\n    )\n    in_df_raw = preprocess.df.loc[in_mask].set_index(preprocess.date_col)\n    out_df_raw = preprocess.df.loc[out_mask].set_index(preprocess.date_col)\n\n    # Ensure monthly continuity inside each window.\n    # If one side of the split is empty but the other has data, allow reindexing\n    # to preserve the expected calendar. If both sides are empty (or the in\n    # window is empty), keep empties so callers receive SAMPLE_WINDOW_EMPTY.\n    allow_in_empty = not out_df_raw.empty\n    allow_out_empty = not in_df_raw.empty\n    in_df = _fill_missing_months(\n        in_df_raw,\n        start=in_sdate,\n        end=in_edate,\n        allow_empty_reindex=allow_in_empty,\n    )\n    out_df = _fill_missing_months(\n        out_df_raw,\n        start=out_sdate,\n        end=out_edate,\n        allow_empty_reindex=allow_out_empty,\n    )\n\n    def _is_effectively_empty(frame: pd.DataFrame) -> bool:\n        if frame.empty:\n            return True\n        # A reindexed-but-empty slice can have rows but no data (all NaNs).\n        # Treat that as an empty window for diagnostics.\n        try:\n            return bool(frame.dropna(how=\"all\").empty)\n        except Exception:  # pragma: no cover - defensive\n            return bool(frame.empty)\n\n    if _is_effectively_empty(in_df) or _is_effectively_empty(out_df):\n        return pipeline_failure(\n            PipelineReasonCode.SAMPLE_WINDOW_EMPTY,\n            context={\n                \"in_rows\": int(in_df.shape[0]),\n                \"out_rows\": int(out_df.shape[0]),\n            },\n        )\n\n    return _WindowStage(\n        in_df=in_df,\n        out_df=out_df,\n        in_start=in_sdate,\n        in_end=in_edate,\n        out_start=out_sdate,\n        out_end=out_edate,\n        periods_per_year=preprocess.periods_per_year,\n        date_col=preprocess.date_col,\n    )\n\n\ndef _select_universe(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    *,\n    in_label: str,\n    in_end_label: str,\n    selection_mode: str,\n    random_n: int,\n    custom_weights: dict[str, float] | None,\n    rank_kwargs: Mapping[str, Any] | None,\n    manual_funds: list[str] | None,\n    indices_list: list[str] | None,\n    seed: int,\n    stats_cfg: RiskStatsConfig | None,\n    risk_free_column: str | None,\n    allow_risk_free_fallback: bool | None,\n) -> _SelectionStage | PipelineResult:\n    requested_indices = [str(idx) for idx in indices_list] if indices_list else []\n    valid_indices: list[str] = []\n    missing_indices: list[str] = []\n    if requested_indices:\n        available_cols = set(window.in_df.columns)\n        available_indices = [idx for idx in requested_indices if idx in available_cols]\n        missing_indices = [\n            idx for idx in requested_indices if idx not in available_cols\n        ]\n\n        for idx in available_indices:\n            has_data = window.in_df[idx].notnull().any()\n            if has_data:\n                valid_indices.append(idx)\n            else:\n                missing_indices.append(idx)\n\n        if not valid_indices:\n            return pipeline_failure(\n                PipelineReasonCode.INDICES_ABSENT,\n                context={\n                    \"requested_indices\": requested_indices,\n                    \"missing_indices\": missing_indices,\n                    \"available_columns\": sorted(available_cols),\n                },\n            )\n    indices_list = valid_indices\n\n    rf_col: str\n    fund_cols: list[str]\n    rf_source: str\n    fallback_window = pd.concat(\n        [window.in_df.reset_index(), window.out_df.reset_index()],\n        ignore_index=True,\n    )\n    if (\n        preprocess.date_col not in fallback_window.columns\n        and \"index\" in fallback_window.columns\n    ):\n        fallback_window = fallback_window.rename(columns={\"index\": preprocess.date_col})\n    rf_col, fund_cols, rf_source = _resolve_risk_free_column(\n        preprocess.df,\n        date_col=preprocess.date_col,\n        indices_list=indices_list,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        fallback_window=fallback_window,\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_16","type":"reasoning","text":"**Continuing to review selections**"}}
{"type":"item.started","item":{"id":"item_17","type":"command_execution","command":"/bin/bash -lc \"sed -n '620,1300p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_17","type":"command_execution","command":"/bin/bash -lc \"sed -n '620,1300p' src/trend_analysis/pipeline.py\"","aggregated_output":"        fallback_window=fallback_window,\n    )\n\n    if selection_mode == \"all\" and custom_weights is not None:\n        fund_cols = [c for c in fund_cols if c in custom_weights]\n        if not fund_cols and custom_weights:\n            fund_cols = list(custom_weights.keys())\n        else:\n            custom_weights = None\n\n    # keep only funds that satisfy missing-data policy in both windows. The\n    # default behaviour enforces strict completeness, while ``na_as_zero`` can\n    # provide tolerances for total and consecutive gaps (Issue #3633).\n    def _max_consecutive_nans(series: pd.Series) -> int:\n        if not series.isna().any():\n            return 0\n        is_na = series.isna().astype(int)\n        groups = (is_na != is_na.shift()).cumsum()\n        runs = is_na.groupby(groups).cumsum() * is_na\n        return int(runs.max()) if not runs.empty else 0\n\n    na_cfg = getattr(stats_cfg, \"na_as_zero_cfg\", None) if stats_cfg else None\n    if na_cfg and bool(na_cfg.get(\"enabled\", False)):\n        max_missing = int(na_cfg.get(\"max_missing_per_window\", 0) or 0)\n        max_gap = int(na_cfg.get(\"max_consecutive_gap\", 0) or 0)\n\n        def _window_ok(window_df: pd.DataFrame, column: str) -> bool:\n            series = window_df[column]\n            missing = int(series.isna().sum())\n            if missing == 0:\n                return True\n            if missing > max_missing:\n                return False\n            if max_gap <= 0:\n                return True\n            return _max_consecutive_nans(series) <= max_gap\n\n        fund_cols = [\n            col\n            for col in fund_cols\n            if _window_ok(window.in_df, col) and _window_ok(window.out_df, col)\n        ]\n    else:\n        in_ok = ~window.in_df[fund_cols].isna().any()\n        out_ok = ~window.out_df[fund_cols].isna().any()\n        fund_cols = [c for c in fund_cols if in_ok[c] and out_ok[c]]\n\n    if stats_cfg is None:\n        stats_cfg = RiskStatsConfig(risk_free=0.0)\n\n    risk_free_override = window.in_df[rf_col]\n\n    if selection_mode == \"random\" and len(fund_cols) > random_n:\n        rng = np.random.default_rng(seed)\n        fund_cols = rng.choice(fund_cols, size=random_n, replace=False).tolist()\n    elif selection_mode == \"rank\":\n        mask = (preprocess.df[preprocess.date_col] >= window.in_start) & (\n            preprocess.df[preprocess.date_col] <= window.in_end\n        )\n        sub = preprocess.df.loc[mask, fund_cols]\n        window_key = None\n        bundle = None\n        if stats_cfg is not None and fund_cols:\n            try:\n                window_key = make_window_key(\n                    window.in_start, window.in_end, sub.columns, stats_cfg\n                )\n            except Exception:  # pragma: no cover - defensive\n                window_key = None\n        if window_key is not None:\n            bundle = get_window_metric_bundle(window_key)\n        rank_options: dict[str, Any] = dict(rank_kwargs or {})\n        rank_options.setdefault(\"window_key\", window_key)\n        rank_options.setdefault(\"bundle\", bundle)\n        rank_result = rank_select_funds(\n            sub,\n            stats_cfg,\n            **rank_options,\n            risk_free=risk_free_override,\n        )\n        if isinstance(rank_result, tuple):\n            fund_cols = rank_result[0]\n        else:\n            fund_cols = rank_result\n    elif selection_mode == \"manual\":\n        if manual_funds:  # pragma: no cover - rarely hit\n            fund_cols = [c for c in fund_cols if c in manual_funds]\n        else:\n            fund_cols = []  # pragma: no cover\n\n    if not fund_cols:\n        return pipeline_failure(\n            PipelineReasonCode.NO_FUNDS_SELECTED,\n            context={\n                \"selection_mode\": selection_mode,\n                \"universe_size\": len(preprocess.value_cols_all),\n            },\n        )\n\n    score_frame = single_period_run(\n        preprocess.df[[preprocess.date_col] + fund_cols],\n        in_label,\n        in_end_label,\n        stats_cfg=stats_cfg,\n        risk_free=risk_free_override,\n    )\n\n    return _SelectionStage(\n        fund_cols=fund_cols,\n        rf_col=rf_col,\n        rf_source=rf_source,\n        score_frame=score_frame,\n        risk_free_override=risk_free_override,\n        indices_list=valid_indices,\n        requested_indices=requested_indices,\n        missing_indices=missing_indices,\n    )\n\n\ndef _compute_weights_and_stats(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    selection: _SelectionStage,\n    *,\n    target_vol: float | None,\n    monthly_cost: float,\n    custom_weights: dict[str, float] | None,\n    weighting_scheme: str | None,\n    constraints: Mapping[str, Any] | None,\n    risk_window: Mapping[str, Any] | None,\n    previous_weights: Mapping[str, float] | None,\n    lambda_tc: float | None,\n    max_turnover: float | None,\n    signal_spec: TrendSpec | None,\n    weight_policy: Mapping[str, Any] | None,\n    warmup: int,\n    min_floor: float,\n    stats_cfg: RiskStatsConfig,\n    weight_engine_params: Mapping[str, Any] | None,\n) -> _ComputationStage:\n    fund_cols = selection.fund_cols\n\n    def _enforce_window_bounds(\n        frame: pd.DataFrame,\n        label: str,\n        allowed_start: pd.Timestamp,\n        allowed_end: pd.Timestamp,\n    ) -> None:\n        if frame.empty:\n            return\n        idx = frame.index\n        outside_mask = (idx < allowed_start) | (idx > allowed_end)\n        if bool(outside_mask.any()):\n            oob_index = idx[outside_mask]\n            first = pd.Timestamp(oob_index.min())\n            last = pd.Timestamp(oob_index.max())\n            msg = (\n                f\"{label} contain dates outside the active analysis window: \"\n                f\"[{first} â†’ {last}] not within [{allowed_start} â†’ {allowed_end}]\"\n            )\n            raise ValueError(msg)\n\n    _enforce_window_bounds(\n        window.in_df,\n        label=\"In-sample returns\",\n        allowed_start=window.in_start,\n        allowed_end=window.in_end,\n    )\n    _enforce_window_bounds(\n        window.out_df,\n        label=\"Out-of-sample returns\",\n        allowed_start=window.out_start,\n        allowed_end=window.out_end,\n    )\n\n    def _scoped_signal_inputs() -> pd.DataFrame:\n        if not fund_cols:\n            return pd.DataFrame(dtype=float)\n\n        allowed_start = window.in_start\n        allowed_end = window.out_end\n\n        def _filter_window(frame: pd.DataFrame, *, strict: bool) -> pd.DataFrame:\n            outside_mask = (frame.index < allowed_start) | (frame.index > allowed_end)\n            if strict and bool(outside_mask.any()):\n                first = pd.Timestamp(frame.index[outside_mask].min())\n                last = pd.Timestamp(frame.index[outside_mask].max())\n                msg = (\n                    \"Signal inputs contain dates outside the active analysis window: \"\n                    f\"[{first} â†’ {last}] not within [{allowed_start} â†’ {allowed_end}]\"\n                )\n                raise ValueError(msg)\n\n            scoped = frame.loc[\n                (frame.index >= allowed_start) & (frame.index <= allowed_end)\n            ]\n            scoped = scoped.loc[:, ~scoped.columns.duplicated()]\n            scoped = scoped.reindex(columns=fund_cols)\n            return scoped.astype(float)\n\n        signal_source: pd.DataFrame | None = None\n        strict_enforcement = True\n        try:\n            scoped_cols = [preprocess.date_col, *fund_cols]\n            # Copy before ``set_index`` so DataFrame subclasses (see\n            # ``tests.test_pipeline_helpers_additional.SignalFrame``) can signal\n            # that no usable signal data are available.\n            subset = preprocess.df[scoped_cols].copy()\n            signal_source = subset.set_index(preprocess.date_col)\n            strict_enforcement = False\n        except Exception:\n            signal_source = None\n\n        if signal_source is None:\n            signal_source = (\n                pd.concat([window.in_df, window.out_df])\n                .sort_index()\n                .reindex(columns=fund_cols)\n            )\n\n        return _filter_window(signal_source, strict=strict_enforcement)\n\n    custom_weights_input = custom_weights is not None\n    weight_engine_used = False\n    weight_engine_fallback: dict[str, Any] | None = None\n    weight_engine_diagnostics: dict[str, Any] | None = None\n    if (\n        custom_weights is None\n        and weighting_scheme\n        and weighting_scheme.lower() != \"equal\"\n    ):\n        try:\n            from .plugins import create_weight_engine\n\n            cov = window.in_df[fund_cols].cov()\n            engine = create_weight_engine(\n                weighting_scheme.lower(), **(weight_engine_params or {})\n            )\n            w_series = engine.weight(cov).reindex(fund_cols).fillna(0.0)\n            custom_weights = {c: float(w_series.get(c, 0.0) * 100.0) for c in fund_cols}\n            weight_engine_used = True\n            weight_engine_diagnostics = getattr(engine, \"diagnostics\", None)\n            if (\n                weight_engine_diagnostics\n                and isinstance(weight_engine_diagnostics, Mapping)\n                and weight_engine_diagnostics.get(\"used_safe_mode\")\n            ):\n                safe_mode = weight_engine_diagnostics.get(\"safe_mode\")\n                condition_number = weight_engine_diagnostics.get(\"condition_number\")\n                condition_threshold = weight_engine_diagnostics.get(\n                    \"condition_threshold\"\n                )\n                condition_source = weight_engine_diagnostics.get(\"condition_source\")\n                raw_condition_number = weight_engine_diagnostics.get(\n                    \"raw_condition_number\"\n                )\n                shrunk_condition_number = weight_engine_diagnostics.get(\n                    \"shrunk_condition_number\"\n                )\n                shrinkage_info = weight_engine_diagnostics.get(\"shrinkage\")\n                fallback_reason = weight_engine_diagnostics.get(\n                    \"fallback_reason\", \"safe_mode\"\n                )\n                weight_engine_fallback = {\n                    \"engine\": str(weighting_scheme),\n                    \"reason\": str(fallback_reason),\n                    \"safe_mode\": safe_mode,\n                    \"condition_number\": condition_number,\n                    \"condition_threshold\": condition_threshold,\n                    \"condition_source\": condition_source,\n                }\n                if raw_condition_number is not None:\n                    weight_engine_fallback[\"raw_condition_number\"] = (\n                        raw_condition_number\n                    )\n                if shrunk_condition_number is not None:\n                    weight_engine_fallback[\"shrunk_condition_number\"] = (\n                        shrunk_condition_number\n                    )\n                if isinstance(shrinkage_info, Mapping):\n                    weight_engine_fallback[\"shrinkage\"] = dict(shrinkage_info)\n                if isinstance(condition_number, (int, float)) and isinstance(\n                    condition_threshold, (int, float)\n                ):\n                    logger.warning(\n                        \"Weight engine '%s' switched to safe mode '%s' \"\n                        \"(%s condition number %.2e > threshold %.2e).\",\n                        weighting_scheme,\n                        safe_mode,\n                        condition_source or \"covariance\",\n                        condition_number,\n                        condition_threshold,\n                    )\n                else:\n                    logger.warning(\n                        \"Weight engine '%s' switched to safe mode '%s'.\",\n                        weighting_scheme,\n                        safe_mode,\n                    )\n            logger.debug(\n                \"Successfully created %s weight engine\",\n                weighting_scheme,\n                extra={\"weight_engine\": weighting_scheme},\n            )\n        except Exception as e:  # pragma: no cover - exercised via tests\n            msg = (\n                \"Weight engine '%s' failed (%s: %s); falling back to equal weights\"\n                % (weighting_scheme, type(e).__name__, e)\n            )\n            logger.warning(msg)\n            logger.debug(\n                \"Weight engine creation failed, falling back to equal weights: %s\", e\n            )\n            weight_engine_fallback = {\n                \"engine\": str(weighting_scheme),\n                \"error_type\": type(e).__name__,\n                \"error\": str(e),\n                \"logger_level\": logging.getLevelName(logger.getEffectiveLevel()),\n            }\n            custom_weights = None\n\n    if custom_weights is None:\n        custom_weights = {c: 100 / len(fund_cols) for c in fund_cols}\n\n    constraints_cfg = constraints or {}\n    if not isinstance(constraints_cfg, Mapping):\n        constraints_cfg = {}\n    long_only = bool(constraints_cfg.get(\"long_only\", True))\n    raw_max_weight = constraints_cfg.get(\"max_weight\")\n    try:\n        max_weight_val = float(raw_max_weight) if raw_max_weight is not None else None\n    except (TypeError, ValueError):\n        max_weight_val = None\n    raw_max_active = constraints_cfg.get(\"max_active_positions\")\n    if raw_max_active is None:\n        raw_max_active = constraints_cfg.get(\"max_active\")\n    try:\n        max_active_val = int(raw_max_active) if raw_max_active is not None else None\n    except (TypeError, ValueError):\n        max_active_val = None\n    if max_active_val is not None and max_active_val <= 0:\n        max_active_val = None\n    raw_group_caps = constraints_cfg.get(\"group_caps\")\n    group_caps_map = (\n        {str(k): float(v) for k, v in raw_group_caps.items()}\n        if isinstance(raw_group_caps, Mapping)\n        else None\n    )\n    raw_groups = constraints_cfg.get(\"groups\")\n    groups_map = (\n        {str(k): str(v) for k, v in raw_groups.items()}\n        if isinstance(raw_groups, Mapping)\n        else None\n    )\n\n    base_series = pd.Series(\n        {c: float(custom_weights.get(c, 0.0)) / 100.0 for c in fund_cols},\n        dtype=float,\n    )\n    if float(base_series.sum()) <= 0:\n        base_series = pd.Series(\n            np.repeat(1.0 / len(fund_cols), len(fund_cols)),\n            index=fund_cols,\n            dtype=float,\n        )\n\n    negative_assets = base_series[base_series < 0].index.tolist()\n    if negative_assets:\n        if weight_engine_used:\n            source = f\"weight engine '{weighting_scheme}'\"\n        elif custom_weights_input:\n            source = \"custom weights\"\n        else:\n            source = \"base weights\"\n        action = \"clip negatives to zero\" if long_only else \"allow short allocations\"\n        logger.info(\n            \"%s produced %d negative weights; long_only=%s so pipeline will %s.\",\n            source,\n            len(negative_assets),\n            long_only,\n            action,\n        )\n\n    window_cfg = dict(risk_window or {})\n    try:\n        window_length = int(window_cfg.get(\"length\", len(window.in_df)))\n    except (TypeError, ValueError):\n        window_length = len(window.in_df)\n    if window_length <= 0:\n        window_length = max(len(window.in_df), 1)\n    decay_mode = str(window_cfg.get(\"decay\", \"simple\"))\n    lambda_value = window_cfg.get(\"lambda\", window_cfg.get(\"ewma_lambda\", 0.94))\n    try:\n        ewma_lambda = float(lambda_value)\n    except (TypeError, ValueError):\n        ewma_lambda = 0.94\n    window_spec = RiskWindow(\n        length=window_length, decay=decay_mode, ewma_lambda=ewma_lambda\n    )\n\n    turnover_cap = None\n    if max_turnover is not None:\n        try:\n            mt = float(max_turnover)\n        except (TypeError, ValueError):\n            mt = None\n        if mt is not None and mt > 0:\n            turnover_cap = mt\n\n    effective_signal_spec = signal_spec or TrendSpec(\n        window=window_spec.length,\n        min_periods=None,\n        lag=1,\n        vol_adjust=False,\n        vol_target=None,\n        zscore=False,\n    )\n    signal_inputs = _scoped_signal_inputs()\n    if not signal_inputs.empty:\n        signal_frame = compute_trend_signals(signal_inputs, effective_signal_spec)\n    else:\n        signal_frame = pd.DataFrame(dtype=float)\n\n    try:\n        weights_series, risk_diagnostics = compute_constrained_weights(\n            base_series,\n            window.in_df[fund_cols],\n            window=window_spec,\n            target_vol=target_vol,\n            periods_per_year=window.periods_per_year,\n            floor_vol=min_floor if min_floor > 0 else None,\n            long_only=long_only,\n            max_weight=max_weight_val,\n            max_active_positions=max_active_val,\n            previous_weights=previous_weights,\n            lambda_tc=lambda_tc,\n            max_turnover=turnover_cap,\n            group_caps=group_caps_map,\n            groups=groups_map,\n        )\n    except Exception as exc:  # pragma: no cover - defensive fallback\n        logger.warning(\n            \"Risk controls failed; falling back to base weights: %s\", exc, exc_info=True\n        )\n        weights_series = base_series.copy()\n        asset_vol = realised_volatility(\n            window.in_df[fund_cols],\n            window_spec,\n            periods_per_year=window.periods_per_year,\n        )\n        latest_vol = asset_vol.iloc[-1].reindex(fund_cols)\n        latest_vol = latest_vol.ffill().bfill()\n        positive = latest_vol[latest_vol > 0]\n        fallback_vol = float(positive.min()) if not positive.empty else 1.0\n        latest_vol = latest_vol.fillna(fallback_vol)\n        if min_floor > 0:\n            latest_vol = latest_vol.clip(lower=min_floor)\n        if target_vol is None:\n            scale_factors = pd.Series(1.0, index=fund_cols, dtype=float)\n        else:\n            scale_factors = (\n                pd.Series(target_vol, index=fund_cols, dtype=float)\n                .div(latest_vol)\n                .replace([np.inf, -np.inf], 0.0)\n                .fillna(0.0)\n            )\n        scaled_returns = window.in_df[fund_cols].mul(scale_factors, axis=1)\n        portfolio_returns = scaled_returns.mul(weights_series, axis=1).sum(axis=1)\n        portfolio_vol = realised_volatility(\n            portfolio_returns.to_frame(\"portfolio\"),\n            window_spec,\n            periods_per_year=window.periods_per_year,\n        )[\"portfolio\"]\n        risk_diagnostics = RiskDiagnostics(\n            asset_volatility=asset_vol,\n            portfolio_volatility=portfolio_vol,\n            turnover=pd.Series(dtype=float, name=\"turnover\"),\n            turnover_value=float(\"nan\"),\n            scale_factors=scale_factors,\n        )\n\n    policy_cfg = dict(weight_policy or {})\n    policy_mode = str(policy_cfg.get(\"mode\", policy_cfg.get(\"policy\", \"drop\"))).lower()\n    min_assets_policy = int(policy_cfg.get(\"min_assets\", 1) or 0)\n\n    signal_snapshot: pd.Series | None = None\n    if not signal_frame.empty:\n        try:\n            target_index = (\n                window.out_df.index[0]\n                if len(window.out_df.index)\n                else signal_frame.index[-1]\n            )\n            aligned = signal_frame.reindex(columns=fund_cols)\n            if target_index in aligned.index:\n                signal_snapshot = aligned.loc[target_index]\n            elif not aligned.empty:\n                signal_snapshot = aligned.iloc[-1]\n        except Exception:  # pragma: no cover - defensive\n            signal_snapshot = None\n\n    weights_series = (\n        apply_weight_policy(\n            weights_series,\n            signal_snapshot,\n            mode=policy_mode,\n            min_assets=min_assets_policy,\n            previous=previous_weights,\n        )\n        .reindex(fund_cols)\n        .fillna(0.0)\n    )\n    scale_factors = risk_diagnostics.scale_factors.reindex(fund_cols).fillna(0.0)\n\n    in_scaled = window.in_df[fund_cols].mul(scale_factors, axis=1) - monthly_cost\n    out_scaled = window.out_df[fund_cols].mul(scale_factors, axis=1) - monthly_cost\n    in_scaled = in_scaled.clip(lower=-1.0)\n    out_scaled = out_scaled.clip(lower=-1.0)\n\n    if warmup > 0:\n        warmup_in = min(warmup, len(in_scaled))\n        warmup_out = min(warmup, len(out_scaled))\n        if warmup_in:\n            in_scaled.iloc[:warmup_in] = 0.0\n        if warmup_out:\n            out_scaled.iloc[:warmup_out] = 0.0\n\n    in_scaled = in_scaled.fillna(0.0)\n    out_scaled = out_scaled.fillna(0.0)\n\n    rf_in = window.in_df[selection.rf_col]\n    rf_out = window.out_df[selection.rf_col]\n\n    want_avg_corr = False\n    try:\n        reg = getattr(stats_cfg, \"metrics_to_run\", []) or []\n        want_avg_corr = \"AvgCorr\" in reg\n    except Exception:  # pragma: no cover - defensive\n        want_avg_corr = False\n\n    is_avg_corr: dict[str, float] | None = None\n    os_avg_corr: dict[str, float] | None = None\n    if want_avg_corr and len(fund_cols) > 1:\n        try:\n            corr_in = in_scaled[fund_cols].corr()\n            corr_out = out_scaled[fund_cols].corr()\n            n_f = len(fund_cols)\n            is_avg_corr = {}\n            os_avg_corr = {}\n            denominator = float(n_f - 1) if n_f > 1 else 1.0\n            for f in fund_cols:\n                in_sum = cast(float, corr_in.loc[f].sum())\n                out_sum = cast(float, corr_out.loc[f].sum())\n                in_val = (in_sum - 1.0) / denominator\n                out_val = (out_sum - 1.0) / denominator\n                is_avg_corr[f] = float(in_val)\n                os_avg_corr[f] = float(out_val)\n        except Exception:  # pragma: no cover - defensive\n            is_avg_corr = None\n            os_avg_corr = None\n\n    in_stats = _compute_stats(\n        in_scaled,\n        rf_in,\n        in_sample_avg_corr=is_avg_corr,\n        out_sample_avg_corr=None,\n    )\n    out_stats = _compute_stats(\n        out_scaled,\n        rf_out,\n        in_sample_avg_corr=None,\n        out_sample_avg_corr=os_avg_corr,\n    )\n    out_stats_raw = _compute_stats(\n        window.out_df[fund_cols],\n        rf_out,\n        in_sample_avg_corr=None,\n        out_sample_avg_corr=os_avg_corr,\n    )\n\n    ew_weights = np.repeat(1.0 / len(fund_cols), len(fund_cols))\n    ew_w_dict = {c: w for c, w in zip(fund_cols, ew_weights)}\n    in_ew = calc_portfolio_returns(ew_weights, in_scaled)\n    out_ew = calc_portfolio_returns(ew_weights, out_scaled)\n    out_ew_raw = calc_portfolio_returns(ew_weights, window.out_df[fund_cols])\n\n    in_ew_stats = _compute_stats(pd.DataFrame({\"ew\": in_ew}), rf_in)[\"ew\"]\n    out_ew_stats = _compute_stats(pd.DataFrame({\"ew\": out_ew}), rf_out)[\"ew\"]\n    out_ew_stats_raw = _compute_stats(pd.DataFrame({\"ew\": out_ew_raw}), rf_out)[\"ew\"]\n\n    user_w = weights_series.to_numpy(dtype=float, copy=False)\n    user_w_dict = {c: float(weights_series[c]) for c in fund_cols}\n\n    in_user = calc_portfolio_returns(user_w, in_scaled)\n    out_user = calc_portfolio_returns(user_w, out_scaled)\n    out_user_raw = calc_portfolio_returns(user_w, window.out_df[fund_cols])\n\n    in_user_stats = _compute_stats(pd.DataFrame({\"user\": in_user}), rf_in)[\"user\"]\n    out_user_stats = _compute_stats(pd.DataFrame({\"user\": out_user}), rf_out)[\"user\"]\n    out_user_stats_raw = _compute_stats(pd.DataFrame({\"user\": out_user_raw}), rf_out)[\n        \"user\"\n    ]\n\n    return _ComputationStage(\n        weights_series=weights_series,\n        risk_diagnostics=risk_diagnostics,\n        weight_engine_fallback=weight_engine_fallback,\n        weight_engine_diagnostics=weight_engine_diagnostics,\n        turnover_cap=turnover_cap,\n        in_scaled=in_scaled,\n        out_scaled=out_scaled,\n        rf_in=rf_in,\n        rf_out=rf_out,\n        in_stats=in_stats,\n        out_stats=out_stats,\n        out_stats_raw=out_stats_raw,\n        in_ew_stats=in_ew_stats,\n        out_ew_stats=out_ew_stats,\n        out_ew_stats_raw=out_ew_stats_raw,\n        in_user_stats=in_user_stats,\n        out_user_stats=out_user_stats,\n        out_user_stats_raw=out_user_stats_raw,\n        ew_weights=ew_w_dict,\n        user_weights=user_w_dict,\n        score_frame=selection.score_frame,\n        weight_policy=policy_cfg,\n        signal_frame=signal_frame,\n        effective_signal_spec=effective_signal_spec,\n    )\n\n\ndef _assemble_analysis_output(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    selection: _SelectionStage,\n    computation: _ComputationStage,\n    *,\n    benchmarks: Mapping[str, str] | None,\n    regime_cfg: Mapping[str, Any] | None,\n    target_vol: float | None,\n    monthly_cost: float,\n    min_floor: float,\n) -> PipelineResult:\n    fund_cols = selection.fund_cols\n    rf_col = selection.rf_col\n    benchmark_stats = {}\n    benchmark_ir = {}\n    out_df = window.out_df\n    in_df = window.in_df\n\n    benchmarks = benchmarks or {}\n    indices_list = selection.indices_list\n    all_benchmarks = benchmarks if benchmarks else {}\n    if indices_list:\n        index_map = {idx: idx for idx in indices_list}\n        index_map.update(benchmarks)\n        all_benchmarks = index_map\n\n    out_user = calc_portfolio_returns(\n        computation.weights_series.to_numpy(dtype=float, copy=False),\n        computation.out_scaled,\n    )\n    out_user_raw = calc_portfolio_returns(\n        computation.weights_series.to_numpy(dtype=float, copy=False), out_df[fund_cols]\n    )\n    out_ew = calc_portfolio_returns(\n        np.repeat(1.0 / len(fund_cols), len(fund_cols)), computation.out_scaled\n    )\n    out_ew_raw = calc_portfolio_returns(\n        np.repeat(1.0 / len(fund_cols), len(fund_cols)), out_df[fund_cols]\n    )\n\n    for label, col in all_benchmarks.items():\n        if col not in in_df.columns or col not in out_df.columns:\n            continue\n        benchmark_stats[label] = {\n            \"in_sample\": _compute_stats(\n                pd.DataFrame({label: in_df[col]}), computation.rf_in\n            )[label],\n            \"out_sample\": _compute_stats(\n                pd.DataFrame({label: out_df[col]}), computation.rf_out\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_18","type":"reasoning","text":"**Planning module extraction and restructuring**"}}
{"type":"item.started","item":{"id":"item_19","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_19","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_20","type":"reasoning","text":"**Checking for inception masking**"}}
{"type":"item.started","item":{"id":"item_21","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception\" src/trend_analysis'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_21","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception\" src/trend_analysis'","aggregated_output":"src/trend_analysis/multi_period/engine.py:901:    # Some vendor datasets encode pre-inception history as a flat line of\nsrc/trend_analysis/multi_period/engine.py:903:    # zeros, we must ensure those pre-inception rows are treated as missing\nsrc/trend_analysis/multi_period/engine.py:906:    # Compute inception dates once per run and null-out values before the\nsrc/trend_analysis/multi_period/engine.py:907:    # inferred inception date.\nsrc/trend_analysis/multi_period/engine.py:910:        from ..data import compute_inception_dates\nsrc/trend_analysis/multi_period/engine.py:912:        inception_raw = compute_inception_dates(cleaned)\nsrc/trend_analysis/multi_period/engine.py:913:        # Apply: before inception -> NaN; never-active columns -> NaN\nsrc/trend_analysis/multi_period/engine.py:914:        for col, inc in inception_raw.items():\nsrc/trend_analysis/multi_period/engine.py:929:        cleaned.attrs[\"inception_dates\"] = {\nsrc/trend_analysis/multi_period/engine.py:931:            for k, v in inception_raw.items()\nsrc/trend_analysis/multi_period/engine.py:1348:        # ~0.0 (often vendor pre-inception encoding) even if they are non-missing.\nsrc/trend_analysis/data.py:89:def compute_inception_dates(\nsrc/trend_analysis/data.py:96:    \"\"\"Return per-column inception dates inferred from first non-zero return.\nsrc/trend_analysis/data.py:98:    Many vendor datasets encode \"pre-inception\" history as a flat line of\nsrc/trend_analysis/data.py:100:    as missing; this helper infers the effective inception date as the first\nsrc/trend_analysis/data.py:110:        Optional list of columns to compute inception dates for. Defaults to\nsrc/trend_analysis/data.py:118:        Mapping from column name to inception timestamp (month-end aligned\nsrc/trend_analysis/data.py:132:                \"compute_inception_dates requires a Date column or DatetimeIndex\"\nsrc/trend_analysis/data.py:197:    # Infer inception dates (first non-zero observation) once at ingestion time.\nsrc/trend_analysis/data.py:198:    # This is used by the multi-period engine to exclude pre-inception series\nsrc/trend_analysis/data.py:201:        inception = compute_inception_dates(\nsrc/trend_analysis/data.py:206:        attrs[\"inception_dates\"] = {\nsrc/trend_analysis/data.py:208:            for k, v in inception.items()\nsrc/trend_analysis/data.py:211:        attrs.setdefault(\"inception_dates\", {})\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_22","type":"reasoning","text":"**Checking for inception masking**"}}
{"type":"item.started","item":{"id":"item_23","type":"command_execution","command":"/bin/bash -lc \"sed -n '1860,2005p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_23","type":"command_execution","command":"/bin/bash -lc \"sed -n '1860,2005p' src/trend_analysis/pipeline.py\"","aggregated_output":"                boundary = None\n    ratio_value = _section_get(split_cfg, \"ratio\", 0.7)\n\n    derived = _derive_split_from_periods(\n        periods,\n        method=method,\n        boundary=boundary,\n        ratio=ratio_value,\n    )\n\n    for key, value in derived.items():\n        resolved.setdefault(key, value)\n\n    still_missing = [key for key in required_keys if key not in resolved]\n    if still_missing:\n        raise ValueError(\n            f\"Unable to derive sample split values for: {', '.join(still_missing)}\"\n        )\n    return resolved\n\n\ndef _prepare_input_data(\n    df: pd.DataFrame,\n    *,\n    date_col: str,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    enforce_completeness: bool = True,\n) -> tuple[pd.DataFrame, FrequencySummary, MissingPolicyResult, bool]:\n    if date_col not in df.columns:\n        raise ValueError(f\"DataFrame must contain a '{date_col}' column\")\n\n    work = df.copy()\n    if not pd.api.types.is_datetime64_any_dtype(work[date_col].dtype):\n        work[date_col] = pd.to_datetime(work[date_col])\n    work.sort_values(date_col, inplace=True)\n\n    freq_summary = detect_frequency(work[date_col])\n\n    value_cols = [c for c in work.columns if c != date_col]\n    if value_cols:\n        numeric = work[value_cols].apply(pd.to_numeric, errors=\"coerce\")\n    else:\n        numeric = work[value_cols]\n    numeric.index = pd.DatetimeIndex(work[date_col])\n\n    if freq_summary.resampled:\n        resampled = (1 + numeric).resample(MONTHLY_DATE_FREQ).prod(min_count=1) - 1\n        normalised = True\n    else:\n        resampled = numeric.resample(MONTHLY_DATE_FREQ).last()\n        normalised = False\n\n    policy_spec: str | Mapping[str, str] | None = missing_policy or \"drop\"\n    preserve_empty_periods = True\n    if isinstance(policy_spec, str):\n        preserve_empty_periods = policy_spec.lower() != \"drop\"\n    elif isinstance(policy_spec, Mapping):\n        values = [str(v or \"\").lower() for v in policy_spec.values()]\n        preserve_empty_periods = any(v and v != \"drop\" for v in values)\n\n    if not preserve_empty_periods:\n        resampled = resampled.dropna(how=\"all\")\n    resampled.index.name = date_col\n\n    filled, missing_result = apply_missing_policy(\n        resampled,\n        policy=policy_spec,\n        limit=missing_limit,\n        enforce_completeness=enforce_completeness,\n    )\n    # Only drop rows that remain completely empty after the missing-data policy.\n    filled = filled.dropna(how=\"all\")\n\n    if filled.empty:\n        monthly_df = pd.DataFrame(columns=[date_col])\n    else:\n        monthly_df = filled.reset_index().rename(columns={\"index\": date_col})\n        monthly_df[date_col] = pd.to_datetime(monthly_df[date_col])\n        monthly_df.sort_values(date_col, inplace=True)\n\n    return monthly_df, freq_summary, missing_result, normalised\n\n\ndef calc_portfolio_returns(\n    weights: NDArray[Any], returns_df: pd.DataFrame\n) -> pd.Series:\n    \"\"\"Calculate weighted portfolio returns.\"\"\"\n    return returns_df.mul(weights, axis=1).sum(axis=1)\n\n\ndef _resolve_risk_free_column(\n    df: pd.DataFrame,\n    *,\n    date_col: str,\n    indices_list: list[str] | None,\n    risk_free_column: str | None,\n    allow_risk_free_fallback: bool | None,\n    fallback_window: pd.DataFrame | None = None,\n) -> tuple[str, list[str], str]:\n    \"\"\"Select the risk-free column and investable funds.\n\n    Returns\n    -------\n    tuple[str, list[str], str]\n        ``(risk_free_column, fund_columns, source)`` where ``source`` is\n        ``\"configured\"`` when explicitly provided or ``\"fallback\"`` when the\n        column is inferred. When ``fallback_window`` is supplied, the\n        candidate scan is restricted to that window to avoid picking columns\n        that lack data for the requested analysis period.\n    \"\"\"\n\n    idx_set = {str(c) for c in indices_list or []}\n    candidate_df = fallback_window if fallback_window is not None else df\n    if date_col not in candidate_df.columns:\n        candidate_df = candidate_df.copy()\n        candidate_df[date_col] = candidate_df.index\n\n    candidate_df = candidate_df.copy()\n    candidate_df[date_col] = pd.to_datetime(candidate_df[date_col])\n    candidate_df.sort_values(date_col, inplace=True)\n\n    configured_rf = (risk_free_column or \"\").strip()\n\n    numeric_cols = [\n        c for c in candidate_df.select_dtypes(\"number\").columns if c != date_col\n    ]\n    if not numeric_cols:\n        raise ValueError(\n            \"No numeric return columns were found in the requested window; cannot select risk-free series\"\n        )\n\n    expanded_df = candidate_df.set_index(date_col)\n    if not expanded_df.index.is_monotonic_increasing:\n        expanded_df = expanded_df.sort_index()\n\n    # Align observed dates to calendar month-end without dropping values.\n    # This handles inputs keyed on business month-end or daily observations.\n    try:\n        idx = pd.DatetimeIndex(pd.to_datetime(expanded_df.index))\n        # Map observations to month-end dates at midnight so they align with\n        # `pd.date_range(..., freq=MONTHLY_DATE_FREQ)`.\n        idx_me = idx.to_period(\"M\").to_timestamp(how=\"end\").normalize()\n        expanded_df.index = idx_me\n        if expanded_df.index.has_duplicates:\n            expanded_df = expanded_df.groupby(level=0).last()\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_24","type":"reasoning","text":"**Organizing pipeline into stages modules**\n\nI'm planning to split the pipeline's preprocessing and helper functions into separate stage modules to keep pipeline.py under 500 lines. I'll make pipeline.py mainly an orchestrator with run functions, avoid circular imports by having pipeline import stages, and move dataclasses and helpers out. I'll also explore existing code like src/trend_analysis/selector to avoid duplication and plan to add tests with good coverage for the new modules."}}
{"type":"item.started","item":{"id":"item_25","type":"command_execution","command":"/bin/bash -lc 'rg -n \"pipeline\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_25","type":"command_execution","command":"/bin/bash -lc 'rg -n \"pipeline\" tests'","aggregated_output":"tests/test_vol_floor_and_warmup.py:7:from trend_analysis.pipeline import _run_analysis\ntests/test_score_frame.py:7:from trend_analysis.pipeline import single_period_run\ntests/test_app_coverage.py:1366:        app_module.pipeline,\ntests/test_app_coverage.py:1372:        app_module.pipeline,\ntests/test_app_coverage.py:1440:    \"\"\"Ensure on_run exits early when pipeline returns an empty metrics\ntests/test_app_coverage.py:1491:        app_module.pipeline, \"run\", lambda cfg: run_calls.append(cfg) or pd.DataFrame()\ntests/test_app_coverage.py:1494:        app_module.pipeline,\ntests/test_app_coverage.py:1508:    assert run_calls, \"Expected pipeline.run to be invoked\"\ntests/test_app_coverage.py:1553:    monkeypatch.setattr(app_module.pipeline, \"run\", lambda cfg: metrics)\ntests/test_app_coverage.py:1555:        app_module.pipeline,\ntests/test_pipeline_run_cache_fallbacks.py:7:import trend_analysis.pipeline as pipeline\ntests/test_pipeline_run_cache_fallbacks.py:28:def _stats_payload() -> dict[str, pipeline._Stats]:  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:30:        \"FundA\": pipeline._Stats(  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:63:    monkeypatch.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_run_cache_fallbacks.py:64:    monkeypatch.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_run_cache_fallbacks.py:85:    result = pipeline.run(cfg)\ntests/test_pipeline_run_cache_fallbacks.py:114:    monkeypatch.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_run_cache_fallbacks.py:115:    monkeypatch.setattr(pipeline, \"_run_analysis\", lambda *a, **k: payload)\ntests/test_pipeline_run_cache_fallbacks.py:136:    result = pipeline.run_full(cfg)\ntests/test_pipeline_run_cache_fallbacks.py:146:        pipeline.run({\"data\": {}})\ntests/test_pipeline_run_cache_fallbacks.py:151:        pipeline.run_full({\"data\": {}})\ntests/test_pipeline_run_cache_fallbacks.py:168:    monkeypatch.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_run_cache_fallbacks.py:170:        pipeline, \"_run_analysis\", lambda *a, **k: pipeline._empty_run_full_result()\ntests/test_pipeline_run_cache_fallbacks.py:187:    result = pipeline.run(cfg)\ntests/test_pipeline_run_cache_fallbacks.py:213:    monkeypatch.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_run_cache_fallbacks.py:214:    monkeypatch.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_run_cache_fallbacks.py:228:    payload = pipeline.run_full(cfg)\ntests/test_pipeline_run_cache_fallbacks.py:243:    monkeypatch.setattr(pipeline, \"get_cache\", lambda: cache)\ntests/test_pipeline_run_cache_fallbacks.py:245:    series = pipeline.compute_signal(df, column=\"value\", window=3, min_periods=2)\ntests/test_pipeline_run_cache_fallbacks.py:256:    summary = pipeline._preprocessing_summary(\ntests/test_pipeline_run_cache_fallbacks.py:261:    daily = pipeline._preprocessing_summary(\"D\", normalised=True, missing_summary=None)\ntests/test_pipeline_run_cache_fallbacks.py:267:    assert pipeline._cfg_section(cfg, \"missing\") == {}\ntests/test_pipeline_run_cache_fallbacks.py:269:    assert pipeline._section_get(ns, \"answer\", default=None) == 42\ntests/test_pipeline_run_cache_fallbacks.py:270:    assert pipeline._section_get(None, \"missing\", default=\"fallback\") == \"fallback\"\ntests/test_pipeline_run_cache_fallbacks.py:271:    assert pipeline._unwrap_cfg({\"__cfg__\": {\"__cfg__\": None}}) == {\"__cfg__\": None}\ntests/test_pipeline_run_cache_fallbacks.py:272:    empty = pipeline._empty_run_full_result()\ntests/test_pipeline_run_cache_fallbacks.py:284:        pipeline._derive_split_from_periods(\ntests/test_pipeline_run_cache_fallbacks.py:289:    result = pipeline._derive_split_from_periods(\ntests/test_pipeline_run_cache_fallbacks.py:300:    positions = pipeline.position_from_signal(\ntests/test_pipeline_run_cache_fallbacks.py:311:    policy, limit = pipeline._policy_from_config({})\ntests/test_pipeline_run_cache_fallbacks.py:315:    policy_only, limit_only = pipeline._policy_from_config({\"policy\": \"drop\"})\ntests/test_pipeline_run_cache_fallbacks.py:319:    none_map, none_limit = pipeline._policy_from_config({\"per_asset\": []})\ntests/test_pipeline_run_cache_fallbacks.py:327:    spec = pipeline._build_trend_spec(cfg, vol_cfg)\ntests/test_pipeline_run_cache_fallbacks.py:337:    policy_map, limit_map = pipeline._policy_from_config(mixed)\ntests/test_pipeline_run_cache_fallbacks.py:350:    split = pipeline._resolve_sample_split(df, cfg)\ntests/test_pipeline_run_cache_fallbacks.py:355:    split_high = pipeline._resolve_sample_split(df, cfg_high)\ntests/test_pipeline_run_cache_fallbacks.py:363:        pipeline.single_period_run(df, \"2020-01\", \"2020-02\")\ntests/test_pipeline_run_cache_fallbacks.py:371:    cfg = pipeline.RiskStatsConfig(metrics_to_run=())  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:373:        pipeline.single_period_run(monthly, \"2020-01\", \"2020-02\", stats_cfg=cfg)\ntests/test_pipeline_run_cache_fallbacks.py:393:    monkeypatch.setattr(pipeline, \"get_cache\", lambda: cache)\ntests/test_pipeline_run_cache_fallbacks.py:395:    pipeline.compute_signal(df, column=\"value\", window=2, min_periods=1)\ntests/test_pipeline_run_cache_fallbacks.py:411:    monkeypatch.setattr(pipeline, \"get_cache\", lambda: DisabledCache())\ntests/test_pipeline_run_cache_fallbacks.py:413:    series = pipeline.compute_signal(df, column=\"value\", window=2, min_periods=1)\ntests/test_pipeline_run_cache_fallbacks.py:430:    freq_summary = pipeline.FrequencySummary(\"M\", \"Monthly\", False, \"M\", \"Monthly\")  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:431:    missing_summary = pipeline.MissingPolicyResult(  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:444:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_run_cache_fallbacks.py:452:    monkeypatch.setattr(pipeline, \"rank_select_funds\", fake_rank_select)\ntests/test_pipeline_run_cache_fallbacks.py:453:    monkeypatch.setattr(pipeline, \"get_window_metric_bundle\", lambda key: {\"key\": key})\ntests/test_pipeline_run_cache_fallbacks.py:454:    monkeypatch.setattr(pipeline, \"make_window_key\", lambda *a, **k: \"window-key\")\ntests/test_pipeline_run_cache_fallbacks.py:472:        pipeline, \"compute_constrained_weights\", fake_compute_constrained_weights\ntests/test_pipeline_run_cache_fallbacks.py:475:        pipeline,\ntests/test_pipeline_run_cache_fallbacks.py:480:    result = pipeline._run_analysis(\ntests/test_pipeline_run_cache_fallbacks.py:515:    freq_summary = pipeline.FrequencySummary(\"M\", \"Monthly\", False, \"M\", \"Monthly\")  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:516:    missing_summary = pipeline.MissingPolicyResult(  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:529:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_run_cache_fallbacks.py:545:        pipeline, \"compute_constrained_weights\", fake_compute_constrained_weights\ntests/test_pipeline_run_cache_fallbacks.py:548:        pipeline,\ntests/test_pipeline_run_cache_fallbacks.py:553:    result = pipeline._run_analysis(\ntests/test_pipeline_run_cache_fallbacks.py:571:    monthly, summary, missing, normalised = pipeline._prepare_input_data(\ntests/test_pipeline_run_cache_fallbacks.py:582:    result = pipeline._derive_split_from_periods(\ntests/test_pipeline_run_cache_fallbacks.py:588:    result_high = pipeline._derive_split_from_periods(\ntests/test_pipeline_run_cache_fallbacks.py:597:    freq_summary = pipeline.FrequencySummary(\"M\", \"Monthly\", False, \"M\", \"Monthly\")  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:598:    empty_missing = pipeline.MissingPolicyResult(  # type: ignore[attr-defined]\ntests/test_pipeline_run_cache_fallbacks.py:614:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_run_cache_fallbacks.py:616:    result = pipeline._run_analysis(\ntests/test_pipeline_run_cache_fallbacks.py:637:    res = pipeline.single_period_run(df, \"2020-01\", \"2020-03\")\ntests/test_gui_launch_run.py:24:    monkeypatch.setattr(app.pipeline, \"run\", lambda cfg: metrics)\ntests/test_gui_launch_run.py:25:    monkeypatch.setattr(app.pipeline, \"run_full\", lambda cfg: {\"result\": 1})\ntests/test_gui_launch_run.py:62:    monkeypatch.setattr(app.pipeline, \"run\", lambda cfg: metrics)\ntests/test_gui_launch_run.py:63:    monkeypatch.setattr(app.pipeline, \"run_full\", lambda cfg: {\"full\": \"results\"})\ntests/test_trend_cli_additional.py:35:def test_run_pipeline_captures_portfolio_and_logging(monkeypatch, tmp_path):\ntests/test_trend_cli_additional.py:87:    run_result, run_id, log_path = cli._run_pipeline(\ntests/test_weight_engine_logging.py:8:from trend_analysis import pipeline\ntests/test_weight_engine_logging.py:32:        result = pipeline._run_analysis(\ntests/test_weight_engine_logging.py:61:        result = pipeline._run_analysis(\ntests/test_weight_engine_logging.py:110:            result = pipeline._run_analysis(\ntests/test_weight_engine_logging.py:140:    logger = logging.getLogger(\"trend_analysis.pipeline\")\ntests/test_weight_engine_logging.py:145:        result = pipeline._run_analysis(\ntests/test_weight_engine_logging.py:171:        result = pipeline._run_analysis(\ntests/test_weight_engine_logging.py:199:        result = pipeline._run_analysis(\ntests/test_cli.py:145:    monkeypatch.setattr(cli.pipeline, \"run\", fake_run)\ntests/test_cli.py:146:    monkeypatch.setattr(cli.pipeline, \"run_full\", lambda cfg: {\"dummy\": 1})\ntests/test_cli.py:162:    monkeypatch.setattr(cli.pipeline, \"run\", lambda cfg: pd.DataFrame())\ntests/test_cli.py:163:    monkeypatch.setattr(cli.pipeline, \"run_full\", lambda cfg: None)\ntests/test_cli.py:171:def test_cli_outputs_pipeline_diagnostic(tmp_path, capsys, monkeypatch):\ntests/test_cli.py:265:    monkeypatch.setattr(cli.pipeline, \"run\", lambda cfg: metrics_df)\ntests/test_cli.py:266:    monkeypatch.setattr(cli.pipeline, \"run_full\", lambda cfg: results_payload)\ntests/test_multi_period_sticky_periods.py:100:def _patch_pipeline(monkeypatch: pytest.MonkeyPatch) -> None:\ntests/test_multi_period_sticky_periods.py:138:    _patch_pipeline(monkeypatch)\ntests/test_trend_signals.py:8:from trend_analysis.pipeline import compute_signal\ntests/test_trend_signals.py:71:def test_pipeline_compute_signal_uses_trend_engine():\ntests/test_api_run_simulation.py:9:from trend_analysis import api, pipeline\ntests/test_api_run_simulation.py:97:def test_run_simulation_matches_pipeline(tmp_path):\ntests/test_api_run_simulation.py:103:    expected_details = pipeline.run_full(cfg).unwrap()\ntests/test_api_run_simulation.py:105:    expected_metrics = pipeline.run(cfg)\ntests/test_threshold_hold_alignment.py:106:    # Minimal stub for _run_analysis to avoid heavy pipeline work\ntests/test_pipeline_integration_direct.py:1:\"\"\"Direct pipeline execution tests to boost coverage for export and multi-\ntests/test_pipeline_integration_direct.py:109:def test_direct_pipeline_and_exports(tmp_path: Path) -> None:\ntests/test_pipeline_integration_direct.py:110:    \"\"\"Run the pipeline directly and exercise key exporter paths.\"\"\"\ntests/test_diagnostics.py:32:def test_pipeline_success_exposes_mapping_interface():\ntests/test_diagnostics.py:34:    result = diagnostics.pipeline_success(payload)\ntests/test_diagnostics.py:45:def test_pipeline_result_requires_value_for_item_access():\ntests/test_diagnostics.py:52:def test_pipeline_failure_defaults_message_and_copies_context():\ntests/test_diagnostics.py:54:    result = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:71:def test_coerce_pipeline_result_accepts_diagnostic_result():\ntests/test_diagnostics.py:73:    payload, diagnostic = diagnostics.coerce_pipeline_result(diag_result)\ntests/test_diagnostics.py:79:def test_coerce_pipeline_result_rejects_invalid_diagnostic_type():\ntests/test_diagnostics.py:85:        diagnostics.coerce_pipeline_result(PayloadHolder())\ntests/test_diagnostics.py:88:def test_coerce_pipeline_result_rejects_non_mapping_payload():\ntests/test_diagnostics.py:92:        diagnostics.coerce_pipeline_result(diag_result)\ntests/test_diagnostics.py:95:def test_pipeline_failure_accepts_custom_message_and_context_copy(monkeypatch):\ntests/test_diagnostics.py:98:    result = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:111:def test_pipeline_failure_falls_back_to_reason_code_when_default_missing(monkeypatch):\ntests/test_diagnostics.py:118:    result = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:127:def test_coerce_pipeline_result_converts_mapping_payload_and_preserves_diagnostic():\ntests/test_diagnostics.py:141:    coerced_payload, coerced_diag = diagnostics.coerce_pipeline_result(Wrapper())\ntests/test_diagnostics.py:148:def test_pipeline_result_len_iter_and_copy_with_none_value():\ntests/test_diagnostics.py:157:def test_coerce_pipeline_result_wraps_custom_mapping_into_dict():\ntests/test_diagnostics.py:173:    coerced_payload, diagnostic = diagnostics.coerce_pipeline_result(payload)\ntests/test_diagnostics.py:180:def test_coerce_pipeline_result_preserves_diagnostic_when_payload_missing():\ntests/test_diagnostics.py:190:    payload, coerced_diag = diagnostics.coerce_pipeline_result(Wrapper())\ntests/test_diagnostics.py:196:def test_coerce_pipeline_result_with_pipeline_result_round_trip():\ntests/test_diagnostics.py:197:    failure = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:202:    payload, diagnostic = diagnostics.coerce_pipeline_result(failure)\ntests/test_diagnostics.py:208:def test_pipeline_failure_without_context_sets_none():\ntests/test_diagnostics.py:209:    result = diagnostics.pipeline_failure(diagnostics.PipelineReasonCode.INPUT_NONE)\ntests/test_diagnostics.py:216:def test_pipeline_success_copy_does_not_mutate_original_payload():\ntests/test_diagnostics.py:218:    result = diagnostics.pipeline_success(payload)\ntests/test_diagnostics.py:227:def test_coerce_pipeline_result_handles_wrapper_with_none_payload_and_no_diagnostic():\ntests/test_diagnostics.py:233:    payload, diagnostic = diagnostics.coerce_pipeline_result(Wrapper())\ntests/test_trend_cli_entrypoints.py:190:def test_run_pipeline_sets_metadata_and_bundle(\ntests/test_trend_cli_entrypoints.py:216:    result_obj, run_id, log_path = trend_cli._run_pipeline(\ntests/test_trend_cli_entrypoints.py:240:def test_run_pipeline_requires_transaction_cost(\ntests/test_trend_cli_entrypoints.py:253:        trend_cli._run_pipeline(\ntests/test_trend_cli_entrypoints.py:404:        \"_run_pipeline\",\ntests/test_trend_cli_entrypoints.py:439:        \"_run_pipeline\",\ntests/test_trend_cli_entrypoints.py:490:        \"_run_pipeline\",\ntests/test_trend_cli_entrypoints.py:528:        \"_run_pipeline\",\ntests/test_presets_extended.py:311:    assert presets.pipeline_metric_key(\"vol\") == \"Volatility\"\ntests/test_presets_extended.py:312:    assert presets.pipeline_metric_key(\"unknown\") is None\ntests/test_presets_extended.py:313:    assert presets.pipeline_metric_key(\"\") is None\ntests/test_pipeline_entrypoints.py:5:import trend_analysis.pipeline as pipeline\ntests/test_pipeline_entrypoints.py:8:def _sample_stats(value: float = 0.1) -> pipeline._Stats:  # type: ignore[name-defined]\ntests/test_pipeline_entrypoints.py:11:    return pipeline._Stats(\ntests/test_pipeline_entrypoints.py:25:        pipeline.run({})\ntests/test_pipeline_entrypoints.py:71:    monkeypatch.setattr(pipeline, \"load_csv\", lambda *_, **__: sample_frame)\ntests/test_pipeline_entrypoints.py:73:        pipeline, \"_resolve_sample_split\", lambda *_args, **_kwargs: sample_split\ntests/test_pipeline_entrypoints.py:76:        pipeline, \"_build_trend_spec\", lambda *_args, **_kwargs: object()\ntests/test_pipeline_entrypoints.py:99:    monkeypatch.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_entrypoints.py:101:    result = pipeline.run(base_config)\ntests/test_pipeline_entrypoints.py:123:    monkeypatch.setattr(pipeline, \"load_csv\", lambda *_, **__: sample_frame)\ntests/test_pipeline_entrypoints.py:125:        pipeline, \"_resolve_sample_split\", lambda *_args, **_kwargs: sample_split\ntests/test_pipeline_entrypoints.py:128:        pipeline, \"_build_trend_spec\", lambda *_args, **_kwargs: object()\ntests/test_pipeline_entrypoints.py:130:    monkeypatch.setattr(pipeline, \"_run_analysis\", lambda *_, **__: None)\ntests/test_pipeline_entrypoints.py:132:    result = pipeline.run(base_config)\ntests/test_pipeline_entrypoints.py:142:    monkeypatch.setattr(pipeline, \"load_csv\", lambda *_, **__: sample_frame)\ntests/test_pipeline_entrypoints.py:144:        pipeline, \"_resolve_sample_split\", lambda *_args, **_kwargs: sample_split\ntests/test_pipeline_entrypoints.py:147:        pipeline, \"_build_trend_spec\", lambda *_args, **_kwargs: object()\ntests/test_pipeline_entrypoints.py:155:    monkeypatch.setattr(pipeline, \"_run_analysis\", lambda *_, **__: payload)\ntests/test_pipeline_entrypoints.py:157:    result = pipeline.run_full(base_config)\ntests/test_pipeline_entrypoints.py:167:    monkeypatch.setattr(pipeline, \"load_csv\", lambda *_, **__: sample_frame)\ntests/test_pipeline_entrypoints.py:169:        pipeline, \"_resolve_sample_split\", lambda *_args, **_kwargs: sample_split\ntests/test_pipeline_entrypoints.py:172:        pipeline, \"_build_trend_spec\", lambda *_args, **_kwargs: object()\ntests/test_pipeline_entrypoints.py:174:    monkeypatch.setattr(pipeline, \"_run_analysis\", lambda *_, **__: None)\ntests/test_pipeline_entrypoints.py:176:    result = pipeline.run_full(base_config)\ntests/test_pipeline_entrypoints.py:181:    payload = pipeline._empty_run_full_result()\ntests/test_pipeline_entrypoints.py:199:    stats = pipeline._compute_stats(\ntests/test_pipeline_entrypoints.py:211:    portfolio = pipeline.calc_portfolio_returns(\ntests/test_pipeline_branch_coverage.py:1:\"\"\"Additional branch coverage tests for ``trend_analysis.pipeline``.\"\"\"\ntests/test_pipeline_branch_coverage.py:12:from trend_analysis import pipeline\ntests/test_pipeline_branch_coverage.py:13:from trend_analysis.pipeline import RiskStatsConfig\ntests/test_pipeline_branch_coverage.py:48:    summary = pipeline._preprocessing_summary(\ntests/test_pipeline_branch_coverage.py:63:    result = pipeline._resolve_sample_split(df, split_cfg)\ntests/test_pipeline_branch_coverage.py:69:    prepared, summary, missing, normalised = pipeline._prepare_input_data(\ntests/test_pipeline_branch_coverage.py:85:    result = pipeline.single_period_run(df, \"2024-01\", \"2024-03\", stats_cfg=stats_cfg)\ntests/test_pipeline_branch_coverage.py:91:        pipeline._run_analysis(\ntests/test_pipeline_branch_coverage.py:108:        pipeline._run_analysis(\ntests/test_pipeline_branch_coverage.py:146:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_branch_coverage.py:147:    result = pipeline._run_analysis(\ntests/test_pipeline_branch_coverage.py:184:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_branch_coverage.py:200:    monkeypatch.setattr(pipeline, \"single_period_run\", fake_single_period_run)\ntests/test_pipeline_branch_coverage.py:201:    monkeypatch.setattr(pipeline, \"compute_trend_signals\", fake_compute_trend_signals)\ntests/test_pipeline_branch_coverage.py:203:        pipeline, \"compute_constrained_weights\", fake_compute_constrained_weights\ntests/test_pipeline_branch_coverage.py:206:        pipeline,\ntests/test_pipeline_branch_coverage.py:210:    monkeypatch.setattr(pipeline, \"build_regime_payload\", lambda **_: {})\ntests/test_pipeline_branch_coverage.py:211:    monkeypatch.setattr(pipeline, \"information_ratio\", lambda *_, **__: 0.1)\ntests/test_pipeline_branch_coverage.py:221:    result = pipeline._run_analysis(\ntests/test_pipeline_branch_coverage.py:280:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_branch_coverage.py:282:        pipeline,\ntests/test_pipeline_branch_coverage.py:289:        pipeline,\ntests/test_pipeline_branch_coverage.py:298:        pipeline, \"compute_constrained_weights\", fake_compute_constrained_weights\ntests/test_pipeline_branch_coverage.py:301:        pipeline,\ntests/test_pipeline_branch_coverage.py:305:    monkeypatch.setattr(pipeline, \"build_regime_payload\", lambda **_: {})\ntests/test_pipeline_branch_coverage.py:306:    monkeypatch.setattr(pipeline, \"information_ratio\", raising_information_ratio)\ntests/test_pipeline_branch_coverage.py:311:    result = pipeline._run_analysis(\ntests/test_risk_free_default_alignment.py:12:from trend_analysis.diagnostics import PipelineReasonCode, pipeline_failure\ntests/test_risk_free_default_alignment.py:14:from trend_analysis.pipeline import _resolve_risk_free_column\ntests/test_risk_free_default_alignment.py:141:        return pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED)\ntests/test_risk_free_default_alignment.py:164:        return pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED)\ntests/test_risk_free_default_alignment.py:189:        return pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED)\ntests/test_na_as_zero_policy.py:5:from trend_analysis.pipeline import _run_analysis\ntests/test_optional_notebook_deps.py:10:from trend_analysis import pipeline\ntests/test_optional_notebook_deps.py:65:def test_pipeline_runs_without_notebook_dependencies(monkeypatch: pytest.MonkeyPatch):\ntests/test_optional_notebook_deps.py:71:    result = pipeline.run_analysis(\ntests/test_timeseries_properties.py:20:from trend_analysis.pipeline import compute_signal, position_from_signal\ntests/test_timeseries_properties.py:111:def test_pipeline_outputs_are_finite_and_nan_free(price_frame: pd.DataFrame) -> None:\ntests/test_timeseries_properties.py:123:        \"pipeline stats: min_ret=\"\ntests/test_multi_period_inception_filter.py:82:def _patch_pipeline(monkeypatch: pytest.MonkeyPatch) -> None:\ntests/test_multi_period_inception_filter.py:83:    # Skip real pipeline execution; we only care about the selection score frame.\ntests/test_multi_period_inception_filter.py:84:    def fake_call_pipeline_with_diag(*args: Any, **kwargs: Any):\ntests/test_multi_period_inception_filter.py:89:        engine, \"_call_pipeline_with_diag\", fake_call_pipeline_with_diag\ntests/test_multi_period_inception_filter.py:115:    _patch_pipeline(monkeypatch)\ntests/test_trend_cli.py:173:def test_main_run_invokes_pipeline(monkeypatch, tmp_path: Path) -> None:\ntests/test_trend_cli.py:183:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:184:        captured[\"pipeline_args\"] = kwargs\ntests/test_trend_cli.py:197:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:204:    pipeline_kwargs = captured[\"pipeline_args\"]\ntests/test_trend_cli.py:205:    assert pipeline_kwargs[\"source_path\"] == csv_path.resolve()\ntests/test_trend_cli.py:206:    assert pipeline_kwargs[\"structured_log\"] is True\ntests/test_trend_cli.py:217:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:231:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:258:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:271:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:314:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:318:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:350:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:357:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:398:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:402:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:436:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:443:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:500:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:503:    monkeypatch.setattr(\"trend_analysis.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:536:    def fake_run_pipeline(*args, **kwargs):  # type: ignore[override]\ntests/test_trend_cli.py:541:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli.py:687:def test_run_pipeline_sets_attributes(monkeypatch, tmp_path: Path) -> None:\ntests/test_trend_cli.py:735:    result, run_id, log_path = cli._run_pipeline(\ntests/test_trend_cli.py:756:def test_run_pipeline_handles_non_dict_details(monkeypatch, tmp_path: Path) -> None:\ntests/test_trend_cli.py:782:    result, run_id, log_path = cli._run_pipeline(\ntests/test_multi_period_engine_additional.py:722:def test_run_reconciles_manager_changes_to_pipeline_fund_weights(\ntests/test_multi_period_engine_additional.py:725:    \"\"\"Ensure `manager_changes` matches realised holdings (pipeline fund_weights).\ntests/test_multi_period_engine_additional.py:729:    versa when the pipeline drops a fund due to missing-data filters).\ntests/test_multi_period_engine_additional.py:825:        # Period 2: pipeline drops FundB (e.g. missing-data filter)\ntests/test_multi_period_engine_additional.py:826:        # Period 3: pipeline re-adds FundB\ntests/test_multi_period_engine_missing_policy.py:46:def _fake_pipeline_result() -> mp_engine.DiagnosticResult[dict[str, Any]]:\ntests/test_multi_period_engine_missing_policy.py:69:        mp_engine, \"_call_pipeline_with_diag\", lambda *_, **__: _fake_pipeline_result()\ntests/test_multi_period_engine_missing_policy.py:109:        mp_engine, \"_call_pipeline_with_diag\", lambda *_, **__: _fake_pipeline_result()\ntests/test_pipeline_optional_features.py:9:from trend_analysis import pipeline\ntests/test_pipeline_optional_features.py:76:    score_frame = pipeline.single_period_run(\ntests/test_pipeline_optional_features.py:109:        pipeline.single_period_run(df, \"2020-01\", \"2020-03\", stats_cfg=stats_cfg)\ntests/test_pipeline_optional_features.py:125:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:156:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:181:    base = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:195:    enabled = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:221:    spx = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:234:    acwi = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:265:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:293:    baseline = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:307:    enabled = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:343:    base = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:356:    enabled = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:377:    base = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:390:    enabled = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:415:    base = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:428:    enabled = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:459:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:489:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:526:    monkeypatch.setattr(pipeline, \"single_period_run\", fake_single_period_run)\ntests/test_pipeline_optional_features.py:528:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:558:        if caller.filename.endswith(\"pipeline.py\"):\ntests/test_pipeline_optional_features.py:564:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:597:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:634:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:669:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:703:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:729:    original_calc = pipeline.calc_portfolio_returns\ntests/test_pipeline_optional_features.py:739:    original_ir = pipeline.information_ratio\ntests/test_pipeline_optional_features.py:746:    monkeypatch.setattr(pipeline, \"calc_portfolio_returns\", tagging_calc)\ntests/test_pipeline_optional_features.py:747:    monkeypatch.setattr(pipeline, \"information_ratio\", flaky_information_ratio)\ntests/test_pipeline_optional_features.py:749:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:780:    monkeypatch.setattr(pipeline, \"information_ratio\", scalar_information_ratio)\ntests/test_pipeline_optional_features.py:782:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:808:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:838:    original_ir = pipeline.information_ratio\ntests/test_pipeline_optional_features.py:846:    monkeypatch.setattr(pipeline, \"information_ratio\", scalar_information_ratio)\ntests/test_pipeline_optional_features.py:848:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:878:    result = pipeline._run_analysis(\ntests/test_pipeline_optional_features.py:907:    original_ir = pipeline.information_ratio\ntests/test_pipeline_optional_features.py:908:    original_calc = pipeline.calc_portfolio_returns\ntests/test_pipeline_optional_features.py:925:    monkeypatch.setattr(pipeline, \"calc_portfolio_returns\", tagging_calc)\ntests/test_pipeline_optional_features.py:926:    monkeypatch.setattr(pipeline, \"information_ratio\", fake_information_ratio)\ntests/test_pipeline_optional_features.py:928:    result = pipeline._run_analysis(\ntests/golden/test_demo.py:3:This test runs the complete demo pipeline end-to-end and validates that\ntests/golden/test_demo.py:24:    \"\"\"Golden master tests for demo pipeline outputs.\"\"\"\ntests/golden/test_demo.py:172:    @pytest.mark.xdist_group(name=\"demo_pipeline\")\ntests/golden/test_demo.py:173:    def test_demo_pipeline_end_to_end(self):\ntests/golden/test_demo.py:175:        Golden master test: Run complete demo pipeline and validate outputs.\ntests/golden/test_demo.py:301:        print(\"\\nDemo pipeline golden master validation passed.\")\ntests/golden/test_demo.py:307:    @pytest.mark.xdist_group(name=\"demo_pipeline\")\ntests/golden/test_demo.py:308:    def test_demo_pipeline_deterministic(self):\ntests/golden/test_demo.py:309:        \"\"\"Test that demo pipeline produces deterministic outputs across runs.\ntests/test_trend_cli_soft_coverage.py:446:def test_main_run_uses_env_seed_and_legacy_pipeline(\ntests/test_trend_cli_soft_coverage.py:466:        cli.pipeline, \"run\", lambda cfg_obj: pd.DataFrame({\"Sharpe\": [0.5]})\ntests/test_trend_cli_soft_coverage.py:468:    monkeypatch.setattr(cli.pipeline, \"run_full\", lambda cfg_obj: {})\ntests/test_trend_cli_soft_coverage.py:692:        cli.pipeline, \"run\", lambda cfg_obj: pd.DataFrame({\"Sharpe\": [0.2]})\ntests/test_trend_cli_soft_coverage.py:695:        cli.pipeline,\ntests/test_trend_cli_soft_coverage.py:773:    def fake_run_pipeline(*args: Any, **kwargs: Any) -> tuple[int, str, Path | None]:\ntests/test_trend_cli_soft_coverage.py:774:        called[\"run_pipeline\"] = (args, kwargs)\ntests/test_trend_cli_soft_coverage.py:788:    monkeypatch.setattr(\"trend.cli._run_pipeline\", fake_run_pipeline)\ntests/test_trend_cli_soft_coverage.py:795:    pipeline_result = cli._run_pipeline(\ntests/test_trend_cli_soft_coverage.py:803:    cli._print_summary(\"cfg\", pipeline_result)\ntests/test_trend_cli_soft_coverage.py:804:    cli._write_report_files(Path(\"out\"), \"cfg\", pipeline_result, run_id=\"xyz\")\ntests/test_trend_cli_soft_coverage.py:810:    assert pipeline_result == (1, \"ok\", None)\ntests/test_trend_cli_soft_coverage.py:811:    assert called[\"print_summary\"][1] == pipeline_result\ntests/test_trend_cli_soft_coverage.py:815:def test_main_run_executes_pipeline_success(\ntests/test_pipeline_run_analysis_helpers.py:6:from trend_analysis import pipeline as pipeline_module\ntests/test_pipeline_run_analysis_helpers.py:7:from trend_analysis.pipeline import (\ntests/test_pipeline_run_analysis_helpers.py:217:# Tests that monkeypatch pipeline functions must run serially to avoid\ntests/test_pipeline_run_analysis_helpers.py:232:    monkeypatch.setattr(pipeline_module, \"single_period_run\", _fake_single_period_run)\ntests/test_pipeline_run_analysis_helpers.py:316:    monkeypatch.setattr(pipeline_module, \"single_period_run\", _fake_single_period_run)\ntests/test_pipeline_run_analysis_helpers.py:328:        pipeline_module, \"compute_trend_signals\", _fake_compute_trend_signals\ntests/test_pipeline_run_analysis_helpers.py:403:    monkeypatch.setattr(pipeline_module, \"single_period_run\", _fake_single_period_run)\ntests/test_pipeline_run_analysis_helpers.py:488:    monkeypatch.setattr(pipeline_module, \"single_period_run\", _fake_single_period_run)\ntests/test_multi_period_engine_branch_completion.py:191:    \"\"\"Providing price frames should allow the non-threshold pipeline path to execute.\"\"\"\ntests/test_multi_period_engine_branch_completion.py:241:def test_call_pipeline_with_diag_honors_monkeypatch(\ntests/test_multi_period_engine_branch_completion.py:251:    diag = mp_engine._call_pipeline_with_diag(\ntests/test_multi_period_engine_branch_completion.py:279:    monkeypatch.setattr(mp_engine, \"_call_pipeline_with_diag\", fake_call)\ntests/test_multi_period_engine_branch_completion.py:301:    monkeypatch.setattr(mp_engine, \"_call_pipeline_with_diag\", fake_call)\ntests/test_multi_period_engine_branch_completion.py:322:    monkeypatch.setattr(mp_engine, \"_call_pipeline_with_diag\", fake_call)\ntests/test_rf_handling.py:20:def test_pipeline_respects_lowest_vol_exclusion_as_rf():\ntests/test_rf_handling.py:22:    from trend_analysis import pipeline\ntests/test_rf_handling.py:25:    res = pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:56:    from trend_analysis import pipeline\ntests/test_rf_handling.py:59:    res = pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:89:    from trend_analysis import pipeline\ntests/test_rf_handling.py:92:    res = pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:120:    from trend_analysis import pipeline\ntests/test_rf_handling.py:124:        pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:138:def test_pipeline_constant_rf_via_stats_cfg_executes():\ntests/test_rf_handling.py:140:    from trend_analysis import pipeline\ntests/test_rf_handling.py:144:    res = pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:167:def test_pipeline_requires_configured_risk_free_column():\ntests/test_rf_handling.py:169:    from trend_analysis import pipeline\ntests/test_rf_handling.py:173:        pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:188:def test_pipeline_requires_flag_for_fallback_when_missing_rf():\ntests/test_rf_handling.py:190:    from trend_analysis import pipeline\ntests/test_rf_handling.py:194:        pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_rf_handling.py:208:def test_pipeline_implicit_fallback_enabled_by_default():\ntests/test_rf_handling.py:211:    from trend_analysis import pipeline\ntests/test_rf_handling.py:226:    result = pipeline._run_analysis(**kwargs)  # type: ignore[attr-defined]\ntests/test_rf_handling.py:260:def test_pipeline_uses_configured_series_for_metrics():\ntests/test_rf_handling.py:262:    from trend_analysis import pipeline\ntests/test_rf_handling.py:265:    res = pipeline._run_analysis(  # type: ignore[attr-defined]\ntests/test_pipeline_calendar_alignment.py:4:from trend_analysis import pipeline\ntests/test_pipeline_calendar_alignment.py:8:def test_pipeline_run_applies_calendar_alignment():\ntests/test_pipeline_calendar_alignment.py:20:    result = pipeline._run_analysis(\ntests/test_export_additional_coverage.py:70:from trend_analysis.pipeline import _compute_stats, calc_portfolio_returns\ntests/test_avgcorr_export.py:8:from trend_analysis.pipeline import _run_analysis  # type: ignore\ntests/test_trend_analysis_presets.py:181:    pipeline_metrics = preset.metrics_pipeline()\ntests/test_trend_analysis_presets.py:182:    assert pipeline_metrics == {\"Sharpe\": 1.5, \"MaxDrawdown\": 0.4}\ntests/test_trend_analysis_presets.py:422:    assert preset_module.pipeline_metric_key(\"max_drawdown\") == \"MaxDrawdown\"\ntests/test_trend_analysis_presets.py:423:    assert preset_module.pipeline_metric_key(None) is None  # type: ignore[arg-type]\ntests/workflows/test_autofix_pipeline.py:29:def test_autofix_pipeline_fixes_trivial_ruff_issue(\ntests/test_trend_analysis_init_module.py:66:        \"pipeline\",\ntests/test_single_period_run_avg_corr.py:8:from trend_analysis.pipeline import single_period_run\ntests/test_trend_analysis_diagnostics.py:7:    coerce_pipeline_result,\ntests/test_trend_analysis_diagnostics.py:8:    pipeline_failure,\ntests/test_trend_analysis_diagnostics.py:9:    pipeline_success,\ntests/test_trend_analysis_diagnostics.py:20:def test_pipeline_result_behaves_like_mapping():\ntests/test_trend_analysis_diagnostics.py:23:    result = pipeline_success(payload)\ntests/test_trend_analysis_diagnostics.py:35:def test_pipeline_failure_populates_default_message_and_context_copy():\ntests/test_trend_analysis_diagnostics.py:38:    result = pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED, context=context)\ntests/test_trend_analysis_diagnostics.py:53:def test_pipeline_failure_allows_custom_message_override():\ntests/test_trend_analysis_diagnostics.py:54:    result = pipeline_failure(PipelineReasonCode.INPUT_NONE, message=\"custom override\")\ntests/test_trend_analysis_diagnostics.py:63:        (pipeline_success({\"ok\": True}), {\"ok\": True}, None),\ntests/test_trend_analysis_diagnostics.py:74:def test_coerce_pipeline_result_converts_mapping_inputs(\ntests/test_trend_analysis_diagnostics.py:77:    payload, diagnostic = coerce_pipeline_result(input_obj)\ntests/test_trend_analysis_diagnostics.py:83:def test_coerce_pipeline_result_rejects_non_mapping_payload():\ntests/test_trend_analysis_diagnostics.py:89:        coerce_pipeline_result(ObjectWithValue())\ntests/test_trend_analysis_diagnostics.py:92:def test_coerce_pipeline_result_rejects_invalid_diagnostic_type():\ntests/test_trend_analysis_diagnostics.py:99:        coerce_pipeline_result(ObjectWithInvalidDiagnostic())\ntests/workflows/test_autofix_full_pipeline.py:29:def test_autofix_pipeline_resolves_lint_and_typing(\ntests/test_trend_analysis_presets_additional.py:144:    metrics = preset.metrics_pipeline()\ntests/test_trend_analysis_presets_additional.py:177:    assert presets.pipeline_metric_key(\"volatility\") == \"Volatility\"\ntests/test_trend_analysis_presets_additional.py:178:    assert presets.pipeline_metric_key(None) is None\ntests/test_trend_analysis_package.py:34:        \"trend_analysis.pipeline\",\ntests/test_pipeline_warmup_autofix.py:9:from trend_analysis.pipeline import _run_analysis, run_analysis\ntests/test_gui_app_extended.py:324:        app.pipeline, \"run\", lambda cfg: pd.DataFrame({\"metric\": [1.0]})\ntests/test_gui_app_extended.py:326:    monkeypatch.setattr(app.pipeline, \"run_full\", lambda cfg: {\"extra\": 1})\ntests/workflows/github_scripts/test_parse_chatgpt_topics.py:187:def test_pipeline_processes_issues_style_input(tmp_path: Path) -> None:\ntests/workflows/github_scripts/test_parse_chatgpt_topics.py:188:    workdir = tmp_path / \"pipeline\"\ntests/workflows/github_scripts/test_parse_chatgpt_topics.py:195:        \"Tasks\\n- review pipeline\\n- update documentation\\n\\n\"\ntests/test_pipeline_helpers_additional.py:1:\"\"\"Additional unit tests for ``trend_analysis.pipeline`` helper utilities.\"\"\"\ntests/test_pipeline_helpers_additional.py:12:import trend_analysis.pipeline as pipeline\ntests/test_pipeline_helpers_additional.py:13:from trend_analysis.pipeline import (\ntests/test_pipeline_helpers_additional.py:269:        mp.setattr(pipeline, \"detect_frequency\", lambda series: summary)\ntests/test_pipeline_helpers_additional.py:276:        mp.setattr(pipeline, \"apply_missing_policy\", fake_apply_missing_policy)\ntests/test_pipeline_helpers_additional.py:371:            pipeline,\ntests/test_pipeline_helpers_additional.py:468:        mp.setattr(pipeline, \"detect_frequency\", lambda series: summary)\ntests/test_pipeline_helpers_additional.py:470:            pipeline,\ntests/test_pipeline_helpers_additional.py:508:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", prepare_empty)\ntests/test_pipeline_helpers_additional.py:532:    monkeypatch.setattr(pipeline, \"_prepare_input_data\", prepare_no_values)\ntests/test_pipeline_helpers_additional.py:606:        mp.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_helpers_additional.py:607:        mp.setattr(pipeline, \"single_period_run\", fake_single_period_run)\ntests/test_pipeline_helpers_additional.py:608:        mp.setattr(pipeline, \"make_window_key\", lambda *args, **kwargs: \"key\")\ntests/test_pipeline_helpers_additional.py:609:        mp.setattr(pipeline, \"get_window_metric_bundle\", lambda key: {})\ntests/test_pipeline_helpers_additional.py:610:        mp.setattr(pipeline, \"rank_select_funds\", fake_rank_select_funds)\ntests/test_pipeline_helpers_additional.py:611:        mp.setattr(pipeline, \"compute_trend_signals\", fake_trend_signals)\ntests/test_pipeline_helpers_additional.py:613:        mp.setattr(pipeline, \"compute_constrained_weights\", boom_weights)\ntests/test_pipeline_helpers_additional.py:614:        mp.setattr(pipeline, \"realised_volatility\", fake_realised_volatility)\ntests/test_pipeline_helpers_additional.py:615:        mp.setattr(pipeline, \"information_ratio\", fake_information_ratio)\ntests/test_pipeline_helpers_additional.py:616:        mp.setattr(pipeline, \"build_regime_payload\", fake_regime_payload)\ntests/test_pipeline_helpers_additional.py:705:        mp.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_helpers_additional.py:706:        mp.setattr(pipeline, \"single_period_run\", fake_single_period_run)\ntests/test_pipeline_helpers_additional.py:707:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:708:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:789:        mp.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_helpers_additional.py:791:            pipeline,\ntests/test_pipeline_helpers_additional.py:800:        mp.setattr(pipeline, \"_build_trend_spec\", lambda cfg, vol: SimpleNamespace())\ntests/test_pipeline_helpers_additional.py:801:        mp.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_helpers_additional.py:803:        result = pipeline.run(cfg)\ntests/test_pipeline_helpers_additional.py:849:        mp.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_helpers_additional.py:851:            pipeline,\ntests/test_pipeline_helpers_additional.py:860:        mp.setattr(pipeline, \"_build_trend_spec\", lambda cfg, vol: SimpleNamespace())\ntests/test_pipeline_helpers_additional.py:861:        mp.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_helpers_additional.py:863:        result = pipeline.run_full(cfg)\ntests/test_pipeline_helpers_additional.py:965:    monkeypatch.setattr(pipeline, \"get_cache\", lambda: cache)\ntests/test_pipeline_helpers_additional.py:982:    monkeypatch.setattr(pipeline, \"get_cache\", lambda: DummyCache())\ntests/test_pipeline_helpers_additional.py:995:    positions = pipeline.position_from_signal(\ntests/test_pipeline_helpers_additional.py:1001:def test_pipeline_getattr_unknown() -> None:\ntests/test_pipeline_helpers_additional.py:1003:        pipeline.__getattr__(\"does_not_exist\")\ntests/test_pipeline_helpers_additional.py:1008:        getattr(pipeline, \"missing_attribute\")\ntests/test_pipeline_helpers_additional.py:1012:    assert getattr(pipeline, \"Stats\") is _Stats\ntests/test_pipeline_helpers_additional.py:1058:        mp.setattr(pipeline, \"_prepare_input_data\", fake_prepare)\ntests/test_pipeline_helpers_additional.py:1060:            pipeline,\ntests/test_pipeline_helpers_additional.py:1064:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:1065:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:1067:            pipeline,\ntests/test_pipeline_helpers_additional.py:1073:        mp.setattr(pipeline, \"information_ratio\", lambda *args, **kwargs: 0.0)\ntests/test_pipeline_helpers_additional.py:1141:            pipeline,\ntests/test_pipeline_helpers_additional.py:1209:            pipeline,\ntests/test_pipeline_helpers_additional.py:1269:            pipeline,\ntests/test_pipeline_helpers_additional.py:1274:            pipeline,\ntests/test_pipeline_helpers_additional.py:1280:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:1284:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:1286:            pipeline,\ntests/test_pipeline_helpers_additional.py:1291:            pipeline,\ntests/test_pipeline_helpers_additional.py:1297:        mp.setattr(pipeline, \"information_ratio\", lambda *args, **kwargs: 0.0)\ntests/test_pipeline_helpers_additional.py:1383:            pipeline,\ntests/test_pipeline_helpers_additional.py:1388:            pipeline,\ntests/test_pipeline_helpers_additional.py:1392:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:1393:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:1395:            pipeline,\ntests/test_pipeline_helpers_additional.py:1400:            pipeline,\ntests/test_pipeline_helpers_additional.py:1406:        mp.setattr(pipeline, \"information_ratio\", lambda *args, **kwargs: 0.0)\ntests/test_pipeline_helpers_additional.py:1410:            pipeline,\ntests/test_pipeline_helpers_additional.py:1471:            pipeline,\ntests/test_pipeline_helpers_additional.py:1476:            pipeline,\ntests/test_pipeline_helpers_additional.py:1482:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:1483:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:1485:            pipeline,\ntests/test_pipeline_helpers_additional.py:1490:            pipeline,\ntests/test_pipeline_helpers_additional.py:1496:        mp.setattr(pipeline, \"information_ratio\", lambda *args, **kwargs: 0.0)\ntests/test_pipeline_helpers_additional.py:1557:            pipeline,\ntests/test_pipeline_helpers_additional.py:1562:            pipeline,\ntests/test_pipeline_helpers_additional.py:1568:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:1569:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:1571:            pipeline,\ntests/test_pipeline_helpers_additional.py:1576:            pipeline,\ntests/test_pipeline_helpers_additional.py:1582:        mp.setattr(pipeline, \"information_ratio\", lambda *args, **kwargs: 0.0)\ntests/test_pipeline_helpers_additional.py:1642:            pipeline,\ntests/test_pipeline_helpers_additional.py:1647:            pipeline,\ntests/test_pipeline_helpers_additional.py:1653:        mp.setattr(pipeline, \"compute_constrained_weights\", fake_weights)\ntests/test_pipeline_helpers_additional.py:1654:        mp.setattr(pipeline, \"build_regime_payload\", lambda **kwargs: {})\ntests/test_pipeline_helpers_additional.py:1656:            pipeline,\ntests/test_pipeline_helpers_additional.py:1661:            pipeline,\ntests/test_pipeline_helpers_additional.py:1667:        mp.setattr(pipeline, \"information_ratio\", lambda *args, **kwargs: 0.0)\ntests/test_pipeline_helpers_additional.py:1722:        mp.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_helpers_additional.py:1724:            pipeline,\ntests/test_pipeline_helpers_additional.py:1733:        mp.setattr(pipeline, \"_build_trend_spec\", lambda cfg, vol: SimpleNamespace())\ntests/test_pipeline_helpers_additional.py:1734:        mp.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_helpers_additional.py:1736:        result = pipeline.run(cfg)\ntests/test_pipeline_helpers_additional.py:1775:        mp.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_helpers_additional.py:1777:            pipeline,\ntests/test_pipeline_helpers_additional.py:1786:        mp.setattr(pipeline, \"_build_trend_spec\", lambda cfg, vol: SimpleNamespace())\ntests/test_pipeline_helpers_additional.py:1787:        mp.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_helpers_additional.py:1789:        pipeline.run(cfg)\ntests/test_pipeline_helpers_additional.py:1798:        pipeline.run_full(cfg)\ntests/test_pipeline_helpers_additional.py:1830:        mp.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_helpers_additional.py:1832:            pipeline,\ntests/test_pipeline_helpers_additional.py:1841:        mp.setattr(pipeline, \"_build_trend_spec\", lambda cfg, vol: SimpleNamespace())\ntests/test_pipeline_helpers_additional.py:1842:        mp.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_helpers_additional.py:1844:        result = pipeline.run_full(cfg)\ntests/test_pipeline_helpers_additional.py:1879:        mp.setattr(pipeline, \"load_csv\", fake_load_csv)\ntests/test_pipeline_helpers_additional.py:1881:            pipeline,\ntests/test_pipeline_helpers_additional.py:1890:        mp.setattr(pipeline, \"_build_trend_spec\", lambda cfg, vol: SimpleNamespace())\ntests/test_pipeline_helpers_additional.py:1891:        mp.setattr(pipeline, \"_run_analysis\", fake_run_analysis)\ntests/test_pipeline_helpers_additional.py:1893:        pipeline.run_full(cfg)\ntests/smoke/test_pipeline_smoke.py:3:from trend_analysis.pipeline import run_analysis\ntests/workflows/test_autofix_pipeline_diverse.py:39:def test_autofix_pipeline_handles_diverse_errors(\ntests/workflows/test_autofix_pipeline_diverse.py:98:    numpy_test = tests_dir / \"test_pipeline_warmup_autofix.py\"\ntests/workflows/test_autofix_pipeline_diverse.py:178:        {Path(\"tests/test_pipeline_warmup_autofix.py\")},\ntests/workflows/test_autofix_pipeline_live_docs.py:39:def test_autofix_pipeline_repairs_live_documents(\ntests/workflows/test_autofix_trigger_scenario2.py:1:\"\"\"Intentional lint / style issues to exercise autofix pipeline.\ntests/test_multi_period_exits_cooldown.py:89:def _patch_pipeline(monkeypatch: pytest.MonkeyPatch) -> None:\ntests/test_multi_period_exits_cooldown.py:132:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:184:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:225:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:269:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:328:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:372:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:409:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:445:    _patch_pipeline(monkeypatch)\ntests/test_multi_period_exits_cooldown.py:481:    _patch_pipeline(monkeypatch)\ntests/test_shift_safe_regression.py:5:from trend_analysis.pipeline import compute_signal\ntests/app/test_demo_runner_component.py:146:def test_build_pipeline_config_translates_weights() -> None:\ntests/app/test_demo_runner_component.py:160:    config = demo_runner._build_pipeline_config(sim_cfg, weights, benchmark=\"SPX\")\ntests/app/test_demo_runner_component.py:200:    assert setup.pipeline_config.sample_split[\"out_end\"] == \"2020-06\"\ntests/app/test_demo_runner_component.py:215:        pipeline_config=cast(Config, SimpleNamespace()),\ntests/app/test_demo_runner_component.py:303:    pipeline_config = demo_runner.Config(\ntests/app/test_demo_runner_component.py:324:        pipeline_config=pipeline_config,\ntests/app/test_demo_runner_component.py:355:    assert captured[\"config\"] is pipeline_config\ntests/app/test_demo_runner_component.py:376:        pipeline_config=SimpleNamespace(),\ntests/app/test_demo_runner_component.py:491:    pipeline_config = demo_runner.Config(\ntests/app/test_demo_runner_component.py:512:        pipeline_config=pipeline_config,\ntests/test_logging_module.py:5:the pipeline run logging experience, so we focus on verifying that:\ntests/test_robust_weighting_integration.py:1:\"\"\"Integration checks for robustness settings flowing through the pipeline.\"\"\"\ntests/trend_analysis/test_presets.py:162:def test_metrics_pipeline_translates_keys(sample_preset: presets.TrendPreset):\ntests/trend_analysis/test_presets.py:163:    pipeline_weights = sample_preset.metrics_pipeline()\ntests/trend_analysis/test_presets.py:164:    assert pipeline_weights == {\"Sharpe\": 2.0}\ntests/trend_analysis/test_presets.py:311:    assert presets.pipeline_metric_key(\"volatility\") == \"Volatility\"\ntests/trend_analysis/test_presets.py:312:    assert presets.pipeline_metric_key(None) is None  # type: ignore[arg-type]\ntests/test_run_analysis.py:12:from trend_analysis.pipeline import Stats, calc_portfolio_returns, run_analysis\ntests/test_api_run_simulation_branches.py:40:    \"\"\"When the pipeline returns ``None`` an empty ``RunResult`` is\ntests/test_pipeline_helpers.py:1:\"\"\"Focused unit tests for helper utilities in ``trend_analysis.pipeline``.\"\"\"\ntests/test_pipeline_helpers.py:10:from trend_analysis.pipeline import (\ntests/test_rank_widgets.py:136:    monkeypatch.setattr(rank_widgets.pipeline, \"run_analysis\", fake_run_analysis)\ntests/test_rank_selection.py:4:from trend_analysis.pipeline import run_analysis\ntests/quarantine.yml:7:  - id: tests/test_pipeline.py::test_drawdown_chart_snapshot\ntests/test_pipeline.py:7:from trend_analysis import config, pipeline, risk\ntests/test_pipeline.py:67:    out = pipeline.run(cfg)\ntests/test_pipeline.py:79:    # Some pipeline configurations now emit in/out-of-sample average correlation\ntests/test_pipeline.py:90:    out = pipeline.run(cfg)\ntests/test_pipeline.py:99:        pipeline.run(cfg)\ntests/test_pipeline.py:107:    res = pipeline.run_analysis(\ntests/test_pipeline.py:120:    expected_sharpe = pipeline.sharpe_ratio(\ntests/test_pipeline.py:127:    caplog.set_level(logging.INFO, logger=\"trend_analysis.pipeline\")\ntests/test_pipeline.py:130:    res = pipeline._run_analysis(\ntests/test_pipeline.py:151:    result = pipeline.run(cfg)\ntests/test_pipeline.py:171:    result = pipeline.run(cfg)\ntests/test_pipeline.py:180:        pipeline.run(cfg)\ntests/test_pipeline.py:195:    res = pipeline.run_analysis(\ntests/test_pipeline.py:204:        pipeline.run_analysis(df, \"2020-01\", \"2020-03\", \"2020-04\", \"2020-06\", 1.0, 0.0)\ntests/test_pipeline.py:210:    res = pipeline.run_analysis(\ntests/test_pipeline.py:227:    res = pipeline.run_analysis(\ntests/test_pipeline.py:244:    res_in_empty = pipeline.run_analysis(\ntests/test_pipeline.py:257:    res_out_empty = pipeline.run_analysis(\ntests/test_pipeline.py:283:        pipeline.run(cfg)\ntests/test_pipeline.py:288:    res = pipeline.run_analysis(\ntests/test_pipeline.py:304:    res = pipeline.run_full(cfg)\ntests/test_pipeline.py:327:    res_rp = pipeline.run_full(cfg)\ntests/test_pipeline.py:334:    res_diag = pipeline.run_full(cfg)\ntests/test_pipeline.py:368:    preprocess = pipeline._prepare_preprocess_stage(\ntests/test_pipeline.py:378:    assert not isinstance(preprocess, pipeline.PipelineResult)\ntests/test_pipeline.py:379:    window = pipeline._build_sample_windows(\ntests/test_pipeline.py:386:    assert not isinstance(window, pipeline.PipelineResult)\ntests/test_pipeline.py:391:    res = pipeline.run_full(cfg)\ntests/test_pipeline.py:467:    res = pipeline.run_analysis(\ntests/test_pipeline.py:481:    # The pipeline should adopt the constrained weights returned by the helper.\ntests/test_pipeline.py:500:    res = pipeline.run_analysis(\ntests/test_pipeline.py:514:    # When constraints processing fails the pipeline should keep the equal weights.\ntests/test_pipeline.py:526:    res = pipeline.run_analysis(\ntests/test_pipeline.py:546:# Tests that monkeypatch pipeline functions must run serially.\ntests/test_pipeline.py:552:    original_ir = pipeline.information_ratio\ntests/test_pipeline.py:562:    # Patch the module-level binding in pipeline.py so run_analysis sees our stub\ntests/test_pipeline.py:563:    monkeypatch.setattr(pipeline, \"information_ratio\", selective_boom)\ntests/test_pipeline.py:565:    res = pipeline.run_analysis(\ntests/test_trend_model_cli.py:125:        \"_run_pipeline\",\ntests/test_trend_model_cli.py:180:    def fake_run_pipeline(*args, **kwargs):\ntests/test_trend_model_cli.py:183:    monkeypatch.setattr(cli, \"_run_pipeline\", fake_run_pipeline)\ntests/test_trend_model_cli.py:235:        \"_run_pipeline\",\ntests/test_shift_safe_pipeline.py:9:from trend_analysis.pipeline import compute_signal, position_from_signal\ntests/test_shift_safe_pipeline.py:44:def test_shift_safe_pipeline_is_causal(returns):\ntests/test_no_lookahead.py:13:from trend_analysis.pipeline import compute_signal, position_from_signal\ntests/test_pipeline_constraints_integration.py:4:from trend_analysis import pipeline\ntests/test_pipeline_constraints_integration.py:6:from trend_analysis.pipeline import _run_analysis\ntests/test_pipeline_constraints_integration.py:58:def test_pipeline_applies_cash_and_max_weight_constraints():\ntests/test_pipeline_constraints_integration.py:87:def test_pipeline_max_weight_with_vol_adjust_enabled():\ntests/test_pipeline_constraints_integration.py:144:    result = pipeline.run_full(cfg).unwrap()\ntests/test_pipeline_constraints_integration.py:153:def test_pipeline_long_only_blocks_negative_custom_weights():\ntests/test_pipeline_constraints_integration.py:194:def test_pipeline_long_only_clips_negative_weight_engine_weights():\ntests/test_pipeline_indices.py:3:from trend_analysis.pipeline import run_analysis\ntests/test_trend_analysis_cli_main.py:587:        cli.pipeline, \"run\", lambda cfg: pd.DataFrame({\"metric\": [1.0]})\ntests/test_trend_analysis_cli_main.py:589:    monkeypatch.setattr(cli.pipeline, \"run_full\", lambda cfg: {\"portfolio\": [1, 2, 3]})\ntests/test_trend_analysis_cli_main.py:785:            if name == \"run_pipeline\":\ntests/test_trend_analysis_cli_main.py:795:    stub._run_pipeline = record(\"run_pipeline\")  # type: ignore[attr-defined]\ntests/test_trend_analysis_cli_main.py:807:    result = cli._run_pipeline(\ntests/test_trend_analysis_cli_main.py:818:        \"run_pipeline\",\ntests/test_run_full.py:6:from trend_analysis.pipeline import run, run_full\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_26","type":"reasoning","text":"**Planning pipeline refactor and re-exports**\n\nI'm working through how to shrink pipeline.py below 500 lines by moving most helpers and preprocess/selection/portfolio logic into stage modules or new helper modules, while keeping backward-compatible imports and test monkeypatching working via re-exports. Iâ€™m also considering where to place enigmatic pieces like inception masking and config helpers, thinking about module boundaries and import dependencies as I go."}}
{"type":"item.started","item":{"id":"item_27","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,260p' src/trend_analysis/data.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_27","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,260p' src/trend_analysis/data.py\"","aggregated_output":"import logging\nimport stat\nfrom pathlib import Path\nfrom typing import Any, Literal, Mapping, Optional, cast\n\nimport pandas as pd\nfrom pandas.api.types import is_datetime64_any_dtype\n\nfrom data.contracts import coerce_to_utc, validate_prices\nfrom trend.input_validation import (\n    InputSchema,\n    InputValidationError,\n    validate_input,\n)\n\nfrom .constants import NUMERICAL_TOLERANCE_HIGH\nfrom .io.market_data import (\n    MarketDataValidationError,\n    ValidatedMarketData,\n    validate_market_data,\n)\n\nMissingLimitArg = int | str | Mapping[str, int | str | None] | None\n\nDEFAULT_POLICY_FALLBACK = \"drop\"\nRETURNS_SCHEMA = InputSchema(\n    date_column=\"Date\",\n    required_columns=(\"Date\",),\n    non_nullable=(\"Date\",),\n)\n\n\ndef _normalise_policy_alias(value: str | None) -> str:\n    if value is None:\n        return DEFAULT_POLICY_FALLBACK\n    policy = value.strip().lower()\n    if not policy:\n        return DEFAULT_POLICY_FALLBACK\n    if policy in {\"both\", \"bfill\", \"backfill\"}:\n        return \"ffill\"\n    if policy in {\"zeros\", \"zero_fill\", \"fillzero\"}:\n        return \"zero\"\n    return policy\n\n\ndef _coerce_limit_entry(value: Any) -> Optional[int]:\n    if value in (None, \"\", \"none\"):\n        return None\n    try:\n        limit_int = int(value)\n    except (TypeError, ValueError):\n        raise ValueError(\"Missing-data limit values must be integers or null.\")\n    if limit_int < 0:\n        raise ValueError(\"Missing-data limits cannot be negative.\")\n    return limit_int\n\n\ndef _coerce_policy_kwarg(value: Any) -> str | Mapping[str, str] | None:\n    if value is None:\n        return None\n    if isinstance(value, str):\n        return value\n    if isinstance(value, Mapping):\n        return value\n    raise TypeError(\"missing_policy must be a string, mapping, or None.\")\n\n\ndef _coerce_limit_kwarg(value: Any) -> int | Mapping[str, int | None] | None:\n    if value is None:\n        return None\n    if isinstance(value, Mapping):\n        return value\n    if isinstance(value, (int, float)) and float(value).is_integer():\n        return int(value)\n    if isinstance(value, str):\n        lowered = value.strip().lower()\n        if lowered in {\"\", \"none\", \"null\"}:\n            return None\n        if lowered.isdigit():\n            return int(lowered)\n    raise TypeError(\"missing_limit must be an integer, mapping, or None.\")\n\n\nlogger = logging.getLogger(__name__)\n\nValidationErrorMode = Literal[\"raise\", \"log\"]\n\n\ndef compute_inception_dates(\n    frame: pd.DataFrame,\n    *,\n    date_col: str = \"Date\",\n    columns: list[str] | None = None,\n    nonzero_tol: float = NUMERICAL_TOLERANCE_HIGH,\n) -> dict[str, pd.Timestamp | None]:\n    \"\"\"Return per-column inception dates inferred from first non-zero return.\n\n    Many vendor datasets encode \"pre-inception\" history as a flat line of\n    zeros instead of NaN. For universe construction we must treat those rows\n    as missing; this helper infers the effective inception date as the first\n    timestamp where ``abs(return) > nonzero_tol``.\n\n    Parameters\n    ----------\n    frame:\n        Input frame containing a ``date_col`` column or a DatetimeIndex.\n    date_col:\n        Name of the date column when present.\n    columns:\n        Optional list of columns to compute inception dates for. Defaults to\n        all numeric columns except ``date_col``.\n    nonzero_tol:\n        Absolute tolerance used to treat tiny values as zero.\n\n    Returns\n    -------\n    dict[str, pd.Timestamp | None]\n        Mapping from column name to inception timestamp (month-end aligned\n        as stored in the input). Columns with no non-zero observations return\n        ``None``.\n    \"\"\"\n\n    if frame.empty:\n        return {}\n\n    if date_col in frame.columns:\n        dates = pd.to_datetime(frame[date_col], errors=\"coerce\")\n        values = frame.drop(columns=[date_col])\n    else:\n        if not isinstance(frame.index, pd.DatetimeIndex):\n            raise TypeError(\n                \"compute_inception_dates requires a Date column or DatetimeIndex\"\n            )\n        dates = pd.to_datetime(frame.index, errors=\"coerce\")\n        values = frame\n\n    out: dict[str, pd.Timestamp | None] = {}\n    if columns is None:\n        columns = [\n            str(c)\n            for c in values.select_dtypes(\"number\").columns\n            if str(c) != str(date_col)\n        ]\n\n    for col in columns:\n        if col not in values.columns:\n            continue\n        s = pd.to_numeric(values[col], errors=\"coerce\")\n        active = s.abs() > float(nonzero_tol)\n        if not active.any():\n            out[col] = None\n            continue\n        # First active timestamp\n        first_idx = int(active.to_numpy().argmax())\n        ts = dates.iloc[first_idx]\n        out[col] = None if pd.isna(ts) else pd.Timestamp(ts)\n    return out\n\n\ndef _finalise_validated_frame(\n    validated: ValidatedMarketData, *, include_date_column: bool\n) -> pd.DataFrame:\n    base_frame = validated.frame\n    if include_date_column:\n        result = base_frame.reset_index()\n    else:\n        result = base_frame.copy()\n\n    attrs = dict(base_frame.attrs)\n    attrs.setdefault(\"market_data\", {})\n    attrs[\"market_data\"][\"metadata\"] = validated.metadata\n    attrs[\"market_data_mode\"] = validated.metadata.mode.value\n    attrs[\"market_data_frequency\"] = validated.metadata.frequency\n    attrs[\"market_data_frequency_code\"] = validated.metadata.frequency_detected\n    attrs[\"market_data_frequency_label\"] = validated.metadata.frequency_label\n    attrs[\"market_data_frequency_median_spacing_days\"] = (\n        validated.metadata.frequency_median_spacing_days\n    )\n    attrs[\"market_data_frequency_missing_periods\"] = (\n        validated.metadata.frequency_missing_periods\n    )\n    attrs[\"market_data_frequency_max_gap_periods\"] = (\n        validated.metadata.frequency_max_gap_periods\n    )\n    attrs[\"market_data_frequency_tolerance_periods\"] = (\n        validated.metadata.frequency_tolerance_periods\n    )\n    attrs[\"market_data_columns\"] = list(validated.metadata.columns)\n    attrs[\"market_data_rows\"] = validated.metadata.rows\n    attrs[\"market_data_date_range\"] = validated.metadata.date_range\n    attrs[\"market_data_missing_policy\"] = validated.metadata.missing_policy\n    attrs[\"market_data_missing_policy_limit\"] = validated.metadata.missing_policy_limit\n    attrs[\"market_data_missing_policy_summary\"] = (\n        validated.metadata.missing_policy_summary\n    )\n\n    # Infer inception dates (first non-zero observation) once at ingestion time.\n    # This is used by the multi-period engine to exclude pre-inception series\n    # even when a vendor encodes them as flat zeros.\n    try:\n        inception = compute_inception_dates(\n            base_frame,\n            date_col=\"Date\",\n        )\n        # Store as ISO strings for JSON friendliness.\n        attrs[\"inception_dates\"] = {\n            k: (v.strftime(\"%Y-%m-%d\") if v is not None else None)\n            for k, v in inception.items()\n        }\n    except Exception:  # pragma: no cover - best effort metadata\n        attrs.setdefault(\"inception_dates\", {})\n\n    result.attrs = attrs\n    return result\n\n\ndef _contract_frequency(attrs: Mapping[str, Any]) -> str | None:\n    candidates: list[str | None] = []\n    for key in (\n        \"market_data_frequency_code\",\n        \"market_data_frequency\",\n    ):\n        value = attrs.get(key)\n        if value is None:\n            candidates.append(None)\n            continue\n        candidates.append(str(value))\n\n    market_meta = attrs.get(\"market_data\")\n    if isinstance(market_meta, Mapping):\n        metadata = market_meta.get(\"metadata\")\n        if metadata is not None:\n            candidates.append(getattr(metadata, \"frequency_detected\", None))\n            candidates.append(getattr(metadata, \"frequency\", None))\n\n    for candidate in candidates:\n        if candidate:\n            stripped = candidate.strip()\n            if stripped:\n                return stripped\n    return None\n\n\ndef _apply_price_contract(\n    frame: pd.DataFrame, *, include_date_column: bool\n) -> pd.DataFrame:\n    if frame.empty:\n        return frame\n\n    freq = _contract_frequency(frame.attrs) or \"D\"\n    contract_frame = coerce_to_utc(frame)\n    validate_prices(contract_frame, freq=freq)\n\n    frame.index = contract_frame.index\n    frame.index.name = contract_frame.index.name\n\n    if include_date_column and \"Date\" in frame.columns:\n        frame[\"Date\"] = contract_frame[\"Date\"].to_numpy()\n        # Keeping a \"Date\" column alongside a DatetimeIndex named \"Date\" confuses\n        # downstream operations such as ``DataFrame.sort_values``. Clear the index\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_28","type":"reasoning","text":"**Investigating inception dates usage**"}}
{"type":"item.started","item":{"id":"item_29","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_29","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_30","type":"reasoning","text":"**Investigating inception masking location**"}}
{"type":"item.started","item":{"id":"item_31","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception_dates\" src/trend_analysis'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_31","type":"command_execution","command":"/bin/bash -lc 'rg -n \"inception_dates\" src/trend_analysis'","aggregated_output":"src/trend_analysis/data.py:89:def compute_inception_dates(\nsrc/trend_analysis/data.py:132:                \"compute_inception_dates requires a Date column or DatetimeIndex\"\nsrc/trend_analysis/data.py:201:        inception = compute_inception_dates(\nsrc/trend_analysis/data.py:206:        attrs[\"inception_dates\"] = {\nsrc/trend_analysis/data.py:211:        attrs.setdefault(\"inception_dates\", {})\nsrc/trend_analysis/multi_period/engine.py:910:        from ..data import compute_inception_dates\nsrc/trend_analysis/multi_period/engine.py:912:        inception_raw = compute_inception_dates(cleaned)\nsrc/trend_analysis/multi_period/engine.py:929:        cleaned.attrs[\"inception_dates\"] = {\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_32","type":"reasoning","text":"**Investigating inception masking logic location**"}}
{"type":"item.started","item":{"id":"item_33","type":"command_execution","command":"/bin/bash -lc 'rg -n \"def load_csv\" -n src/trend_analysis/data.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_33","type":"command_execution","command":"/bin/bash -lc 'rg -n \"def load_csv\" -n src/trend_analysis/data.py'","aggregated_output":"404:def load_csv(\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_34","type":"command_execution","command":"/bin/bash -lc \"sed -n '404,520p' src/trend_analysis/data.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_34","type":"command_execution","command":"/bin/bash -lc \"sed -n '404,520p' src/trend_analysis/data.py\"","aggregated_output":"def load_csv(\n    path: str,\n    *,\n    errors: ValidationErrorMode = \"log\",\n    include_date_column: bool = True,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: MissingLimitArg = None,\n    **_legacy_kwargs: object,\n) -> Optional[pd.DataFrame]:\n    \"\"\"Load and validate a CSV expecting a ``Date`` column.\"\"\"\n\n    if missing_policy is None and \"nan_policy\" in _legacy_kwargs:\n        missing_policy = _coerce_policy_kwarg(_legacy_kwargs.pop(\"nan_policy\"))\n    if missing_limit is None and \"nan_limit\" in _legacy_kwargs:\n        missing_limit = _coerce_limit_kwarg(_legacy_kwargs.pop(\"nan_limit\"))\n    if missing_limit is None and \"missing_limit\" in _legacy_kwargs:\n        # ``missing_limit`` is also an explicit keyword argument on the public\n        # signature.  Modern Python will always bind that keyword to the\n        # dedicated parameter, meaning this compatibility branch only existed\n        # for very early call-sites that splatted dictionaries before the\n        # signature was expanded.  Retain the guard for clarity, but mark it as\n        # unreachable for coverage to avoid penalising the suite.\n        missing_limit = cast(\n            MissingLimitArg, _legacy_kwargs.pop(\"missing_limit\")\n        )  # pragma: no cover\n\n    p = Path(path)\n    try:\n        if not p.exists():\n            raise FileNotFoundError(path)\n        if p.is_dir():\n            raise IsADirectoryError(path)\n        mode = p.stat().st_mode\n        if not _is_readable(mode):\n            if errors == \"raise\":\n                raise PermissionError(f\"Permission denied accessing file: {path}\")\n            logger.error(f\"Permission denied accessing file: {path}\")\n            return None\n\n        raw = pd.read_csv(str(p))\n        result = _validate_payload(\n            raw,\n            origin=str(p),\n            errors=errors,\n            include_date_column=include_date_column,\n            missing_policy=missing_policy,\n            missing_limit=missing_limit,\n        )\n        if isinstance(result, pd.DataFrame) and include_date_column:\n            result = result.reset_index(drop=True)\n        return result\n    except (\n        FileNotFoundError,\n        PermissionError,\n        IsADirectoryError,\n        pd.errors.EmptyDataError,\n        pd.errors.ParserError,\n    ) as exc:\n        if errors == \"raise\":\n            raise\n        logger.error(str(exc))\n    except MarketDataValidationError as exc:\n        if errors == \"raise\":\n            raise\n        msg_lower = exc.user_message.lower()\n        message = exc.user_message\n        if \"could not be parsed\" in msg_lower or \"unable to parse\" in msg_lower:\n            message = f\"{exc.user_message}\\nUnable to parse Date values in {path}\"\n        logger.error(\"Validation failed (%s): %s\", path, message)\n    except InputValidationError as exc:\n        if errors == \"raise\":\n            raise\n        logger.error(\"Validation failed (%s): %s\", path, exc.user_message)\n    except Exception as exc:  # pragma: no cover - defensive guard\n        if errors == \"raise\":\n            raise\n        logger.error(\"Unexpected error loading %s: %s\", path, exc)\n    return None\n\n\ndef load_parquet(\n    path: str,\n    *,\n    errors: ValidationErrorMode = \"log\",\n    include_date_column: bool = True,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: MissingLimitArg = None,\n    **_legacy_kwargs: object,\n) -> Optional[pd.DataFrame]:\n    \"\"\"Load and validate a Parquet file containing market data.\"\"\"\n\n    if missing_policy is None and \"nan_policy\" in _legacy_kwargs:\n        missing_policy = _coerce_policy_kwarg(_legacy_kwargs.pop(\"nan_policy\"))\n    if missing_limit is None and \"nan_limit\" in _legacy_kwargs:\n        missing_limit = _coerce_limit_kwarg(_legacy_kwargs.pop(\"nan_limit\"))\n    if missing_limit is None and \"missing_limit\" in _legacy_kwargs:\n        missing_limit = cast(\n            MissingLimitArg, _legacy_kwargs.pop(\"missing_limit\")\n        )  # pragma: no cover\n\n    p = Path(path)\n    try:\n        if not p.exists():\n            raise FileNotFoundError(path)\n        if p.is_dir():\n            raise IsADirectoryError(path)\n        mode = p.stat().st_mode\n        if not _is_readable(mode):\n            raise PermissionError(f\"Permission denied accessing file: {path}\")\n\n        raw = pd.read_parquet(str(p))\n        result = _validate_payload(\n            raw,\n            origin=str(p),\n            errors=errors,\n            include_date_column=include_date_column,\n            missing_policy=missing_policy,\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_35","type":"reasoning","text":"**Investigating inception masking logic**"}}
{"type":"item.started","item":{"id":"item_36","type":"command_execution","command":"/bin/bash -lc 'rg -n \"mask\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_36","type":"command_execution","command":"/bin/bash -lc 'rg -n \"mask\" src/trend_analysis/pipeline.py'","aggregated_output":"498:    in_mask = (preprocess.df[preprocess.date_col] >= in_sdate) & (\n501:    out_mask = (preprocess.df[preprocess.date_col] >= out_sdate) & (\n504:    in_df_raw = preprocess.df.loc[in_mask].set_index(preprocess.date_col)\n505:    out_df_raw = preprocess.df.loc[out_mask].set_index(preprocess.date_col)\n676:        mask = (preprocess.df[preprocess.date_col] >= window.in_start) & (\n679:        sub = preprocess.df.loc[mask, fund_cols]\n771:        outside_mask = (idx < allowed_start) | (idx > allowed_end)\n772:        if bool(outside_mask.any()):\n773:            oob_index = idx[outside_mask]\n803:            outside_mask = (frame.index < allowed_start) | (frame.index > allowed_end)\n804:            if strict and bool(outside_mask.any()):\n805:                first = pd.Timestamp(frame.index[outside_mask].min())\n806:                last = pd.Timestamp(frame.index[outside_mask].max())\n1784:        in_mask = periods <= boundary\n1785:        out_mask = periods > boundary\n1786:        if in_mask.any() and out_mask.any():\n1787:            in_periods = periods[in_mask]\n1788:            out_periods = periods[out_mask]\n2036:    coverage_mask = coverage_counts >= min_non_null\n2081:            c for c in numeric_cols if c not in idx_set and coverage_mask.get(c, False)\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_37","type":"reasoning","text":"**Planning function relocation without behavior changes**"}}
{"type":"item.started","item":{"id":"item_38","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' src/trend_analysis/util/missing.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_38","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' src/trend_analysis/util/missing.py\"","aggregated_output":"\"\"\"Utilities for enforcing missing-data policies on return frames.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom dataclasses import dataclass, field\nfrom typing import Any, Iterable, Iterator\n\nimport pandas as pd\n\n__all__ = [\"MissingPolicyResult\", \"apply_missing_policy\"]\n\n\n@dataclass(frozen=True, slots=True)\nclass MissingPolicyResult(Mapping[str, Any]):\n    \"\"\"Structured summary returned by :func:`apply_missing_policy`.\"\"\"\n\n    policy: dict[str, str]\n    default_policy: str\n    limit: dict[str, int | None]\n    default_limit: int | None\n    filled: dict[str, int]\n    dropped_assets: tuple[str, ...]\n    summary: str\n    _mapping: dict[str, Any] = field(init=False, repr=False)\n\n    def __post_init__(self) -> None:\n        policy = dict(self.policy)\n        limit = dict(self.limit)\n        filled = {k: int(v) for k, v in self.filled.items()}\n        dropped = tuple(self.dropped_assets)\n        total_filled = sum(filled.values())\n        object.__setattr__(self, \"policy\", policy)\n        object.__setattr__(self, \"limit\", limit)\n        object.__setattr__(self, \"filled\", filled)\n        object.__setattr__(self, \"dropped_assets\", dropped)\n        mapping: dict[str, Any] = {\n            \"policy\": policy,\n            \"policy_map\": policy,\n            \"default_policy\": self.default_policy,\n            \"limit\": limit,\n            \"limit_map\": limit,\n            \"default_limit\": self.default_limit,\n            \"filled\": filled,\n            \"dropped\": list(dropped),\n            \"dropped_assets\": list(dropped),\n            \"summary\": self.summary,\n            \"total_filled\": total_filled,\n        }\n        object.__setattr__(self, \"_mapping\", mapping)\n\n    def __getitem__(self, key: str) -> Any:  # pragma: no cover - delegate\n        return self._mapping[key]\n\n    def __iter__(self) -> Iterator[str]:  # pragma: no cover - delegate\n        return iter(self._mapping)\n\n    def __len__(self) -> int:  # pragma: no cover - delegate\n        return len(self._mapping)\n\n    def get(self, key: str, default: Any = None) -> Any:\n        return self._mapping.get(key, default)\n\n    @property\n    def filled_cells(self) -> tuple[tuple[str, int], ...]:\n        return tuple(\n            (asset, count) for asset, count in sorted(self.filled.items()) if count > 0\n        )\n\n    @property\n    def total_filled(self) -> int:\n        return sum(self.filled.values())\n\n\ndef _coerce_policy(policy: str | None) -> str:\n    value = (policy or \"drop\").strip().lower()\n    if value in {\"both\", \"bfill\", \"backfill\"}:\n        value = \"ffill\"\n    if value in {\"zeros\", \"zero_fill\", \"fillzero\"}:\n        value = \"zero\"\n    if value not in {\"drop\", \"ffill\", \"zero\"}:\n        raise ValueError(f\"Unsupported missing-data policy: {policy!r}\")\n    return value\n\n\ndef _coerce_limit(limit: Any) -> int | None:\n    if limit is None:\n        return None\n    try:\n        value = int(limit)\n    except (TypeError, ValueError):  # pragma: no cover - defensive guard\n        raise ValueError(f\"Invalid forward-fill limit: {limit!r}\") from None\n    if value < 0:\n        raise ValueError(\"Forward-fill limit must be non-negative\")\n    return value\n\n\ndef _resolve_mapping(\n    spec: str | Mapping[str, str] | None, default: str\n) -> tuple[str, dict[str, str]]:\n    if spec is None or isinstance(spec, str):\n        return _coerce_policy(spec or default), {}\n    overrides = {k: _coerce_policy(v) for k, v in spec.items() if k != \"default\"}\n    default_policy = _coerce_policy(spec.get(\"default\", default))\n    return default_policy, overrides\n\n\ndef _resolve_limits(\n    limit: int | Mapping[str, int | None] | None,\n) -> tuple[int | None, dict[str, int | None]]:\n    if isinstance(limit, Mapping):\n        resolved = {k: _coerce_limit(v) for k, v in limit.items() if k != \"default\"}\n        default_limit = _coerce_limit(limit.get(\"default\"))\n        return default_limit, resolved\n    return _coerce_limit(limit), {}\n\n\ndef _policy_display(\n    default_policy: str,\n    overrides: Mapping[str, str],\n    default_limit: int | None,\n    limit_overrides: Mapping[str, int | None],\n) -> str:\n    limit_part = f\"limit={default_limit}\" if default_limit is not None else \"unbounded\"\n    text = [f\"default={default_policy}({limit_part})\"]\n    if overrides:\n        over = \", \".join(\n            f\"{asset}={policy}\"\n            + (\n                f\"(limit={limit_overrides.get(asset)})\"\n                if policy == \"ffill\" and asset in limit_overrides\n                else \"\"\n            )\n            for asset, policy in sorted(overrides.items())\n        )\n        text.append(f\"overrides: {over}\")\n    return \"; \".join(text)\n\n\ndef apply_missing_policy(\n    df: pd.DataFrame,\n    policy: str | Mapping[str, str] | None,\n    limit: int | Mapping[str, int | None] | None = None,\n    *,\n    columns: Iterable[str] | None = None,\n    enforce_completeness: bool = True,\n) -> tuple[pd.DataFrame, MissingPolicyResult]:\n    \"\"\"Apply a missing-data policy column by column.\n\n    Parameters\n    ----------\n    df:\n        DataFrame of asset returns indexed by date.\n    policy:\n        Either a single policy name (``\"drop\"``, ``\"ffill\"``, ``\"zero\"``), or a\n        mapping of column names to policies.  The special key ``\"default\"`` sets\n        the default policy when a mapping is provided.\n    limit:\n        Global forward-fill limit, or a mapping of column names to limits.\n    columns:\n        Optional iterable restricting which columns participate.  Columns not in\n        ``columns`` are returned unchanged.\n\n    Returns\n    -------\n    tuple\n        ``(frame, result)`` where ``frame`` is the transformed DataFrame and\n        ``result`` is a :class:`MissingPolicyResult` capturing the effective\n        policy, limits, fills and any dropped columns.\n    \"\"\"\n\n    cols = list(columns) if columns is not None else list(df.columns)\n    work = df.copy()\n\n    default_policy, per_column_policy = _resolve_mapping(policy, \"drop\")\n    default_limit, per_column_limit = _resolve_limits(limit)\n\n    filled_counts: dict[str, int] = {}\n    dropped: list[str] = []\n    applied_policy: dict[str, str] = {}\n    limit_used: dict[str, int | None] = {}\n\n    result_columns: dict[str, pd.Series] = {\n        col: work[col] for col in df.columns if col not in cols\n    }\n    for col in cols:\n        series = work[col]\n        col_policy = per_column_policy.get(col, default_policy)\n        applied_policy[col] = col_policy\n        col_limit = per_column_limit.get(col, default_limit)\n        if col_policy == \"drop\":\n            if series.isna().any() and enforce_completeness:\n                dropped.append(col)\n                continue\n            result_columns[col] = series\n            limit_used[col] = None\n            continue\n        if col_policy == \"ffill\":\n            filled_before = int(series.isna().sum())\n            series = series.ffill(limit=col_limit)\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_39","type":"reasoning","text":"**Planning module refactoring and re-exports**"}}
{"type":"item.started","item":{"id":"item_40","type":"command_execution","command":"/bin/bash -lc \"sed -n '1300,2000p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_40","type":"command_execution","command":"/bin/bash -lc \"sed -n '1300,2000p' src/trend_analysis/pipeline.py\"","aggregated_output":"                pd.DataFrame({label: out_df[col]}), computation.rf_out\n            )[label],\n        }\n        ir_series = information_ratio(computation.out_scaled[fund_cols], out_df[col])\n        ir_dict = (\n            ir_series.to_dict()\n            if isinstance(ir_series, pd.Series)\n            else {fund_cols[0]: float(ir_series)}\n        )\n        try:\n            ir_eq = information_ratio(out_ew_raw, out_df[col])\n            ir_usr = information_ratio(out_user_raw, out_df[col])\n            ir_dict[\"equal_weight\"] = (\n                float(ir_eq)\n                if isinstance(ir_eq, (float, int, np.floating))\n                else float(\"nan\")\n            )\n            ir_dict[\"user_weight\"] = (\n                float(ir_usr)\n                if isinstance(ir_usr, (float, int, np.floating))\n                else float(\"nan\")\n            )\n        except Exception:\n            pass\n        benchmark_ir[label] = ir_dict\n\n    regime_returns_map: dict[str, pd.Series] = {\n        \"User\": out_user.astype(float, copy=False),\n        \"Equal-Weight\": out_ew.astype(float, copy=False),\n    }\n    regime_payload = build_regime_payload(\n        data=preprocess.df,\n        out_index=out_df.index,\n        returns_map=regime_returns_map,\n        risk_free=computation.rf_out,\n        config=regime_cfg,\n        freq_code=preprocess.freq_summary.target,\n        periods_per_year=window.periods_per_year,\n    )\n\n    metadata = build_metadata(\n        universe=preprocess.value_cols_all,\n        selected=fund_cols,\n        lookbacks={\n            \"in_start\": window.in_start,\n            \"in_end\": window.in_end,\n            \"out_start\": window.out_start,\n            \"out_end\": window.out_end,\n        },\n        costs={\n            \"monthly_cost\": monthly_cost,\n            \"target_vol\": target_vol,\n            \"floor_vol\": min_floor if min_floor > 0 else None,\n            \"max_turnover\": computation.turnover_cap,\n        },\n    )\n    metadata[\"frequency\"] = preprocess.frequency_payload\n    metadata[\"missing_data\"] = preprocess.missing_payload\n    metadata[\"risk_free_column\"] = rf_col\n    metadata[\"indices\"] = {\n        \"requested\": selection.requested_indices,\n        \"accepted\": selection.indices_list,\n        \"missing\": selection.missing_indices,\n    }\n\n    return pipeline_success(\n        {\n            \"selected_funds\": fund_cols,\n            \"risk_free_column\": rf_col,\n            \"risk_free_source\": selection.rf_source,\n            \"in_sample_scaled\": computation.in_scaled,\n            \"out_sample_scaled\": computation.out_scaled,\n            \"in_sample_stats\": computation.in_stats,\n            \"out_sample_stats\": computation.out_stats,\n            \"out_sample_stats_raw\": computation.out_stats_raw,\n            \"in_ew_stats\": computation.in_ew_stats,\n            \"out_ew_stats\": computation.out_ew_stats,\n            \"out_ew_stats_raw\": computation.out_ew_stats_raw,\n            \"in_user_stats\": computation.in_user_stats,\n            \"out_user_stats\": computation.out_user_stats,\n            \"out_user_stats_raw\": computation.out_user_stats_raw,\n            \"ew_weights\": computation.ew_weights,\n            \"fund_weights\": computation.user_weights,\n            \"benchmark_stats\": benchmark_stats,\n            \"benchmark_ir\": benchmark_ir,\n            \"score_frame\": computation.score_frame,\n            \"weight_engine_fallback\": computation.weight_engine_fallback,\n            \"weight_engine_diagnostics\": computation.weight_engine_diagnostics,\n            \"preprocessing\": preprocess.preprocess_info,\n            \"preprocessing_summary\": preprocess.preprocess_info.get(\"summary\"),\n            \"risk_diagnostics\": {\n                \"asset_volatility\": computation.risk_diagnostics.asset_volatility,\n                \"portfolio_volatility\": computation.risk_diagnostics.portfolio_volatility,\n                \"turnover\": computation.risk_diagnostics.turnover,\n                \"turnover_value\": computation.risk_diagnostics.turnover_value,\n                \"scale_factors\": computation.risk_diagnostics.scale_factors,\n                \"final_weights\": computation.weights_series,\n            },\n            \"signal_frame\": computation.signal_frame,\n            \"signal_spec\": computation.effective_signal_spec,\n            \"performance_by_regime\": regime_payload.get(\"table\", pd.DataFrame()),\n            \"regime_labels\": regime_payload.get(\"labels\", pd.Series(dtype=\"string\")),\n            \"regime_labels_out\": regime_payload.get(\n                \"out_labels\", pd.Series(dtype=\"string\")\n            ),\n            \"regime_notes\": regime_payload.get(\"notes\", []),\n            \"regime_settings\": regime_payload.get(\"settings\", {}),\n            \"regime_summary\": regime_payload.get(\"summary\"),\n            \"metadata\": metadata,\n        }\n    )\n\n\ndef _cfg_value(cfg: Mapping[str, Any] | Any, key: str, default: Any = None) -> Any:\n    if isinstance(cfg, Mapping):\n        return cfg.get(key, default)\n    return getattr(cfg, key, default)\n\n\ndef _cfg_section(cfg: Mapping[str, Any] | Any, key: str) -> Any:\n    section = _cfg_value(cfg, key, None)\n    if section is None:\n        return {}\n    return section\n\n\ndef _section_get(section: Any, key: str, default: Any = None) -> Any:\n    if section is None:\n        return default\n    if isinstance(section, Mapping):\n        return section.get(key, default)\n    getter = getattr(section, \"get\", None)\n    if callable(getter):\n        try:\n            return getter(key, default)\n        except TypeError:\n            try:\n                return getter(key)\n            except KeyError:\n                return default\n        except KeyError:\n            return default\n    attr_value = getattr(section, key, default)\n    return attr_value\n\n\ndef _resolve_target_vol(vol_adjust_cfg: Mapping[str, Any] | Any) -> float | None:\n    enabled = _section_get(vol_adjust_cfg, \"enabled\")\n    if enabled is False:\n        return None\n    target_raw = _section_get(vol_adjust_cfg, \"target_vol\", 1.0)\n    if target_raw is None:\n        return 1.0\n    try:\n        target = float(target_raw)\n    except (TypeError, ValueError):\n        return 1.0\n    if target <= 0:\n        return None\n    return target\n\n\n# Default multiplier for reducing fund count/selection during risk-off regimes.\n# Must match the value in config/defaults.yml regime.risk_off_fund_count_multiplier\n_DEFAULT_RISK_OFF_FUND_MULTIPLIER = 0.5\n\n\ndef _resolve_regime_label(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    regime_cfg: Mapping[str, Any] | None,\n    benchmarks: Mapping[str, str] | None = None,\n) -> tuple[str | None, Any]:\n    def _resolve_proxy_column(proxy_value: str) -> str | None:\n        columns = window.in_df.columns\n        if proxy_value in columns:\n            return proxy_value\n\n        proxy_lower = proxy_value.lower()\n        if benchmarks:\n            for key, value in benchmarks.items():\n                if proxy_lower == str(key).lower() and value in columns:\n                    return str(value)\n                if proxy_lower == str(value).lower() and value in columns:\n                    return str(value)\n\n        for col in columns:\n            if proxy_lower == str(col).lower():\n                return str(col)\n        return None\n\n    settings = normalise_settings(regime_cfg)\n    if not settings.enabled:\n        return None, settings\n    proxy = settings.proxy\n    if not proxy:\n        return None, settings\n\n    proxy_column = _resolve_proxy_column(proxy)\n    if not proxy_column:\n        return None, settings\n\n    proxy_series = window.in_df[proxy_column].astype(float).dropna()\n    if proxy_series.empty:\n        return None, settings\n    labels = compute_regimes(\n        proxy_series,\n        settings,\n        freq=preprocess.freq_summary.target,\n        periods_per_year=window.periods_per_year,\n    )\n    if labels.empty:\n        return None, settings\n    aligned = labels.reindex(window.in_df.index).ffill().bfill()\n    if aligned.empty:\n        return None, settings\n    return str(aligned.iloc[-1]), settings\n\n\ndef _apply_regime_overrides(\n    *,\n    random_n: int,\n    rank_kwargs: Mapping[str, Any] | None,\n    regime_label: str | None,\n    settings: Any,\n    regime_cfg: Mapping[str, Any] | None = None,\n) -> tuple[int, Mapping[str, Any] | None]:\n    if not regime_label:\n        return random_n, rank_kwargs\n    if regime_label != getattr(settings, \"risk_off_label\", \"Risk-Off\"):\n        return random_n, rank_kwargs\n\n    # Get multiplier from config or use default\n    cfg = dict(regime_cfg or {})\n    multiplier = _DEFAULT_RISK_OFF_FUND_MULTIPLIER\n    if \"risk_off_fund_count_multiplier\" in cfg:\n        try:\n            multiplier = float(cfg[\"risk_off_fund_count_multiplier\"])\n            if multiplier <= 0 or multiplier > 1:\n                multiplier = _DEFAULT_RISK_OFF_FUND_MULTIPLIER\n        except (TypeError, ValueError):\n            pass\n\n    updated_random_n = random_n\n    if isinstance(random_n, int) and random_n > 1:\n        updated_random_n = max(1, int(round(random_n * multiplier)))\n\n    updated_rank = dict(rank_kwargs or {})\n    inclusion_approach = str(updated_rank.get(\"inclusion_approach\", \"\") or \"\").lower()\n    if \"n\" in updated_rank and updated_rank.get(\"n\") is not None:\n        try:\n            current_n = int(updated_rank[\"n\"])\n        except (TypeError, ValueError):\n            current_n = None\n        if current_n is not None and current_n > 1:\n            updated_rank[\"n\"] = max(1, int(round(current_n * multiplier)))\n\n    if inclusion_approach == \"top_pct\" and updated_rank.get(\"pct\") is not None:\n        try:\n            current_pct = float(updated_rank[\"pct\"])\n        except (TypeError, ValueError):\n            current_pct = None\n        if current_pct is not None and current_pct > 0:\n            adjusted_pct = min(1.0, max(0.0, current_pct * multiplier))\n            updated_rank[\"pct\"] = adjusted_pct\n\n    if inclusion_approach == \"threshold\" and updated_rank.get(\"threshold\") is not None:\n        try:\n            current_threshold = float(updated_rank[\"threshold\"])\n        except (TypeError, ValueError):\n            current_threshold = None\n        if current_threshold is not None:\n            if current_threshold > 0:\n                updated_rank[\"threshold\"] = current_threshold / multiplier\n            elif current_threshold < 0:\n                updated_rank[\"threshold\"] = current_threshold * multiplier\n\n    return updated_random_n, updated_rank if updated_rank else rank_kwargs\n\n\ndef _apply_regime_weight_overrides(\n    *,\n    target_vol: float | None,\n    constraints: dict[str, Any] | None,\n    regime_label: str | None,\n    settings: Any,\n    regime_cfg: Mapping[str, Any] | None,\n) -> tuple[float | None, dict[str, Any] | None]:\n    if target_vol is None:\n        return None, constraints\n    if not regime_label:\n        return target_vol, constraints\n    if regime_label != getattr(settings, \"risk_off_label\", \"Risk-Off\"):\n        return target_vol, constraints\n\n    cfg = dict(regime_cfg or {})\n\n    def _coerce_positive_float(value: Any, default: float) -> float:\n        try:\n            num = float(value)\n        except (TypeError, ValueError):\n            return default\n        if num <= 0:\n            return default\n        return num\n\n    updated_target = target_vol\n    if \"risk_off_target_vol\" in cfg:\n        updated_target = _coerce_positive_float(\n            cfg.get(\"risk_off_target_vol\"), target_vol\n        )\n    else:\n        multiplier = _coerce_positive_float(\n            cfg.get(\"risk_off_target_vol_multiplier\", 0.5), 0.5\n        )\n        updated_target = float(target_vol) * multiplier\n\n    return updated_target, constraints\n\n\ndef _unwrap_cfg(cfg: Mapping[str, Any] | Any) -> Any:\n    current = cfg\n    visited: set[int] = set()\n    while isinstance(current, Mapping) and \"__cfg__\" in current:\n        marker = id(current)\n        if marker in visited:  # pragma: no cover - defensive cycle guard\n            break\n        visited.add(marker)\n        candidate = current.get(\"__cfg__\")\n        if candidate is None:\n            break\n        current = candidate\n    return current\n\n\ndef _empty_run_full_result() -> dict[str, object]:\n    return {\n        \"out_sample_stats\": {},\n        \"in_sample_stats\": {},\n        \"benchmark_ir\": {},\n        \"risk_diagnostics\": {},\n        \"fund_weights\": {},\n    }\n\n\ndef _build_trend_spec(\n    cfg: Mapping[str, Any] | Any,\n    vol_adjust_cfg: Mapping[str, Any] | Any,\n) -> TrendSpec | None:\n    \"\"\"Build a TrendSpec from config, or None if no signals config is present.\n\n    Returns None when no ``signals`` section is configured, so that callers\n    fall back to the existing default behaviour (signal window derived from\n    the in-sample risk window).\n    \"\"\"\n    signals_cfg = _cfg_section(cfg, \"signals\")\n\n    # Return None when no signals config is present - this preserves the old\n    # default behaviour where signal_spec=None causes the pipeline to derive\n    # the window from the risk window length rather than hardcoding 63.\n    if not signals_cfg:\n        return None\n\n    def _signal_setting(key: str, alias: str | None, default: Any = None) -> Any:\n        value = _section_get(signals_cfg, key, None)\n        if value is None and alias:\n            value = _section_get(signals_cfg, alias, None)\n        return default if value is None else value\n\n    kind = str(_section_get(signals_cfg, \"kind\", \"tsmom\") or \"tsmom\").lower()\n    if kind != \"tsmom\":  # pragma: no cover - future extension guard\n        raise ValueError(f\"Unsupported trend signal kind: {kind}\")\n\n    try:\n        window_raw = _signal_setting(\"window\", \"trend_window\", 63)\n        window = int(window_raw)\n    except (TypeError, ValueError):\n        window = 63\n    min_periods_raw = _signal_setting(\"min_periods\", \"trend_min_periods\")\n    try:\n        min_periods = int(min_periods_raw) if min_periods_raw is not None else None\n    except (TypeError, ValueError):\n        min_periods = None\n\n    try:\n        lag_raw = _signal_setting(\"lag\", \"trend_lag\", 1)\n        lag = max(1, int(lag_raw))\n    except (TypeError, ValueError):\n        lag = 1\n\n    vol_adjust_default = bool(_section_get(vol_adjust_cfg, \"enabled\", False))\n    vol_adjust_flag = bool(\n        _signal_setting(\"vol_adjust\", \"trend_vol_adjust\", vol_adjust_default)\n    )\n    vol_target_raw = _signal_setting(\"vol_target\", \"trend_vol_target\")\n    if vol_target_raw is None and vol_adjust_flag:\n        vol_target_raw = _section_get(vol_adjust_cfg, \"target_vol\")\n    try:\n        vol_target = float(vol_target_raw) if vol_target_raw is not None else None\n        if vol_target is not None and vol_target <= 0:\n            vol_target = None\n    except (TypeError, ValueError):\n        vol_target = None\n\n    zscore_setting = _signal_setting(\"zscore\", \"trend_zscore\", False)\n    if isinstance(zscore_setting, bool):\n        zscore_flag: bool | float = zscore_setting\n    else:\n        try:\n            zscore_value = float(zscore_setting)\n        except (TypeError, ValueError):\n            zscore_flag = False\n        else:\n            zscore_flag = zscore_value if np.isfinite(zscore_value) else False\n            if isinstance(zscore_flag, float) and zscore_flag <= 0:\n                zscore_flag = False\n\n    return TrendSpec(\n        kind=\"tsmom\",\n        window=max(1, window),\n        min_periods=min_periods,\n        lag=lag,\n        vol_adjust=vol_adjust_flag,\n        vol_target=vol_target,\n        zscore=zscore_flag,\n    )\n\n\ndef _policy_from_config(\n    cfg: Mapping[str, Any] | None,\n) -> tuple[str | Mapping[str, str] | None, int | Mapping[str, int | None] | None]:\n    if not cfg:\n        return None, None\n    policy_base = cfg.get(\"policy\")\n    per_asset = cfg.get(\"per_asset\")\n    policy_spec: str | Mapping[str, str] | None\n    if isinstance(per_asset, Mapping):\n        policy_spec = {str(k): str(v) for k, v in per_asset.items()}\n        if policy_base is not None:\n            policy_spec = {\"default\": str(policy_base), **policy_spec}\n    elif policy_base is not None:\n        policy_spec = str(policy_base)\n    else:\n        policy_spec = None\n\n    limit_base = cfg.get(\"limit\")\n    per_asset_limit = cfg.get(\"per_asset_limit\")\n    if isinstance(per_asset_limit, Mapping):\n        limit_map: dict[str, int | None] = {\n            str(k): v for k, v in per_asset_limit.items()\n        }\n        if limit_base is not None:\n            limit_map = {\"default\": limit_base, **limit_map}\n        limit_spec: Mapping[str, int | None] | None = limit_map\n    else:\n        limit_spec = limit_base\n    return policy_spec, limit_spec\n\n\ndef _format_period(period: pd.Period) -> str:\n    return f\"{period.year:04d}-{period.month:02d}\"\n\n\ndef _derive_split_from_periods(\n    periods: pd.PeriodIndex,\n    *,\n    method: str,\n    boundary: pd.Period | None,\n    ratio: float,\n) -> dict[str, str]:\n    if len(periods) == 0:\n        raise ValueError(\"Unable to derive sample splits without any observations\")\n    if len(periods) == 1:\n        period = periods[0]\n        formatted = _format_period(period)\n        return {\n            \"in_start\": formatted,\n            \"in_end\": formatted,\n            \"out_start\": formatted,\n            \"out_end\": formatted,\n        }\n\n    # Attempt date-based split first when boundary provided.\n    if method == \"date\" and boundary is not None:\n        in_mask = periods <= boundary\n        out_mask = periods > boundary\n        if in_mask.any() and out_mask.any():\n            in_periods = periods[in_mask]\n            out_periods = periods[out_mask]\n            return {\n                \"in_start\": _format_period(in_periods[0]),\n                \"in_end\": _format_period(in_periods[-1]),\n                \"out_start\": _format_period(out_periods[0]),\n                \"out_end\": _format_period(out_periods[-1]),\n            }\n\n    # Fallback to ratio-based split when date split is unavailable or invalid.\n    try:\n        ratio_val = float(ratio)\n    except (TypeError, ValueError):\n        ratio_val = 0.7\n    if not np.isfinite(ratio_val) or ratio_val <= 0:\n        ratio_val = 0.5\n    if ratio_val >= 1:\n        ratio_val = 0.9\n    in_count = int(round(len(periods) * ratio_val))\n    if in_count <= 0:\n        in_count = 1\n    if in_count >= len(periods):\n        in_count = len(periods) - 1\n\n    in_periods = periods[:in_count]\n    out_periods = periods[in_count:]\n    if len(out_periods) == 0:\n        raise ValueError(\"Unable to derive out-of-sample window from ratio split\")\n    return {\n        \"in_start\": _format_period(in_periods[0]),\n        \"in_end\": _format_period(in_periods[-1]),\n        \"out_start\": _format_period(out_periods[0]),\n        \"out_end\": _format_period(out_periods[-1]),\n    }\n\n\ndef _resolve_sample_split(\n    df: pd.DataFrame,\n    split_cfg: Mapping[str, Any] | Any,\n) -> dict[str, str]:\n    required_keys = (\"in_start\", \"in_end\", \"out_start\", \"out_end\")\n    resolved: dict[str, str] = {}\n    for key in required_keys:\n        value = _section_get(split_cfg, key)\n        if value not in (None, \"\"):\n            resolved[key] = str(value)\n\n    missing = [key for key in required_keys if key not in resolved]\n    if not missing:\n        return resolved\n\n    if \"Date\" not in df.columns:\n        raise ValueError(\n            \"Input data must contain a 'Date' column to derive sample splits\"\n        )\n\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n    date_series = date_series.dropna()\n    if date_series.empty:\n        raise ValueError(\"Input data contains no valid dates to derive sample splits\")\n\n    sorted_periods = date_series.dt.to_period(\"M\").sort_values()\n    periods = pd.PeriodIndex(sorted_periods.unique())\n\n    method_raw = _section_get(split_cfg, \"method\", \"date\")\n    method = str(method_raw or \"date\").lower()\n    boundary: pd.Period | None = None\n    if method == \"date\":\n        raw_boundary = _section_get(split_cfg, \"date\")\n        if raw_boundary not in (None, \"\"):\n            try:\n                boundary = pd.Period(str(raw_boundary), freq=\"M\")\n            except Exception:\n                boundary = None\n    ratio_value = _section_get(split_cfg, \"ratio\", 0.7)\n\n    derived = _derive_split_from_periods(\n        periods,\n        method=method,\n        boundary=boundary,\n        ratio=ratio_value,\n    )\n\n    for key, value in derived.items():\n        resolved.setdefault(key, value)\n\n    still_missing = [key for key in required_keys if key not in resolved]\n    if still_missing:\n        raise ValueError(\n            f\"Unable to derive sample split values for: {', '.join(still_missing)}\"\n        )\n    return resolved\n\n\ndef _prepare_input_data(\n    df: pd.DataFrame,\n    *,\n    date_col: str,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    enforce_completeness: bool = True,\n) -> tuple[pd.DataFrame, FrequencySummary, MissingPolicyResult, bool]:\n    if date_col not in df.columns:\n        raise ValueError(f\"DataFrame must contain a '{date_col}' column\")\n\n    work = df.copy()\n    if not pd.api.types.is_datetime64_any_dtype(work[date_col].dtype):\n        work[date_col] = pd.to_datetime(work[date_col])\n    work.sort_values(date_col, inplace=True)\n\n    freq_summary = detect_frequency(work[date_col])\n\n    value_cols = [c for c in work.columns if c != date_col]\n    if value_cols:\n        numeric = work[value_cols].apply(pd.to_numeric, errors=\"coerce\")\n    else:\n        numeric = work[value_cols]\n    numeric.index = pd.DatetimeIndex(work[date_col])\n\n    if freq_summary.resampled:\n        resampled = (1 + numeric).resample(MONTHLY_DATE_FREQ).prod(min_count=1) - 1\n        normalised = True\n    else:\n        resampled = numeric.resample(MONTHLY_DATE_FREQ).last()\n        normalised = False\n\n    policy_spec: str | Mapping[str, str] | None = missing_policy or \"drop\"\n    preserve_empty_periods = True\n    if isinstance(policy_spec, str):\n        preserve_empty_periods = policy_spec.lower() != \"drop\"\n    elif isinstance(policy_spec, Mapping):\n        values = [str(v or \"\").lower() for v in policy_spec.values()]\n        preserve_empty_periods = any(v and v != \"drop\" for v in values)\n\n    if not preserve_empty_periods:\n        resampled = resampled.dropna(how=\"all\")\n    resampled.index.name = date_col\n\n    filled, missing_result = apply_missing_policy(\n        resampled,\n        policy=policy_spec,\n        limit=missing_limit,\n        enforce_completeness=enforce_completeness,\n    )\n    # Only drop rows that remain completely empty after the missing-data policy.\n    filled = filled.dropna(how=\"all\")\n\n    if filled.empty:\n        monthly_df = pd.DataFrame(columns=[date_col])\n    else:\n        monthly_df = filled.reset_index().rename(columns={\"index\": date_col})\n        monthly_df[date_col] = pd.to_datetime(monthly_df[date_col])\n        monthly_df.sort_values(date_col, inplace=True)\n\n    return monthly_df, freq_summary, missing_result, normalised\n\n\ndef calc_portfolio_returns(\n    weights: NDArray[Any], returns_df: pd.DataFrame\n) -> pd.Series:\n    \"\"\"Calculate weighted portfolio returns.\"\"\"\n    return returns_df.mul(weights, axis=1).sum(axis=1)\n\n\ndef _resolve_risk_free_column(\n    df: pd.DataFrame,\n    *,\n    date_col: str,\n    indices_list: list[str] | None,\n    risk_free_column: str | None,\n    allow_risk_free_fallback: bool | None,\n    fallback_window: pd.DataFrame | None = None,\n) -> tuple[str, list[str], str]:\n    \"\"\"Select the risk-free column and investable funds.\n\n    Returns\n    -------\n    tuple[str, list[str], str]\n        ``(risk_free_column, fund_columns, source)`` where ``source`` is\n        ``\"configured\"`` when explicitly provided or ``\"fallback\"`` when the\n        column is inferred. When ``fallback_window`` is supplied, the\n        candidate scan is restricted to that window to avoid picking columns\n        that lack data for the requested analysis period.\n    \"\"\"\n\n    idx_set = {str(c) for c in indices_list or []}\n    candidate_df = fallback_window if fallback_window is not None else df\n    if date_col not in candidate_df.columns:\n        candidate_df = candidate_df.copy()\n        candidate_df[date_col] = candidate_df.index\n\n    candidate_df = candidate_df.copy()\n    candidate_df[date_col] = pd.to_datetime(candidate_df[date_col])\n    candidate_df.sort_values(date_col, inplace=True)\n\n    configured_rf = (risk_free_column or \"\").strip()\n\n    numeric_cols = [\n        c for c in candidate_df.select_dtypes(\"number\").columns if c != date_col\n    ]\n    if not numeric_cols:\n        raise ValueError(\n            \"No numeric return columns were found in the requested window; cannot select risk-free series\"\n        )\n\n    expanded_df = candidate_df.set_index(date_col)\n    if not expanded_df.index.is_monotonic_increasing:\n        expanded_df = expanded_df.sort_index()\n\n    # Align observed dates to calendar month-end without dropping values.\n    # This handles inputs keyed on business month-end or daily observations.\n    try:\n        idx = pd.DatetimeIndex(pd.to_datetime(expanded_df.index))\n        # Map observations to month-end dates at midnight so they align with\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_41","type":"reasoning","text":"**Planning pipeline refactor and modularization**\n\nI'm considering moving most functions out of the pipeline to new stage modules and helpers to trim pipeline.py below 500 lines. I want to keep thin wrappers like run(), run_full(), and run_analysis() in pipeline.py while possibly relocating core logic like _run_analysis to a runner module. I'll check the file bottom to confirm how these are defined and think about how tests might be affected."}}
{"type":"item.started","item":{"id":"item_42","type":"command_execution","command":"/bin/bash -lc \"sed -n '2000,3005p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_42","type":"command_execution","command":"/bin/bash -lc \"sed -n '2000,3005p' src/trend_analysis/pipeline.py\"","aggregated_output":"        # Map observations to month-end dates at midnight so they align with\n        # `pd.date_range(..., freq=MONTHLY_DATE_FREQ)`.\n        idx_me = idx.to_period(\"M\").to_timestamp(how=\"end\").normalize()\n        expanded_df.index = idx_me\n        if expanded_df.index.has_duplicates:\n            expanded_df = expanded_df.groupby(level=0).last()\n    except Exception:  # pragma: no cover - best-effort alignment\n        pass\n\n    if not expanded_df.empty:\n        start_me = pd.Timestamp(expanded_df.index.min())\n        end_me = pd.Timestamp(expanded_df.index.max())\n        # If the risk-free series is explicitly configured, compute coverage\n        # over the span where that series actually has observations. This avoids\n        # penalising coverage for trailing empty months that can be introduced\n        # by window reindexing elsewhere in the pipeline.\n        if configured_rf and configured_rf in expanded_df.columns:\n            observed_idx = expanded_df.index[expanded_df[configured_rf].notna()]\n            if len(observed_idx) > 0:\n                start_me = pd.Timestamp(observed_idx.min())\n                end_me = pd.Timestamp(observed_idx.max())\n\n        full_index = pd.date_range(start=start_me, end=end_me, freq=MONTHLY_DATE_FREQ)\n        expanded_df = expanded_df.reindex(full_index)\n    expanded_df.index.name = date_col\n\n    total_rows = len(expanded_df)\n    if total_rows == 0:\n        raise ValueError(\"Requested window is empty; cannot select risk-free series\")\n\n    # Coverage threshold for selecting a risk-free proxy. Clamp to the window\n    # length so truncated/short windows (e.g., a 1-month final OOS period)\n    # don't fail with an impossible requirement like 2/1 observations.\n    min_non_null = math.ceil(total_rows * _MIN_FALLBACK_COVERAGE_RATIO)\n    min_non_null = max(1, min(total_rows, min_non_null))\n    coverage_counts = expanded_df[numeric_cols].notna().sum()\n    coverage_mask = coverage_counts >= min_non_null\n\n    if configured_rf:\n        if configured_rf == date_col:\n            raise ValueError(\"Risk-free column cannot reuse the date column\")\n        if configured_rf not in df.columns:\n            raise ValueError(\n                f\"Configured risk-free column '{configured_rf}' was not found in the dataset\"\n            )\n        if configured_rf not in candidate_df.select_dtypes(\"number\").columns:\n            raise ValueError(\n                f\"Configured risk-free column '{configured_rf}' must be numeric\"\n            )\n        if configured_rf in idx_set:\n            raise ValueError(\n                f\"Risk-free column '{configured_rf}' cannot also be listed as an index/benchmark\"\n            )\n\n        # Fund candidates come from all numeric columns (excluding indices and rf).\n        ret_cols = [c for c in numeric_cols if c not in idx_set]\n\n        configured_coverage = int(coverage_counts.get(configured_rf, 0))\n        if configured_coverage == 0:\n            # Window may be out of data range (common in multi-period schedules).\n            # Let the pipeline proceed so the period can be skipped with a\n            # diagnostic instead of raising here.\n            logger.warning(\n                \"Configured risk-free column '%s' has no coverage in the requested window; proceeding\",\n                configured_rf,\n            )\n        elif configured_coverage < min_non_null:\n            raise ValueError(\n                (\n                    f\"Configured risk-free column '{configured_rf}' has insufficient coverage \"\n                    f\"in the requested window ({configured_coverage}/{total_rows} non-null; \"\n                    f\"require at least {min_non_null})\"\n                )\n            )\n        rf_col = configured_rf\n        source = \"configured\"\n    else:\n        # Restrict candidates to columns with sufficient non-null coverage within\n        # the requested windows. This keeps the fallback selection aligned with the\n        # analysis slice rather than the full dataset.\n        ret_cols = [\n            c for c in numeric_cols if c not in idx_set and coverage_mask.get(c, False)\n        ]\n\n        if not ret_cols:\n            raise ValueError(\n                (\n                    \"No numeric return columns meet the coverage requirement \"\n                    f\"({min_non_null}/{total_rows} non-null observations) in the requested window\"\n                )\n            )\n\n        # BREAKING CHANGE: The default behavior of allow_risk_free_fallback has changed.\n        # Previously, fallback was only enabled if explicitly set to True.\n        # Now, fallback is enabled unless explicitly set to False.\n        # This may cause unexpected behavior in existing configurations.\n        # Please document this change in the release notes.\n        fallback_enabled = allow_risk_free_fallback is not False\n        if fallback_enabled and allow_risk_free_fallback is None:\n            logger.warning(\n                \"Risk-free fallback is enabled by default. This is a breaking change \"\n                \"from previous versions. Please review your configuration.\"\n            )\n        if not fallback_enabled:\n            raise ValueError(\n                \"Set data.risk_free_column or enable data.allow_risk_free_fallback to select a risk-free series.\"\n            )\n        window_df = expanded_df.reset_index().rename(columns={\"index\": date_col})\n        probe_cols = (\n            [date_col, *ret_cols] if date_col in window_df.columns else ret_cols\n        )\n\n        # With <2 observations, volatility is undefined (std = NaN), which can\n        # cause the fallback heuristic to return NaN. Prefer obvious RF-like\n        # columns or fall back deterministically.\n        if total_rows < 2:\n            rf_like = (\n                \"RF\",\n                \"RISK_FREE\",\n                \"RISK-FREE\",\n                \"CASH\",\n                \"TBILL\",\n                \"TBILLS\",\n                \"T-BILL\",\n                \"T-BILLS\",\n            )\n            by_upper = {str(c).upper(): str(c) for c in ret_cols}\n            pick = None\n            for key in rf_like:\n                if key in by_upper:\n                    pick = by_upper[key]\n                    break\n            rf_col = pick or sorted(map(str, ret_cols))[0]\n            source = \"fallback\"\n            logger.info(\n                \"Using '%s' as risk-free (fallback short-window)\",\n                rf_col,\n            )\n        else:\n            detected = identify_risk_free_fund(window_df[probe_cols])\n            if detected is None or (\n                isinstance(detected, float) and math.isnan(detected)\n            ):\n                raise ValueError(\n                    \"Risk-free fallback could not find a numeric return series in the requested window\"\n                )\n            rf_col = str(detected)\n            source = \"fallback\"\n            logger.info(\n                \"Using lowest-volatility column '%s' as risk-free (fallback enabled)\",\n                rf_col,\n            )\n\n    fund_cols = [c for c in ret_cols if c != rf_col]\n    return rf_col, fund_cols, source\n\n\ndef single_period_run(\n    df: pd.DataFrame,\n    start: str,\n    end: str,\n    *,\n    stats_cfg: RiskStatsConfig | None = None,\n    risk_free: float | pd.Series | None = None,\n) -> pd.DataFrame:\n    \"\"\"Return a score frame of metrics for a single period.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        Input returns data with a ``Date`` column.\n    start, end : str\n        Inclusive period in ``YYYY-MM`` format.\n    stats_cfg : RiskStatsConfig | None\n        Metric configuration; defaults to ``RiskStatsConfig()``.\n\n    Returns\n    -------\n    pd.DataFrame\n        Table of metric values (index = fund code).  The frame is pure\n        and carries ``insample_len`` and ``period`` metadata so callers\n        can reason about the analysed window.\n    \"\"\"\n    from .core.rank_selection import RiskStatsConfig, _compute_metric_series\n\n    if stats_cfg is None:\n        stats_cfg = RiskStatsConfig()\n\n    if \"Date\" not in df.columns:\n        raise ValueError(\"DataFrame must contain a 'Date' column\")\n\n    df = df.copy()\n    if not pd.api.types.is_datetime64_any_dtype(df[\"Date\"].dtype):\n        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\n    def _parse_month(s: str) -> pd.Timestamp:\n        return pd.to_datetime(f\"{s}-01\") + pd.offsets.MonthEnd(0)\n\n    sdate, edate = _parse_month(start), _parse_month(end)\n    window = df[(df[\"Date\"] >= sdate) & (df[\"Date\"] <= edate)].set_index(\"Date\")\n\n    if window.empty:\n        raise ValueError(\n            \"single_period_run found no rows in the requested period\"\n            f\" {start} to {end}; check the date filter or input data.\"\n        )\n\n    window_no_all_nan = window.dropna(axis=1, how=\"all\")\n    if window_no_all_nan.empty:\n        raise ValueError(\n            \"single_period_run found only empty return columns in the requested\"\n            f\" period {start} to {end}; verify the input contains non-NaN returns.\"\n        )\n\n    metrics = stats_cfg.metrics_to_run\n    if not metrics:\n        raise ValueError(\"stats_cfg.metrics_to_run must not be empty\")\n\n    parts = [\n        _compute_metric_series(\n            window_no_all_nan, m, stats_cfg, risk_free_override=risk_free\n        )\n        for m in metrics\n    ]\n    score_frame = pd.concat(parts, axis=1)\n    score_frame.columns = metrics\n    score_frame.attrs[\"insample_len\"] = len(window)\n    score_frame.attrs[\"period\"] = (start, end)\n    # Optional derived correlation metric (opt-in via stats_cfg.extra_metrics)\n    extra = getattr(stats_cfg, \"extra_metrics\", [])\n    if (\n        \"AvgCorr\" in extra\n        and score_frame.shape[1] > 0\n        and window_no_all_nan.shape[1] > 1\n        and \"AvgCorr\" not in score_frame.columns\n    ):\n        from .core.rank_selection import compute_metric_series_with_cache\n\n        try:\n            avg_corr_series = compute_metric_series_with_cache(\n                window_no_all_nan,\n                \"AvgCorr\",\n                stats_cfg,\n                risk_free_override=risk_free,\n                enable_cache=False,\n            )\n        except Exception as exc:  # pragma: no cover - defensive\n            msg = (\n                \"Failed to compute AvgCorr for single_period_run\"\n                f\" window {start} to {end}: {exc}\"\n            )\n            logger.error(msg)\n            raise RuntimeError(msg) from exc\n\n        score_frame = pd.concat([score_frame, avg_corr_series], axis=1)\n    return score_frame.astype(float)\n\n\ndef _compute_stats(\n    df: pd.DataFrame,\n    rf: pd.Series,\n    *,\n    in_sample_avg_corr: dict[str, float] | None = None,\n    out_sample_avg_corr: dict[str, float] | None = None,\n) -> dict[str, _Stats]:\n    # Metrics expect 1D Series; iterating keeps the logic simple for a handful\n    # of columns and avoids reshaping into higher-dimensional arrays.\n    stats: dict[str, _Stats] = {}\n    for col in df:\n        key = str(col)\n        stats[key] = _Stats(\n            cagr=float(annual_return(df[col])),\n            vol=float(volatility(df[col])),\n            sharpe=float(sharpe_ratio(df[col], rf)),\n            sortino=float(sortino_ratio(df[col], rf)),\n            max_drawdown=float(max_drawdown(df[col])),\n            information_ratio=float(information_ratio(df[col], rf)),\n            is_avg_corr=(in_sample_avg_corr or {}).get(col),\n            os_avg_corr=(out_sample_avg_corr or {}).get(col),\n        )\n    return stats\n\n\ndef _run_analysis_with_diagnostics(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \"all\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year_override: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    preprocess_stage = _prepare_preprocess_stage(\n        df,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        stats_cfg=stats_cfg,\n        periods_per_year_override=periods_per_year_override,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n    )\n    if isinstance(preprocess_stage, PipelineResult):\n        return preprocess_stage\n\n    window_stage = _build_sample_windows(\n        preprocess_stage,\n        in_start=in_start,\n        in_end=in_end,\n        out_start=out_start,\n        out_end=out_end,\n    )\n    if isinstance(window_stage, PipelineResult):\n        return window_stage\n\n    regime_label, regime_settings = _resolve_regime_label(\n        preprocess_stage,\n        window_stage,\n        regime_cfg,\n        benchmarks=benchmarks,\n    )\n    random_n, rank_kwargs = _apply_regime_overrides(\n        random_n=random_n,\n        rank_kwargs=rank_kwargs,\n        regime_label=regime_label,\n        settings=regime_settings,\n        regime_cfg=regime_cfg,\n    )\n    target_vol, constraints = _apply_regime_weight_overrides(\n        target_vol=target_vol,\n        constraints=constraints,\n        regime_label=regime_label,\n        settings=regime_settings,\n        regime_cfg=regime_cfg,\n    )\n\n    selection_stage = _select_universe(\n        preprocess_stage,\n        window_stage,\n        in_label=in_start,\n        in_end_label=in_end,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n    )\n    if isinstance(selection_stage, PipelineResult):\n        return selection_stage\n\n    stats_cfg_obj = stats_cfg or RiskStatsConfig(risk_free=0.0)\n    computation_stage = _compute_weights_and_stats(\n        preprocess_stage,\n        window_stage,\n        selection_stage,\n        target_vol=target_vol,\n        monthly_cost=monthly_cost,\n        custom_weights=custom_weights,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        risk_window=risk_window,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        weight_policy=weight_policy,\n        warmup=preprocess_stage.warmup,\n        min_floor=preprocess_stage.min_floor,\n        stats_cfg=stats_cfg_obj,\n        weight_engine_params=weight_engine_params,\n    )\n\n    return _assemble_analysis_output(\n        preprocess_stage,\n        window_stage,\n        selection_stage,\n        computation_stage,\n        benchmarks=benchmarks,\n        regime_cfg=regime_cfg,\n        target_vol=target_vol,\n        monthly_cost=monthly_cost,\n        min_floor=preprocess_stage.min_floor,\n    )\n\n\ndef _run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \"all\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year_override: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> AnalysisResult | None:\n    \"\"\"Backward-compatible wrapper returning raw payloads for tests.\"\"\"\n\n    result = _run_analysis_with_diagnostics(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year_override,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n    return result.unwrap()\n\n\n_DEFAULT_RUN_ANALYSIS = _run_analysis\n\n\ndef _invoke_analysis_with_diag(*args: Any, **kwargs: Any) -> PipelineResult:\n    \"\"\"Call the patched analysis hook and normalise into a PipelineResult.\"\"\"\n\n    if _run_analysis is _DEFAULT_RUN_ANALYSIS:\n        return _run_analysis_with_diagnostics(*args, **kwargs)\n    patched_result = _run_analysis(*args, **kwargs)\n    if isinstance(patched_result, PipelineResult):\n        return patched_result\n    if isinstance(patched_result, DiagnosticResult):\n        return PipelineResult(\n            value=patched_result.value,\n            diagnostic=patched_result.diagnostic,\n        )\n    return PipelineResult(value=patched_result, diagnostic=None)\n\n\ndef run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \"all\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    calendar_frequency: str | None = None,\n    calendar_timezone: str | None = None,\n    holiday_calendar: str | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    \"\"\"Diagnostics-aware wrapper mirroring ``_run_analysis``.\"\"\"\n    if any(\n        value is not None\n        for value in (calendar_frequency, calendar_timezone, holiday_calendar)\n    ):\n        df = df.copy()\n        calendar_settings = dict(getattr(df, \"attrs\", {}).get(\"calendar_settings\", {}))\n        if calendar_frequency is not None:\n            calendar_settings[\"frequency\"] = calendar_frequency\n        if calendar_timezone is not None:\n            calendar_settings[\"timezone\"] = calendar_timezone\n        if holiday_calendar is not None:\n            calendar_settings[\"holiday_calendar\"] = holiday_calendar\n        df.attrs[\"calendar_settings\"] = calendar_settings\n    return _invoke_analysis_with_diag(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _attach_calendar_settings(df: pd.DataFrame, cfg: Config) -> None:\n    preprocessing_section = _cfg_section(cfg, \"preprocessing\")\n    data_settings = _cfg_section(cfg, \"data\")\n    data_frequency = _section_get(data_settings, \"frequency\")\n    data_timezone = _section_get(data_settings, \"timezone\", \"UTC\")\n    holiday_calendar = _section_get(preprocessing_section, \"holiday_calendar\")\n    df.attrs[\"calendar_settings\"] = {\n        \"frequency\": data_frequency,\n        \"timezone\": data_timezone,\n        \"holiday_calendar\": holiday_calendar,\n    }\n\n\ndef run(cfg: Config) -> pd.DataFrame:\n    \"\"\"Execute the analysis pipeline based on ``cfg``.\"\"\"\n    cfg = _unwrap_cfg(cfg)\n    preprocessing_section = _cfg_section(cfg, \"preprocessing\")\n    data_settings = _cfg_section(cfg, \"data\")\n    csv_path = _section_get(data_settings, \"csv_path\")\n    if csv_path is None:\n        raise KeyError(\"cfg.data['csv_path'] must be provided\")\n\n    missing_policy_cfg = _section_get(data_settings, \"missing_policy\")\n    if missing_policy_cfg is None:\n        missing_policy_cfg = _section_get(data_settings, \"nan_policy\")\n    missing_limit_cfg = _section_get(data_settings, \"missing_limit\")\n    if missing_limit_cfg is None:\n        missing_limit_cfg = _section_get(data_settings, \"nan_limit\")\n\n    df = load_csv(\n        csv_path,\n        errors=\"raise\",\n        missing_policy=missing_policy_cfg,\n        missing_limit=missing_limit_cfg,\n    )\n    df = cast(pd.DataFrame, df)\n\n    _attach_calendar_settings(df, cfg)\n\n    split_cfg = _cfg_section(cfg, \"sample_split\")\n    resolved_split = _resolve_sample_split(df, split_cfg)\n    metrics_section = _cfg_section(cfg, \"metrics\")\n    metrics_list = _section_get(metrics_section, \"registry\")\n    stats_cfg = None\n    if metrics_list:\n        from .core.rank_selection import RiskStatsConfig, canonical_metric_list\n\n        stats_cfg = RiskStatsConfig(\n            metrics_to_run=canonical_metric_list(metrics_list),\n            risk_free=0.0,\n        )\n\n    missing_section = _section_get(preprocessing_section, \"missing_data\")\n    if not isinstance(missing_section, Mapping):\n        missing_section = None\n    policy_spec, limit_spec = _policy_from_config(\n        missing_section if isinstance(missing_section, Mapping) else None\n    )\n\n    vol_adjust = _cfg_section(cfg, \"vol_adjust\")\n    run_settings = _cfg_section(cfg, \"run\")\n    portfolio_cfg = _cfg_section(cfg, \"portfolio\")\n    weighting_scheme = _section_get(portfolio_cfg, \"weighting_scheme\", \"equal\")\n    robustness_cfg = _section_get(portfolio_cfg, \"robustness\")\n    if not isinstance(robustness_cfg, Mapping):\n        robustness_cfg = _cfg_section(cfg, \"robustness\")\n    weight_engine_params = weight_engine_params_from_robustness(\n        weighting_scheme, robustness_cfg\n    )\n    trend_spec = _build_trend_spec(cfg, vol_adjust)\n    lambda_tc_val = _section_get(portfolio_cfg, \"lambda_tc\", 0.0)\n    risk_free_column = _section_get(data_settings, \"risk_free_column\")\n    allow_risk_free_fallback = _section_get(data_settings, \"allow_risk_free_fallback\")\n\n    diag_res = _invoke_analysis_with_diag(\n        df,\n        resolved_split[\"in_start\"],\n        resolved_split[\"in_end\"],\n        resolved_split[\"out_start\"],\n        resolved_split[\"out_end\"],\n        _resolve_target_vol(vol_adjust),\n        _section_get(run_settings, \"monthly_cost\", 0.0),\n        floor_vol=_section_get(vol_adjust, \"floor_vol\"),\n        warmup_periods=int(_section_get(vol_adjust, \"warmup_periods\", 0) or 0),\n        selection_mode=_section_get(portfolio_cfg, \"selection_mode\", \"all\"),\n        random_n=_section_get(portfolio_cfg, \"random_n\", 8),\n        custom_weights=_section_get(portfolio_cfg, \"custom_weights\"),\n        rank_kwargs=_section_get(portfolio_cfg, \"rank\"),\n        manual_funds=_section_get(portfolio_cfg, \"manual_list\"),\n        indices_list=_section_get(portfolio_cfg, \"indices_list\"),\n        benchmarks=_cfg_value(cfg, \"benchmarks\"),\n        seed=_cfg_value(cfg, \"seed\", 42),\n        weighting_scheme=weighting_scheme,\n        constraints=_section_get(portfolio_cfg, \"constraints\"),\n        stats_cfg=stats_cfg,\n        missing_policy=policy_spec,\n        missing_limit=limit_spec,\n        risk_window=_section_get(vol_adjust, \"window\"),\n        previous_weights=_section_get(portfolio_cfg, \"previous_weights\"),\n        lambda_tc=lambda_tc_val,\n        max_turnover=_section_get(portfolio_cfg, \"max_turnover\"),\n        signal_spec=trend_spec,\n        regime_cfg=_cfg_section(cfg, \"regime\"),\n        weight_policy=_section_get(portfolio_cfg, \"weight_policy\"),\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n    diag = diag_res.diagnostic\n    if diag_res.value is None:\n        if diag:\n            logger.warning(\n                \"pipeline.run aborted (%s): %s\",\n                diag.reason_code,\n                diag.message,\n            )\n        empty = pd.DataFrame()\n        if diag:\n            empty.attrs[\"diagnostic\"] = diag\n        return empty\n\n    res = diag_res.value\n    stats = cast(dict[str, _Stats], res[\"out_sample_stats\"])\n    df = pd.DataFrame({k: vars(v) for k, v in stats.items()}).T\n    for label, ir_map in cast(\n        dict[str, dict[str, float]], res.get(\"benchmark_ir\", {})\n    ).items():\n        col = f\"ir_{label}\"\n        df[col] = pd.Series(\n            {\n                k: v\n                for k, v in ir_map.items()\n                if k not in {\"equal_weight\", \"user_weight\"}\n            }\n        )\n    if diag:\n        df.attrs[\"diagnostic\"] = diag\n    return df\n\n\ndef run_full(cfg: Config) -> PipelineResult:\n    \"\"\"Return the full analysis results (with diagnostics) based on ``cfg``.\"\"\"\n    cfg = _unwrap_cfg(cfg)\n    preprocessing_section = _cfg_section(cfg, \"preprocessing\")\n    data_settings = _cfg_section(cfg, \"data\")\n    csv_path = _section_get(data_settings, \"csv_path\")\n    if csv_path is None:\n        raise KeyError(\"cfg.data['csv_path'] must be provided\")\n\n    missing_policy_cfg = _section_get(data_settings, \"missing_policy\")\n    if missing_policy_cfg is None:\n        missing_policy_cfg = _section_get(data_settings, \"nan_policy\")\n    missing_limit_cfg = _section_get(data_settings, \"missing_limit\")\n    if missing_limit_cfg is None:\n        missing_limit_cfg = _section_get(data_settings, \"nan_limit\")\n\n    df = load_csv(\n        csv_path,\n        errors=\"raise\",\n        missing_policy=missing_policy_cfg,\n        missing_limit=missing_limit_cfg,\n    )\n    df = cast(pd.DataFrame, df)\n\n    _attach_calendar_settings(df, cfg)\n\n    split_cfg = _cfg_section(cfg, \"sample_split\")\n    resolved_split = _resolve_sample_split(df, split_cfg)\n    metrics_section = _cfg_section(cfg, \"metrics\")\n    metrics_list = _section_get(metrics_section, \"registry\")\n    stats_cfg = None\n    if metrics_list:\n        from .core.rank_selection import RiskStatsConfig, canonical_metric_list\n\n        stats_cfg = RiskStatsConfig(\n            metrics_to_run=canonical_metric_list(metrics_list),\n            risk_free=0.0,\n        )\n\n    missing_section = _section_get(preprocessing_section, \"missing_data\")\n    if not isinstance(missing_section, Mapping):\n        missing_section = None\n    policy_spec, limit_spec = _policy_from_config(\n        missing_section if isinstance(missing_section, Mapping) else None\n    )\n\n    vol_adjust = _cfg_section(cfg, \"vol_adjust\")\n    run_settings = _cfg_section(cfg, \"run\")\n    portfolio_cfg = _cfg_section(cfg, \"portfolio\")\n    weighting_scheme = _section_get(portfolio_cfg, \"weighting_scheme\", \"equal\")\n    robustness_cfg = _section_get(portfolio_cfg, \"robustness\")\n    if not isinstance(robustness_cfg, Mapping):\n        robustness_cfg = _cfg_section(cfg, \"robustness\")\n    weight_engine_params = weight_engine_params_from_robustness(\n        weighting_scheme, robustness_cfg\n    )\n    risk_free_column = _section_get(data_settings, \"risk_free_column\")\n    trend_spec = _build_trend_spec(cfg, vol_adjust)\n    lambda_tc_val = _section_get(portfolio_cfg, \"lambda_tc\", 0.0)\n    risk_free_column = _section_get(data_settings, \"risk_free_column\")\n    allow_risk_free_fallback = _section_get(data_settings, \"allow_risk_free_fallback\")\n\n    diag_res = _invoke_analysis_with_diag(\n        df,\n        resolved_split[\"in_start\"],\n        resolved_split[\"in_end\"],\n        resolved_split[\"out_start\"],\n        resolved_split[\"out_end\"],\n        _resolve_target_vol(vol_adjust),\n        _section_get(run_settings, \"monthly_cost\", 0.0),\n        floor_vol=_section_get(vol_adjust, \"floor_vol\"),\n        warmup_periods=int(_section_get(vol_adjust, \"warmup_periods\", 0) or 0),\n        selection_mode=_section_get(portfolio_cfg, \"selection_mode\", \"all\"),\n        random_n=_section_get(portfolio_cfg, \"random_n\", 8),\n        custom_weights=_section_get(portfolio_cfg, \"custom_weights\"),\n        rank_kwargs=_section_get(portfolio_cfg, \"rank\"),\n        manual_funds=_section_get(portfolio_cfg, \"manual_list\"),\n        indices_list=_section_get(portfolio_cfg, \"indices_list\"),\n        benchmarks=_cfg_value(cfg, \"benchmarks\"),\n        seed=_cfg_value(cfg, \"seed\", 42),\n        weighting_scheme=weighting_scheme,\n        constraints=_section_get(portfolio_cfg, \"constraints\"),\n        stats_cfg=stats_cfg,\n        missing_policy=policy_spec,\n        missing_limit=limit_spec,\n        risk_window=_section_get(vol_adjust, \"window\"),\n        previous_weights=_section_get(portfolio_cfg, \"previous_weights\"),\n        lambda_tc=lambda_tc_val,\n        max_turnover=_section_get(portfolio_cfg, \"max_turnover\"),\n        signal_spec=trend_spec,\n        regime_cfg=_cfg_section(cfg, \"regime\"),\n        weight_policy=_section_get(portfolio_cfg, \"weight_policy\"),\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n    diag = diag_res.diagnostic\n    if diag_res.value is None:\n        if diag:\n            logger.warning(\n                \"pipeline.run_full aborted (%s): %s\",\n                diag.reason_code,\n                diag.message,\n            )\n        else:\n            logger.warning(\"pipeline.run_full aborted with no diagnostic context\")\n    return diag_res\n\n\n# --- Shift-safe helpers ----------------------------------------------------\n\n\ndef compute_signal(\n    df: pd.DataFrame,\n    *,\n    column: str = \"returns\",\n    window: int = 3,\n    min_periods: int | None = None,\n) -> pd.Series:\n    \"\"\"Return a trailing rolling-mean signal using information strictly prior\n    to the current row.\n\n    Args:\n        df (pd.DataFrame): Input DataFrame containing the data.\n        column (str, optional): Name of the column to compute the signal from.\n            Defaults to \"returns\".\n        window (int, optional): Size of the trailing window for the rolling mean.\n            Must be positive. Defaults to 3.\n        min_periods (int or None, optional): Minimum number of observations in window\n            required to have a value (otherwise result is NaN). If None, defaults to\n            the value of `window`.\n\n    Returns:\n        pd.Series: A float Series containing the strictly causal (lookâ€‘back only)\n            rolling mean of the specified column. Value at index t uses rows\n            (t-window) .. (t-1) and never the current row, enforcing shiftâ€‘safe\n            behaviour. The Series is named \"<column>_signal\". NaN values appear\n            until at least `min_periods` prior observations exist (plus one for\n            the shift). Dtype is float.\n    \"\"\"\n\n    if column not in df.columns:\n        raise KeyError(column)\n    if window <= 0:\n        raise ValueError(\"window must be a positive integer\")\n\n    base = df[column].astype(float)\n    effective_min_periods = window if min_periods is None else int(min_periods)\n    if effective_min_periods <= 0:\n        raise ValueError(\"min_periods must be positive\")\n\n    def _compute() -> pd.Series:\n        signal = (\n            base.rolling(window=window, min_periods=effective_min_periods)\n            .mean()\n            .shift(1)\n            .rename(f\"{column}_signal\")\n        )\n        return signal.astype(float)\n\n    try:\n        cache = get_cache()\n    except Exception:  # pragma: no cover - defensive\n        return _compute()\n\n    if not getattr(cache, \"is_enabled\", lambda: False)():\n        return _compute()\n\n    # For small series, the rolling mean is cheap and a filesystem-backed cache\n    # can add overhead (hashing + IO) that dominates runtime and makes\n    # property-based tests flaky on constrained runners.\n    #\n    # Still call into non-filesystem caches (e.g. test doubles) so cache\n    # integration can be verified independently.\n    try:\n        from .perf.rolling_cache import RollingCache as _RollingCache\n\n        if isinstance(cache, _RollingCache) and len(base) < 256:\n            return _compute()\n    except Exception:  # pragma: no cover - best-effort guard\n        pass\n\n    # Avoid relying on index .freq (tests may supply an index that raises).\n    freq = \"unknown\"\n    try:\n        freq_str = getattr(df.index, \"freqstr\", None)\n        if isinstance(freq_str, str) and freq_str:\n            freq = freq_str\n    except Exception as exc:  # pragma: no cover - best-effort guard\n        logger.debug(\n            \"Failed to read index.freqstr when computing signal cache key: %s\",\n            exc,\n        )\n\n    dataset_hash = compute_dataset_hash([base])\n    method = f\"compute_signal:{column}:min{effective_min_periods}\"\n    return cache.get_or_compute(dataset_hash, window, freq, method, _compute)\n\n\ndef position_from_signal(\n    signal: pd.Series,\n    *,\n    long_position: float = 1.0,\n    short_position: float = -1.0,\n    neutral_position: float = 0.0,\n) -> pd.Series:\n    \"\"\"Convert a trading signal into positions using only past information.\n\n    This function maps a time series of trading signals to position values, using only\n    information available up to each point in time (no look-ahead bias).\n\n    Rules:\n        - The initial position is set to `neutral_position`.\n        - For each signal value:\n            - If the value is NaN or exactly zero, the position retains its previous value.\n            - If the value is positive, the position is set to `long_position`.\n            - If the value is negative, the position is set to `short_position`.\n    Parameters:\n        signal (pd.Series): The input trading signal.\n        long_position (float, optional): Position value for positive signals (default: 1.0).\n        short_position (float, optional): Position value for negative signals (default: -1.0).\n        neutral_position (float, optional): Initial position and value for zero/NaN signals (default: 0.0).\n    Returns:\n        pd.Series: Series of position values, named \"position\", indexed as the input signal.\n    \"\"\"\n    values = signal.astype(float).to_numpy()\n    positions = np.empty_like(values, dtype=float)\n    current = float(neutral_position)\n\n    for idx, value in enumerate(values):\n        if np.isnan(value) or value == 0.0:\n            positions[idx] = current\n            continue\n        current = float(long_position if value > 0.0 else short_position)\n        positions[idx] = current\n\n    out = pd.Series(positions, index=signal.index, name=\"position\")\n    return out\n\n\n# Export alias for backward compatibility\nStats = _Stats\n\n__all__ = [\n    \"Stats\",  # noqa: F822\n    \"calc_portfolio_returns\",\n    \"single_period_run\",\n    \"run_analysis\",\n    \"run\",\n    \"run_full\",\n    \"compute_signal\",\n    \"position_from_signal\",\n]\n\n\ndef __getattr__(name: str) -> object:\n    if name == \"Stats\":\n        return _Stats\n    raise AttributeError(name)\n\n\ndel Stats\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_43","type":"reasoning","text":"**Designing modular stage refactor**\n\nI'm planning to split the massive pipeline module into smaller, focused stage modulesâ€”preprocessing, selection, portfolioâ€”plus helpers and runner modules to reduce pipeline.py to under 500 lines. I'll carefully move functions and dataclasses into these while maintaining interfaces and test coverage. Iâ€™m also considering how to keep logging consistent, avoid circular imports, and ensure tests referencing pipeline namespace still work by selectively re-exporting key names. The goal is a clean, testable, and well-structured codebase with integration tests verifying stage isolation doesn't alter outputs."}}
{"type":"item.started","item":{"id":"item_44","type":"command_execution","command":"/bin/bash -lc 'rg -n \"identify_risk_free_fund\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_44","type":"command_execution","command":"/bin/bash -lc 'rg -n \"identify_risk_free_fund\" tests'","aggregated_output":"tests/test_data.py:114:def test_identify_risk_free_fund_basic() -> None:\ntests/test_data.py:122:    assert data_mod.identify_risk_free_fund(df) == \"B\"\ntests/test_data.py:125:def test_identify_risk_free_fund_no_numeric() -> None:\ntests/test_data.py:127:    assert data_mod.identify_risk_free_fund(df) is None\ntests/test_data.py:776:def test_identify_risk_free_fund_logs_choice(caplog: pytest.LogCaptureFixture) -> None:\ntests/test_data.py:786:        fund = data_mod.identify_risk_free_fund(frame)\ntests/test_trend_analysis_data_keepalive.py:460:def test_identify_risk_free_fund_prefers_lowest_volatility() -> None:\ntests/test_trend_analysis_data_keepalive.py:475:    choice = data_mod.identify_risk_free_fund(DummyFrame())\ntests/test_trend_analysis_data_keepalive.py:479:def test_identify_risk_free_fund_returns_none_for_non_numeric() -> None:\ntests/test_trend_analysis_data_keepalive.py:485:    assert data_mod.identify_risk_free_fund(DummyFrame()) is None\ntests/test_trend_analysis_data_module.py:455:def test_identify_risk_free_fund_selects_lowest_std():\ntests/test_trend_analysis_data_module.py:464:    assert data_module.identify_risk_free_fund(df) == \"alpha\"\ntests/test_trend_analysis_data_module.py:467:def test_identify_risk_free_fund_handles_no_numeric():\ntests/test_trend_analysis_data_module.py:469:    assert data_module.identify_risk_free_fund(df) is None\ntests/test_rf_handling.py:241:    from trend_analysis.data import identify_risk_free_fund\ntests/test_rf_handling.py:243:    assert identify_risk_free_fund(df) == \"RiskFree\"\ntests/test_rf_handling.py:255:    from trend_analysis.data import identify_risk_free_fund\ntests/test_rf_handling.py:257:    assert identify_risk_free_fund(df) == \"t-Bill\"\ntests/test_trend_analysis_init_module.py:311:        trend_analysis.__dict__, \"identify_risk_free_fund\", raising=False\ntests/test_trend_analysis_init_module.py:316:    assert \"identify_risk_free_fund\" not in module.__dict__\ntests/test_trend_analysis_package.py:68:    assert \"identify_risk_free_fund\" not in missing_optional.__dict__\ntests/test_package_init.py:36:    # ``load_csv`` and ``identify_risk_free_fund`` are re-exported when the\ntests/test_package_init.py:39:    assert trend_analysis.identify_risk_free_fund is data_mod.identify_risk_free_fund\ntests/trend_analysis/test_data.py:762:def test_identify_risk_free_fund_returns_none_for_non_numeric():\ntests/trend_analysis/test_data.py:764:    assert data.identify_risk_free_fund(df) is None\ntests/trend_analysis/test_data.py:767:def test_identify_risk_free_fund_selects_lowest_std(caplog):\ntests/trend_analysis/test_data.py:777:        result = data.identify_risk_free_fund(df)\ntests/trend_analysis/test_package_init.py:237:    sentinel.identify_risk_free_fund = object()\ntests/trend_analysis/test_package_init.py:266:    assert module.identify_risk_free_fund is sentinel.identify_risk_free_fund\ntests/test_trend_analysis_package_init.py:60:    # ``load_csv`` and ``identify_risk_free_fund`` should come from the data module.\ntests/test_trend_analysis_package_init.py:63:    assert hasattr(module, \"identify_risk_free_fund\")\ntests/test_trend_analysis_package_init.py:64:    assert module.identify_risk_free_fund is module.data.identify_risk_free_fund\ntests/test_trend_analysis_package_init.py:112:        context.delattr(module, \"identify_risk_free_fund\", raising=False)\ntests/test_trend_analysis_package_init.py:119:        assert not hasattr(reloaded, \"identify_risk_free_fund\")\ntests/soft_coverage/test_data_soft.py:21:    identify_risk_free_fund,\ntests/soft_coverage/test_data_soft.py:526:def test_identify_risk_free_fund_returns_lowest_volatility() -> None:\ntests/soft_coverage/test_data_soft.py:534:    assert identify_risk_free_fund(df) == \"FundA\"\ntests/soft_coverage/test_data_soft.py:537:def test_identify_risk_free_fund_handles_missing_numeric() -> None:\ntests/soft_coverage/test_data_soft.py:539:    assert identify_risk_free_fund(df) is None\ntests/soft_coverage/test_trend_analysis_init.py:194:    from .data import identify_risk_free_fund, load_csv\ntests/soft_coverage/test_trend_analysis_init.py:225:        trend_analysis_module.identify_risk_free_fund\ntests/soft_coverage/test_trend_analysis_init.py:226:        is trend_analysis_module.data.identify_risk_free_fund\ntests/test_trend_analysis_data.py:21:    identify_risk_free_fund,\ntests/test_trend_analysis_data.py:372:def test_identify_risk_free_fund_returns_lowest_volatility() -> None:\ntests/test_trend_analysis_data.py:381:    assert identify_risk_free_fund(df) == \"FundB\"\ntests/test_trend_analysis_data.py:384:def test_identify_risk_free_fund_returns_none_when_no_numeric() -> None:\ntests/test_trend_analysis_data.py:388:    assert identify_risk_free_fund(df) is None\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_45","type":"reasoning","text":"**Searching for risk-free fund monkeypatch**"}}
{"type":"item.started","item":{"id":"item_46","type":"command_execution","command":"/bin/bash -lc 'rg -n \"identify_risk_free_fund\" tests/test_pipeline* tests/test_*pipeline*'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_46","type":"command_execution","command":"/bin/bash -lc 'rg -n \"identify_risk_free_fund\" tests/test_pipeline* tests/test_*pipeline*'","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_47","type":"reasoning","text":"**Analyzing dependency injection for patching**"}}
{"type":"item.completed","item":{"id":"item_48","type":"reasoning","text":"**Organizing helpers and runner modules**\n\nIâ€™m sorting pipeline_helpers to hold utility functions like compute_signal with dependency injection, while pipeline_runner will manage orchestration and analysis functions to keep pipeline small and test-friendly. This setup helps tests patch pipeline functions easily and keeps the responsibilities clear."}}
{"type":"item.started","item":{"id":"item_49","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_MIN_FALLBACK_COVERAGE_RATIO\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_49","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_MIN_FALLBACK_COVERAGE_RATIO\" tests'","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_50","type":"reasoning","text":"**Verifying pipeline stage classes**"}}
{"type":"item.started","item":{"id":"item_51","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_PreprocessStage|_WindowStage|_SelectionStage|_ComputationStage\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_51","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_PreprocessStage|_WindowStage|_SelectionStage|_ComputationStage\" tests'","aggregated_output":"tests/test_pipeline_run_analysis_helpers.py:16:    _WindowStage,\ntests/test_pipeline_run_analysis_helpers.py:121:    assert isinstance(window, _WindowStage)\ntests/test_pipeline_run_analysis_helpers.py:441:    tampered_window = _WindowStage(\ntests/test_pipeline_helpers.py:177:    # _prepare_preprocess_stage returns either a _PreprocessStage or a PipelineResult\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_52","type":"reasoning","text":"**Checking test imports**"}}
{"type":"item.started","item":{"id":"item_53","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,80p' tests/test_pipeline_run_analysis_helpers.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_53","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,80p' tests/test_pipeline_run_analysis_helpers.py\"","aggregated_output":"import warnings\n\nimport pandas as pd\nimport pytest\n\nfrom trend_analysis import pipeline as pipeline_module\nfrom trend_analysis.pipeline import (\n    PipelineReasonCode,\n    PipelineResult,\n    RiskStatsConfig,\n    _assemble_analysis_output,\n    _build_sample_windows,\n    _compute_weights_and_stats,\n    _prepare_preprocess_stage,\n    _select_universe,\n    _WindowStage,\n)\n\n\ndef _make_simple_frame() -> pd.DataFrame:\n    dates = pd.date_range(\"2020-01-31\", periods=6, freq=\"ME\", tz=\"UTC\")\n    frame = pd.DataFrame(\n        {\n            \"Date\": dates,\n            \"A\": [0.01, 0.02, 0.015, 0.0, -0.01, 0.005],\n            \"B\": [0.02, 0.01, 0.0, 0.005, -0.02, 0.01],\n            \"rf\": [0.001] * 6,\n        }\n    )\n    frame.attrs[\"calendar_settings\"] = {\"timezone\": None}\n    return frame\n\n\ndef test_prepare_preprocess_stage_rejects_missing_dates() -> None:\n    df = pd.DataFrame({\"Date\": [pd.NaT, pd.NaT], \"A\": [1, 2]})\n\n    result = _prepare_preprocess_stage(\n        df,\n        floor_vol=None,\n        warmup_periods=0,\n        missing_policy=None,\n        missing_limit=None,\n        stats_cfg=RiskStatsConfig(risk_free=0.0),\n        periods_per_year_override=None,\n        allow_risk_free_fallback=None,\n    )\n\n    assert isinstance(result.diagnostic.reason_code, str)\n    assert result.diagnostic.reason_code == PipelineReasonCode.NO_VALID_DATES.value\n\n\ndef test_prepare_preprocess_stage_returns_payload() -> None:\n    df = _make_simple_frame()\n\n    stage = _prepare_preprocess_stage(\n        df,\n        floor_vol=None,\n        warmup_periods=1,\n        missing_policy=None,\n        missing_limit=None,\n        stats_cfg=RiskStatsConfig(risk_free=0.0),\n        periods_per_year_override=None,\n        allow_risk_free_fallback=None,\n    )\n\n    assert stage.freq_summary.code == \"M\"\n    assert stage.preprocess_info[\"summary\"].startswith(\"Cadence\")\n    assert stage.warmup == 1\n\n\ndef test_build_sample_windows_handles_empty_slice() -> None:\n    df = _make_simple_frame()\n    stats_cfg = RiskStatsConfig(metrics_to_run=[\"Return\"], risk_free=0.0)\n    preprocess = _prepare_preprocess_stage(\n        df,\n        floor_vol=None,\n        warmup_periods=0,\n        missing_policy=None,\n        missing_limit=None,\n        stats_cfg=stats_cfg,\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_54","type":"reasoning","text":"**Planning module re-exports for testing**"}}
{"type":"item.started","item":{"id":"item_55","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_resolve_risk_free_column\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_55","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_resolve_risk_free_column\" tests'","aggregated_output":"tests/test_risk_free_default_alignment.py:14:from trend_analysis.pipeline import _resolve_risk_free_column\ntests/test_risk_free_default_alignment.py:90:def test_resolve_risk_free_column_handles_business_month_end_bounds() -> None:\ntests/test_risk_free_default_alignment.py:105:    rf_col, funds, source = _resolve_risk_free_column(\ntests/test_risk_free_default_alignment.py:182:        _resolve_risk_free_column(\ntests/test_multi_period_engine_keepalive.py:284:    # Mock _resolve_risk_free_column to bypass validation and return a\ntests/test_multi_period_engine_keepalive.py:297:    monkeypatch.setattr(mp_engine, \"_resolve_risk_free_column\", mock_resolve_rf)\ntests/test_pipeline_helpers_additional.py:1407:        # Mock _resolve_risk_free_column to bypass stricter coverage validation\ntests/test_pipeline_helpers_additional.py:1411:            \"_resolve_risk_free_column\",\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_56","type":"reasoning","text":"**Planning synchronization of pipeline dependencies**\n\nI'm working through how to sync pipeline module functions with stage modules, especially for monkeypatching to work in tests. I want to update stage module globals from pipeline counterparts before analysis runs, likely in `_invoke_analysis_with_diag`. Iâ€™m also checking how tests call internal functions to be sure this approach covers them all. Let's explore those test calls and patching details!"}}
{"type":"item.started","item":{"id":"item_57","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_compute_weights_and_stats\" -n tests/test_pipeline_run_analysis_helpers.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_57","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_compute_weights_and_stats\" -n tests/test_pipeline_run_analysis_helpers.py'","aggregated_output":"13:    _compute_weights_and_stats,\n220:def test_compute_weights_and_stats_produces_metrics(\n266:    computation = _compute_weights_and_stats(\n365:    _compute_weights_and_stats(\n453:        _compute_weights_and_stats(\n522:    computation = _compute_weights_and_stats(\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_58","type":"command_execution","command":"/bin/bash -lc \"sed -n '200,320p' tests/test_pipeline_run_analysis_helpers.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_58","type":"command_execution","command":"/bin/bash -lc \"sed -n '200,320p' tests/test_pipeline_run_analysis_helpers.py\"","aggregated_output":"        indices_list=[\"Missing\"],\n        seed=1,\n        stats_cfg=RiskStatsConfig(risk_free=0.0),\n        risk_free_column=\"rf\",\n        allow_risk_free_fallback=True,\n    )\n\n    assert isinstance(selection, PipelineResult)\n    assert selection.diagnostic is not None\n    assert selection.diagnostic.reason_code == PipelineReasonCode.INDICES_ABSENT.value\n    assert selection.diagnostic.context == {\n        \"requested_indices\": [\"Missing\"],\n        \"missing_indices\": [\"Missing\"],\n        \"available_columns\": [\"A\", \"B\", \"rf\"],\n    }\n\n\n# Tests that monkeypatch pipeline functions must run serially to avoid\n# interfering with parallel test execution.\n@pytest.mark.serial\ndef test_compute_weights_and_stats_produces_metrics(\n    monkeypatch: pytest.MonkeyPatch,\n) -> None:\n    df = _make_simple_frame()\n    stats_cfg = RiskStatsConfig(metrics_to_run=[\"Sharpe\"], risk_free=0.0)\n\n    def _fake_single_period_run(\n        df: pd.DataFrame, *_: object, **__: object\n    ) -> pd.DataFrame:\n        cols = [c for c in df.columns if c != \"Date\"]\n        return pd.DataFrame({\"Sharpe\": [0.1] * len(cols)}, index=cols)\n\n    monkeypatch.setattr(pipeline_module, \"single_period_run\", _fake_single_period_run)\n    preprocess = _prepare_preprocess_stage(\n        df,\n        floor_vol=None,\n        warmup_periods=0,\n        missing_policy=None,\n        missing_limit=None,\n        stats_cfg=stats_cfg,\n        periods_per_year_override=None,\n        allow_risk_free_fallback=None,\n    )\n    window = _build_sample_windows(\n        preprocess,\n        in_start=\"2020-01-31\",\n        in_end=\"2020-03-31\",\n        out_start=\"2020-04-30\",\n        out_end=\"2020-06-30\",\n    )\n    selection = _select_universe(\n        preprocess,\n        window,\n        in_label=\"2020-01-31\",\n        in_end_label=\"2020-03-31\",\n        selection_mode=\"all\",\n        random_n=1,\n        custom_weights=None,\n        rank_kwargs=None,\n        manual_funds=None,\n        indices_list=None,\n        seed=1,\n        stats_cfg=stats_cfg,\n        risk_free_column=\"rf\",\n        allow_risk_free_fallback=True,\n    )\n    computation = _compute_weights_and_stats(\n        preprocess,\n        window,\n        selection,\n        target_vol=0.1,\n        monthly_cost=0.0,\n        custom_weights=None,\n        weighting_scheme=None,\n        constraints=None,\n        risk_window=None,\n        previous_weights=None,\n        lambda_tc=None,\n        max_turnover=None,\n        signal_spec=None,\n        weight_policy=None,\n        warmup=0,\n        min_floor=0.0,\n        stats_cfg=stats_cfg,\n        weight_engine_params=None,\n    )\n\n    assert set(computation.in_stats.keys()) == set(selection.fund_cols)\n    assert computation.risk_diagnostics.scale_factors.shape[0] == len(\n        selection.fund_cols\n    )\n\n\n@pytest.mark.serial\ndef test_compute_weights_scopes_signal_inputs_to_window(\n    monkeypatch: pytest.MonkeyPatch,\n) -> None:\n    base = _make_simple_frame()\n    extra = pd.DataFrame(\n        {\n            \"Date\": [pd.Timestamp(\"2020-07-31\", tz=\"UTC\")],\n            \"A\": [0.02],\n            \"B\": [0.01],\n            \"rf\": [0.001],\n        }\n    )\n    df = pd.concat([base, extra], ignore_index=True)\n    df.attrs[\"calendar_settings\"] = {\"timezone\": None}\n    stats_cfg = RiskStatsConfig(metrics_to_run=[\"Sharpe\"], risk_free=0.0)\n\n    def _fake_single_period_run(\n        df: pd.DataFrame, *_: object, **__: object\n    ) -> pd.DataFrame:\n        cols = [c for c in df.columns if c != \"Date\"]\n        return pd.DataFrame({\"Sharpe\": [0.1] * len(cols)}, index=cols)\n\n    monkeypatch.setattr(pipeline_module, \"single_period_run\", _fake_single_period_run)\n\n    observed: dict[str, pd.Timestamp] = {}\n\n    def _fake_compute_trend_signals(\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_59","type":"reasoning","text":"**Analyzing dependency syncing for test monkeypatches**\n\nI'm working through how the pipeline module's stage functions rely on patched dependencies when tests monkeypatch them. To ensure patched versions are used during direct callsâ€”like to _select_universe or _compute_weights_and_statsâ€”I'll create small wrapper functions in pipeline that sync the selection and portfolio modules' globals to pipeline's patched versions just before delegating calls. This syncing will maintain consistency for all stage functions and keep pipeline relatively thin while accommodating test patches effectively."}}
{"type":"item.started","item":{"id":"item_60","type":"command_execution","command":"/bin/bash -lc 'rg -n \"apply_weight_policy\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_60","type":"command_execution","command":"/bin/bash -lc 'rg -n \"apply_weight_policy\" tests'","aggregated_output":"tests/test_weight_policy.py:5:from trend_analysis.portfolio import apply_weight_policy\ntests/test_weight_policy.py:16:def test_apply_weight_policy_drop_normalises_after_filtering():\ntests/test_weight_policy.py:20:    result = apply_weight_policy(weights, signals, mode=\"drop\", min_assets=1)\ntests/test_weight_policy.py:27:def test_apply_weight_policy_carry_uses_previous_weights():\ntests/test_weight_policy.py:32:    result = apply_weight_policy(\ntests/test_weight_policy.py:41:def test_apply_weight_policy_cash_preserves_cash_buffer():\ntests/test_weight_policy.py:45:    result = apply_weight_policy(weights, signals, mode=\"cash\", min_assets=1)\ntests/test_weight_policy.py:51:def test_apply_weight_policy_handles_warmup_with_previous_weights():\ntests/test_weight_policy.py:56:    result = apply_weight_policy(\ntests/test_weight_policy.py:67:def test_apply_weight_policy_cash_mode_clips_negatives():\ntests/test_weight_policy.py:71:    result = apply_weight_policy(weights, signals, mode=\"cash\", min_assets=1)\ntests/test_weight_policy.py:78:def test_apply_weight_policy_drop_mode_fallback_under_min():\ntests/test_weight_policy.py:83:    result = apply_weight_policy(\ntests/test_weight_policy.py:94:def test_apply_weight_policy_falls_back_to_empty_when_previous_insufficient():\ntests/test_weight_policy.py:98:    result = apply_weight_policy(\ntests/test_weight_policy.py:105:def test_apply_weight_policy_zero_sum_returns_zeros():\ntests/test_weight_policy.py:109:    result = apply_weight_policy(weights, signals, mode=\"drop\", min_assets=1)\ntests/test_weight_policy.py:116:def test_apply_weight_policy_returns_empty_without_valid_inputs():\ntests/test_weight_policy.py:120:    empty_result = apply_weight_policy(weights, signals, mode=\"drop\", min_assets=1)\ntests/test_weight_policy.py:125:    result = apply_weight_policy(\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_61","type":"reasoning","text":"**Designing dependency synchronization and wrappers**\n\nThis is a detailed plan to sync patched dependencies across pipeline and stage modules by creating wrappers and a `_sync_stage_dependencies` function. Iâ€™m thinking through how to handle recursion risks with wrappers and ensure tests patching functions in pipeline module propagate correctly into underlying stage modules. Iâ€™m also considering moving heavy logic to helper modules while keeping pipeline functions as thin wrappers to maintain patchability during tests. This involves aliasing some functions instead of wrapping them and planning how to structure modules like `pipeline_runner` and `pipeline_entrypoints.py` to balance maintainability and test compatibility."}}
{"type":"item.completed","item":{"id":"item_62","type":"reasoning","text":"**Planning modularization and testing strategies**\n\nIâ€™m outlining how to split pipeline code into new stage and helper modules to keep patchability for tests while moving heavy logic out of pipeline.py. Iâ€™m also considering how to design bindings for dependency injection in entrypoints, manage logging, and ensure that tests patching pipeline functions affect helpers correctly. Additionally, Iâ€™m planning new integration tests to verify that isolating stages doesnâ€™t affect output and contemplating coverage requirements for new stage modules. This involves careful orchestration of imports and exports to avoid circular dependencies and keep existing tests effective."}}
{"type":"item.started","item":{"id":"item_63","type":"command_execution","command":"/bin/bash -lc 'rg -n \"pipeline_failure|pipeline_success\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_63","type":"command_execution","command":"/bin/bash -lc 'rg -n \"pipeline_failure|pipeline_success\" tests'","aggregated_output":"tests/test_diagnostics.py:32:def test_pipeline_success_exposes_mapping_interface():\ntests/test_diagnostics.py:34:    result = diagnostics.pipeline_success(payload)\ntests/test_diagnostics.py:52:def test_pipeline_failure_defaults_message_and_copies_context():\ntests/test_diagnostics.py:54:    result = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:95:def test_pipeline_failure_accepts_custom_message_and_context_copy(monkeypatch):\ntests/test_diagnostics.py:98:    result = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:111:def test_pipeline_failure_falls_back_to_reason_code_when_default_missing(monkeypatch):\ntests/test_diagnostics.py:118:    result = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:197:    failure = diagnostics.pipeline_failure(\ntests/test_diagnostics.py:208:def test_pipeline_failure_without_context_sets_none():\ntests/test_diagnostics.py:209:    result = diagnostics.pipeline_failure(diagnostics.PipelineReasonCode.INPUT_NONE)\ntests/test_diagnostics.py:216:def test_pipeline_success_copy_does_not_mutate_original_payload():\ntests/test_diagnostics.py:218:    result = diagnostics.pipeline_success(payload)\ntests/test_risk_free_default_alignment.py:12:from trend_analysis.diagnostics import PipelineReasonCode, pipeline_failure\ntests/test_risk_free_default_alignment.py:141:        return pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED)\ntests/test_risk_free_default_alignment.py:164:        return pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED)\ntests/test_risk_free_default_alignment.py:189:        return pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED)\ntests/test_trend_cli_soft_coverage.py:815:def test_main_run_executes_pipeline_success(\ntests/test_trend_analysis_diagnostics.py:8:    pipeline_failure,\ntests/test_trend_analysis_diagnostics.py:9:    pipeline_success,\ntests/test_trend_analysis_diagnostics.py:23:    result = pipeline_success(payload)\ntests/test_trend_analysis_diagnostics.py:35:def test_pipeline_failure_populates_default_message_and_context_copy():\ntests/test_trend_analysis_diagnostics.py:38:    result = pipeline_failure(PipelineReasonCode.NO_FUNDS_SELECTED, context=context)\ntests/test_trend_analysis_diagnostics.py:53:def test_pipeline_failure_allows_custom_message_override():\ntests/test_trend_analysis_diagnostics.py:54:    result = pipeline_failure(PipelineReasonCode.INPUT_NONE, message=\"custom override\")\ntests/test_trend_analysis_diagnostics.py:63:        (pipeline_success({\"ok\": True}), {\"ok\": True}, None),\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_64","type":"reasoning","text":"**Reviewing pipeline imports and exports**"}}
{"type":"item.started","item":{"id":"item_65","type":"command_execution","command":"/bin/bash -lc 'rg -n \"periods_per_year_from_code\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_65","type":"command_execution","command":"/bin/bash -lc 'rg -n \"periods_per_year_from_code\" tests'","aggregated_output":"tests/test_risk_additional.py:326:def test_periods_per_year_from_code_defaults():\ntests/test_risk_additional.py:327:    assert risk.periods_per_year_from_code(None) == 12.0\ntests/test_risk_additional.py:328:    assert risk.periods_per_year_from_code(\"w\") == 52.0\ntests/test_risk_additional.py:329:    assert risk.periods_per_year_from_code(\"unknown\") == 12.0\ntests/test_risk.py:223:def test_periods_per_year_from_code_defaults() -> None:\ntests/test_risk.py:224:    assert risk.periods_per_year_from_code(None) == 12.0\ntests/test_risk.py:225:    assert risk.periods_per_year_from_code(\"W\") == 52.0\ntests/test_risk.py:226:    assert risk.periods_per_year_from_code(\"unknown\") == 12.0\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_66","type":"reasoning","text":"**Designing pipeline module structure**\n\nIâ€™m sorting out how to structure the pipeline module with wrappers and helpers, considering imports and how pipeline_runner will provide core analysis functions. Iâ€™m planning to start implementation by creating the stages directory and building up from there step by step."}}
{"type":"item.completed","item":{"id":"item_67","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/stages/__init__.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_68","type":"reasoning","text":"**Preparing preprocessing module code**"}}
{"type":"item.completed","item":{"id":"item_69","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/stages/preprocessing.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_70","type":"reasoning","text":"**Creating selection module structure**"}}
{"type":"item.completed","item":{"id":"item_71","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/stages/selection.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_72","type":"reasoning","text":"**Preparing portfolio module setup**"}}
{"type":"item.completed","item":{"id":"item_73","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/stages/portfolio.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_74","type":"reasoning","text":"**Extracting and designing pipeline helpers module**\n\nI'm planning to move multiple helper functions and constants from the pipeline module into a new pipeline_helpers module. I'll carefully replicate imports like logger, allow injection of dependencies such as get_cache and compute_dataset_hash, and maintain typing where possible while simplifying with Any or Mapping for some types. This module will organize utilities like compute_signal, position_from_signal, and regime-related helpers with their dependencies cleanly handled."}}
{"type":"item.completed","item":{"id":"item_75","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_76","type":"reasoning","text":"**Implementing analysis in pipeline runner**"}}
{"type":"item.completed","item":{"id":"item_77","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_runner.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_78","type":"reasoning","text":"**Designing pipeline entrypoints module**\n\nI'll create `pipeline_entrypoints.py` defining `ConfigBindings` with many referenced functions and classes to replicate pipeline run logic, carefully balancing imports versus bindings to preserve test patching flexibility, and include consistent logging and typing for expected return types like DataFrame or PipelineResult."}}
{"type":"item.completed","item":{"id":"item_79","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_entrypoints.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_80","type":"reasoning","text":"**Outlining major pipeline.py refactoring**\n\nI'm planning a major rewrite of pipeline.py to slim it down and organize imports clearly. I want to carefully manage syncing between pipeline wrappers and stage modules to enable patching without recursion, especially for key functions like _resolve_risk_free_column, single_period_run, and _prepare_input_data. I'll create wrappers that call a sync function to update stage dependencies before delegating to real implementations, avoiding recursion traps by aliasing and selectively wrapping functions. This setup should also support tests patching pipeline functions while keeping stage modules in sync."}}
{"type":"item.started","item":{"id":"item_81","type":"command_execution","command":"/bin/bash -lc \"rg -n \\\"_compute_stats\\\\(\\\" tests\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_81","type":"command_execution","command":"/bin/bash -lc \"rg -n \\\"_compute_stats\\\\(\\\" tests\"","aggregated_output":"tests/test_pipeline_entrypoints.py:199:    stats = pipeline._compute_stats(\ntests/test_export_additional_coverage.py:106:    fund_in_stats = _compute_stats(in_df, rf_in)\ntests/test_export_additional_coverage.py:107:    fund_out_stats = _compute_stats(out_df, rf_out)\ntests/test_export_additional_coverage.py:114:        return _compute_stats(pd.DataFrame({\"p\": returns}), rf)[\"p\"]\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_82","type":"reasoning","text":"**Analyzing pipeline module synchronization and wrappers**"}}
{"type":"item.started","item":{"id":"item_83","type":"command_execution","command":"/bin/bash -lc \"cat <<'PY' > src/trend_analysis/pipeline.py\nfrom __future__ import annotations\n\nimport logging\nfrom typing import Any, Mapping, cast\n\nimport pandas as pd\n\nfrom trend.diagnostics import DiagnosticResult\n\nfrom .core.rank_selection import (\n    RiskStatsConfig,\n    get_window_metric_bundle,\n    make_window_key,\n    rank_select_funds,\n)\nfrom .data import identify_risk_free_fund, load_csv\nfrom .diagnostics import AnalysisResult, PipelineReasonCode, PipelineResult\nfrom .metrics import (\n    annual_return,\n    information_ratio,\n    max_drawdown,\n    sharpe_ratio,\n    sortino_ratio,\n    volatility,\n)\nfrom .perf.rolling_cache import compute_dataset_hash, get_cache\nfrom .portfolio import apply_weight_policy\nfrom .regimes import build_regime_payload\nfrom .risk import compute_constrained_weights, realised_volatility\nfrom .signals import TrendSpec, compute_trend_signals\nfrom .time_utils import align_calendar\nfrom .util.frequency import FrequencySummary, detect_frequency\nfrom .util.missing import MissingPolicyResult, apply_missing_policy\nfrom .weights.robust_config import weight_engine_params_from_robustness\n\nfrom . import stages\nfrom .pipeline_entrypoints import ConfigBindings, run_from_config, run_full_from_config\nfrom .pipeline_helpers import (\n    _apply_regime_overrides,\n    _apply_regime_weight_overrides,\n    _attach_calendar_settings,\n    _build_trend_spec,\n    _cfg_section,\n    _cfg_value,\n    _derive_split_from_periods,\n    _empty_run_full_result,\n    _format_period,\n    _policy_from_config,\n    _resolve_regime_label,\n    _resolve_sample_split,\n    _resolve_target_vol,\n    _section_get,\n    _unwrap_cfg,\n    compute_signal as _compute_signal_impl,\n    position_from_signal as _position_from_signal_impl,\n)\nfrom .pipeline_runner import (\n    _run_analysis as _run_analysis_impl,\n    _run_analysis_with_diagnostics as _run_analysis_with_diagnostics_impl,\n)\nfrom .stages import portfolio as portfolio_stage\nfrom .stages import preprocessing as preprocessing_stage\nfrom .stages import selection as selection_stage\nfrom .stages.portfolio import (\n    _ComputationStage,\n    _Stats,\n    _assemble_analysis_output as _assemble_analysis_output_impl,\n    _compute_stats,\n    _compute_weights_and_stats as _compute_weights_and_stats_impl,\n    calc_portfolio_returns,\n)\nfrom .stages.preprocessing import (\n    _PreprocessStage,\n    _WindowStage,\n    _build_sample_windows as _build_sample_windows_impl,\n    _frequency_label,\n    _prepare_input_data as _prepare_input_data_impl,\n    _prepare_preprocess_stage as _prepare_preprocess_stage_impl,\n    _preprocessing_summary,\n)\nfrom .stages.selection import (\n    _SelectionStage,\n    _resolve_risk_free_column,\n    _select_universe as _select_universe_impl,\n    single_period_run,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _sync_stage_dependencies() -> None:\n    \\\"\\\"\\\"Synchronize stage module globals with pipeline-level bindings.\n\n    This ensures monkeypatching pipeline functions affects stage execution.\n    \\\"\\\"\\\"\n\n    preprocessing_stage.detect_frequency = detect_frequency\n    preprocessing_stage.apply_missing_policy = apply_missing_policy\n    preprocessing_stage.align_calendar = align_calendar\n    preprocessing_stage._prepare_input_data = _prepare_input_data\n\n    selection_stage.rank_select_funds = rank_select_funds\n    selection_stage.get_window_metric_bundle = get_window_metric_bundle\n    selection_stage.make_window_key = make_window_key\n    selection_stage.single_period_run = single_period_run\n    selection_stage._resolve_risk_free_column = _resolve_risk_free_column\n    selection_stage.identify_risk_free_fund = identify_risk_free_fund\n\n    portfolio_stage.compute_trend_signals = compute_trend_signals\n    portfolio_stage.compute_constrained_weights = compute_constrained_weights\n    portfolio_stage.realised_volatility = realised_volatility\n    portfolio_stage.apply_weight_policy = apply_weight_policy\n    portfolio_stage.information_ratio = information_ratio\n    portfolio_stage.annual_return = annual_return\n    portfolio_stage.volatility = volatility\n    portfolio_stage.sharpe_ratio = sharpe_ratio\n    portfolio_stage.sortino_ratio = sortino_ratio\n    portfolio_stage.max_drawdown = max_drawdown\n    portfolio_stage.build_regime_payload = build_regime_payload\n\n\ndef _prepare_input_data(\n    df: pd.DataFrame,\n    *,\n    date_col: str,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    enforce_completeness: bool = True,\n) -> tuple[pd.DataFrame, FrequencySummary, MissingPolicyResult, bool]:\n    _sync_stage_dependencies()\n    return _prepare_input_data_impl(\n        df,\n        date_col=date_col,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        enforce_completeness=enforce_completeness,\n    )\n\n\ndef _prepare_preprocess_stage(\n    df: pd.DataFrame | None,\n    *,\n    floor_vol: float | None,\n    warmup_periods: int,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    stats_cfg: RiskStatsConfig | None,\n    periods_per_year_override: float | None,\n    allow_risk_free_fallback: bool | None,\n) -> _PreprocessStage | PipelineResult:\n    _sync_stage_dependencies()\n    return _prepare_preprocess_stage_impl(\n        df,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        stats_cfg=stats_cfg,\n        periods_per_year_override=periods_per_year_override,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n    )\n\n\ndef _build_sample_windows(\n    preprocess: _PreprocessStage,\n    *,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n) -> _WindowStage | PipelineResult:\n    _sync_stage_dependencies()\n    return _build_sample_windows_impl(\n        preprocess,\n        in_start=in_start,\n        in_end=in_end,\n        out_start=out_start,\n        out_end=out_end,\n    )\n\n\ndef _select_universe(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    *,\n    in_label: str,\n    in_end_label: str,\n    selection_mode: str,\n    random_n: int,\n    custom_weights: dict[str, float] | None,\n    rank_kwargs: Mapping[str, Any] | None,\n    manual_funds: list[str] | None,\n    indices_list: list[str] | None,\n    seed: int,\n    stats_cfg: RiskStatsConfig | None,\n    risk_free_column: str | None,\n    allow_risk_free_fallback: bool | None,\n) -> _SelectionStage | PipelineResult:\n    _sync_stage_dependencies()\n    return _select_universe_impl(\n        preprocess,\n        window,\n        in_label=in_label,\n        in_end_label=in_end_label,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n    )\n\n\ndef _compute_weights_and_stats(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    selection: _SelectionStage,\n    *,\n    target_vol: float | None,\n    monthly_cost: float,\n    custom_weights: dict[str, float] | None,\n    weighting_scheme: str | None,\n    constraints: Mapping[str, Any] | None,\n    risk_window: Mapping[str, Any] | None,\n    previous_weights: Mapping[str, float] | None,\n    lambda_tc: float | None,\n    max_turnover: float | None,\n    signal_spec: TrendSpec | None,\n    weight_policy: Mapping[str, Any] | None,\n    warmup: int,\n    min_floor: float,\n    stats_cfg: RiskStatsConfig,\n    weight_engine_params: Mapping[str, Any] | None,\n) -> _ComputationStage:\n    _sync_stage_dependencies()\n    return _compute_weights_and_stats_impl(\n        preprocess,\n        window,\n        selection,\n        target_vol=target_vol,\n        monthly_cost=monthly_cost,\n        custom_weights=custom_weights,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        risk_window=risk_window,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        weight_policy=weight_policy,\n        warmup=warmup,\n        min_floor=min_floor,\n        stats_cfg=stats_cfg,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _assemble_analysis_output(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    selection: _SelectionStage,\n    computation: _ComputationStage,\n    *,\n    benchmarks: Mapping[str, str] | None,\n    regime_cfg: Mapping[str, Any] | None,\n    target_vol: float | None,\n    monthly_cost: float,\n    min_floor: float,\n) -> PipelineResult:\n    _sync_stage_dependencies()\n    return _assemble_analysis_output_impl(\n        preprocess,\n        window,\n        selection,\n        computation,\n        benchmarks=benchmarks,\n        regime_cfg=regime_cfg,\n        target_vol=target_vol,\n        monthly_cost=monthly_cost,\n        min_floor=min_floor,\n    )\n\n\ndef _run_analysis_with_diagnostics(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \\\"all\\\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year_override: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    _sync_stage_dependencies()\n    return _run_analysis_with_diagnostics_impl(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year_override,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \\\"all\\\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year_override: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> AnalysisResult | None:\n    \\\"\\\"\\\"Backward-compatible wrapper returning raw payloads for tests.\\\"\\\"\\\"\n\n    _sync_stage_dependencies()\n    return _run_analysis_impl(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year_override,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\n_DEFAULT_RUN_ANALYSIS = _run_analysis\n\n\ndef _invoke_analysis_with_diag(*args: Any, **kwargs: Any) -> PipelineResult:\n    \\\"\\\"\\\"Call the patched analysis hook and normalise into a PipelineResult.\\\"\\\"\\\"\n\n    if _run_analysis is _DEFAULT_RUN_ANALYSIS:\n        return _run_analysis_with_diagnostics(*args, **kwargs)\n    patched_result = _run_analysis(*args, **kwargs)\n    if isinstance(patched_result, PipelineResult):\n        return patched_result\n    if isinstance(patched_result, DiagnosticResult):\n        return PipelineResult(\n            value=patched_result.value,\n            diagnostic=patched_result.diagnostic,\n        )\n    return PipelineResult(value=patched_result, diagnostic=None)\n\n\ndef run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \\\"all\\\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    calendar_frequency: str | None = None,\n    calendar_timezone: str | None = None,\n    holiday_calendar: str | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    \\\"\\\"\\\"Diagnostics-aware wrapper mirroring \"'``_run_analysis``.\"\"\"\n    if any(\n        value is not None\n        for value in (calendar_frequency, calendar_timezone, holiday_calendar)\n    ):\n        df = df.copy()\n        calendar_settings = dict(getattr(df, \"attrs\", {}).get(\"calendar_settings\", {}))\n        if calendar_frequency is not None:\n            calendar_settings[\"frequency\"] = calendar_frequency\n        if calendar_timezone is not None:\n            calendar_settings[\"timezone\"] = calendar_timezone\n        if holiday_calendar is not None:\n            calendar_settings[\"holiday_calendar\"] = holiday_calendar\n        df.attrs[\"calendar_settings\"] = calendar_settings\n    return _invoke_analysis_with_diag(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _bindings() -> ConfigBindings:\n    return ConfigBindings(\n        load_csv=load_csv,\n        attach_calendar_settings=_attach_calendar_settings,\n        unwrap_cfg=_unwrap_cfg,\n        cfg_section=_cfg_section,\n        section_get=_section_get,\n        cfg_value=_cfg_value,\n        resolve_sample_split=_resolve_sample_split,\n        policy_from_config=_policy_from_config,\n        build_trend_spec=_build_trend_spec,\n        resolve_target_vol=_resolve_target_vol,\n        invoke_analysis_with_diag=_invoke_analysis_with_diag,\n        weight_engine_params_from_robustness=weight_engine_params_from_robustness,\n        RiskStatsConfig=RiskStatsConfig,\n    )\n\n\ndef run(cfg: Any) -> pd.DataFrame:\n    \"\"\"Execute the analysis pipeline based on ``cfg``.\"\"\"\n    return run_from_config(cfg, bindings=_bindings())\n\n\ndef run_full(cfg: Any) -> PipelineResult:\n    \"\"\"Return the full analysis results (with diagnostics) based on ``cfg``.\"\"\"\n    return run_full_from_config(cfg, bindings=_bindings())\n\n\n# --- Shift-safe helpers ----------------------------------------------------\n\n\ndef compute_signal(\n    df: pd.DataFrame,\n    *,\n    column: str = \"returns\",\n    window: int = 3,\n    min_periods: int | None = None,\n) -> pd.Series:\n    return _compute_signal_impl(\n        df,\n        column=column,\n        window=window,\n        min_periods=min_periods,\n        get_cache_func=get_cache,\n        compute_dataset_hash_func=compute_dataset_hash,\n        log=logger,\n    )\n\n\ndef position_from_signal(\n    signal: pd.Series,\n    *,\n    long_position: float = 1.0,\n    short_position: float = -1.0,\n    neutral_position: float = 0.0,\n) -> pd.Series:\n    return _position_from_signal_impl(\n        signal,\n        long_position=long_position,\n        short_position=short_position,\n        neutral_position=neutral_position,\n    )\n\n\n# Export alias for backward compatibility\n+Stats = _Stats\n+\n+__all__ = [\n+    \"Stats\",  # noqa: F822\n+    \"calc_portfolio_returns\",\n+    \"single_period_run\",\n+    \"run_analysis\",\n+    \"run\",\n+    \"run_full\",\n+    \"compute_signal\",\n+    \"position_from_signal\",\n+]\n+\n+\n+def __getattr__(name: str) -> object:\n+    if name == \"Stats\":\n+        return _Stats\n+    raise AttributeError(name)\n+\n+\n+del Stats\n+PY\n'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_83","type":"command_execution","command":"/bin/bash -lc \"cat <<'PY' > src/trend_analysis/pipeline.py\nfrom __future__ import annotations\n\nimport logging\nfrom typing import Any, Mapping, cast\n\nimport pandas as pd\n\nfrom trend.diagnostics import DiagnosticResult\n\nfrom .core.rank_selection import (\n    RiskStatsConfig,\n    get_window_metric_bundle,\n    make_window_key,\n    rank_select_funds,\n)\nfrom .data import identify_risk_free_fund, load_csv\nfrom .diagnostics import AnalysisResult, PipelineReasonCode, PipelineResult\nfrom .metrics import (\n    annual_return,\n    information_ratio,\n    max_drawdown,\n    sharpe_ratio,\n    sortino_ratio,\n    volatility,\n)\nfrom .perf.rolling_cache import compute_dataset_hash, get_cache\nfrom .portfolio import apply_weight_policy\nfrom .regimes import build_regime_payload\nfrom .risk import compute_constrained_weights, realised_volatility\nfrom .signals import TrendSpec, compute_trend_signals\nfrom .time_utils import align_calendar\nfrom .util.frequency import FrequencySummary, detect_frequency\nfrom .util.missing import MissingPolicyResult, apply_missing_policy\nfrom .weights.robust_config import weight_engine_params_from_robustness\n\nfrom . import stages\nfrom .pipeline_entrypoints import ConfigBindings, run_from_config, run_full_from_config\nfrom .pipeline_helpers import (\n    _apply_regime_overrides,\n    _apply_regime_weight_overrides,\n    _attach_calendar_settings,\n    _build_trend_spec,\n    _cfg_section,\n    _cfg_value,\n    _derive_split_from_periods,\n    _empty_run_full_result,\n    _format_period,\n    _policy_from_config,\n    _resolve_regime_label,\n    _resolve_sample_split,\n    _resolve_target_vol,\n    _section_get,\n    _unwrap_cfg,\n    compute_signal as _compute_signal_impl,\n    position_from_signal as _position_from_signal_impl,\n)\nfrom .pipeline_runner import (\n    _run_analysis as _run_analysis_impl,\n    _run_analysis_with_diagnostics as _run_analysis_with_diagnostics_impl,\n)\nfrom .stages import portfolio as portfolio_stage\nfrom .stages import preprocessing as preprocessing_stage\nfrom .stages import selection as selection_stage\nfrom .stages.portfolio import (\n    _ComputationStage,\n    _Stats,\n    _assemble_analysis_output as _assemble_analysis_output_impl,\n    _compute_stats,\n    _compute_weights_and_stats as _compute_weights_and_stats_impl,\n    calc_portfolio_returns,\n)\nfrom .stages.preprocessing import (\n    _PreprocessStage,\n    _WindowStage,\n    _build_sample_windows as _build_sample_windows_impl,\n    _frequency_label,\n    _prepare_input_data as _prepare_input_data_impl,\n    _prepare_preprocess_stage as _prepare_preprocess_stage_impl,\n    _preprocessing_summary,\n)\nfrom .stages.selection import (\n    _SelectionStage,\n    _resolve_risk_free_column,\n    _select_universe as _select_universe_impl,\n    single_period_run,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _sync_stage_dependencies() -> None:\n    \\\"\\\"\\\"Synchronize stage module globals with pipeline-level bindings.\n\n    This ensures monkeypatching pipeline functions affects stage execution.\n    \\\"\\\"\\\"\n\n    preprocessing_stage.detect_frequency = detect_frequency\n    preprocessing_stage.apply_missing_policy = apply_missing_policy\n    preprocessing_stage.align_calendar = align_calendar\n    preprocessing_stage._prepare_input_data = _prepare_input_data\n\n    selection_stage.rank_select_funds = rank_select_funds\n    selection_stage.get_window_metric_bundle = get_window_metric_bundle\n    selection_stage.make_window_key = make_window_key\n    selection_stage.single_period_run = single_period_run\n    selection_stage._resolve_risk_free_column = _resolve_risk_free_column\n    selection_stage.identify_risk_free_fund = identify_risk_free_fund\n\n    portfolio_stage.compute_trend_signals = compute_trend_signals\n    portfolio_stage.compute_constrained_weights = compute_constrained_weights\n    portfolio_stage.realised_volatility = realised_volatility\n    portfolio_stage.apply_weight_policy = apply_weight_policy\n    portfolio_stage.information_ratio = information_ratio\n    portfolio_stage.annual_return = annual_return\n    portfolio_stage.volatility = volatility\n    portfolio_stage.sharpe_ratio = sharpe_ratio\n    portfolio_stage.sortino_ratio = sortino_ratio\n    portfolio_stage.max_drawdown = max_drawdown\n    portfolio_stage.build_regime_payload = build_regime_payload\n\n\ndef _prepare_input_data(\n    df: pd.DataFrame,\n    *,\n    date_col: str,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    enforce_completeness: bool = True,\n) -> tuple[pd.DataFrame, FrequencySummary, MissingPolicyResult, bool]:\n    _sync_stage_dependencies()\n    return _prepare_input_data_impl(\n        df,\n        date_col=date_col,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        enforce_completeness=enforce_completeness,\n    )\n\n\ndef _prepare_preprocess_stage(\n    df: pd.DataFrame | None,\n    *,\n    floor_vol: float | None,\n    warmup_periods: int,\n    missing_policy: str | Mapping[str, str] | None,\n    missing_limit: int | Mapping[str, int | None] | None,\n    stats_cfg: RiskStatsConfig | None,\n    periods_per_year_override: float | None,\n    allow_risk_free_fallback: bool | None,\n) -> _PreprocessStage | PipelineResult:\n    _sync_stage_dependencies()\n    return _prepare_preprocess_stage_impl(\n        df,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        stats_cfg=stats_cfg,\n        periods_per_year_override=periods_per_year_override,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n    )\n\n\ndef _build_sample_windows(\n    preprocess: _PreprocessStage,\n    *,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n) -> _WindowStage | PipelineResult:\n    _sync_stage_dependencies()\n    return _build_sample_windows_impl(\n        preprocess,\n        in_start=in_start,\n        in_end=in_end,\n        out_start=out_start,\n        out_end=out_end,\n    )\n\n\ndef _select_universe(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    *,\n    in_label: str,\n    in_end_label: str,\n    selection_mode: str,\n    random_n: int,\n    custom_weights: dict[str, float] | None,\n    rank_kwargs: Mapping[str, Any] | None,\n    manual_funds: list[str] | None,\n    indices_list: list[str] | None,\n    seed: int,\n    stats_cfg: RiskStatsConfig | None,\n    risk_free_column: str | None,\n    allow_risk_free_fallback: bool | None,\n) -> _SelectionStage | PipelineResult:\n    _sync_stage_dependencies()\n    return _select_universe_impl(\n        preprocess,\n        window,\n        in_label=in_label,\n        in_end_label=in_end_label,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n    )\n\n\ndef _compute_weights_and_stats(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    selection: _SelectionStage,\n    *,\n    target_vol: float | None,\n    monthly_cost: float,\n    custom_weights: dict[str, float] | None,\n    weighting_scheme: str | None,\n    constraints: Mapping[str, Any] | None,\n    risk_window: Mapping[str, Any] | None,\n    previous_weights: Mapping[str, float] | None,\n    lambda_tc: float | None,\n    max_turnover: float | None,\n    signal_spec: TrendSpec | None,\n    weight_policy: Mapping[str, Any] | None,\n    warmup: int,\n    min_floor: float,\n    stats_cfg: RiskStatsConfig,\n    weight_engine_params: Mapping[str, Any] | None,\n) -> _ComputationStage:\n    _sync_stage_dependencies()\n    return _compute_weights_and_stats_impl(\n        preprocess,\n        window,\n        selection,\n        target_vol=target_vol,\n        monthly_cost=monthly_cost,\n        custom_weights=custom_weights,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        risk_window=risk_window,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        weight_policy=weight_policy,\n        warmup=warmup,\n        min_floor=min_floor,\n        stats_cfg=stats_cfg,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _assemble_analysis_output(\n    preprocess: _PreprocessStage,\n    window: _WindowStage,\n    selection: _SelectionStage,\n    computation: _ComputationStage,\n    *,\n    benchmarks: Mapping[str, str] | None,\n    regime_cfg: Mapping[str, Any] | None,\n    target_vol: float | None,\n    monthly_cost: float,\n    min_floor: float,\n) -> PipelineResult:\n    _sync_stage_dependencies()\n    return _assemble_analysis_output_impl(\n        preprocess,\n        window,\n        selection,\n        computation,\n        benchmarks=benchmarks,\n        regime_cfg=regime_cfg,\n        target_vol=target_vol,\n        monthly_cost=monthly_cost,\n        min_floor=min_floor,\n    )\n\n\ndef _run_analysis_with_diagnostics(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \\\"all\\\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year_override: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    _sync_stage_dependencies()\n    return _run_analysis_with_diagnostics_impl(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year_override,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \\\"all\\\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year_override: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> AnalysisResult | None:\n    \\\"\\\"\\\"Backward-compatible wrapper returning raw payloads for tests.\\\"\\\"\\\"\n\n    _sync_stage_dependencies()\n    return _run_analysis_impl(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year_override,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\n_DEFAULT_RUN_ANALYSIS = _run_analysis\n\n\ndef _invoke_analysis_with_diag(*args: Any, **kwargs: Any) -> PipelineResult:\n    \\\"\\\"\\\"Call the patched analysis hook and normalise into a PipelineResult.\\\"\\\"\\\"\n\n    if _run_analysis is _DEFAULT_RUN_ANALYSIS:\n        return _run_analysis_with_diagnostics(*args, **kwargs)\n    patched_result = _run_analysis(*args, **kwargs)\n    if isinstance(patched_result, PipelineResult):\n        return patched_result\n    if isinstance(patched_result, DiagnosticResult):\n        return PipelineResult(\n            value=patched_result.value,\n            diagnostic=patched_result.diagnostic,\n        )\n    return PipelineResult(value=patched_result, diagnostic=None)\n\n\ndef run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \\\"all\\\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    calendar_frequency: str | None = None,\n    calendar_timezone: str | None = None,\n    holiday_calendar: str | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    \\\"\\\"\\\"Diagnostics-aware wrapper mirroring \"'``_run_analysis``.\"\"\"\n    if any(\n        value is not None\n        for value in (calendar_frequency, calendar_timezone, holiday_calendar)\n    ):\n        df = df.copy()\n        calendar_settings = dict(getattr(df, \"attrs\", {}).get(\"calendar_settings\", {}))\n        if calendar_frequency is not None:\n            calendar_settings[\"frequency\"] = calendar_frequency\n        if calendar_timezone is not None:\n            calendar_settings[\"timezone\"] = calendar_timezone\n        if holiday_calendar is not None:\n            calendar_settings[\"holiday_calendar\"] = holiday_calendar\n        df.attrs[\"calendar_settings\"] = calendar_settings\n    return _invoke_analysis_with_diag(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n\n\ndef _bindings() -> ConfigBindings:\n    return ConfigBindings(\n        load_csv=load_csv,\n        attach_calendar_settings=_attach_calendar_settings,\n        unwrap_cfg=_unwrap_cfg,\n        cfg_section=_cfg_section,\n        section_get=_section_get,\n        cfg_value=_cfg_value,\n        resolve_sample_split=_resolve_sample_split,\n        policy_from_config=_policy_from_config,\n        build_trend_spec=_build_trend_spec,\n        resolve_target_vol=_resolve_target_vol,\n        invoke_analysis_with_diag=_invoke_analysis_with_diag,\n        weight_engine_params_from_robustness=weight_engine_params_from_robustness,\n        RiskStatsConfig=RiskStatsConfig,\n    )\n\n\ndef run(cfg: Any) -> pd.DataFrame:\n    \"\"\"Execute the analysis pipeline based on ``cfg``.\"\"\"\n    return run_from_config(cfg, bindings=_bindings())\n\n\ndef run_full(cfg: Any) -> PipelineResult:\n    \"\"\"Return the full analysis results (with diagnostics) based on ``cfg``.\"\"\"\n    return run_full_from_config(cfg, bindings=_bindings())\n\n\n# --- Shift-safe helpers ----------------------------------------------------\n\n\ndef compute_signal(\n    df: pd.DataFrame,\n    *,\n    column: str = \"returns\",\n    window: int = 3,\n    min_periods: int | None = None,\n) -> pd.Series:\n    return _compute_signal_impl(\n        df,\n        column=column,\n        window=window,\n        min_periods=min_periods,\n        get_cache_func=get_cache,\n        compute_dataset_hash_func=compute_dataset_hash,\n        log=logger,\n    )\n\n\ndef position_from_signal(\n    signal: pd.Series,\n    *,\n    long_position: float = 1.0,\n    short_position: float = -1.0,\n    neutral_position: float = 0.0,\n) -> pd.Series:\n    return _position_from_signal_impl(\n        signal,\n        long_position=long_position,\n        short_position=short_position,\n        neutral_position=neutral_position,\n    )\n\n\n# Export alias for backward compatibility\n+Stats = _Stats\n+\n+__all__ = [\n+    \"Stats\",  # noqa: F822\n+    \"calc_portfolio_returns\",\n+    \"single_period_run\",\n+    \"run_analysis\",\n+    \"run\",\n+    \"run_full\",\n+    \"compute_signal\",\n+    \"position_from_signal\",\n+]\n+\n+\n+def __getattr__(name: str) -> object:\n+    if name == \"Stats\":\n+        return _Stats\n+    raise AttributeError(name)\n+\n+\n+del Stats\n+PY\n'","aggregated_output":"/bin/bash: line 634: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_84","type":"reasoning","text":"**Correcting patch file format**"}}
{"type":"item.started","item":{"id":"item_85","type":"command_execution","command":"/bin/bash -lc 'tail -n 40 src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_85","type":"command_execution","command":"/bin/bash -lc 'tail -n 40 src/trend_analysis/pipeline.py'","aggregated_output":"\n\ndef position_from_signal(\n    signal: pd.Series,\n    *,\n    long_position: float = 1.0,\n    short_position: float = -1.0,\n    neutral_position: float = 0.0,\n) -> pd.Series:\n    return _position_from_signal_impl(\n        signal,\n        long_position=long_position,\n        short_position=short_position,\n        neutral_position=neutral_position,\n    )\n\n\n# Export alias for backward compatibility\n+Stats = _Stats\n+\n+__all__ = [\n+    \"Stats\",  # noqa: F822\n+    \"calc_portfolio_returns\",\n+    \"single_period_run\",\n+    \"run_analysis\",\n+    \"run\",\n+    \"run_full\",\n+    \"compute_signal\",\n+    \"position_from_signal\",\n+]\n+\n+\n+def __getattr__(name: str) -> object:\n+    if name == \"Stats\":\n+        return _Stats\n+    raise AttributeError(name)\n+\n+\n+del Stats\n+PY\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_86","type":"reasoning","text":"**Fixing patch formatting issues**"}}
{"type":"item.completed","item":{"id":"item_87","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_88","type":"reasoning","text":"**Reviewing file start for issues**"}}
{"type":"item.started","item":{"id":"item_89","type":"command_execution","command":"/bin/bash -lc 'head -n 40 src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_89","type":"command_execution","command":"/bin/bash -lc 'head -n 40 src/trend_analysis/pipeline.py'","aggregated_output":"from __future__ import annotations\n\nimport logging\nfrom typing import Any, Mapping, cast\n\nimport pandas as pd\n\nfrom trend.diagnostics import DiagnosticResult\n\nfrom .core.rank_selection import (\n    RiskStatsConfig,\n    get_window_metric_bundle,\n    make_window_key,\n    rank_select_funds,\n)\nfrom .data import identify_risk_free_fund, load_csv\nfrom .diagnostics import AnalysisResult, PipelineReasonCode, PipelineResult\nfrom .metrics import (\n    annual_return,\n    information_ratio,\n    max_drawdown,\n    sharpe_ratio,\n    sortino_ratio,\n    volatility,\n)\nfrom .perf.rolling_cache import compute_dataset_hash, get_cache\nfrom .portfolio import apply_weight_policy\nfrom .regimes import build_regime_payload\nfrom .risk import compute_constrained_weights, realised_volatility\nfrom .signals import TrendSpec, compute_trend_signals\nfrom .time_utils import align_calendar\nfrom .util.frequency import FrequencySummary, detect_frequency\nfrom .util.missing import MissingPolicyResult, apply_missing_policy\nfrom .weights.robust_config import weight_engine_params_from_robustness\n\nfrom . import stages\nfrom .pipeline_entrypoints import ConfigBindings, run_from_config, run_full_from_config\nfrom .pipeline_helpers import (\n    _apply_regime_overrides,\n    _apply_regime_weight_overrides,\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_90","type":"reasoning","text":"**Reviewing imports and type casting usage**\n\nI'm checking unused imports like `stages` and `cast`, considering removal for cleanliness but cautious about tests and module namespace. I realized entrypoints convert to DataFrame differently from pipeline code; to keep consistent type safety and behavior, Iâ€™ll switch entrypoints to use `cast(pd.DataFrame, df)` instead of `pd.DataFrame(df)`. This means adding the `cast` import back and adjusting the code accordingly."}}
{"type":"item.completed","item":{"id":"item_91","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_entrypoints.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_92","type":"reasoning","text":"**Cleaning up unused imports**"}}
{"type":"item.completed","item":{"id":"item_93","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_94","type":"reasoning","text":"**Cleaning up unused imports**"}}
{"type":"item.completed","item":{"id":"item_95","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_96","type":"reasoning","text":"**Reviewing pipeline imports and aliases**"}}
{"type":"item.started","item":{"id":"item_97","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_97","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"631 src/trend_analysis/pipeline.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_98","type":"reasoning","text":"**Optimizing pipeline wrapper functions**"}}
{"type":"item.started","item":{"id":"item_99","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_apply_regime_overrides|_apply_regime_weight_overrides|_resolve_regime_label\" tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_99","type":"command_execution","command":"/bin/bash -lc 'rg -n \"_apply_regime_overrides|_apply_regime_weight_overrides|_resolve_regime_label\" tests'","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_100","type":"reasoning","text":"**Reducing code verbosity with helper function**"}}
{"type":"item.completed","item":{"id":"item_101","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_102","type":"reasoning","text":"**Counting lines**"}}
{"type":"item.started","item":{"id":"item_103","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_103","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"632 src/trend_analysis/pipeline.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_104","type":"reasoning","text":"**Considering line count reduction strategies**"}}
{"type":"item.completed","item":{"id":"item_105","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_106","type":"reasoning","text":"**Checking patch syntax near function definition**"}}
{"type":"item.started","item":{"id":"item_107","type":"command_execution","command":"/bin/bash -lc \"sed -n '150,260p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_107","type":"command_execution","command":"/bin/bash -lc \"sed -n '150,260p' src/trend_analysis/pipeline.py\"","aggregated_output":"\ndef _run_analysis(*args: Any, **kwargs: Any) -> Any:\\n    \\\"\\\"\\\"Backward-compatible wrapper returning raw payloads for tests.\\\"\\\"\\\"\\n    return _call_with_sync(_run_analysis_impl, *args, **kwargs)\\n*** End Patch\"}}\n\n\n_DEFAULT_RUN_ANALYSIS = _run_analysis\n\n\ndef _invoke_analysis_with_diag(*args: Any, **kwargs: Any) -> PipelineResult:\n    \"\"\"Call the patched analysis hook and normalise into a PipelineResult.\"\"\"\n\n    if _run_analysis is _DEFAULT_RUN_ANALYSIS:\n        return _run_analysis_with_diagnostics(*args, **kwargs)\n    patched_result = _run_analysis(*args, **kwargs)\n    if isinstance(patched_result, PipelineResult):\n        return patched_result\n    if isinstance(patched_result, DiagnosticResult):\n        return PipelineResult(\n            value=patched_result.value,\n            diagnostic=patched_result.diagnostic,\n        )\n    return PipelineResult(value=patched_result, diagnostic=None)\n\n\ndef run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \"all\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n    indices_list: list[str] | None = None,\n    benchmarks: dict[str, str] | None = None,\n    seed: int = 42,\n    stats_cfg: RiskStatsConfig | None = None,\n    weighting_scheme: str | None = None,\n    constraints: dict[str, Any] | None = None,\n    missing_policy: str | Mapping[str, str] | None = None,\n    missing_limit: int | Mapping[str, int | None] | None = None,\n    risk_window: Mapping[str, Any] | None = None,\n    periods_per_year: float | None = None,\n    previous_weights: Mapping[str, float] | None = None,\n    lambda_tc: float | None = None,\n    max_turnover: float | None = None,\n    signal_spec: TrendSpec | None = None,\n    regime_cfg: Mapping[str, Any] | None = None,\n    calendar_frequency: str | None = None,\n    calendar_timezone: str | None = None,\n    holiday_calendar: str | None = None,\n    weight_policy: Mapping[str, Any] | None = None,\n    risk_free_column: str | None = None,\n    allow_risk_free_fallback: bool | None = None,\n    weight_engine_params: Mapping[str, Any] | None = None,\n) -> PipelineResult:\n    \"\"\"Diagnostics-aware wrapper mirroring ``_run_analysis``.\"\"\"\n    if any(\n        value is not None\n        for value in (calendar_frequency, calendar_timezone, holiday_calendar)\n    ):\n        df = df.copy()\n        calendar_settings = dict(getattr(df, \"attrs\", {}).get(\"calendar_settings\", {}))\n        if calendar_frequency is not None:\n            calendar_settings[\"frequency\"] = calendar_frequency\n        if calendar_timezone is not None:\n            calendar_settings[\"timezone\"] = calendar_timezone\n        if holiday_calendar is not None:\n            calendar_settings[\"holiday_calendar\"] = holiday_calendar\n        df.attrs[\"calendar_settings\"] = calendar_settings\n    return _invoke_analysis_with_diag(\n        df,\n        in_start,\n        in_end,\n        out_start,\n        out_end,\n        target_vol,\n        monthly_cost,\n        floor_vol=floor_vol,\n        warmup_periods=warmup_periods,\n        selection_mode=selection_mode,\n        random_n=random_n,\n        custom_weights=custom_weights,\n        rank_kwargs=rank_kwargs,\n        manual_funds=manual_funds,\n        indices_list=indices_list,\n        benchmarks=benchmarks,\n        seed=seed,\n        stats_cfg=stats_cfg,\n        weighting_scheme=weighting_scheme,\n        constraints=constraints,\n        missing_policy=missing_policy,\n        missing_limit=missing_limit,\n        risk_window=risk_window,\n        periods_per_year_override=periods_per_year,\n        previous_weights=previous_weights,\n        lambda_tc=lambda_tc,\n        max_turnover=max_turnover,\n        signal_spec=signal_spec,\n        regime_cfg=regime_cfg,\n        weight_policy=weight_policy,\n        risk_free_column=risk_free_column,\n        allow_risk_free_fallback=allow_risk_free_fallback,\n        weight_engine_params=weight_engine_params,\n    )\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_108","type":"reasoning","text":"**Correcting patch errors**"}}
{"type":"item.completed","item":{"id":"item_109","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_110","type":"reasoning","text":"**Verifying patch boundary markers**"}}
{"type":"item.started","item":{"id":"item_111","type":"command_execution","command":"/bin/bash -lc \"rg -n \\\"End Patch|\\\\\\\\n\\\" src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_111","type":"command_execution","command":"/bin/bash -lc \"rg -n \\\"End Patch|\\\\\\\\n\\\" src/trend_analysis/pipeline.py\"","aggregated_output":"rg: the literal \"\\n\" is not allowed in a regex\n\nConsider enabling multiline mode with the --multiline flag (or -U for short).\nWhen multiline mode is enabled, new line characters can be matched.\n","exit_code":2,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_112","type":"reasoning","text":"**Searching for \"End Patch\" markers**"}}
{"type":"item.started","item":{"id":"item_113","type":"command_execution","command":"/bin/bash -lc 'rg -n \"End Patch\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_113","type":"command_execution","command":"/bin/bash -lc 'rg -n \"End Patch\" src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_114","type":"reasoning","text":"**Checking _run_analysis area**"}}
{"type":"item.started","item":{"id":"item_115","type":"command_execution","command":"/bin/bash -lc \"sed -n '120,190p' src/trend_analysis/pipeline.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_115","type":"command_execution","command":"/bin/bash -lc \"sed -n '120,190p' src/trend_analysis/pipeline.py\"","aggregated_output":"    return func(*args, **kwargs)\n\n\ndef _prepare_input_data(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_prepare_input_data_impl, *args, **kwargs)\n\n\ndef _prepare_preprocess_stage(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_prepare_preprocess_stage_impl, *args, **kwargs)\n\n\ndef _build_sample_windows(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_build_sample_windows_impl, *args, **kwargs)\n\n\ndef _select_universe(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_select_universe_impl, *args, **kwargs)\n\n\ndef _compute_weights_and_stats(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_compute_weights_and_stats_impl, *args, **kwargs)\n\n\ndef _assemble_analysis_output(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_assemble_analysis_output_impl, *args, **kwargs)\n\n\ndef _run_analysis_with_diagnostics(*args: Any, **kwargs: Any) -> Any:\n    return _call_with_sync(_run_analysis_with_diagnostics_impl, *args, **kwargs)\n\n\ndef _run_analysis(*args: Any, **kwargs: Any) -> Any:\n    \"\"\"Backward-compatible wrapper returning raw payloads for tests.\"\"\"\n    return _call_with_sync(_run_analysis_impl, *args, **kwargs)\n\n\n_DEFAULT_RUN_ANALYSIS = _run_analysis\n\n\ndef _invoke_analysis_with_diag(*args: Any, **kwargs: Any) -> PipelineResult:\n    \"\"\"Call the patched analysis hook and normalise into a PipelineResult.\"\"\"\n\n    if _run_analysis is _DEFAULT_RUN_ANALYSIS:\n        return _run_analysis_with_diagnostics(*args, **kwargs)\n    patched_result = _run_analysis(*args, **kwargs)\n    if isinstance(patched_result, PipelineResult):\n        return patched_result\n    if isinstance(patched_result, DiagnosticResult):\n        return PipelineResult(\n            value=patched_result.value,\n            diagnostic=patched_result.diagnostic,\n        )\n    return PipelineResult(value=patched_result, diagnostic=None)\n\n\ndef run_analysis(\n    df: pd.DataFrame,\n    in_start: str,\n    in_end: str,\n    out_start: str,\n    out_end: str,\n    target_vol: float | None,\n    monthly_cost: float,\n    *,\n    floor_vol: float | None = None,\n    warmup_periods: int = 0,\n    selection_mode: str = \"all\",\n    random_n: int = 8,\n    custom_weights: dict[str, float] | None = None,\n    rank_kwargs: Mapping[str, Any] | None = None,\n    manual_funds: list[str] | None = None,\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_116","type":"reasoning","text":"**Checking line count after changes**"}}
{"type":"item.started","item":{"id":"item_117","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_117","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"350 src/trend_analysis/pipeline.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_118","type":"reasoning","text":"**Ensuring pipeline integrity and updating plan**"}}
{"type":"item.updated","item":{"id":"item_7","type":"todo_list","items":[{"text":"Inspect pipeline.py to identify preprocessing/selection/portfolio logic boundaries and dependent helpers","completed":true},{"text":"Create stages package and move preprocessing/selection/portfolio logic into new modules with tests","completed":false},{"text":"Refactor pipeline.py to orchestrate via stages, preserve public API, and add integration test + coverage checks","completed":false}]}}
{"type":"item.completed","item":{"id":"item_119","type":"reasoning","text":"**Designing stage isolation integration tests**\n\nIâ€™m mapping out an integration test that compares outputs from the full pipeline run with manual invocation of individual stage modules to verify they produce matching results independently. Iâ€™m also considering coverage implications and planning to create a new test file focused on stage isolation to ensure solid testing across the refactored modules."}}
{"type":"item.completed","item":{"id":"item_120","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_pipeline_stage_isolation.py","kind":"add"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_121","type":"reasoning","text":"**Planning targeted test coverage runs**\n\nI'm figuring out how to run the tests efficiently by targeting coverage for each pipeline stage module individually to meet >80% coverage, while also considering the instruction to run existing tests before committing. It seems best to run the coverage commands for preprocessing, selection, and portfolio stages separately, treating those as tests too, to balance thoroughness and time. I'll start by running coverage for the preprocessing stage as a first step."}}
{"type":"item.started","item":{"id":"item_122","type":"command_execution","command":"/bin/bash -lc 'pytest tests/ --cov=src/trend_analysis/stages/preprocessing --cov-report=term-missing -m \"not slow\" -x'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_122","type":"command_execution","command":"/bin/bash -lc 'pytest tests/ --cov=src/trend_analysis/stages/preprocessing --cov-report=term-missing -m \"not slow\" -x'","aggregated_output":"mkdir -p failed for path /home/runner/.config/matplotlib: [Errno 13] Permission denied: '/home/runner/.config/matplotlib'\nMatplotlib created a temporary cache directory at /tmp/matplotlib-3zicnjj5 because there was an issue with the default path (/home/runner/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\nINTERNALERROR> Traceback (most recent call last):\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/main.py\", line 314, in wrap_session\nINTERNALERROR>     config._do_configure()\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 1159, in _do_configure\nINTERNALERROR>     self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_hooks.py\", line 534, in call_historic\nINTERNALERROR>     res = self._hookexec(self.name, self._hookimpls.copy(), kwargs, False)\nINTERNALERROR>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_manager.py\", line 120, in _hookexec\nINTERNALERROR>     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\nINTERNALERROR>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_callers.py\", line 167, in _multicall\nINTERNALERROR>     raise exception\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_callers.py\", line 121, in _multicall\nINTERNALERROR>     res = hook_impl.function(*args)\nINTERNALERROR>           ^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 347, in pytest_configure\nINTERNALERROR>     config.failures_db = ServerStatusDB()\nINTERNALERROR>                          ^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 451, in __init__\nINTERNALERROR>     super().__init__()\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 432, in __init__\nINTERNALERROR>     self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nINTERNALERROR>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/socket.py\", line 232, in __init__\nINTERNALERROR>     _socket.socket.__init__(self, family, type, proto, fileno)\nINTERNALERROR> PermissionError: [Errno 1] Operation not permitted\n","exit_code":3,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_123","type":"reasoning","text":"**Adjusting test environment to fix permission errors**\n\nI'm setting environment variables to rerun the tests while avoiding permission issues with matplotlib config and socket creation. I'll disable the pytest_rerunfailures plugin and redirect MPLCONFIGDIR to a writable directory like /tmp/matplotlib, then rerun the tests with these settings to work around sandbox restrictions."}}
{"type":"item.started","item":{"id":"item_124","type":"command_execution","command":"/bin/bash -lc 'MPLCONFIGDIR=/tmp/matplotlib PYTEST_ADDOPTS=\"-p no:pytest_rerunfailures\" pytest tests/ --cov=src/trend_analysis/stages/preprocessing --cov-report=term-missing -m \"not slow\" -x'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_124","type":"command_execution","command":"/bin/bash -lc 'MPLCONFIGDIR=/tmp/matplotlib PYTEST_ADDOPTS=\"-p no:pytest_rerunfailures\" pytest tests/ --cov=src/trend_analysis/stages/preprocessing --cov-report=term-missing -m \"not slow\" -x'","aggregated_output":"INTERNALERROR> Traceback (most recent call last):\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/main.py\", line 314, in wrap_session\nINTERNALERROR>     config._do_configure()\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 1159, in _do_configure\nINTERNALERROR>     self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_hooks.py\", line 534, in call_historic\nINTERNALERROR>     res = self._hookexec(self.name, self._hookimpls.copy(), kwargs, False)\nINTERNALERROR>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_manager.py\", line 120, in _hookexec\nINTERNALERROR>     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\nINTERNALERROR>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_callers.py\", line 167, in _multicall\nINTERNALERROR>     raise exception\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_callers.py\", line 121, in _multicall\nINTERNALERROR>     res = hook_impl.function(*args)\nINTERNALERROR>           ^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 347, in pytest_configure\nINTERNALERROR>     config.failures_db = ServerStatusDB()\nINTERNALERROR>                          ^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 451, in __init__\nINTERNALERROR>     super().__init__()\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 432, in __init__\nINTERNALERROR>     self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nINTERNALERROR>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/socket.py\", line 232, in __init__\nINTERNALERROR>     _socket.socket.__init__(self, family, type, proto, fileno)\nINTERNALERROR> PermissionError: [Errno 1] Operation not permitted\n","exit_code":3,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_125","type":"reasoning","text":"**Testing plugin disabling approach**"}}
{"type":"item.started","item":{"id":"item_126","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_126","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 3637 items\n\ntests/backtesting/test_bootstrap.py ........                             [  0%]\ntests/backtesting/test_harness.py ...........................            [  0%]\ntests/golden/test_demo.py ....                                           [  1%]\ntests/proxy/test_server.py ...............                               [  1%]\ntests/scripts/test_ci_history.py ................                        [  1%]\ntests/scripts/test_ci_metrics.py .....................                   [  2%]\ntests/scripts/test_evaluate_settings_effectiveness.py ....               [  2%]\ntests/scripts/test_sync_test_dependencies.py ......                      [  2%]\ntests/scripts/test_sync_tool_versions.py ....                            [  2%]\ntests/scripts/test_verify_trusted_config.py .......                      [  3%]\ntests/smoke/test_pipeline_smoke.py .                                     [  3%]\ntests/soft_coverage/test_data_soft.py ................................   [  3%]\ntests/soft_coverage/test_regimes_soft.py ......................          [  4%]\ntests/soft_coverage/test_signal_presets_soft.py .....                    [  4%]\ntests/soft_coverage/test_trend_analysis_init.py ..........               [  5%]\ntests/test_adaptive_bayes.py .....                                       [  5%]\ntests/test_analysis_results_module.py ......                             [  5%]\ntests/test_api_run_simulation.py .......                                 [  5%]\ntests/test_api_run_simulation_branches.py .......                        [  5%]\ntests/test_api_run_simulation_extra.py .....                             [  5%]\ntests/test_api_safe_len.py ...                                           [  5%]\ntests/test_api_signal_settings.py ..                                     [  5%]\ntests/test_app_coverage.py ...........................................   [  7%]\ntests/test_avg_corr_metric.py .                                          [  7%]\ntests/test_avgcorr_export.py ..                                          [  7%]\ntests/test_backtest_utils.py ...                                         [  7%]\ntests/test_backtesting_harness_additional.py .........                   [  7%]\ntests/test_backtesting_harness_membership.py ...                         [  7%]\ntests/test_build_autofix_pr_comment.py .............                     [  8%]\ntests/test_buy_and_hold_selection.py .......s                            [  8%]\ntests/test_cache_disable.py .                                            [  8%]\ntests/test_cli.py ..........                                             [  8%]\ntests/test_cli_api_golden_master.py ..                                   [  8%]\ntests/test_cli_cache_stats.py .                                          [  8%]\ntests/test_cli_cache_stats_disabled.py .                                 [  8%]\ntests/test_cli_cache_stats_extended.py ...                               [  8%]\ntests/test_cli_check.py .....                                            [  8%]\ntests/test_cli_helpers.py .....                                          [  8%]\ntests/test_cli_installed.py .....                                        [  9%]\ntests/test_cli_module.py .........                                       [  9%]\ntests/test_cli_no_cache_flag.py .                                        [  9%]\ntests/test_cli_no_structured_log.py .                                    [  9%]\ntests/test_cli_smoke.py .....                                            [  9%]\ntests/test_cli_trend_presets.py ...                                      [  9%]\ntests/test_cli_utils.py .....                                            [  9%]\ntests/test_config.py .                                                   [  9%]\ntests/test_config_alignment.py ..                                        [  9%]\ntests/test_config_bridge.py ........                                     [ 10%]\ntests/test_config_bridge_parity.py .                                     [ 10%]\ntests/test_config_errors.py .                                            [ 10%]\ntests/test_config_fallback_additional.py ................                [ 10%]\ntests/test_config_fallback_minimal.py ..........                         [ 10%]\ntests/test_config_human_errors.py .....................                  [ 11%]\ntests/test_config_legacy.py ...                                          [ 11%]\ntests/test_config_legacy_output_conversion.py ....                       [ 11%]\ntests/test_config_load.py .......                                        [ 11%]\ntests/test_config_model.py ............................................. [ 13%]\n......                                                                   [ 13%]\ntests/test_config_model_branch_coverage.py ............                  [ 13%]\ntests/test_config_model_validation.py ................                   [ 13%]\ntests/test_config_models.py ...                                          [ 14%]\ntests/test_config_models_additional.py ..............                    [ 14%]\ntests/test_config_models_coverage_extensions.py ............             [ 14%]\ntests/test_config_models_fallback_loader.py ....                         [ 14%]\ntests/test_config_models_fallback_unit.py .................              [ 15%]\ntests/test_config_path_discovery.py ......                               [ 15%]\ntests/test_config_pydantic_fallback.py ......                            [ 15%]\ntests/test_config_schema.py .......                                      [ 15%]\ntests/test_config_turnover_validation.py .................               [ 16%]\ntests/test_config_validation.py ....                                     [ 16%]\ntests/test_configure_presets.py ......                                   [ 16%]\ntests/test_constants.py .......                                          [ 16%]\ntests/test_constraint_optimizer.py .........                             [ 17%]\ntests/test_cov_cache_integration.py .                                    [ 17%]\ntests/test_coverage_trend.py ............                                [ 17%]\ntests/test_cv.py ...                                                     [ 17%]\ntests/test_data.py ..................................................... [ 18%]\n..........                                                               [ 19%]\ntests/test_data_contracts.py .........                                   [ 19%]\ntests/test_data_malformed_dates.py .......                               [ 19%]\ntests/test_data_schema.py .............                                  [ 20%]\ntests/test_date_correction.py ....................                       [ 20%]\ntests/test_decode_raw_input.py ............                              [ 20%]\ntests/test_default_export.py .                                           [ 20%]\ntests/test_dependency_enforcement.py ...                                 [ 21%]\ntests/test_dependency_version_alignment.py .                             [ 21%]\ntests/test_determinism_cli.py ..                                         [ 21%]\ntests/test_diagnostics.py ..................                             [ 21%]\ntests/test_engine_incremental_cov.py ..                                  [ 21%]\ntests/test_export_additional_coverage.py ............................    [ 22%]\ntests/test_export_bundle.py ...............                              [ 22%]\ntests/test_export_errors.py .                                            [ 22%]\ntests/test_export_formatter.py ....................                      [ 23%]\ntests/test_export_manifest_schema.py ..                                  [ 23%]\ntests/test_export_openpyxl_adapter.py ................                   [ 23%]\ntests/test_export_outputs.py ..                                          [ 23%]\ntests/test_exports.py .........                                          [ 24%]\ntests/test_frequency_missing.py ........                                 [ 24%]\ntests/test_gui.py ........                                               [ 24%]\ntests/test_gui_app_extended.py .....                                     [ 24%]\ntests/test_gui_app_simple.py ...........                                 [ 25%]\ntests/test_gui_launch_run.py ..                                          [ 25%]\ntests/test_gui_support.py .....                                          [ 25%]\ntests/test_gui_utils_extra.py .....                                      [ 25%]\ntests/test_hash_utils.py ....                                            [ 25%]\ntests/test_health_summarize_module.py ..........................         [ 26%]\ntests/test_import_excludes.py ..                                         [ 26%]\ntests/test_import_sanity.py ...                                          [ 26%]\ntests/test_inception_dates.py .                                          [ 26%]\ntests/test_incremental_cov.py .                                          [ 26%]\ntests/test_input_validation.py .......                                   [ 26%]\ntests/test_invariants.py ........                                        [ 26%]\ntests/test_io_utils.py ...........                                       [ 27%]\ntests/test_io_utils_cleanup.py ....                                      [ 27%]\ntests/test_io_validators_additional.py ...s                              [ 27%]\ntests/test_io_validators_extra.py .................................      [ 28%]\ntests/test_io_validators_negative_paths.py ....                          [ 28%]\ntests/test_is_zero_everywhere_helper.py .......                          [ 28%]\ntests/test_joblib_import.py ......                                       [ 28%]\ntests/test_joblib_shim.py .                                              [ 28%]\ntests/test_label_rules_assert.py ..                                      [ 28%]\ntests/test_legacy_imports.py ....                                        [ 28%]\ntests/test_lockfile_consistency.py s...                                  [ 29%]\ntests/test_logging_helpers.py ....                                       [ 29%]\ntests/test_logging_integration.py .                                      [ 29%]\ntests/test_logging_module.py ......                                      [ 29%]\ntests/test_logging_utils.py .....                                        [ 29%]\ntests/test_malformed_date_validation.py .....                            [ 29%]\ntests/test_market_data_validation.py ..................................  [ 30%]\ntests/test_market_data_validation_additional.py ........................ [ 31%]\n..                                                                       [ 31%]\ntests/test_metric_cache.py .....                                         [ 31%]\ntests/test_metric_vectorise.py .                                         [ 31%]\ntests/test_metric_vectorise_param.py .....                               [ 31%]\ntests/test_metrics.py .....                                              [ 31%]\ntests/test_metrics_attribution.py ........                               [ 31%]\ntests/test_metrics_edgecases.py ....                                     [ 32%]\ntests/test_metrics_extra.py ...........                                  [ 32%]\ntests/test_metrics_rolling.py .....                                      [ 32%]\ntests/test_metrics_rolling_cache_disabled.py .                           [ 32%]\ntests/test_metrics_summary.py .                                          [ 32%]\ntests/test_metrics_turnover_extra.py ..                                  [ 32%]\ntests/test_multi_period_engine.py .......                                [ 32%]\ntests/test_multi_period_engine_additional.py ................            [ 33%]\ntests/test_multi_period_engine_branch_completion.py ..........           [ 33%]\ntests/test_multi_period_engine_branch_coverage.py .....                  [ 33%]\ntests/test_multi_period_engine_branch_new.py ............                [ 33%]\ntests/test_multi_period_engine_cov_cache.py ...                          [ 34%]\ntests/test_multi_period_engine_debug.py .                                [ 34%]\ntests/test_multi_period_engine_extended.py .....                         [ 34%]\ntests/test_multi_period_engine_helpers_additional.py ....                [ 34%]\ntests/test_multi_period_engine_incremental_cov.py .............          [ 34%]\ntests/test_multi_period_engine_incremental_extra.py ....                 [ 34%]\ntests/test_multi_period_engine_incremental_fallback.py .                 [ 34%]\ntests/test_multi_period_engine_keepalive.py ......                       [ 35%]\ntests/test_multi_period_engine_lambda_tc.py .                            [ 35%]\ntests/test_multi_period_engine_missing_policy.py ..                      [ 35%]\ntests/test_multi_period_engine_portfolio_unit.py ....                    [ 35%]\ntests/test_multi_period_engine_price_frames.py .........                 [ 35%]\ntests/test_multi_period_engine_price_frames_extra.py ........            [ 35%]\ntests/test_multi_period_engine_run_schedule_extra.py ..                  [ 35%]\ntests/test_multi_period_engine_threshold_bounds.py ..                    [ 35%]\ntests/test_multi_period_engine_threshold_edgecases.py ........           [ 35%]\ntests/test_multi_period_engine_threshold_events_extended.py ..           [ 36%]\ntests/test_multi_period_engine_turnover_extended.py ...                  [ 36%]\ntests/test_multi_period_engine_turnover_regression.py ....               [ 36%]\ntests/test_multi_period_exits_cooldown.py .........                      [ 36%]\ntests/test_multi_period_export.py .................                      [ 36%]\ntests/test_multi_period_inception_filter.py .                            [ 36%]\ntests/test_multi_period_loaders.py ...................                   [ 37%]\ntests/test_multi_period_missing_policy_observability.py ..               [ 37%]\ntests/test_multi_period_rebalancer.py ...........                        [ 37%]\ntests/test_multi_period_regime_wiring.py ..                              [ 37%]\ntests/test_multi_period_scheduler.py ...                                 [ 37%]\ntests/test_multi_period_selection.py .                                   [ 38%]\ntests/test_multi_period_sticky_periods.py ...                            [ 38%]\ntests/test_multi_period_stub.py ..                                       [ 38%]\ntests/test_mypy_autofix.py .......                                       [ 38%]\ntests/test_na_as_zero_policy.py ...                                      [ 38%]\ntests/test_no_hardcoded_sleeps.py ...                                    [ 38%]\ntests/test_no_invalid_period_freq_aliases.py ..                          [ 38%]\ntests/test_no_lookahead.py ....                                          [ 38%]\ntests/test_optimizer.py .........                                        [ 38%]\ntests/test_optimizer_branch_coverage.py ...............                  [ 39%]\ntests/test_optimizer_constraints.py ...........................          [ 40%]\ntests/test_optimizer_constraints_additional.py ......................... [ 40%]\n                                                                         [ 40%]\ntests/test_optimizer_constraints_guardrails.py ..............            [ 41%]\ntests/test_optional_notebook_deps.py ..                                  [ 41%]\ntests/test_package_init.py .....                                         [ 41%]\ntests/test_perf_cache.py ..                                              [ 41%]\ntests/test_perf_cache_additional.py ...                                  [ 41%]\ntests/test_perf_cache_extended.py .........                              [ 41%]\ntests/test_perf_timing.py ....                                           [ 41%]\ntests/test_pipeline.py .......................                           [ 42%]\ntests/test_pipeline_branch_coverage.py .........                         [ 42%]\ntests/test_pipeline_calendar_alignment.py .                              [ 42%]\ntests/test_pipeline_constraints_integration.py .....                     [ 42%]\ntests/test_pipeline_entrypoints.py ........                              [ 43%]\ntests/test_pipeline_helpers.py ..........                                [ 43%]\ntests/test_pipeline_helpers_additional.py ................F\n\n=================================== FAILURES ===================================\n__________________ test_resolve_sample_split_reports_missing ___________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1ef5309f50>\n\n    def test_resolve_sample_split_reports_missing(monkeypatch: pytest.MonkeyPatch) -> None:\n        df = pd.DataFrame(\n            {\"Date\": pd.date_range(\"2020-01-31\", periods=4, freq=\"ME\"), \"A\": np.arange(4)}\n        )\n        with monkeypatch.context() as mp:\n            mp.setattr(\n                pipeline,\n                \"_derive_split_from_periods\",\n                lambda *args, **kwargs: {\"in_start\": \"2020-01\"},\n            )\n>           with pytest.raises(ValueError, match=\"Unable to derive sample split values\"):\nE           Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_pipeline_helpers_additional.py:375: Failed\n=============================== warnings summary ===============================\ntests/golden/test_demo.py:172\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:172: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/golden/test_demo.py:307\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:307: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:628: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n    quarterly = pd.date_range(\"2020-01-01\", periods=5, freq=\"Q\")\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:636: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    very_sparse = pd.date_range(\"2020-01-01\", periods=2, freq=\"36M\")\n\ntests/soft_coverage/test_regimes_soft.py: 14 warnings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/soft_coverage/test_regimes_soft.py:28: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    return pd.date_range(\"2024-01-31\", periods=periods, freq=freq)\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:194: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:343: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, utc=True, errors=\"coerce\")\n\ntests/test_date_correction.py::TestDateCorrection::test_iso_format_dates_corrected\ntests/test_date_correction.py::TestDateCorrection::test_completely_invalid_date_not_correctable\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/streamlit_app/components/date_correction.py:221: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_malformed_date_validation.py::TestMalformedDateValidation::test_all_malformed_dates\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values_partial\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/io/market_data.py:134: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_market_data_validation.py::test_classify_frequency_gap_tolerance_exceeded\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_market_data_validation.py:339: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    idx = pd.date_range(\"2020-01-31\", periods=4, freq=\"2M\")\n\ntests/test_multi_period_engine_branch_new.py::test_run_raises_when_policy_drops_all\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_multi_period_engine_branch_new.py:118: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<NA>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n    empty.iloc[:, :] = pd.NA\n\ntests/test_pipeline_helpers_additional.py::test_resolve_sample_split_invalid_dates_raise\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py:465: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nSKIPPED [1] tests/test_buy_and_hold_selection.py:377: Could not import analysis_runner: No module named 'streamlit'\nSKIPPED [1] tests/test_io_validators_additional.py:50: could not import 'pyarrow': No module named 'pyarrow'\nSKIPPED [1] tests/test_lockfile_consistency.py:63: Dependency lockfile check only runs during scheduled refresh\nFAILED tests/test_pipeline_helpers_additional.py::test_resolve_sample_split_reports_missing - Failed: DID NOT RAISE <class 'ValueError'>\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\n====== 1 failed, 1591 passed, 3 skipped, 31 warnings in 107.38s (0:01:47) ======\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_127","type":"reasoning","text":"**Resolving patching conflicts between pipeline and helpers**\n\nI'm working out how to ensure that patching `pipeline._derive_split_from_periods` correctly affects the helper function `pipeline_helpers._derive_split_from_periods` used inside `_resolve_sample_split`. To do this, I plan to wrap `_resolve_sample_split` in the pipeline module so it updates the helper's function reference before calling the original implementation, adjusting imports to avoid circular dependencies and ensuring patches hit all relevant calls."}}
{"type":"item.completed","item":{"id":"item_128","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_129","type":"reasoning","text":"**Planning optimized test coverage rerun**\n\nI'm figuring out how to rerun the tests with coverage efficiently after a failure. Running the full suite thrice would be heavy, so Iâ€™m considering a single pytest run with multiple targeted `--cov` options for each stage module to get separate coverage reports without multiple full runs. This should handle plugin issues while meeting the >80% coverage requirement. I'll rerun once with the combined coverage flags after verifying the fix."}}
{"type":"item.started","item":{"id":"item_130","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_130","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 3637 items\n\ntests/backtesting/test_bootstrap.py ........                             [  0%]\ntests/backtesting/test_harness.py ...........................            [  0%]\ntests/golden/test_demo.py ....                                           [  1%]\ntests/proxy/test_server.py ...............                               [  1%]\ntests/scripts/test_ci_history.py ................                        [  1%]\ntests/scripts/test_ci_metrics.py .....................                   [  2%]\ntests/scripts/test_evaluate_settings_effectiveness.py ....               [  2%]\ntests/scripts/test_sync_test_dependencies.py ......                      [  2%]\ntests/scripts/test_sync_tool_versions.py ....                            [  2%]\ntests/scripts/test_verify_trusted_config.py .......                      [  3%]\ntests/smoke/test_pipeline_smoke.py .                                     [  3%]\ntests/soft_coverage/test_data_soft.py ................................   [  3%]\ntests/soft_coverage/test_regimes_soft.py ......................          [  4%]\ntests/soft_coverage/test_signal_presets_soft.py .....                    [  4%]\ntests/soft_coverage/test_trend_analysis_init.py ..........               [  5%]\ntests/test_adaptive_bayes.py .....                                       [  5%]\ntests/test_analysis_results_module.py ......                             [  5%]\ntests/test_api_run_simulation.py .......                                 [  5%]\ntests/test_api_run_simulation_branches.py .......                        [  5%]\ntests/test_api_run_simulation_extra.py .....                             [  5%]\ntests/test_api_safe_len.py ...                                           [  5%]\ntests/test_api_signal_settings.py ..                                     [  5%]\ntests/test_app_coverage.py ...........................................   [  7%]\ntests/test_avg_corr_metric.py .                                          [  7%]\ntests/test_avgcorr_export.py ..                                          [  7%]\ntests/test_backtest_utils.py ...                                         [  7%]\ntests/test_backtesting_harness_additional.py .........                   [  7%]\ntests/test_backtesting_harness_membership.py ...                         [  7%]\ntests/test_build_autofix_pr_comment.py .............                     [  8%]\ntests/test_buy_and_hold_selection.py .......s                            [  8%]\ntests/test_cache_disable.py .                                            [  8%]\ntests/test_cli.py ..........                                             [  8%]\ntests/test_cli_api_golden_master.py ..                                   [  8%]\ntests/test_cli_cache_stats.py .                                          [  8%]\ntests/test_cli_cache_stats_disabled.py .                                 [  8%]\ntests/test_cli_cache_stats_extended.py ...                               [  8%]\ntests/test_cli_check.py .....                                            [  8%]\ntests/test_cli_helpers.py .....                                          [  8%]\ntests/test_cli_installed.py .....                                        [  9%]\ntests/test_cli_module.py .........                                       [  9%]\ntests/test_cli_no_cache_flag.py .                                        [  9%]\ntests/test_cli_no_structured_log.py .                                    [  9%]\ntests/test_cli_smoke.py .....                                            [  9%]\ntests/test_cli_trend_presets.py ...                                      [  9%]\ntests/test_cli_utils.py .....                                            [  9%]\ntests/test_config.py .                                                   [  9%]\ntests/test_config_alignment.py ..                                        [  9%]\ntests/test_config_bridge.py ........                                     [ 10%]\ntests/test_config_bridge_parity.py .                                     [ 10%]\ntests/test_config_errors.py .                                            [ 10%]\ntests/test_config_fallback_additional.py ................                [ 10%]\ntests/test_config_fallback_minimal.py ..........                         [ 10%]\ntests/test_config_human_errors.py .....................                  [ 11%]\ntests/test_config_legacy.py ...                                          [ 11%]\ntests/test_config_legacy_output_conversion.py ....                       [ 11%]\ntests/test_config_load.py .......                                        [ 11%]\ntests/test_config_model.py ............................................. [ 13%]\n......                                                                   [ 13%]\ntests/test_config_model_branch_coverage.py ............                  [ 13%]\ntests/test_config_model_validation.py ................                   [ 13%]\ntests/test_config_models.py ...                                          [ 14%]\ntests/test_config_models_additional.py ..............                    [ 14%]\ntests/test_config_models_coverage_extensions.py ............             [ 14%]\ntests/test_config_models_fallback_loader.py ....                         [ 14%]\ntests/test_config_models_fallback_unit.py .................              [ 15%]\ntests/test_config_path_discovery.py ......                               [ 15%]\ntests/test_config_pydantic_fallback.py ......                            [ 15%]\ntests/test_config_schema.py .......                                      [ 15%]\ntests/test_config_turnover_validation.py .................               [ 16%]\ntests/test_config_validation.py ....                                     [ 16%]\ntests/test_configure_presets.py ......                                   [ 16%]\ntests/test_constants.py .......                                          [ 16%]\ntests/test_constraint_optimizer.py .........                             [ 17%]\ntests/test_cov_cache_integration.py .                                    [ 17%]\ntests/test_coverage_trend.py ............                                [ 17%]\ntests/test_cv.py ...                                                     [ 17%]\ntests/test_data.py ..................................................... [ 18%]\n..........                                                               [ 19%]\ntests/test_data_contracts.py .........                                   [ 19%]\ntests/test_data_malformed_dates.py .......                               [ 19%]\ntests/test_data_schema.py .............                                  [ 20%]\ntests/test_date_correction.py ....................                       [ 20%]\ntests/test_decode_raw_input.py ............                              [ 20%]\ntests/test_default_export.py .                                           [ 20%]\ntests/test_dependency_enforcement.py ...                                 [ 21%]\ntests/test_dependency_version_alignment.py .                             [ 21%]\ntests/test_determinism_cli.py ..                                         [ 21%]\ntests/test_diagnostics.py ..................                             [ 21%]\ntests/test_engine_incremental_cov.py ..                                  [ 21%]\ntests/test_export_additional_coverage.py ............................    [ 22%]\ntests/test_export_bundle.py ...............                              [ 22%]\ntests/test_export_errors.py .                                            [ 22%]\ntests/test_export_formatter.py ....................                      [ 23%]\ntests/test_export_manifest_schema.py ..                                  [ 23%]\ntests/test_export_openpyxl_adapter.py ................                   [ 23%]\ntests/test_export_outputs.py ..                                          [ 23%]\ntests/test_exports.py .........                                          [ 24%]\ntests/test_frequency_missing.py ........                                 [ 24%]\ntests/test_gui.py ........                                               [ 24%]\ntests/test_gui_app_extended.py .....                                     [ 24%]\ntests/test_gui_app_simple.py ...........                                 [ 25%]\ntests/test_gui_launch_run.py ..                                          [ 25%]\ntests/test_gui_support.py .....                                          [ 25%]\ntests/test_gui_utils_extra.py .....                                      [ 25%]\ntests/test_hash_utils.py ....                                            [ 25%]\ntests/test_health_summarize_module.py ..........................         [ 26%]\ntests/test_import_excludes.py ..                                         [ 26%]\ntests/test_import_sanity.py ...                                          [ 26%]\ntests/test_inception_dates.py .                                          [ 26%]\ntests/test_incremental_cov.py .                                          [ 26%]\ntests/test_input_validation.py .......                                   [ 26%]\ntests/test_invariants.py ........                                        [ 26%]\ntests/test_io_utils.py ...........                                       [ 27%]\ntests/test_io_utils_cleanup.py ....                                      [ 27%]\ntests/test_io_validators_additional.py ...s                              [ 27%]\ntests/test_io_validators_extra.py .................................      [ 28%]\ntests/test_io_validators_negative_paths.py ....                          [ 28%]\ntests/test_is_zero_everywhere_helper.py .......                          [ 28%]\ntests/test_joblib_import.py ......                                       [ 28%]\ntests/test_joblib_shim.py .                                              [ 28%]\ntests/test_label_rules_assert.py ..                                      [ 28%]\ntests/test_legacy_imports.py ....                                        [ 28%]\ntests/test_lockfile_consistency.py s...                                  [ 29%]\ntests/test_logging_helpers.py ....                                       [ 29%]\ntests/test_logging_integration.py .                                      [ 29%]\ntests/test_logging_module.py ......                                      [ 29%]\ntests/test_logging_utils.py .....                                        [ 29%]\ntests/test_malformed_date_validation.py .....                            [ 29%]\ntests/test_market_data_validation.py ..................................  [ 30%]\ntests/test_market_data_validation_additional.py ........................ [ 31%]\n..                                                                       [ 31%]\ntests/test_metric_cache.py .....                                         [ 31%]\ntests/test_metric_vectorise.py .                                         [ 31%]\ntests/test_metric_vectorise_param.py .....                               [ 31%]\ntests/test_metrics.py .....                                              [ 31%]\ntests/test_metrics_attribution.py ........                               [ 31%]\ntests/test_metrics_edgecases.py ....                                     [ 32%]\ntests/test_metrics_extra.py ...........                                  [ 32%]\ntests/test_metrics_rolling.py .....                                      [ 32%]\ntests/test_metrics_rolling_cache_disabled.py .                           [ 32%]\ntests/test_metrics_summary.py .                                          [ 32%]\ntests/test_metrics_turnover_extra.py ..                                  [ 32%]\ntests/test_multi_period_engine.py .......                                [ 32%]\ntests/test_multi_period_engine_additional.py ................            [ 33%]\ntests/test_multi_period_engine_branch_completion.py ..........           [ 33%]\ntests/test_multi_period_engine_branch_coverage.py .....                  [ 33%]\ntests/test_multi_period_engine_branch_new.py ............                [ 33%]\ntests/test_multi_period_engine_cov_cache.py ...                          [ 34%]\ntests/test_multi_period_engine_debug.py .                                [ 34%]\ntests/test_multi_period_engine_extended.py .....                         [ 34%]\ntests/test_multi_period_engine_helpers_additional.py ....                [ 34%]\ntests/test_multi_period_engine_incremental_cov.py .............          [ 34%]\ntests/test_multi_period_engine_incremental_extra.py ....                 [ 34%]\ntests/test_multi_period_engine_incremental_fallback.py .                 [ 34%]\ntests/test_multi_period_engine_keepalive.py ......                       [ 35%]\ntests/test_multi_period_engine_lambda_tc.py .                            [ 35%]\ntests/test_multi_period_engine_missing_policy.py ..                      [ 35%]\ntests/test_multi_period_engine_portfolio_unit.py ....                    [ 35%]\ntests/test_multi_period_engine_price_frames.py .........                 [ 35%]\ntests/test_multi_period_engine_price_frames_extra.py ........            [ 35%]\ntests/test_multi_period_engine_run_schedule_extra.py ..                  [ 35%]\ntests/test_multi_period_engine_threshold_bounds.py ..                    [ 35%]\ntests/test_multi_period_engine_threshold_edgecases.py ........           [ 35%]\ntests/test_multi_period_engine_threshold_events_extended.py ..           [ 36%]\ntests/test_multi_period_engine_turnover_extended.py ...                  [ 36%]\ntests/test_multi_period_engine_turnover_regression.py ....               [ 36%]\ntests/test_multi_period_exits_cooldown.py .........                      [ 36%]\ntests/test_multi_period_export.py .................                      [ 36%]\ntests/test_multi_period_inception_filter.py .                            [ 36%]\ntests/test_multi_period_loaders.py ...................                   [ 37%]\ntests/test_multi_period_missing_policy_observability.py ..               [ 37%]\ntests/test_multi_period_rebalancer.py ...........                        [ 37%]\ntests/test_multi_period_regime_wiring.py ..                              [ 37%]\ntests/test_multi_period_scheduler.py ...                                 [ 37%]\ntests/test_multi_period_selection.py .                                   [ 38%]\ntests/test_multi_period_sticky_periods.py ...                            [ 38%]\ntests/test_multi_period_stub.py ..                                       [ 38%]\ntests/test_mypy_autofix.py .......                                       [ 38%]\ntests/test_na_as_zero_policy.py ...                                      [ 38%]\ntests/test_no_hardcoded_sleeps.py ...                                    [ 38%]\ntests/test_no_invalid_period_freq_aliases.py ..                          [ 38%]\ntests/test_no_lookahead.py ....                                          [ 38%]\ntests/test_optimizer.py .........                                        [ 38%]\ntests/test_optimizer_branch_coverage.py ...............                  [ 39%]\ntests/test_optimizer_constraints.py ...........................          [ 40%]\ntests/test_optimizer_constraints_additional.py ......................... [ 40%]\n                                                                         [ 40%]\ntests/test_optimizer_constraints_guardrails.py ..............            [ 41%]\ntests/test_optional_notebook_deps.py ..                                  [ 41%]\ntests/test_package_init.py .....                                         [ 41%]\ntests/test_perf_cache.py ..                                              [ 41%]\ntests/test_perf_cache_additional.py ...                                  [ 41%]\ntests/test_perf_cache_extended.py .........                              [ 41%]\ntests/test_perf_timing.py ....                                           [ 41%]\ntests/test_pipeline.py .......................                           [ 42%]\ntests/test_pipeline_branch_coverage.py .........                         [ 42%]\ntests/test_pipeline_calendar_alignment.py .                              [ 42%]\ntests/test_pipeline_constraints_integration.py .....                     [ 42%]\ntests/test_pipeline_entrypoints.py ........                              [ 43%]\ntests/test_pipeline_helpers.py ..........                                [ 43%]\ntests/test_pipeline_helpers_additional.py .............................. [ 44%]\n.......................                                                  [ 44%]\ntests/test_pipeline_indices.py ...                                       [ 44%]\ntests/test_pipeline_integration_direct.py ..                             [ 44%]\ntests/test_pipeline_optional_features.py ..............F\n\n=================================== FAILURES ===================================\n___________________ test_run_analysis_avg_corr_corr_failure ____________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fd1950cb410>\n\n    def test_run_analysis_avg_corr_corr_failure(monkeypatch: pytest.MonkeyPatch) -> None:\n        df = _clean_returns_frame()\n        stats_cfg = RiskStatsConfig()\n        stats_cfg.metrics_to_run = list(stats_cfg.metrics_to_run) + [\"AvgCorr\"]\n        setattr(stats_cfg, \"extra_metrics\", [\"AvgCorr\"])\n    \n        original_corr = pd.DataFrame.corr\n    \n        def flaky_corr(self, *args, **kwargs):  # type: ignore[override]\n            caller = inspect.stack()[1]\n            if caller.filename.endswith(\"pipeline.py\"):\n                raise RuntimeError(\"corr failure\")\n            return original_corr(self, *args, **kwargs)\n    \n        monkeypatch.setattr(pd.DataFrame, \"corr\", flaky_corr)\n    \n        result = pipeline._run_analysis(\n            df,\n            \"2020-01\",\n            \"2020-02\",\n            \"2020-03\",\n            \"2020-04\",\n            target_vol=1.0,\n            monthly_cost=0.0,\n            stats_cfg=stats_cfg,\n            indices_list=[\"Benchmark\"],\n            benchmarks={\"SPX\": \"Benchmark\"},\n            **RUN_KWARGS,\n        )\n    \n        assert result is not None\n        in_stats = result[\"in_sample_stats\"][\"FundA\"]\n        out_stats = result[\"out_sample_stats\"][\"FundA\"]\n>       assert in_stats.is_avg_corr is None\nE       assert 1.0 is None\nE        +  where 1.0 = _Stats(cagr=19939233085288.414, vol=1.414213562373096, sharpe=14085984682056.482, sortino=nan, max_drawdown=0.0, information_ratio=100.42059417273593, is_avg_corr=1.0, os_avg_corr=None).is_avg_corr\n\ntests/test_pipeline_optional_features.py:581: AssertionError\n=============================== warnings summary ===============================\ntests/golden/test_demo.py:172\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:172: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/golden/test_demo.py:307\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:307: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:628: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n    quarterly = pd.date_range(\"2020-01-01\", periods=5, freq=\"Q\")\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:636: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    very_sparse = pd.date_range(\"2020-01-01\", periods=2, freq=\"36M\")\n\ntests/soft_coverage/test_regimes_soft.py: 14 warnings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/soft_coverage/test_regimes_soft.py:28: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    return pd.date_range(\"2024-01-31\", periods=periods, freq=freq)\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:194: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:343: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, utc=True, errors=\"coerce\")\n\ntests/test_date_correction.py::TestDateCorrection::test_iso_format_dates_corrected\ntests/test_date_correction.py::TestDateCorrection::test_completely_invalid_date_not_correctable\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/streamlit_app/components/date_correction.py:221: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_malformed_date_validation.py::TestMalformedDateValidation::test_all_malformed_dates\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values_partial\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/io/market_data.py:134: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_market_data_validation.py::test_classify_frequency_gap_tolerance_exceeded\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_market_data_validation.py:339: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    idx = pd.date_range(\"2020-01-31\", periods=4, freq=\"2M\")\n\ntests/test_multi_period_engine_branch_new.py::test_run_raises_when_policy_drops_all\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_multi_period_engine_branch_new.py:118: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<NA>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n    empty.iloc[:, :] = pd.NA\n\ntests/test_pipeline_helpers_additional.py::test_resolve_sample_split_invalid_dates_raise\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py:465: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nSKIPPED [1] tests/test_buy_and_hold_selection.py:377: Could not import analysis_runner: No module named 'streamlit'\nSKIPPED [1] tests/test_io_validators_additional.py:50: could not import 'pyarrow': No module named 'pyarrow'\nSKIPPED [1] tests/test_lockfile_consistency.py:63: Dependency lockfile check only runs during scheduled refresh\nFAILED tests/test_pipeline_optional_features.py::test_run_analysis_avg_corr_corr_failure - assert 1.0 is None\n +  where 1.0 = _Stats(cagr=19939233085288.414, vol=1.414213562373096, sharpe=14085984682056.482, sortino=nan, max_drawdown=0.0, information_ratio=100.42059417273593, is_avg_corr=1.0, os_avg_corr=None).is_avg_corr\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\n====== 1 failed, 1647 passed, 3 skipped, 31 warnings in 104.09s (0:01:44) ======\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_131","type":"reasoning","text":"**Designing avg_corr handler injection**\n\nI'm devising a design to move the avg_corr pandas correlation call into a handler function defined in the pipeline module so the patched DataFrame.corr raises as expected in tests, while the portfolio module catches the exception properly. This involves introducing a module-level avg_corr_handler in portfolio.py with a default, allowing pipeline.py to override it during dependency syncâ€”preserving test behavior without circular imports. I'll start by modifying portfolio.py before implementing the pipeline-side handler."}}
{"type":"item.completed","item":{"id":"item_132","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/stages/portfolio.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_133","type":"reasoning","text":"**Adding average correlation handler function**"}}
{"type":"item.completed","item":{"id":"item_134","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_135","type":"reasoning","text":"**Updating _sync_stage_dependencies function**"}}
{"type":"item.completed","item":{"id":"item_136","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_137","type":"reasoning","text":"**Rerunning coverage tests**"}}
{"type":"item.started","item":{"id":"item_138","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_138","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 3637 items\n\ntests/backtesting/test_bootstrap.py ........                             [  0%]\ntests/backtesting/test_harness.py ...........................            [  0%]\ntests/golden/test_demo.py ....                                           [  1%]\ntests/proxy/test_server.py ...............                               [  1%]\ntests/scripts/test_ci_history.py ................                        [  1%]\ntests/scripts/test_ci_metrics.py .....................                   [  2%]\ntests/scripts/test_evaluate_settings_effectiveness.py ....               [  2%]\ntests/scripts/test_sync_test_dependencies.py ......                      [  2%]\ntests/scripts/test_sync_tool_versions.py ....                            [  2%]\ntests/scripts/test_verify_trusted_config.py .......                      [  3%]\ntests/smoke/test_pipeline_smoke.py .                                     [  3%]\ntests/soft_coverage/test_data_soft.py ................................   [  3%]\ntests/soft_coverage/test_regimes_soft.py ......................          [  4%]\ntests/soft_coverage/test_signal_presets_soft.py .....                    [  4%]\ntests/soft_coverage/test_trend_analysis_init.py ..........               [  5%]\ntests/test_adaptive_bayes.py .....                                       [  5%]\ntests/test_analysis_results_module.py ......                             [  5%]\ntests/test_api_run_simulation.py .......                                 [  5%]\ntests/test_api_run_simulation_branches.py .......                        [  5%]\ntests/test_api_run_simulation_extra.py .....                             [  5%]\ntests/test_api_safe_len.py ...                                           [  5%]\ntests/test_api_signal_settings.py ..                                     [  5%]\ntests/test_app_coverage.py ...........................................   [  7%]\ntests/test_avg_corr_metric.py .                                          [  7%]\ntests/test_avgcorr_export.py ..                                          [  7%]\ntests/test_backtest_utils.py ...                                         [  7%]\ntests/test_backtesting_harness_additional.py .........                   [  7%]\ntests/test_backtesting_harness_membership.py ...                         [  7%]\ntests/test_build_autofix_pr_comment.py .............                     [  8%]\ntests/test_buy_and_hold_selection.py .......s                            [  8%]\ntests/test_cache_disable.py .                                            [  8%]\ntests/test_cli.py ..........                                             [  8%]\ntests/test_cli_api_golden_master.py ..                                   [  8%]\ntests/test_cli_cache_stats.py .                                          [  8%]\ntests/test_cli_cache_stats_disabled.py .                                 [  8%]\ntests/test_cli_cache_stats_extended.py ...                               [  8%]\ntests/test_cli_check.py .....                                            [  8%]\ntests/test_cli_helpers.py .....                                          [  8%]\ntests/test_cli_installed.py .....                                        [  9%]\ntests/test_cli_module.py .........                                       [  9%]\ntests/test_cli_no_cache_flag.py .                                        [  9%]\ntests/test_cli_no_structured_log.py .                                    [  9%]\ntests/test_cli_smoke.py .....                                            [  9%]\ntests/test_cli_trend_presets.py ...                                      [  9%]\ntests/test_cli_utils.py .....                                            [  9%]\ntests/test_config.py .                                                   [  9%]\ntests/test_config_alignment.py ..                                        [  9%]\ntests/test_config_bridge.py ........                                     [ 10%]\ntests/test_config_bridge_parity.py .                                     [ 10%]\ntests/test_config_errors.py .                                            [ 10%]\ntests/test_config_fallback_additional.py ................                [ 10%]\ntests/test_config_fallback_minimal.py ..........                         [ 10%]\ntests/test_config_human_errors.py .....................                  [ 11%]\ntests/test_config_legacy.py ...                                          [ 11%]\ntests/test_config_legacy_output_conversion.py ....                       [ 11%]\ntests/test_config_load.py .......                                        [ 11%]\ntests/test_config_model.py ............................................. [ 13%]\n......                                                                   [ 13%]\ntests/test_config_model_branch_coverage.py ............                  [ 13%]\ntests/test_config_model_validation.py ................                   [ 13%]\ntests/test_config_models.py ...                                          [ 14%]\ntests/test_config_models_additional.py ..............                    [ 14%]\ntests/test_config_models_coverage_extensions.py ............             [ 14%]\ntests/test_config_models_fallback_loader.py ....                         [ 14%]\ntests/test_config_models_fallback_unit.py .................              [ 15%]\ntests/test_config_path_discovery.py ......                               [ 15%]\ntests/test_config_pydantic_fallback.py ......                            [ 15%]\ntests/test_config_schema.py .......                                      [ 15%]\ntests/test_config_turnover_validation.py .................               [ 16%]\ntests/test_config_validation.py ....                                     [ 16%]\ntests/test_configure_presets.py ......                                   [ 16%]\ntests/test_constants.py .......                                          [ 16%]\ntests/test_constraint_optimizer.py .........                             [ 17%]\ntests/test_cov_cache_integration.py .                                    [ 17%]\ntests/test_coverage_trend.py ............                                [ 17%]\ntests/test_cv.py ...                                                     [ 17%]\ntests/test_data.py ..................................................... [ 18%]\n..........                                                               [ 19%]\ntests/test_data_contracts.py .........                                   [ 19%]\ntests/test_data_malformed_dates.py .......                               [ 19%]\ntests/test_data_schema.py .............                                  [ 20%]\ntests/test_date_correction.py ....................                       [ 20%]\ntests/test_decode_raw_input.py ............                              [ 20%]\ntests/test_default_export.py .                                           [ 20%]\ntests/test_dependency_enforcement.py ...                                 [ 21%]\ntests/test_dependency_version_alignment.py .                             [ 21%]\ntests/test_determinism_cli.py ..                                         [ 21%]\ntests/test_diagnostics.py ..................                             [ 21%]\ntests/test_engine_incremental_cov.py ..                                  [ 21%]\ntests/test_export_additional_coverage.py ............................    [ 22%]\ntests/test_export_bundle.py ...............                              [ 22%]\ntests/test_export_errors.py .                                            [ 22%]\ntests/test_export_formatter.py ....................                      [ 23%]\ntests/test_export_manifest_schema.py ..                                  [ 23%]\ntests/test_export_openpyxl_adapter.py ................                   [ 23%]\ntests/test_export_outputs.py ..                                          [ 23%]\ntests/test_exports.py .........                                          [ 24%]\ntests/test_frequency_missing.py ........                                 [ 24%]\ntests/test_gui.py ........                                               [ 24%]\ntests/test_gui_app_extended.py .....                                     [ 24%]\ntests/test_gui_app_simple.py ...........                                 [ 25%]\ntests/test_gui_launch_run.py ..                                          [ 25%]\ntests/test_gui_support.py .....                                          [ 25%]\ntests/test_gui_utils_extra.py .....                                      [ 25%]\ntests/test_hash_utils.py ....                                            [ 25%]\ntests/test_health_summarize_module.py ..........................         [ 26%]\ntests/test_import_excludes.py ..                                         [ 26%]\ntests/test_import_sanity.py ...                                          [ 26%]\ntests/test_inception_dates.py .                                          [ 26%]\ntests/test_incremental_cov.py .                                          [ 26%]\ntests/test_input_validation.py .......                                   [ 26%]\ntests/test_invariants.py ........                                        [ 26%]\ntests/test_io_utils.py ...........                                       [ 27%]\ntests/test_io_utils_cleanup.py ....                                      [ 27%]\ntests/test_io_validators_additional.py ...s                              [ 27%]\ntests/test_io_validators_extra.py .................................      [ 28%]\ntests/test_io_validators_negative_paths.py ....                          [ 28%]\ntests/test_is_zero_everywhere_helper.py .......                          [ 28%]\ntests/test_joblib_import.py ......                                       [ 28%]\ntests/test_joblib_shim.py .                                              [ 28%]\ntests/test_label_rules_assert.py ..                                      [ 28%]\ntests/test_legacy_imports.py ....                                        [ 28%]\ntests/test_lockfile_consistency.py s...                                  [ 29%]\ntests/test_logging_helpers.py ....                                       [ 29%]\ntests/test_logging_integration.py .                                      [ 29%]\ntests/test_logging_module.py ......                                      [ 29%]\ntests/test_logging_utils.py .....                                        [ 29%]\ntests/test_malformed_date_validation.py .....                            [ 29%]\ntests/test_market_data_validation.py ..................................  [ 30%]\ntests/test_market_data_validation_additional.py ........................ [ 31%]\n..                                                                       [ 31%]\ntests/test_metric_cache.py .....                                         [ 31%]\ntests/test_metric_vectorise.py .                                         [ 31%]\ntests/test_metric_vectorise_param.py .....                               [ 31%]\ntests/test_metrics.py .....                                              [ 31%]\ntests/test_metrics_attribution.py ........                               [ 31%]\ntests/test_metrics_edgecases.py ....                                     [ 32%]\ntests/test_metrics_extra.py ...........                                  [ 32%]\ntests/test_metrics_rolling.py .....                                      [ 32%]\ntests/test_metrics_rolling_cache_disabled.py .                           [ 32%]\ntests/test_metrics_summary.py .                                          [ 32%]\ntests/test_metrics_turnover_extra.py ..                                  [ 32%]\ntests/test_multi_period_engine.py .......                                [ 32%]\ntests/test_multi_period_engine_additional.py ................            [ 33%]\ntests/test_multi_period_engine_branch_completion.py ..........           [ 33%]\ntests/test_multi_period_engine_branch_coverage.py .....                  [ 33%]\ntests/test_multi_period_engine_branch_new.py ............                [ 33%]\ntests/test_multi_period_engine_cov_cache.py ...                          [ 34%]\ntests/test_multi_period_engine_debug.py .                                [ 34%]\ntests/test_multi_period_engine_extended.py .....                         [ 34%]\ntests/test_multi_period_engine_helpers_additional.py ....                [ 34%]\ntests/test_multi_period_engine_incremental_cov.py .............          [ 34%]\ntests/test_multi_period_engine_incremental_extra.py ....                 [ 34%]\ntests/test_multi_period_engine_incremental_fallback.py .                 [ 34%]\ntests/test_multi_period_engine_keepalive.py ......                       [ 35%]\ntests/test_multi_period_engine_lambda_tc.py .                            [ 35%]\ntests/test_multi_period_engine_missing_policy.py ..                      [ 35%]\ntests/test_multi_period_engine_portfolio_unit.py ....                    [ 35%]\ntests/test_multi_period_engine_price_frames.py .........                 [ 35%]\ntests/test_multi_period_engine_price_frames_extra.py ........            [ 35%]\ntests/test_multi_period_engine_run_schedule_extra.py ..                  [ 35%]\ntests/test_multi_period_engine_threshold_bounds.py ..                    [ 35%]\ntests/test_multi_period_engine_threshold_edgecases.py ........           [ 35%]\ntests/test_multi_period_engine_threshold_events_extended.py ..           [ 36%]\ntests/test_multi_period_engine_turnover_extended.py ...                  [ 36%]\ntests/test_multi_period_engine_turnover_regression.py ....               [ 36%]\ntests/test_multi_period_exits_cooldown.py .........                      [ 36%]\ntests/test_multi_period_export.py .................                      [ 36%]\ntests/test_multi_period_inception_filter.py .                            [ 36%]\ntests/test_multi_period_loaders.py ...................                   [ 37%]\ntests/test_multi_period_missing_policy_observability.py ..               [ 37%]\ntests/test_multi_period_rebalancer.py ...........                        [ 37%]\ntests/test_multi_period_regime_wiring.py ..                              [ 37%]\ntests/test_multi_period_scheduler.py ...                                 [ 37%]\ntests/test_multi_period_selection.py .                                   [ 38%]\ntests/test_multi_period_sticky_periods.py ...                            [ 38%]\ntests/test_multi_period_stub.py ..                                       [ 38%]\ntests/test_mypy_autofix.py .......                                       [ 38%]\ntests/test_na_as_zero_policy.py ...                                      [ 38%]\ntests/test_no_hardcoded_sleeps.py ...                                    [ 38%]\ntests/test_no_invalid_period_freq_aliases.py ..                          [ 38%]\ntests/test_no_lookahead.py ....                                          [ 38%]\ntests/test_optimizer.py .........                                        [ 38%]\ntests/test_optimizer_branch_coverage.py ...............                  [ 39%]\ntests/test_optimizer_constraints.py ...........................          [ 40%]\ntests/test_optimizer_constraints_additional.py ......................... [ 40%]\n                                                                         [ 40%]\ntests/test_optimizer_constraints_guardrails.py ..............            [ 41%]\ntests/test_optional_notebook_deps.py ..                                  [ 41%]\ntests/test_package_init.py .....                                         [ 41%]\ntests/test_perf_cache.py ..                                              [ 41%]\ntests/test_perf_cache_additional.py ...                                  [ 41%]\ntests/test_perf_cache_extended.py .........                              [ 41%]\ntests/test_perf_timing.py ....                                           [ 41%]\ntests/test_pipeline.py .......................                           [ 42%]\ntests/test_pipeline_branch_coverage.py .........                         [ 42%]\ntests/test_pipeline_calendar_alignment.py .                              [ 42%]\ntests/test_pipeline_constraints_integration.py .....                     [ 42%]\ntests/test_pipeline_entrypoints.py ........                              [ 43%]\ntests/test_pipeline_helpers.py ..........                                [ 43%]\ntests/test_pipeline_helpers_additional.py .............................. [ 44%]\n.......................                                                  [ 44%]\ntests/test_pipeline_indices.py ...                                       [ 44%]\ntests/test_pipeline_integration_direct.py ..                             [ 44%]\ntests/test_pipeline_optional_features.py ...................F\n\n=================================== FAILURES ===================================\n__________________ test_run_analysis_benchmark_ir_best_effort __________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdc7ef54650>\n\n    def test_run_analysis_benchmark_ir_best_effort(monkeypatch: pytest.MonkeyPatch) -> None:\n        df = _clean_returns_frame()\n        stats_cfg = RiskStatsConfig()\n    \n        original_calc = pipeline.calc_portfolio_returns\n    \n        def tagging_calc(weights: np.ndarray, returns_df: pd.DataFrame) -> pd.Series:\n            series = original_calc(weights, returns_df)\n            if np.allclose(weights, np.repeat(1.0 / len(weights), len(weights))):\n                series.attrs[\"portfolio_role\"] = \"equal_weight\"\n            else:\n                series.attrs[\"portfolio_role\"] = \"user_weight\"\n            return series\n    \n        original_ir = pipeline.information_ratio\n    \n        def flaky_information_ratio(a, b):\n            if isinstance(a, pd.Series) and a.attrs.get(\"portfolio_role\") == \"equal_weight\":\n                raise RuntimeError(\"portfolio IR failure\")\n            return original_ir(a, b)\n    \n        monkeypatch.setattr(pipeline, \"calc_portfolio_returns\", tagging_calc)\n        monkeypatch.setattr(pipeline, \"information_ratio\", flaky_information_ratio)\n    \n        result = pipeline._run_analysis(\n            df,\n            \"2020-01\",\n            \"2020-02\",\n            \"2020-03\",\n            \"2020-04\",\n            target_vol=1.0,\n            monthly_cost=0.0,\n            stats_cfg=stats_cfg,\n            custom_weights={\"FundA\": 55.0, \"FundB\": 45.0},\n            indices_list=[\"Benchmark\"],\n            benchmarks={\"SPX\": \"Benchmark\"},\n            **RUN_KWARGS,\n        )\n    \n        assert result is not None\n        ir_payload = result[\"benchmark_ir\"].get(\"SPX\", {})\n        # Fallback path should skip enriching the portfolio-level IR keys.\n>       assert \"equal_weight\" not in ir_payload\nE       AssertionError: assert 'equal_weight' not in {'FundA': 109.98986134950982, 'FundB': 66.20422308564741, 'equal_weight': 61.23724356957949, 'user_weight': 57.67434939825836}\n\ntests/test_pipeline_optional_features.py:767: AssertionError\n=============================== warnings summary ===============================\ntests/golden/test_demo.py:172\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:172: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/golden/test_demo.py:307\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:307: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:628: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n    quarterly = pd.date_range(\"2020-01-01\", periods=5, freq=\"Q\")\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:636: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    very_sparse = pd.date_range(\"2020-01-01\", periods=2, freq=\"36M\")\n\ntests/soft_coverage/test_regimes_soft.py: 14 warnings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/soft_coverage/test_regimes_soft.py:28: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    return pd.date_range(\"2024-01-31\", periods=periods, freq=freq)\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:194: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:343: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, utc=True, errors=\"coerce\")\n\ntests/test_date_correction.py::TestDateCorrection::test_iso_format_dates_corrected\ntests/test_date_correction.py::TestDateCorrection::test_completely_invalid_date_not_correctable\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/streamlit_app/components/date_correction.py:221: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_malformed_date_validation.py::TestMalformedDateValidation::test_all_malformed_dates\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values_partial\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/io/market_data.py:134: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_market_data_validation.py::test_classify_frequency_gap_tolerance_exceeded\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_market_data_validation.py:339: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    idx = pd.date_range(\"2020-01-31\", periods=4, freq=\"2M\")\n\ntests/test_multi_period_engine_branch_new.py::test_run_raises_when_policy_drops_all\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_multi_period_engine_branch_new.py:118: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<NA>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n    empty.iloc[:, :] = pd.NA\n\ntests/test_pipeline_helpers_additional.py::test_resolve_sample_split_invalid_dates_raise\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py:465: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nSKIPPED [1] tests/test_buy_and_hold_selection.py:377: Could not import analysis_runner: No module named 'streamlit'\nSKIPPED [1] tests/test_io_validators_additional.py:50: could not import 'pyarrow': No module named 'pyarrow'\nSKIPPED [1] tests/test_lockfile_consistency.py:63: Dependency lockfile check only runs during scheduled refresh\nFAILED tests/test_pipeline_optional_features.py::test_run_analysis_benchmark_ir_best_effort - AssertionError: assert 'equal_weight' not in {'FundA': 109.98986134950982, 'FundB': 66.20422308564741, 'equal_weight': 61.23724356957949, 'user_weight': 57.67434939825836}\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\n====== 1 failed, 1652 passed, 3 skipped, 31 warnings in 104.18s (0:01:44) ======\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_139","type":"reasoning","text":"**Fixing patch synchronization between modules**\n\nI'm figuring out that the test patches to `pipeline.calc_portfolio_returns` arenâ€™t affecting the `portfolio_stage` because `_sync_stage_dependencies` doesnâ€™t sync `calc_portfolio_returns` yet. Iâ€™ll update the sync method to assign `portfolio_stage.calc_portfolio_returns` from `pipeline.calc_portfolio_returns` so patched versions propagate correctly and the test behaves as expected."}}
{"type":"item.completed","item":{"id":"item_140","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_141","type":"reasoning","text":"**Rerunning tests for verification**"}}
{"type":"item.started","item":{"id":"item_142","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_142","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 3637 items\n\ntests/backtesting/test_bootstrap.py ........                             [  0%]\ntests/backtesting/test_harness.py ...........................            [  0%]\ntests/golden/test_demo.py ....                                           [  1%]\ntests/proxy/test_server.py ...............                               [  1%]\ntests/scripts/test_ci_history.py ................                        [  1%]\ntests/scripts/test_ci_metrics.py .....................                   [  2%]\ntests/scripts/test_evaluate_settings_effectiveness.py ....               [  2%]\ntests/scripts/test_sync_test_dependencies.py ......                      [  2%]\ntests/scripts/test_sync_tool_versions.py ....                            [  2%]\ntests/scripts/test_verify_trusted_config.py .......                      [  3%]\ntests/smoke/test_pipeline_smoke.py .                                     [  3%]\ntests/soft_coverage/test_data_soft.py ................................   [  3%]\ntests/soft_coverage/test_regimes_soft.py ......................          [  4%]\ntests/soft_coverage/test_signal_presets_soft.py .....                    [  4%]\ntests/soft_coverage/test_trend_analysis_init.py ..........               [  5%]\ntests/test_adaptive_bayes.py .....                                       [  5%]\ntests/test_analysis_results_module.py ......                             [  5%]\ntests/test_api_run_simulation.py .......                                 [  5%]\ntests/test_api_run_simulation_branches.py .......                        [  5%]\ntests/test_api_run_simulation_extra.py .....                             [  5%]\ntests/test_api_safe_len.py ...                                           [  5%]\ntests/test_api_signal_settings.py ..                                     [  5%]\ntests/test_app_coverage.py ...........................................   [  7%]\ntests/test_avg_corr_metric.py .                                          [  7%]\ntests/test_avgcorr_export.py ..                                          [  7%]\ntests/test_backtest_utils.py ...                                         [  7%]\ntests/test_backtesting_harness_additional.py .........                   [  7%]\ntests/test_backtesting_harness_membership.py ...                         [  7%]\ntests/test_build_autofix_pr_comment.py .............                     [  8%]\ntests/test_buy_and_hold_selection.py .......s                            [  8%]\ntests/test_cache_disable.py .                                            [  8%]\ntests/test_cli.py ..........                                             [  8%]\ntests/test_cli_api_golden_master.py ..                                   [  8%]\ntests/test_cli_cache_stats.py .                                          [  8%]\ntests/test_cli_cache_stats_disabled.py .                                 [  8%]\ntests/test_cli_cache_stats_extended.py ...                               [  8%]\ntests/test_cli_check.py .....                                            [  8%]\ntests/test_cli_helpers.py .....                                          [  8%]\ntests/test_cli_installed.py .....                                        [  9%]\ntests/test_cli_module.py .........                                       [  9%]\ntests/test_cli_no_cache_flag.py .                                        [  9%]\ntests/test_cli_no_structured_log.py .                                    [  9%]\ntests/test_cli_smoke.py .....                                            [  9%]\ntests/test_cli_trend_presets.py ...                                      [  9%]\ntests/test_cli_utils.py .....                                            [  9%]\ntests/test_config.py .                                                   [  9%]\ntests/test_config_alignment.py ..                                        [  9%]\ntests/test_config_bridge.py ........                                     [ 10%]\ntests/test_config_bridge_parity.py .                                     [ 10%]\ntests/test_config_errors.py .                                            [ 10%]\ntests/test_config_fallback_additional.py ................                [ 10%]\ntests/test_config_fallback_minimal.py ..........                         [ 10%]\ntests/test_config_human_errors.py .....................                  [ 11%]\ntests/test_config_legacy.py ...                                          [ 11%]\ntests/test_config_legacy_output_conversion.py ....                       [ 11%]\ntests/test_config_load.py .......                                        [ 11%]\ntests/test_config_model.py ............................................. [ 13%]\n......                                                                   [ 13%]\ntests/test_config_model_branch_coverage.py ............                  [ 13%]\ntests/test_config_model_validation.py ................                   [ 13%]\ntests/test_config_models.py ...                                          [ 14%]\ntests/test_config_models_additional.py ..............                    [ 14%]\ntests/test_config_models_coverage_extensions.py ............             [ 14%]\ntests/test_config_models_fallback_loader.py ....                         [ 14%]\ntests/test_config_models_fallback_unit.py .................              [ 15%]\ntests/test_config_path_discovery.py ......                               [ 15%]\ntests/test_config_pydantic_fallback.py ......                            [ 15%]\ntests/test_config_schema.py .......                                      [ 15%]\ntests/test_config_turnover_validation.py .................               [ 16%]\ntests/test_config_validation.py ....                                     [ 16%]\ntests/test_configure_presets.py ......                                   [ 16%]\ntests/test_constants.py .......                                          [ 16%]\ntests/test_constraint_optimizer.py .........                             [ 17%]\ntests/test_cov_cache_integration.py .                                    [ 17%]\ntests/test_coverage_trend.py ............                                [ 17%]\ntests/test_cv.py ...                                                     [ 17%]\ntests/test_data.py ..................................................... [ 18%]\n..........                                                               [ 19%]\ntests/test_data_contracts.py .........                                   [ 19%]\ntests/test_data_malformed_dates.py .......                               [ 19%]\ntests/test_data_schema.py .............                                  [ 20%]\ntests/test_date_correction.py ....................                       [ 20%]\ntests/test_decode_raw_input.py ............                              [ 20%]\ntests/test_default_export.py .                                           [ 20%]\ntests/test_dependency_enforcement.py ...                                 [ 21%]\ntests/test_dependency_version_alignment.py .                             [ 21%]\ntests/test_determinism_cli.py ..                                         [ 21%]\ntests/test_diagnostics.py ..................                             [ 21%]\ntests/test_engine_incremental_cov.py ..                                  [ 21%]\ntests/test_export_additional_coverage.py ............................    [ 22%]\ntests/test_export_bundle.py ...............                              [ 22%]\ntests/test_export_errors.py .                                            [ 22%]\ntests/test_export_formatter.py ....................                      [ 23%]\ntests/test_export_manifest_schema.py ..                                  [ 23%]\ntests/test_export_openpyxl_adapter.py ................                   [ 23%]\ntests/test_export_outputs.py ..                                          [ 23%]\ntests/test_exports.py .........                                          [ 24%]\ntests/test_frequency_missing.py ........                                 [ 24%]\ntests/test_gui.py ........                                               [ 24%]\ntests/test_gui_app_extended.py .....                                     [ 24%]\ntests/test_gui_app_simple.py ...........                                 [ 25%]\ntests/test_gui_launch_run.py ..                                          [ 25%]\ntests/test_gui_support.py .....                                          [ 25%]\ntests/test_gui_utils_extra.py .....                                      [ 25%]\ntests/test_hash_utils.py ....                                            [ 25%]\ntests/test_health_summarize_module.py ..........................         [ 26%]\ntests/test_import_excludes.py ..                                         [ 26%]\ntests/test_import_sanity.py ...                                          [ 26%]\ntests/test_inception_dates.py .                                          [ 26%]\ntests/test_incremental_cov.py .                                          [ 26%]\ntests/test_input_validation.py .......                                   [ 26%]\ntests/test_invariants.py ........                                        [ 26%]\ntests/test_io_utils.py ...........                                       [ 27%]\ntests/test_io_utils_cleanup.py ....                                      [ 27%]\ntests/test_io_validators_additional.py ...s                              [ 27%]\ntests/test_io_validators_extra.py .................................      [ 28%]\ntests/test_io_validators_negative_paths.py ....                          [ 28%]\ntests/test_is_zero_everywhere_helper.py .......                          [ 28%]\ntests/test_joblib_import.py ......                                       [ 28%]\ntests/test_joblib_shim.py .                                              [ 28%]\ntests/test_label_rules_assert.py ..                                      [ 28%]\ntests/test_legacy_imports.py ....                                        [ 28%]\ntests/test_lockfile_consistency.py s...                                  [ 29%]\ntests/test_logging_helpers.py ....                                       [ 29%]\ntests/test_logging_integration.py .                                      [ 29%]\ntests/test_logging_module.py ......                                      [ 29%]\ntests/test_logging_utils.py .....                                        [ 29%]\ntests/test_malformed_date_validation.py .....                            [ 29%]\ntests/test_market_data_validation.py ..................................  [ 30%]\ntests/test_market_data_validation_additional.py ........................ [ 31%]\n..                                                                       [ 31%]\ntests/test_metric_cache.py .....                                         [ 31%]\ntests/test_metric_vectorise.py .                                         [ 31%]\ntests/test_metric_vectorise_param.py .....                               [ 31%]\ntests/test_metrics.py .....                                              [ 31%]\ntests/test_metrics_attribution.py ........                               [ 31%]\ntests/test_metrics_edgecases.py ....                                     [ 32%]\ntests/test_metrics_extra.py ...........                                  [ 32%]\ntests/test_metrics_rolling.py .....                                      [ 32%]\ntests/test_metrics_rolling_cache_disabled.py .                           [ 32%]\ntests/test_metrics_summary.py .                                          [ 32%]\ntests/test_metrics_turnover_extra.py ..                                  [ 32%]\ntests/test_multi_period_engine.py .......                                [ 32%]\ntests/test_multi_period_engine_additional.py ................            [ 33%]\ntests/test_multi_period_engine_branch_completion.py ..........           [ 33%]\ntests/test_multi_period_engine_branch_coverage.py .....                  [ 33%]\ntests/test_multi_period_engine_branch_new.py ............                [ 33%]\ntests/test_multi_period_engine_cov_cache.py ...                          [ 34%]\ntests/test_multi_period_engine_debug.py .                                [ 34%]\ntests/test_multi_period_engine_extended.py .....                         [ 34%]\ntests/test_multi_period_engine_helpers_additional.py ....                [ 34%]\ntests/test_multi_period_engine_incremental_cov.py .............          [ 34%]\ntests/test_multi_period_engine_incremental_extra.py ....                 [ 34%]\ntests/test_multi_period_engine_incremental_fallback.py .                 [ 34%]\ntests/test_multi_period_engine_keepalive.py ......                       [ 35%]\ntests/test_multi_period_engine_lambda_tc.py .                            [ 35%]\ntests/test_multi_period_engine_missing_policy.py ..                      [ 35%]\ntests/test_multi_period_engine_portfolio_unit.py ....                    [ 35%]\ntests/test_multi_period_engine_price_frames.py .........                 [ 35%]\ntests/test_multi_period_engine_price_frames_extra.py ........            [ 35%]\ntests/test_multi_period_engine_run_schedule_extra.py ..                  [ 35%]\ntests/test_multi_period_engine_threshold_bounds.py ..                    [ 35%]\ntests/test_multi_period_engine_threshold_edgecases.py ........           [ 35%]\ntests/test_multi_period_engine_threshold_events_extended.py ..           [ 36%]\ntests/test_multi_period_engine_turnover_extended.py ...                  [ 36%]\ntests/test_multi_period_engine_turnover_regression.py ....               [ 36%]\ntests/test_multi_period_exits_cooldown.py .........                      [ 36%]\ntests/test_multi_period_export.py .................                      [ 36%]\ntests/test_multi_period_inception_filter.py .                            [ 36%]\ntests/test_multi_period_loaders.py ...................                   [ 37%]\ntests/test_multi_period_missing_policy_observability.py ..               [ 37%]\ntests/test_multi_period_rebalancer.py ...........                        [ 37%]\ntests/test_multi_period_regime_wiring.py ..                              [ 37%]\ntests/test_multi_period_scheduler.py ...                                 [ 37%]\ntests/test_multi_period_selection.py .                                   [ 38%]\ntests/test_multi_period_sticky_periods.py ...                            [ 38%]\ntests/test_multi_period_stub.py ..                                       [ 38%]\ntests/test_mypy_autofix.py .......                                       [ 38%]\ntests/test_na_as_zero_policy.py ...                                      [ 38%]\ntests/test_no_hardcoded_sleeps.py ...                                    [ 38%]\ntests/test_no_invalid_period_freq_aliases.py ..                          [ 38%]\ntests/test_no_lookahead.py ....                                          [ 38%]\ntests/test_optimizer.py .........                                        [ 38%]\ntests/test_optimizer_branch_coverage.py ...............                  [ 39%]\ntests/test_optimizer_constraints.py ...........................          [ 40%]\ntests/test_optimizer_constraints_additional.py ......................... [ 40%]\n                                                                         [ 40%]\ntests/test_optimizer_constraints_guardrails.py ..............            [ 41%]\ntests/test_optional_notebook_deps.py ..                                  [ 41%]\ntests/test_package_init.py .....                                         [ 41%]\ntests/test_perf_cache.py ..                                              [ 41%]\ntests/test_perf_cache_additional.py ...                                  [ 41%]\ntests/test_perf_cache_extended.py .........                              [ 41%]\ntests/test_perf_timing.py ....                                           [ 41%]\ntests/test_pipeline.py .......................                           [ 42%]\ntests/test_pipeline_branch_coverage.py .........                         [ 42%]\ntests/test_pipeline_calendar_alignment.py .                              [ 42%]\ntests/test_pipeline_constraints_integration.py .....                     [ 42%]\ntests/test_pipeline_entrypoints.py ........                              [ 43%]\ntests/test_pipeline_helpers.py ..........                                [ 43%]\ntests/test_pipeline_helpers_additional.py .............................. [ 44%]\n.......................                                                  [ 44%]\ntests/test_pipeline_indices.py ...                                       [ 44%]\ntests/test_pipeline_integration_direct.py ..                             [ 44%]\ntests/test_pipeline_optional_features.py .........................       [ 45%]\ntests/test_pipeline_run_analysis_helpers.py ..........                   [ 45%]\ntests/test_pipeline_run_cache_fallbacks.py .......................       [ 46%]\ntests/test_pipeline_stage_isolation.py F\n\n=================================== FAILURES ===================================\n_________________ test_stage_isolation_matches_pipeline_output _________________\n\n    def test_stage_isolation_matches_pipeline_output() -> None:\n        df = _sample_frame()\n        stats_cfg = RiskStatsConfig(metrics_to_run=[\"Sharpe\"], risk_free=0.0)\n    \n>       pipeline_result = pipeline.run_analysis(\n            df,\n            \"2020-01-31\",\n            \"2020-03-31\",\n            \"2020-04-30\",\n            \"2020-06-30\",\n            0.1,\n            0.0,\n            stats_cfg=stats_cfg,\n            risk_free_column=\"rf\",\n            allow_risk_free_fallback=True,\n        )\n\ntests/test_pipeline_stage_isolation.py:28: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/trend_analysis/pipeline.py:257: in run_analysis\n    return _invoke_analysis_with_diag(\nsrc/trend_analysis/pipeline.py:192: in _invoke_analysis_with_diag\n    return _run_analysis_with_diagnostics(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/trend_analysis/pipeline.py:172: in _run_analysis_with_diagnostics\n    return _call_with_sync(_run_analysis_with_diagnostics_impl, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/trend_analysis/pipeline.py:123: in _call_with_sync\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nsrc/trend_analysis/pipeline_runner.py:102: in _run_analysis_with_diagnostics\n    selection_stage_result = selection_stage._select_universe(\nsrc/trend_analysis/stages/selection.py:519: in _select_universe\n    score_frame = single_period_run(\nsrc/trend_analysis/stages/selection.py:317: in single_period_run\n    parts = [\nsrc/trend_analysis/stages/selection.py:318: in <listcomp>\n    _compute_metric_series(\nsrc/trend_analysis/core/rank_selection.py:924: in _compute_metric_series\n    return in_sample_df.apply(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/frame.py:10401: in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n           ^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/apply.py:916: in apply\n    return self.apply_standard()\n           ^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/apply.py:1063: in apply_standard\n    results, res_index = self.apply_series_generator()\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/apply.py:1081: in apply_series_generator\n    results[i] = self.func(v, *self.args, **self.kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/trend_analysis/core/rank_selection.py:825: in <lambda>\n    lambda s, *, periods_per_year=12, risk_free=0.0: _metrics.sharpe_ratio(\nsrc/trend_analysis/metrics/__init__.py:242: in sharpe_ratio\n    _check_shapes(returns, risk_free, \"sharpe_ratio\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nret = Date\n2020-02-29    0.020\n2020-03-31    0.015\nName: A, dtype: float64\nother = 2020-01-31    0.001\n2020-02-29    0.001\n2020-03-31    0.001\nFreq: ME, Name: rf, dtype: float64\nfn = 'sharpe_ratio'\n\n    def _check_shapes(\n        ret: Series | DataFrame,\n        other: Series | DataFrame | float | int,\n        fn: str,\n    ) -> None:\n        \"\"\"Raise ValueError if *other* is not scalar **and** its exact shape\n        differs from `ret`, or if the pandas types disagree (Series vs\n        DataFrame).\"\"\"\n        if np.isscalar(other):\n            return\n        assert isinstance(other, (Series, DataFrame))\n        if ret.shape != other.shape or isinstance(ret, DataFrame) != isinstance(\n            other, DataFrame\n        ):\n>           raise ValueError(f\"{fn}: inputs must have identical shape\")\nE           ValueError: sharpe_ratio: inputs must have identical shape\n\nsrc/trend_analysis/metrics/__init__.py:127: ValueError\n=============================== warnings summary ===============================\ntests/golden/test_demo.py:172\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:172: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/golden/test_demo.py:307\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/golden/test_demo.py:307: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.xdist_group(name=\"demo_pipeline\")\n\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:628: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n    quarterly = pd.date_range(\"2020-01-01\", periods=5, freq=\"Q\")\n\ntests/backtesting/test_harness.py::test_infer_periods_per_year_handles_various_spacings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/backtesting/test_harness.py:636: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    very_sparse = pd.date_range(\"2020-01-01\", periods=2, freq=\"36M\")\n\ntests/soft_coverage/test_regimes_soft.py: 14 warnings\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/soft_coverage/test_regimes_soft.py:28: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    return pd.date_range(\"2024-01-31\", periods=periods, freq=freq)\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:194: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_data.py::test_load_csv_numeric_normalisation\ntests/test_data_malformed_dates.py::TestDataLoadingMalformedDates::test_load_csv_with_valid_dates_succeeds\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend/input_validation.py:343: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, utc=True, errors=\"coerce\")\n\ntests/test_date_correction.py::TestDateCorrection::test_iso_format_dates_corrected\ntests/test_date_correction.py::TestDateCorrection::test_completely_invalid_date_not_correctable\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/streamlit_app/components/date_correction.py:221: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_malformed_date_validation.py::TestMalformedDateValidation::test_all_malformed_dates\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values\ntests/test_market_data_validation_additional.py::test_resolve_datetime_index_drops_unparseable_values_partial\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/io/market_data.py:134: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    parsed = pd.to_datetime(raw_dates, errors=\"coerce\")\n\ntests/test_market_data_validation.py::test_classify_frequency_gap_tolerance_exceeded\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_market_data_validation.py:339: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n    idx = pd.date_range(\"2020-01-31\", periods=4, freq=\"2M\")\n\ntests/test_multi_period_engine_branch_new.py::test_run_raises_when_policy_drops_all\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_multi_period_engine_branch_new.py:118: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<NA>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n    empty.iloc[:, :] = pd.NA\n\ntests/test_pipeline_helpers_additional.py::test_resolve_sample_split_invalid_dates_raise\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py:465: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nSKIPPED [1] tests/test_buy_and_hold_selection.py:377: Could not import analysis_runner: No module named 'streamlit'\nSKIPPED [1] tests/test_io_validators_additional.py:50: could not import 'pyarrow': No module named 'pyarrow'\nSKIPPED [1] tests/test_lockfile_consistency.py:63: Dependency lockfile check only runs during scheduled refresh\nFAILED tests/test_pipeline_stage_isolation.py::test_stage_isolation_matches_pipeline_output - ValueError: sharpe_ratio: inputs must have identical shape\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\n====== 1 failed, 1691 passed, 3 skipped, 31 warnings in 106.27s (0:01:46) ======\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_143","type":"reasoning","text":"**Diagnosing date format mismatch in test failure**"}}
{"type":"item.completed","item":{"id":"item_144","type":"file_change","changes":[{"path":"/home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/test_pipeline_stage_isolation.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_145","type":"reasoning","text":"**Rerunning tests with coverage**"}}
{"type":"item.started","item":{"id":"item_146","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_146","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 3637 items\n\ntests/backtesting/test_bootstrap.py ........                             [  0%]\ntests/backtesting/test_harness.py ...........................            [  0%]\ntests/golden/test_demo.py ....                                           [  1%]\ntests/proxy/test_server.py ...............                               [  1%]\ntests/scripts/test_ci_history.py ................                        [  1%]\ntests/scripts/test_ci_metrics.py .....................                   [  2%]\ntests/scripts/test_evaluate_settings_effectiveness.py ....               [  2%]\ntests/scripts/test_sync_test_dependencies.py ......                      [  2%]\ntests/scripts/test_sync_tool_versions.py ....                            [  2%]\ntests/scripts/test_verify_trusted_config.py .......                      [  3%]\ntests/smoke/test_pipeline_smoke.py .                                     [  3%]\ntests/soft_coverage/test_data_soft.py ................................   [  3%]\ntests/soft_coverage/test_regimes_soft.py ......................          [  4%]\ntests/soft_coverage/test_signal_presets_soft.py .....                    [  4%]\ntests/soft_coverage/test_trend_analysis_init.py ..........               [  5%]\ntests/test_adaptive_bayes.py .....                                       [  5%]\ntests/test_analysis_results_module.py ......                             [  5%]\ntests/test_api_run_simulation.py .......                                 [  5%]\ntests/test_api_run_simulation_branches.py .......                        [  5%]\ntests/test_api_run_simulation_extra.py .....                             [  5%]\ntests/test_api_safe_len.py ...                                           [  5%]\ntests/test_api_signal_settings.py ..                                     [  5%]\ntests/test_app_coverage.py ...........................................   [  7%]\ntests/test_avg_corr_metric.py .                                          [  7%]\ntests/test_avgcorr_export.py ..                                          [  7%]\ntests/test_backtest_utils.py ...                                         [  7%]\ntests/test_backtesting_harness_additional.py .........                   [  7%]\ntests/test_backtesting_harness_membership.py ...                         [  7%]\ntests/test_build_autofix_pr_comment.py .............                     [  8%]\ntests/test_buy_and_hold_selection.py .......s                            [  8%]\ntests/test_cache_disable.py .                                            [  8%]\ntests/test_cli.py ..........                                             [  8%]\ntests/test_cli_api_golden_master.py ..                                   [  8%]\ntests/test_cli_cache_stats.py .                                          [  8%]\ntests/test_cli_cache_stats_disabled.py .                                 [  8%]\ntests/test_cli_cache_stats_extended.py ...                               [  8%]\ntests/test_cli_check.py .....                                            [  8%]\ntests/test_cli_helpers.py .....                                          [  8%]\ntests/test_cli_installed.py .....                                        [  9%]\ntests/test_cli_module.py .........                                       [  9%]\ntests/test_cli_no_cache_flag.py .                                        [  9%]\ntests/test_cli_no_structured_log.py .                                    [  9%]\ntests/test_cli_smoke.py .....                                            [  9%]\ntests/test_cli_trend_presets.py ...                                      [  9%]\ntests/test_cli_utils.py .....                                            [  9%]\ntests/test_config.py .                                                   [  9%]\ntests/test_config_alignment.py ..                                        [  9%]\ntests/test_config_bridge.py ........                                     [ 10%]\ntests/test_config_bridge_parity.py .                                     [ 10%]\ntests/test_config_errors.py .                                            [ 10%]\ntests/test_config_fallback_additional.py ................                [ 10%]\ntests/test_config_fallback_minimal.py ..........                         [ 10%]\ntests/test_config_human_errors.py .....................                  [ 11%]\ntests/test_config_legacy.py ...                                          [ 11%]\ntests/test_config_legacy_output_conversion.py ....                       [ 11%]\ntests/test_config_load.py .......                                        [ 11%]\ntests/test_config_model.py ............................................. [ 13%]\n......                                                                   [ 13%]\ntests/test_config_model_branch_coverage.py ............                  [ 13%]\ntests/test_config_model_validation.py ................                   [ 13%]\ntests/test_config_models.py ...                                          [ 14%]\ntests/test_config_models_additional.py ..............                    [ 14%]\ntests/test_config_models_coverage_extensions.py ............             [ 14%]\ntests/test_config_models_fallback_loader.py ....                         [ 14%]\ntests/test_config_models_fallback_unit.py .................              [ 15%]\ntests/test_config_path_discovery.py ......                               [ 15%]\ntests/test_config_pydantic_fallback.py ......                            [ 15%]\ntests/test_config_schema.py .......                                      [ 15%]\ntests/test_config_turnover_validation.py .................               [ 16%]\ntests/test_config_validation.py ....                                     [ 16%]\ntests/test_configure_presets.py ......                                   [ 16%]\ntests/test_constants.py .......                                          [ 16%]\ntests/test_constraint_optimizer.py .........                             [ 17%]\ntests/test_cov_cache_integration.py .                                    [ 17%]\ntests/test_coverage_trend.py ............                                [ 17%]\ntests/test_cv.py ...                                                     [ 17%]\ntests/test_data.py ..................................................... [ 18%]\n..........                                                               [ 19%]\ntests/test_data_contracts.py .........                                   [ 19%]\ntests/test_data_malformed_dates.py .......                               [ 19%]\ntests/test_data_schema.py .............                                  [ 20%]\ntests/test_date_correction.py ....................                       [ 20%]\ntests/test_decode_raw_input.py ............                              [ 20%]\ntests/test_default_export.py .                                           [ 20%]\ntests/test_dependency_enforcement.py ...                                 [ 21%]\ntests/test_dependency_version_alignment.py .                             [ 21%]\ntests/test_determinism_cli.py ..                                         [ 21%]\ntests/test_diagnostics.py ..................                             [ 21%]\ntests/test_engine_incremental_cov.py ..                                  [ 21%]\ntests/test_export_additional_coverage.py ............................    [ 22%]\ntests/test_export_bundle.py ...............                              [ 22%]\ntests/test_export_errors.py .                                            [ 22%]\ntests/test_export_formatter.py ....................                      [ 23%]\ntests/test_export_manifest_schema.py ..                                  [ 23%]\ntests/test_export_openpyxl_adapter.py ................                   [ 23%]\ntests/test_export_outputs.py ..                                          [ 23%]\ntests/test_exports.py .........                                          [ 24%]\ntests/test_frequency_missing.py ........                                 [ 24%]\ntests/test_gui.py ........                                               [ 24%]\ntests/test_gui_app_extended.py .....                                     [ 24%]\ntests/test_gui_app_simple.py ...........                                 [ 25%]\ntests/test_gui_launch_run.py ..                                          [ 25%]\ntests/test_gui_support.py .....                                          [ 25%]\ntests/test_gui_utils_extra.py .....                                      [ 25%]\ntests/test_hash_utils.py ....                                            [ 25%]\ntests/test_health_summarize_module.py ..........................         [ 26%]\ntests/test_import_excludes.py ..                                         [ 26%]\ntests/test_import_sanity.py ...                                          [ 26%]\ntests/test_inception_dates.py .                                          [ 26%]\ntests/test_incremental_cov.py .                                          [ 26%]\ntests/test_input_validation.py .......                                   [ 26%]\ntests/test_invariants.py ........                                        [ 26%]\ntests/test_io_utils.py ...........                                       [ 27%]\ntests/test_io_utils_cleanup.py ....                                      [ 27%]\ntests/test_io_validators_additional.py ...s                              [ 27%]\ntests/test_io_validators_extra.py .................................      [ 28%]\ntests/test_io_validators_negative_paths.py ....                          [ 28%]\ntests/test_is_zero_everywhere_helper.py .......                          [ 28%]\ntests/test_joblib_import.py ......                                       [ 28%]\ntests/test_joblib_shim.py .                                              [ 28%]\ntests/test_label_rules_assert.py ..                                      [ 28%]\ntests/test_legacy_imports.py ....                                        [ 28%]\ntests/test_lockfile_consistency.py s...                                  [ 29%]\ntests/test_logging_helpers.py ....                                       [ 29%]\ntests/test_logging_integration.py .                                      [ 29%]\ntests/test_logging_module.py ......                                      [ 29%]\ntests/test_logging_utils.py .....                                        [ 29%]\ntests/test_malformed_date_validation.py .....                            [ 29%]\ntests/test_market_data_validation.py ..................................  [ 30%]\ntests/test_market_data_validation_additional.py ........................ [ 31%]\n..                                                                       [ 31%]\ntests/test_metric_cache.py .....                                         [ 31%]\ntests/test_metric_vectorise.py .                                         [ 31%]\ntests/test_metric_vectorise_param.py .....                               [ 31%]\ntests/test_metrics.py .....                                              [ 31%]\ntests/test_metrics_attribution.py ........                               [ 31%]\ntests/test_metrics_edgecases.py ....                                     [ 32%]\ntests/test_metrics_extra.py ...........                                  [ 32%]\ntests/test_metrics_rolling.py .....                                      [ 32%]\ntests/test_metrics_rolling_cache_disabled.py .                           [ 32%]\ntests/test_metrics_summary.py .                                          [ 32%]\ntests/test_metrics_turnover_extra.py ..                                  [ 32%]\ntests/test_multi_period_engine.py .......                                [ 32%]\ntests/test_multi_period_engine_additional.py ................            [ 33%]\ntests/test_multi_period_engine_branch_completion.py ..........           [ 33%]\ntests/test_multi_period_engine_branch_coverage.py .....                  [ 33%]\ntests/test_multi_period_engine_branch_new.py ............                [ 33%]\ntests/test_multi_period_engine_cov_cache.py ...                          [ 34%]\ntests/test_multi_period_engine_debug.py .                                [ 34%]\ntests/test_multi_period_engine_extended.py .....                         [ 34%]\ntests/test_multi_period_engine_helpers_additional.py ....                [ 34%]\ntests/test_multi_period_engine_incremental_cov.py .............          [ 34%]\ntests/test_multi_period_engine_incremental_extra.py ....                 [ 34%]\ntests/test_multi_period_engine_incremental_fallback.py .                 [ 34%]\ntests/test_multi_period_engine_keepalive.py ......                       [ 35%]\ntests/test_multi_period_engine_lambda_tc.py .                            [ 35%]\ntests/test_multi_period_engine_missing_policy.py ..                      [ 35%]\ntests/test_multi_period_engine_portfolio_unit.py ....                    [ 35%]\ntests/test_multi_period_engine_price_frames.py .........                 [ 35%]\ntests/test_multi_period_engine_price_frames_extra.py ........            [ 35%]\ntests/test_multi_period_engine_run_schedule_extra.py ..                  [ 35%]\ntests/test_multi_period_engine_threshold_bounds.py ..                    [ 35%]\ntests/test_multi_period_engine_threshold_edgecases.py ........           [ 35%]\ntests/test_multi_period_engine_threshold_events_extended.py ..           [ 36%]\ntests/test_multi_period_engine_turnover_extended.py ...                  [ 36%]\ntests/test_multi_period_engine_turnover_regression.py ....               [ 36%]\ntests/test_multi_period_exits_cooldown.py .........                      [ 36%]\ntests/test_multi_period_export.py .................                      [ 36%]\ntests/test_multi_period_inception_filter.py .                            [ 36%]\ntests/test_multi_period_loaders.py ...................                   [ 37%]\ntests/test_multi_period_missing_policy_observability.py ..               [ 37%]\ntests/test_multi_period_rebalancer.py ...........                        [ 37%]\ntests/test_multi_period_regime_wiring.py ..                              [ 37%]\ntests/test_multi_period_scheduler.py ...                                 [ 37%]\ntests/test_multi_period_selection.py .                                   [ 38%]\ntests/test_multi_period_sticky_periods.py ...                            [ 38%]\ntests/test_multi_period_stub.py ..                                       [ 38%]\ntests/test_mypy_autofix.py .......                                       [ 38%]\ntests/test_na_as_zero_policy.py ...                                      [ 38%]\ntests/test_no_hardcoded_sleeps.py ...                                    [ 38%]\ntests/test_no_invalid_period_freq_aliases.py ..                          [ 38%]\ntests/test_no_lookahead.py ....                                          [ 38%]\ntests/test_optimizer.py .........                                        [ 38%]\ntests/test_optimizer_branch_coverage.py ...............                  [ 39%]\ntests/test_optimizer_constraints.py ...........................          [ 40%]\ntests/test_optimizer_constraints_additional.py ......................... [ 40%]\n                                                                         [ 40%]\ntests/test_optimizer_constraints_guardrails.py ..............            [ 41%]\ntests/test_optional_notebook_deps.py ..                                  [ 41%]\ntests/test_package_init.py .....                                         [ 41%]\ntests/test_perf_cache.py ..                                              [ 41%]\ntests/test_perf_cache_additional.py ...                                  [ 41%]\ntests/test_perf_cache_extended.py .........                              [ 41%]\ntests/test_perf_timing.py ....                                           [ 41%]\ntests/test_pipeline.py .......................                           [ 42%]\ntests/test_pipeline_branch_coverage.py .........                         [ 42%]\ntests/test_pipeline_calendar_alignment.py .                              [ 42%]\ntests/test_pipeline_constraints_integration.py .....                     [ 42%]\ntests/test_pipeline_entrypoints.py ........                              [ 43%]\ntests/test_pipeline_helpers.py ..........                                [ 43%]\ntests/test_pipeline_helpers_additional.py .............................. [ 44%]\n.......................                                                  [ 44%]\ntests/test_pipeline_indices.py ...                                       [ 44%]\ntests/test_pipeline_integration_direct.py ..                             [ 44%]\ntests/test_pipeline_optional_features.py .........................       [ 45%]\ntests/test_pipeline_run_analysis_helpers.py ..........                   [ 45%]\ntests/test_pipeline_run_cache_fallbacks.py .......................       [ 46%]\ntests/test_pipeline_stage_isolation.py .                                 [ 46%]\ntests/test_pipeline_warmup_autofix.py ..                                 [ 46%]\ntests/test_plugin_registry.py .....                                      [ 46%]\ntests/test_policy_engine_cov.py .........                                [ 47%]\ntests/test_portfolio_app_data_schema.py ......                           [ 47%]\ntests/test_post_ci_summary.py ..........                                 [ 47%]\ntests/test_presets_extended.py ..............                            [ 47%]\ntests/test_prices_validation.py .....                                    [ 48%]\ntests/test_proxy.py .ss.....                                             [ 48%]\ntests/test_proxy_cli.py ....                                             [ 48%]\ntests/test_proxy_cli_entrypoint.py .                                     [ 48%]\ntests/test_proxy_server_additional.py .............                      [ 48%]\ntests/test_proxy_server_missing_optional.py .                            [ 48%]\ntests/test_proxy_server_runtime_extra.py ...                             [ 48%]\ntests/test_quick_summary_diagnostics.py ...                              [ 48%]\ntests/test_quick_summary_report.py ..                                    [ 48%]\ntests/test_rank_selection.py .....                                       [ 49%]\ntests/test_rank_selection_additional.py ...............                  [ 49%]\ntests/test_rank_selection_diagnostics.py ...                             [ 49%]\ntests/test_rank_selection_fix.py ..                                      [ 49%]\ntests/test_rank_selection_helper.py ...                                  [ 49%]\ntests/test_rank_selection_uncovered.py ......                            [ 49%]\ntests/test_rank_selection_utils.py ........                              [ 50%]\ntests/test_rank_transform.py .                                           [ 50%]\ntests/test_rank_widgets.py ..                                            [ 50%]\ntests/test_rebalance_frequency_wiring.py .                               [ 50%]\ntests/test_rebalance_schedule.py ......................                  [ 50%]\ntests/test_rebalancing_cash_policy.py ......................             [ 51%]\ntests/test_rebalancing_imports.py ....                                   [ 51%]\ntests/test_rebalancing_integration.py ...                                [ 51%]\ntests/test_rebalancing_strategies.py .....                               [ 51%]\ntests/test_regex_optimization.py ..                                      [ 51%]\ntests/test_regimes.py ...........                                        [ 52%]\ntests/test_regimes_additional.py ..........................              [ 52%]\ntests/test_render_cosmetic_summary.py ..                                 [ 52%]\ntests/test_replacer.py ....                                              [ 53%]\ntests/test_rf_handling.py ...........                                    [ 53%]\ntests/test_risk.py ...............                                       [ 53%]\ntests/test_risk_additional.py ..........                                 [ 54%]\ntests/test_risk_free_default_alignment.py ..............                 [ 54%]\ntests/test_robust_weighting.py ....................................      [ 55%]\ntests/test_robust_weighting_integration.py .....                         [ 55%]\ntests/test_rolling_cache.py .....                                        [ 55%]\ntests/test_rolling_cache_additional_paths.py .........                   [ 55%]\ntests/test_run_analysis.py .......                                       [ 56%]\ntests/test_run_analysis_additional.py ........                           [ 56%]\ntests/test_run_analysis_cli.py ...........                               [ 56%]\ntests/test_run_analysis_cli_branches.py .......                          [ 56%]\ntests/test_run_analysis_cli_coverage.py ......                           [ 56%]\ntests/test_run_analysis_cli_default.py .                                 [ 56%]\ntests/test_run_analysis_cli_export.py .                                  [ 57%]\ntests/test_run_analysis_cli_keepalive.py ....                            [ 57%]\ntests/test_run_analysis_cli_parameters.py ..                             [ 57%]\ntests/test_run_analysis_cli_soft_round1.py ....                          [ 57%]\ntests/test_run_analysis_entrypoint_modern.py .....                       [ 57%]\ntests/test_run_artifacts.py .......                                      [ 57%]\ntests/test_run_full.py .....                                             [ 57%]\ntests/test_run_multi_analysis_additional.py ..                           [ 57%]\ntests/test_run_multi_analysis_cli.py ..                                  [ 57%]\ntests/test_score_frame.py .....                                          [ 58%]\ntests/test_script_error_handling.py ...","exit_code":124,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_147","type":"reasoning","text":"**Extending test timeout**"}}
{"type":"item.started","item":{"id":"item_148","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_148","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 3637 items\n\ntests/backtesting/test_bootstrap.py ........                             [  0%]\ntests/backtesting/test_harness.py ...........................            [  0%]\ntests/golden/test_demo.py ....                                           [  1%]\ntests/proxy/test_server.py ...............                               [  1%]\ntests/scripts/test_ci_history.py ................                        [  1%]\ntests/scripts/test_ci_metrics.py .....................                   [  2%]\ntests/scripts/test_evaluate_settings_effectiveness.py ....               [  2%]\ntests/scripts/test_sync_test_dependencies.py ......                      [  2%]\ntests/scripts/test_sync_tool_versions.py ....                            [  2%]\ntests/scripts/test_verify_trusted_config.py .......                      [  3%]\ntests/smoke/test_pipeline_smoke.py .                                     [  3%]\ntests/soft_coverage/test_data_soft.py ................................   [  3%]\ntests/soft_coverage/test_regimes_soft.py ......................          [  4%]\ntests/soft_coverage/test_signal_presets_soft.py .....                    [  4%]\ntests/soft_coverage/test_trend_analysis_init.py ..........               [  5%]\ntests/test_adaptive_bayes.py .....                                       [  5%]\ntests/test_analysis_results_module.py ......                             [  5%]\ntests/test_api_run_simulation.py .......                                 [  5%]\ntests/test_api_run_simulation_branches.py .......                        [  5%]\ntests/test_api_run_simulation_extra.py .....                             [  5%]\ntests/test_api_safe_len.py ...                                           [  5%]\ntests/test_api_signal_settings.py ..                                     [  5%]\ntests/test_app_coverage.py ...........................................   [  7%]\ntests/test_avg_corr_metric.py .                                          [  7%]\ntests/test_avgcorr_export.py ..                                          [  7%]\ntests/test_backtest_utils.py ...                                         [  7%]\ntests/test_backtesting_harness_additional.py .........                   [  7%]\ntests/test_backtesting_harness_membership.py ...                         [  7%]\ntests/test_build_autofix_pr_comment.py .............                     [  8%]\ntests/test_buy_and_hold_selection.py .......s                            [  8%]\ntests/test_cache_disable.py .                                            [  8%]\ntests/test_cli.py ..........                                             [  8%]\ntests/test_cli_api_golden_master.py ..                                   [  8%]\ntests/test_cli_cache_stats.py .                                          [  8%]\ntests/test_cli_cache_stats_disabled.py .                                 [  8%]\ntests/test_cli_cache_stats_extended.py ...                               [  8%]\ntests/test_cli_check.py .....                                            [  8%]\ntests/test_cli_helpers.py .....                                          [  8%]\ntests/test_cli_installed.py .....                                        [  9%]\ntests/test_cli_module.py .........                                       [  9%]\ntests/test_cli_no_cache_flag.py .                                        [  9%]\ntests/test_cli_no_structured_log.py .                                    [  9%]\ntests/test_cli_smoke.py .....                                            [  9%]\ntests/test_cli_trend_presets.py ...                                      [  9%]\ntests/test_cli_utils.py .....                                            [  9%]\ntests/test_config.py .                                                   [  9%]\ntests/test_config_alignment.py ..                                        [  9%]\ntests/test_config_bridge.py ........                                     [ 10%]\ntests/test_config_bridge_parity.py .                                     [ 10%]\ntests/test_config_errors.py .                                            [ 10%]\ntests/test_config_fallback_additional.py ................                [ 10%]\ntests/test_config_fallback_minimal.py ..........                         [ 10%]\ntests/test_config_human_errors.py .....................                  [ 11%]\ntests/test_config_legacy.py ...                                          [ 11%]\ntests/test_config_legacy_output_conversion.py ....                       [ 11%]\ntests/test_config_load.py .......                                        [ 11%]\ntests/test_config_model.py ............................................. [ 13%]\n......                                                                   [ 13%]\ntests/test_config_model_branch_coverage.py ............                  [ 13%]\ntests/test_config_model_validation.py ................                   [ 13%]\ntests/test_config_models.py ...                                          [ 14%]\ntests/test_config_models_additional.py ..............                    [ 14%]\ntests/test_config_models_coverage_extensions.py ............             [ 14%]\ntests/test_config_models_fallback_loader.py ....                         [ 14%]\ntests/test_config_models_fallback_unit.py .................              [ 15%]\ntests/test_config_path_discovery.py ......                               [ 15%]\ntests/test_config_pydantic_fallback.py ......                            [ 15%]\ntests/test_config_schema.py .......                                      [ 15%]\ntests/test_config_turnover_validation.py .................               [ 16%]\ntests/test_config_validation.py ....                                     [ 16%]\ntests/test_configure_presets.py ......                                   [ 16%]\ntests/test_constants.py .......                                          [ 16%]\ntests/test_constraint_optimizer.py .........                             [ 17%]\ntests/test_cov_cache_integration.py .                                    [ 17%]\ntests/test_coverage_trend.py ............                                [ 17%]\ntests/test_cv.py ...                                                     [ 17%]\ntests/test_data.py ..................................................... [ 18%]\n..........                                                               [ 19%]\ntests/test_data_contracts.py .........                                   [ 19%]\ntests/test_data_malformed_dates.py .......                               [ 19%]\ntests/test_data_schema.py .............                                  [ 20%]\ntests/test_date_correction.py ....................                       [ 20%]\ntests/test_decode_raw_input.py ............                              [ 20%]\ntests/test_default_export.py .                                           [ 20%]\ntests/test_dependency_enforcement.py ...                                 [ 21%]\ntests/test_dependency_version_alignment.py .                             [ 21%]\ntests/test_determinism_cli.py ..                                         [ 21%]\ntests/test_diagnostics.py ..................                             [ 21%]\ntests/test_engine_incremental_cov.py ..                                  [ 21%]\ntests/test_export_additional_coverage.py ............................    [ 22%]\ntests/test_export_bundle.py ...............                              [ 22%]\ntests/test_export_errors.py .                                            [ 22%]\ntests/test_export_formatter.py ....................                      [ 23%]\ntests/test_export_manifest_schema.py ..                                  [ 23%]\ntests/test_export_openpyxl_adapter.py ................                   [ 23%]\ntests/test_export_outputs.py ..                                          [ 23%]\ntests/test_exports.py .........                                          [ 24%]\ntests/test_frequency_missing.py ........                                 [ 24%]\ntests/test_gui.py ........                                               [ 24%]\ntests/test_gui_app_extended.py .....                                     [ 24%]\ntests/test_gui_app_simple.py ...........                                 [ 25%]\ntests/test_gui_launch_run.py ..                                          [ 25%]\ntests/test_gui_support.py .....                                          [ 25%]\ntests/test_gui_utils_extra.py .....                                      [ 25%]\ntests/test_hash_utils.py ....                                            [ 25%]\ntests/test_health_summarize_module.py ..........................         [ 26%]\ntests/test_import_excludes.py ..                                         [ 26%]\ntests/test_import_sanity.py ...                                          [ 26%]\ntests/test_inception_dates.py .                                          [ 26%]\ntests/test_incremental_cov.py .                                          [ 26%]\ntests/test_input_validation.py .......                                   [ 26%]\ntests/test_invariants.py ........                                        [ 26%]\ntests/test_io_utils.py ...........                                       [ 27%]\ntests/test_io_utils_cleanup.py ....                                      [ 27%]\ntests/test_io_validators_additional.py ...s                              [ 27%]\ntests/test_io_validators_extra.py .................................      [ 28%]\ntests/test_io_validators_negative_paths.py ....                          [ 28%]\ntests/test_is_zero_everywhere_helper.py .......                          [ 28%]\ntests/test_joblib_import.py ......                                       [ 28%]\ntests/test_joblib_shim.py .                                              [ 28%]\ntests/test_label_rules_assert.py ..                                      [ 28%]\ntests/test_legacy_imports.py ....                                        [ 28%]\ntests/test_lockfile_consistency.py s...                                  [ 29%]\ntests/test_logging_helpers.py ....                                       [ 29%]\ntests/test_logging_integration.py .                                      [ 29%]\ntests/test_logging_module.py ......                                      [ 29%]\ntests/test_logging_utils.py .....                                        [ 29%]\ntests/test_malformed_date_validation.py .....                            [ 29%]\ntests/test_market_data_validation.py ..................................  [ 30%]\ntests/test_market_data_validation_additional.py ........................ [ 31%]\n..                                                                       [ 31%]\ntests/test_metric_cache.py .....                                         [ 31%]\ntests/test_metric_vectorise.py .                                         [ 31%]\ntests/test_metric_vectorise_param.py .....                               [ 31%]\ntests/test_metrics.py .....                                              [ 31%]\ntests/test_metrics_attribution.py ........                               [ 31%]\ntests/test_metrics_edgecases.py ....                                     [ 32%]\ntests/test_metrics_extra.py ...........                                  [ 32%]\ntests/test_metrics_rolling.py .....                                      [ 32%]\ntests/test_metrics_rolling_cache_disabled.py .                           [ 32%]\ntests/test_metrics_summary.py .                                          [ 32%]\ntests/test_metrics_turnover_extra.py ..                                  [ 32%]\ntests/test_multi_period_engine.py .......                                [ 32%]\ntests/test_multi_period_engine_additional.py ................            [ 33%]\ntests/test_multi_period_engine_branch_completion.py ..........           [ 33%]\ntests/test_multi_period_engine_branch_coverage.py .....                  [ 33%]\ntests/test_multi_period_engine_branch_new.py ............                [ 33%]\ntests/test_multi_period_engine_cov_cache.py ...                          [ 34%]\ntests/test_multi_period_engine_debug.py .                                [ 34%]\ntests/test_multi_period_engine_extended.py .....                         [ 34%]\ntests/test_multi_period_engine_helpers_additional.py ....                [ 34%]\ntests/test_multi_period_engine_incremental_cov.py .............          [ 34%]\ntests/test_multi_period_engine_incremental_extra.py ....                 [ 34%]\ntests/test_multi_period_engine_incremental_fallback.py .                 [ 34%]\ntests/test_multi_period_engine_keepalive.py ......                       [ 35%]\ntests/test_multi_period_engine_lambda_tc.py .                            [ 35%]\ntests/test_multi_period_engine_missing_policy.py ..                      [ 35%]\ntests/test_multi_period_engine_portfolio_unit.py ....                    [ 35%]\ntests/test_multi_period_engine_price_frames.py .........                 [ 35%]\ntests/test_multi_period_engine_price_frames_extra.py ........            [ 35%]\ntests/test_multi_period_engine_run_schedule_extra.py ..                  [ 35%]\ntests/test_multi_period_engine_threshold_bounds.py ..                    [ 35%]\ntests/test_multi_period_engine_threshold_edgecases.py ........           [ 35%]\ntests/test_multi_period_engine_threshold_events_extended.py ..           [ 36%]\ntests/test_multi_period_engine_turnover_extended.py ...                  [ 36%]\ntests/test_multi_period_engine_turnover_regression.py ....               [ 36%]\ntests/test_multi_period_exits_cooldown.py .........                      [ 36%]\ntests/test_multi_period_export.py .................                      [ 36%]\ntests/test_multi_period_inception_filter.py .                            [ 36%]\ntests/test_multi_period_loaders.py ...................                   [ 37%]\ntests/test_multi_period_missing_policy_observability.py ..               [ 37%]\ntests/test_multi_period_rebalancer.py ...........                        [ 37%]\ntests/test_multi_period_regime_wiring.py ..                              [ 37%]\ntests/test_multi_period_scheduler.py ...                                 [ 37%]\ntests/test_multi_period_selection.py .                                   [ 38%]\ntests/test_multi_period_sticky_periods.py ...                            [ 38%]\ntests/test_multi_period_stub.py ..                                       [ 38%]\ntests/test_mypy_autofix.py .......                                       [ 38%]\ntests/test_na_as_zero_policy.py ...                                      [ 38%]\ntests/test_no_hardcoded_sleeps.py ...                                    [ 38%]\ntests/test_no_invalid_period_freq_aliases.py ..                          [ 38%]\ntests/test_no_lookahead.py ....                                          [ 38%]\ntests/test_optimizer.py .........                                        [ 38%]\ntests/test_optimizer_branch_coverage.py ...............                  [ 39%]\ntests/test_optimizer_constraints.py ...........................          [ 40%]\ntests/test_optimizer_constraints_additional.py ......................... [ 40%]\n                                                                         [ 40%]\ntests/test_optimizer_constraints_guardrails.py ..............            [ 41%]\ntests/test_optional_notebook_deps.py ..                                  [ 41%]\ntests/test_package_init.py .....                                         [ 41%]\ntests/test_perf_cache.py ..                                              [ 41%]\ntests/test_perf_cache_additional.py ...                                  [ 41%]\ntests/test_perf_cache_extended.py .........                              [ 41%]\ntests/test_perf_timing.py ....                                           [ 41%]\ntests/test_pipeline.py .......................                           [ 42%]\ntests/test_pipeline_branch_coverage.py .........                         [ 42%]\ntests/test_pipeline_calendar_alignment.py .                              [ 42%]\ntests/test_pipeline_constraints_integration.py .....                     [ 42%]\ntests/test_pipeline_entrypoints.py ........                              [ 43%]\ntests/test_pipeline_helpers.py ..........                                [ 43%]\ntests/test_pipeline_helpers_additional.py .............................. [ 44%]\n.......................                                                  [ 44%]\ntests/test_pipeline_indices.py ...                                       [ 44%]\ntests/test_pipeline_integration_direct.py ..                             [ 44%]\ntests/test_pipeline_optional_features.py .........................       [ 45%]\ntests/test_pipeline_run_analysis_helpers.py ..........                   [ 45%]\ntests/test_pipeline_run_cache_fallbacks.py .......................       [ 46%]\ntests/test_pipeline_stage_isolation.py .                                 [ 46%]\ntests/test_pipeline_warmup_autofix.py ..                                 [ 46%]\ntests/test_plugin_registry.py .....                                      [ 46%]\ntests/test_policy_engine_cov.py .........                                [ 47%]\ntests/test_portfolio_app_data_schema.py ......                           [ 47%]\ntests/test_post_ci_summary.py ..........                                 [ 47%]\ntests/test_presets_extended.py ..............                            [ 47%]\ntests/test_prices_validation.py .....                                    [ 48%]\ntests/test_proxy.py .ss.....                                             [ 48%]\ntests/test_proxy_cli.py ....                                             [ 48%]\ntests/test_proxy_cli_entrypoint.py .                                     [ 48%]\ntests/test_proxy_server_additional.py .............                      [ 48%]\ntests/test_proxy_server_missing_optional.py .                            [ 48%]\ntests/test_proxy_server_runtime_extra.py ...                             [ 48%]\ntests/test_quick_summary_diagnostics.py ...                              [ 48%]\ntests/test_quick_summary_report.py ..                                    [ 48%]\ntests/test_rank_selection.py .....                                       [ 49%]\ntests/test_rank_selection_additional.py ...............                  [ 49%]\ntests/test_rank_selection_diagnostics.py ...                             [ 49%]\ntests/test_rank_selection_fix.py ..                                      [ 49%]\ntests/test_rank_selection_helper.py ...                                  [ 49%]\ntests/test_rank_selection_uncovered.py ......                            [ 49%]\ntests/test_rank_selection_utils.py ........                              [ 50%]\ntests/test_rank_transform.py .                                           [ 50%]\ntests/test_rank_widgets.py ..                                            [ 50%]\ntests/test_rebalance_frequency_wiring.py .                               [ 50%]\ntests/test_rebalance_schedule.py ......................                  [ 50%]\ntests/test_rebalancing_cash_policy.py ......................             [ 51%]\ntests/test_rebalancing_imports.py ....                                   [ 51%]\ntests/test_rebalancing_integration.py ...                                [ 51%]\ntests/test_rebalancing_strategies.py .....                               [ 51%]\ntests/test_regex_optimization.py ..                                      [ 51%]\ntests/test_regimes.py ...........                                        [ 52%]\ntests/test_regimes_additional.py ..........................              [ 52%]\ntests/test_render_cosmetic_summary.py ..                                 [ 52%]\ntests/test_replacer.py ....                                              [ 53%]\ntests/test_rf_handling.py ...........                                    [ 53%]\ntests/test_risk.py ...............                                       [ 53%]\ntests/test_risk_additional.py ..........                                 [ 54%]\ntests/test_risk_free_default_alignment.py ..............                 [ 54%]\ntests/test_robust_weighting.py ....................................      [ 55%]\ntests/test_robust_weighting_integration.py .....                         [ 55%]\ntests/test_rolling_cache.py .....                                        [ 55%]\ntests/test_rolling_cache_additional_paths.py .........                   [ 55%]\ntests/test_run_analysis.py .......                                       [ 56%]\ntests/test_run_analysis_additional.py ........                           [ 56%]\ntests/test_run_analysis_cli.py ...........                               [ 56%]\ntests/test_run_analysis_cli_branches.py .......                          [ 56%]\ntests/test_run_analysis_cli_coverage.py ......                           [ 56%]\ntests/test_run_analysis_cli_default.py .                                 [ 56%]\ntests/test_run_analysis_cli_export.py .                                  [ 57%]\ntests/test_run_analysis_cli_keepalive.py ....                            [ 57%]\ntests/test_run_analysis_cli_parameters.py ..                             [ 57%]\ntests/test_run_analysis_cli_soft_round1.py ....                          [ 57%]\ntests/test_run_analysis_entrypoint_modern.py .....                       [ 57%]\ntests/test_run_artifacts.py .......                                      [ 57%]\ntests/test_run_full.py .....                                             [ 57%]\ntests/test_run_multi_analysis_additional.py ..                           [ 57%]\ntests/test_run_multi_analysis_cli.py ..                                  [ 57%]\ntests/test_score_frame.py .....                                          [ 58%]\ntests/test_script_error_handling.py ......                               [ 58%]\ntests/test_selector.py .......                                           [ 58%]\ntests/test_selector_cache.py ...                                         [ 58%]\ntests/test_selector_plugins.py ........                                  [ 58%]\ntests/test_selector_weighting.py ....","exit_code":124,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_149","type":"reasoning","text":"**Devising targeted coverage strategy**\n\nIâ€™m figuring out how to get over 80% coverage on stage modules without timing out by running the full test suite. Since full runs time out around 240 seconds, I plan to run a carefully selected subset of pipeline-related tests that cover stage code sufficiently. Creating or using matching test files focused on stages should meet instructions and keep run time manageable. Iâ€™m preparing a long pytest command with these tests to run coverage under a higher timeout and check if this approach works well."}}
{"type":"item.started","item":{"id":"item_150","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_150","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=src/trend_analysis/stages/preprocessing --cov=src/trend_analysis/stages/selection --cov=src/trend_analysis/stages/portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 174 items\n\ntests/test_pipeline.py .......................                           [ 13%]\ntests/test_pipeline_branch_coverage.py .........                         [ 18%]\ntests/test_pipeline_helpers.py ..........                                [ 24%]\ntests/test_pipeline_helpers_additional.py .............................. [ 41%]\n.......................                                                  [ 54%]\ntests/test_pipeline_run_analysis_helpers.py ..........                   [ 60%]\ntests/test_pipeline_optional_features.py .........................       [ 74%]\ntests/test_pipeline_run_cache_fallbacks.py .......................       [ 87%]\ntests/test_pipeline_indices.py ...                                       [ 89%]\ntests/test_pipeline_constraints_integration.py .....                     [ 92%]\ntests/test_pipeline_stage_isolation.py .                                 [ 93%]\ntests/test_score_frame.py .....                                          [ 95%]\ntests/test_run_analysis.py ......./opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/coverage/inorout.py:497: CoverageWarning: Module src/trend_analysis/stages/preprocessing was never imported. (module-not-imported); see https://coverage.readthedocs.io/en/7.13.1/messages.html#warning-module-not-imported\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/coverage/inorout.py:497: CoverageWarning: Module src/trend_analysis/stages/selection was never imported. (module-not-imported); see https://coverage.readthedocs.io/en/7.13.1/messages.html#warning-module-not-imported\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/coverage/inorout.py:497: CoverageWarning: Module src/trend_analysis/stages/portfolio was never imported. (module-not-imported); see https://coverage.readthedocs.io/en/7.13.1/messages.html#warning-module-not-imported\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/coverage/control.py:958: CoverageWarning: No data was collected. (no-data-collected); see https://coverage.readthedocs.io/en/7.13.1/messages.html#warning-no-data-collected\n  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_cov/plugin.py:363: CovReportWarning: Failed to generate report: No data to report.\n\n  warnings.warn(CovReportWarning(message), stacklevel=1)\n\nWARNING: Failed to generate report: No data to report.\n\n                                                                         [100%]\n\n=============================== warnings summary ===============================\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\ntests/test_pipeline_helpers_additional.py::test_resolve_sample_split_invalid_dates_raise\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py:465: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================================ tests coverage ================================\n_______________ coverage: platform linux, python 3.11.14-final-0 _______________\n\n======================= 174 passed, 2 warnings in 10.94s =======================\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_151","type":"reasoning","text":"**Correcting coverage configuration**"}}
{"type":"item.started","item":{"id":"item_152","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis.stages.preprocessing --cov=trend_analysis.stages.selection --cov=trend_analysis.stages.portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_152","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis.stages.preprocessing --cov=trend_analysis.stages.selection --cov=trend_analysis.stages.portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 174 items\n\ntests/test_pipeline.py F\n\n=================================== FAILURES ===================================\n__________________________ test_run_returns_dataframe __________________________\n\ntmp_path = PosixPath('/tmp/pytest-of-runner/pytest-7/test_run_returns_dataframe0')\n\n    def test_run_returns_dataframe(tmp_path):\n>       cfg = make_cfg(tmp_path, make_df())\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests/test_pipeline.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_pipeline.py:20: in make_cfg\n    df.to_csv(csv, index=False)\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/util/_decorators.py:333: in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/generic.py:3989: in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/format.py:1014: in to_csv\n    csv_formatter.save()\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:270: in save\n    self._save()\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:275: in _save\n    self._save_body()\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313: in _save_body\n    self._save_chunk(start_i, end_i)\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:320: in _save_chunk\n    res = df._get_values_for_csv(**self._number_format)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/frame.py:1414: in _get_values_for_csv\n    mgr = self._mgr.get_values_for_csv(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/internals/managers.py:485: in get_values_for_csv\n    return self.apply(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/internals/managers.py:363: in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/internals/blocks.py:806: in get_values_for_csv\n    result = get_values_for_csv(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/indexes/base.py:7868: in get_values_for_csv\n    result = values[i, :]._format_native_types(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:749: in _format_native_types\n    if date_format is None and self._is_dates_only:\n                               ^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:2444: in _is_dates_only\n    even_days = np.logical_and(consider_values, values_int % ppd != 0).sum() == 0\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\na = array([False, False, False, False, False, False]), axis = None, dtype = None\nout = None, keepdims = False, initial = <no value>, where = True\n\n    def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n             initial=_NoValue, where=True):\n>       return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       TypeError: int() argument must be a string, a bytes-like object or a real number, not '_NoValueType'\n\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/numpy/_core/_methods.py:51: TypeError\n=============================== warnings summary ===============================\nsrc/trend_analysis/metrics/__init__.py:16\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/metrics/__init__.py:16: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.\n    import numpy as np\n\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nFAILED tests/test_pipeline.py::test_run_returns_dataframe - TypeError: int() argument must be a string, a bytes-like object or a real number, not '_NoValueType'\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\n======================== 1 failed, 2 warnings in 3.80s =========================\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_153","type":"reasoning","text":"**Investigating numpy reload error during tests**\n\nI'm troubleshooting a perplexing numpy reload error linked to using `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1` with pytest coverage and module names for coverage. The error pops in pandas' to_csv involving numpy's internal _NoValue, possibly from numpy being imported twice during test runs. I'm weighing how coverage options and environment variables might trigger or avoid the reload issue, and planning to rerun tests to check reproducibility and isolate the cause."}}
{"type":"item.started","item":{"id":"item_154","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis.stages.preprocessing --cov=trend_analysis.stages.selection --cov=trend_analysis.stages.portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_154","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis.stages.preprocessing --cov=trend_analysis.stages.selection --cov=trend_analysis.stages.portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 23 items\n\ntests/test_pipeline.py F\n\n=================================== FAILURES ===================================\n__________________________ test_run_returns_dataframe __________________________\n\ntmp_path = PosixPath('/tmp/pytest-of-runner/pytest-8/test_run_returns_dataframe0')\n\n    def test_run_returns_dataframe(tmp_path):\n>       cfg = make_cfg(tmp_path, make_df())\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests/test_pipeline.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_pipeline.py:20: in make_cfg\n    df.to_csv(csv, index=False)\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/util/_decorators.py:333: in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/generic.py:3989: in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/format.py:1014: in to_csv\n    csv_formatter.save()\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:270: in save\n    self._save()\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:275: in _save\n    self._save_body()\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313: in _save_body\n    self._save_chunk(start_i, end_i)\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/formats/csvs.py:320: in _save_chunk\n    res = df._get_values_for_csv(**self._number_format)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/frame.py:1414: in _get_values_for_csv\n    mgr = self._mgr.get_values_for_csv(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/internals/managers.py:485: in get_values_for_csv\n    return self.apply(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/internals/managers.py:363: in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/internals/blocks.py:806: in get_values_for_csv\n    result = get_values_for_csv(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/indexes/base.py:7868: in get_values_for_csv\n    result = values[i, :]._format_native_types(\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:749: in _format_native_types\n    if date_format is None and self._is_dates_only:\n                               ^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:2444: in _is_dates_only\n    even_days = np.logical_and(consider_values, values_int % ppd != 0).sum() == 0\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\na = array([False, False, False, False, False, False]), axis = None, dtype = None\nout = None, keepdims = False, initial = <no value>, where = True\n\n    def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n             initial=_NoValue, where=True):\n>       return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       TypeError: int() argument must be a string, a bytes-like object or a real number, not '_NoValueType'\n\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/numpy/_core/_methods.py:51: TypeError\n=============================== warnings summary ===============================\nsrc/trend_analysis/metrics/__init__.py:16\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/metrics/__init__.py:16: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.\n    import numpy as np\n\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nFAILED tests/test_pipeline.py::test_run_returns_dataframe - TypeError: int() argument must be a string, a bytes-like object or a real number, not '_NoValueType'\n!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\n======================== 1 failed, 2 warnings in 1.21s =========================\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_155","type":"reasoning","text":"**Investigating numpy reload during coverage testing**\n\nI'm exploring why numpy reloads when running pytest with coverage on certain modules; it might be linked to importlib-based module loading. I'm considering changes to pytest plugin disables to avoid socket errors and numpy reload, such as disabling pytest_rerunfailures explicitly without turning off plugin autoload, and testing with a smaller command focused on a single test file."}}
{"type":"item.started","item":{"id":"item_156","type":"command_execution","command":"/bin/bash -lc 'MPLCONFIGDIR=/tmp/matplotlib pytest -p no:pytest_rerunfailures --cov=trend_analysis.stages.preprocessing --cov=trend_analysis.stages.selection --cov=trend_analysis.stages.portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_156","type":"command_execution","command":"/bin/bash -lc 'MPLCONFIGDIR=/tmp/matplotlib pytest -p no:pytest_rerunfailures --cov=trend_analysis.stages.preprocessing --cov=trend_analysis.stages.selection --cov=trend_analysis.stages.portfolio --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py'","aggregated_output":"INTERNALERROR> Traceback (most recent call last):\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/main.py\", line 314, in wrap_session\nINTERNALERROR>     config._do_configure()\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 1159, in _do_configure\nINTERNALERROR>     self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_hooks.py\", line 534, in call_historic\nINTERNALERROR>     res = self._hookexec(self.name, self._hookimpls.copy(), kwargs, False)\nINTERNALERROR>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_manager.py\", line 120, in _hookexec\nINTERNALERROR>     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\nINTERNALERROR>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_callers.py\", line 167, in _multicall\nINTERNALERROR>     raise exception\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pluggy/_callers.py\", line 121, in _multicall\nINTERNALERROR>     res = hook_impl.function(*args)\nINTERNALERROR>           ^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 347, in pytest_configure\nINTERNALERROR>     config.failures_db = ServerStatusDB()\nINTERNALERROR>                          ^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 451, in __init__\nINTERNALERROR>     super().__init__()\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_rerunfailures.py\", line 432, in __init__\nINTERNALERROR>     self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nINTERNALERROR>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/socket.py\", line 232, in __init__\nINTERNALERROR>     _socket.socket.__init__(self, family, type, proto, fileno)\nINTERNALERROR> PermissionError: [Errno 1] Operation not permitted\n","exit_code":3,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_157","type":"reasoning","text":"**Investigating pytest plugin and numpy reload issues**"}}
{"type":"item.started","item":{"id":"item_158","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' src/trend_analysis/__init__.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_158","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' src/trend_analysis/__init__.py\"","aggregated_output":"\"\"\"Trend analysis package.\"\"\"\n\nimport importlib\nimport importlib.metadata\nimport sys\nfrom types import ModuleType\nfrom typing import Any, cast\n\n\ndef _patch_dataclasses_module_guard() -> None:\n    \"\"\"Ensure dataclass processing tolerates cleared ``sys.modules`` entries.\n\n    Some heavy integration tests mutate ``sys.modules`` by removing previously\n    imported ``tests.*`` packages.  When later tests define dataclasses within\n    those modules, the stdlib ``dataclasses`` helper attempts to look the module\n    back up and crashes when it is absent.  We patch the private\n    ``dataclasses._is_type`` helper so it re-imports the missing module (falling\n    back to a lightweight placeholder) before retrying the lookup.  The patch is\n    safe for production code because it only triggers when the module reference\n    truly disappeared, which should not happen during normal execution.\n    \"\"\"\n\n    import dataclasses\n\n    original = getattr(dataclasses, \"_is_type\", None)\n    if original is None:\n        return\n    if getattr(dataclasses, \"_trend_model_patched\", False):\n        globals()[\"_SAFE_IS_TYPE\"] = dataclasses._is_type  # type: ignore[attr-defined]\n        return\n\n    def _safe_is_type(\n        annotation: Any,\n        cls: type[Any],\n        a_module: Any,\n        a_type: Any,\n        predicate: Any,\n    ) -> bool:\n        try:\n            return bool(original(annotation, cls, a_module, a_type, predicate))\n        except AttributeError:\n            module_name = getattr(cls, \"__module__\", None)\n            if not module_name:\n                raise\n\n            module = sys.modules.get(module_name)\n            if module is None:\n                try:\n                    module = importlib.import_module(module_name)\n                except Exception:\n                    module = ModuleType(module_name)\n                    module.__dict__[\"__package__\"] = module_name.rpartition(\".\")[0]\n                sys.modules[module_name] = module\n\n            return bool(original(annotation, cls, a_module, a_type, predicate))\n\n    dataclasses._is_type = _safe_is_type  # type: ignore[attr-defined]\n    dataclasses._trend_model_patched = True  # type: ignore[attr-defined]\n    globals()[\"_SAFE_IS_TYPE\"] = _safe_is_type\n\n\n_patch_dataclasses_module_guard()\n\n_MODULE_SELF = sys.modules[__name__]\n\n\ndef _ensure_registered() -> None:\n    if sys.modules.get(__name__) is not _MODULE_SELF:\n        sys.modules[__name__] = _MODULE_SELF\n\n\n_ORIGINAL_SPEC = globals().get(\"__spec__\")\n\n\nclass _SpecProxy:\n    __slots__ = (\"_spec\",)\n\n    def __init__(self, spec: Any) -> None:\n        self._spec = spec\n\n    def __getattr__(self, attr: str) -> Any:\n        return getattr(self._spec, attr)\n\n    @property\n    def name(self) -> str:\n        _ensure_registered()\n        return cast(str, getattr(self._spec, \"name\"))\n\n\nif _ORIGINAL_SPEC is not None:\n    globals()[\"__spec__\"] = _SpecProxy(_ORIGINAL_SPEC)\n\n_ensure_registered()\n\n# Attempt to import a core set of lighter submodules eagerly. Heavier or\n# optional pieces are exposed lazily via __getattr__ to avoid hard failures\n# when the environment is only partially initialised (e.g. before venv\n# activation). This also prevents transient ModuleNotFoundError masking when\n# optional dependencies of those submodules are absent.\n_EAGER_SUBMODULES = [\n    \"metrics\",\n    \"config\",\n    \"data\",\n    \"pipeline\",\n    \"export\",\n    \"signals\",\n    \"backtesting\",\n]\n\n# Modules that may drag optional / heavy deps; imported on first attribute access.\n_LAZY_SUBMODULES = {\n    \"api\": \"trend_analysis.api\",\n    \"cli\": \"trend_analysis.cli\",\n    \"io\": \"trend_analysis.io\",\n    \"selector\": \"trend_analysis.selector\",\n    \"weighting\": \"trend_analysis.weighting\",\n    \"weights\": \"trend_analysis.weights\",\n    \"presets\": \"trend_analysis.presets\",\n    \"run_multi_analysis\": \"trend_analysis.run_multi_analysis\",\n    \"engine\": \"trend_analysis.engine\",\n    \"perf\": \"trend_analysis.perf\",\n    \"regimes\": \"trend_analysis.regimes\",\n    \"multi_period\": \"trend_analysis.multi_period\",\n    \"plugins\": \"trend_analysis.plugins\",\n    \"proxy\": \"trend_analysis.proxy\",\n}\n\n# Purge stale lazy-loaded attributes so reload() restores deferred imports.\nfor _lazy_attr in list(_LAZY_SUBMODULES):\n    globals().pop(_lazy_attr, None)\n\nfor _name in _EAGER_SUBMODULES:\n    try:  # pragma: no cover - import side effects\n        globals()[_name] = importlib.import_module(f\"trend_analysis.{_name}\")\n    except ImportError:\n        # Missing optional dependency chain; submodule simply not exposed.\n        continue\n\n\ndef __getattr__(attr: str) -> ModuleType:  # pragma: no cover - thin lazy loader\n    target = _LAZY_SUBMODULES.get(attr)\n    if target is None:\n        # Fallback: attempt to load an eager submodule that may have failed\n        # during initial import (e.g., due to race conditions in parallel tests).\n        if attr in _EAGER_SUBMODULES:\n            try:\n                mod = importlib.import_module(f\"trend_analysis.{attr}\")\n                globals()[attr] = mod\n                return mod\n            except ImportError:\n                pass\n        raise AttributeError(attr)\n    mod = importlib.import_module(target)\n    globals()[attr] = mod\n    return mod\n\n\n# Forward declarations for static type checkers; actual values are assigned\n# dynamically above via importlib. This avoids mypy complaints about names\n# listed in __all__ not being present in the module at type-check time.\nmetrics: Any\nconfig: Any\ndata: Any\npipeline: Any\nexport: Any\nsignals: Any\nio: Any\nbacktesting: Any\napi: Any\nselector: Any\nweighting: Any\npresets: Any\nrun_multi_analysis: Any\nengine: Any\nperf: Any\nregimes: Any\nmulti_period: Any\nplugins: Any\nproxy: Any\n\nif \"data\" in globals():\n    # Conditional import: 'data' submodule may not always be present\n    # due to optional dependencies.\n    from .data import identify_risk_free_fund, load_csv\n\nif \"export\" in globals():\n    from .export import (\n        combined_summary_frame,\n        combined_summary_result,\n        export_bundle,\n        export_data,\n        export_multi_period_metrics,\n        export_phase1_multi_metrics,\n        export_phase1_workbook,\n        export_to_csv,\n        export_to_excel,\n        export_to_json,\n        export_to_txt,\n        flat_frames_from_results,\n        make_summary_formatter,\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_159","type":"reasoning","text":"**Analyzing numpy reload causes with coverage**\n\nI'm thinking through how importing submodules eagerly might cause pipeline imports that pull in numpy multiple times, triggering reload warnings during coverage runs. Iâ€™m considering if specifying coverage at the package level and disabling pytest plugin autoload might prevent numpy from being reloaded, since tests could cause sys.modules resets or importlib.reload calls. I plan to test coverage with `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1` and see if this approach avoids the numpy reload error in `test_pipeline.py`."}}
{"type":"item.started","item":{"id":"item_160","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_160","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 23 items\n\ntests/test_pipeline.py .......................                           [100%]\n\n=============================== warnings summary ===============================\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================================ tests coverage ================================\n_______________ coverage: platform linux, python 3.11.14-final-0 _______________\n\nName                                                     Stmts   Miss Branch BrPart  Cover   Missing\n----------------------------------------------------------------------------------------------------\nsrc/trend_analysis/__init__.py                              86     21     18      6    70%   27, 29-30, 41-55, 69, 86-87, 90->93, 135-137, 181->186, 186->208\nsrc/trend_analysis/_autofix_probe.py                         4      4      0      0     0%   7-18\nsrc/trend_analysis/_autofix_trigger_sample.py               13     13      0      0     0%   1-35\nsrc/trend_analysis/_autofix_violation_case2.py              19     19      4      0     0%   16-59\nsrc/trend_analysis/_autofix_violation_case3.py              15     15      0      0     0%   1-36\nsrc/trend_analysis/_ci_probe_faults.py                      15     15      0      0     0%   8-36\nsrc/trend_analysis/_typing.py                               10      0      0      0   100%\nsrc/trend_analysis/api.py                                  290    290     88      0     0%   1-696\nsrc/trend_analysis/api_server/__init__.py                   24     24      2      0     0%   7-87\nsrc/trend_analysis/api_server/__main__.py                    3      3      2      0     0%   3-7\nsrc/trend_analysis/automation_multifailure.py                4      4      0      0     0%   9-16\nsrc/trend_analysis/backtesting/__init__.py                   3      0      0      0   100%\nsrc/trend_analysis/backtesting/bootstrap.py                 63     53     24      0    11%   13-15, 19-32, 45-57, 88-131\nsrc/trend_analysis/backtesting/harness.py                  417    347    180      0    12%   40-50, 54-57, 61-64, 67-72, 75, 107, 135, 177-354, 375-382, 386-400, 408-432, 436-446, 450-453, 462-514, 518-534, 538-543, 547-550, 554-565, 569-587, 593-597, 604-609, 613-615, 621-627, 637-666, 678-681, 685-696, 700-704, 708\nsrc/trend_analysis/cash_policy.py                            8      0      0      0   100%\nsrc/trend_analysis/cli.py                                  400    400    122      0     0%   1-770\nsrc/trend_analysis/config/__init__.py                        3      0      0      0   100%\nsrc/trend_analysis/config/bridge.py                         38     38      6      0     0%   3-96\nsrc/trend_analysis/config/legacy.py                         49     49     10      0     0%   3-111\nsrc/trend_analysis/config/model.py                         390    206    154     23    38%   52->55, 59-76, 80, 85, 90, 105-118, 124-137, 143-161, 191, 193->195, 200-215, 220-225, 231, 235, 241, 244, 252, 261, 265, 268-269, 277-281, 288-295, 302-304, 323-333, 340-342, 373, 375-376, 383, 391-396, 406, 408, 416-418, 428, 434-442, 447-457, 462-470, 475-485, 505, 511-517, 522-528, 548-565, 576-587, 595-600\nsrc/trend_analysis/config/models.py                        442    221    188     29    43%   126-133, 137, 141, 152-158, 168, 171, 173, 218-219, 252, 261, 317, 319, 332, 341, 351, 354, 363, 365, 369-378, 384->388, 402-561, 569, 602-605, 609-610, 634-640, 651, 662-666, 679, 689, 695-707, 712-722, 730-772, 784, 792-799, 803-826, 830, 844, 846, 852-859, 862, 870, 872-874\nsrc/trend_analysis/constants.py                              6      0      0      0   100%\nsrc/trend_analysis/core/__init__.py                          0      0      0      0   100%\nsrc/trend_analysis/core/metric_cache.py                     49     49     10      0     0%   1-115\nsrc/trend_analysis/core/rank_selection.py                  520    372    198      6    22%   57-66, 72-78, 84-97, 103-110, 114-115, 119-124, 144-146, 151, 156, 169-208, 221-222, 225-229, 232-237, 240-243, 246-252, 255-260, 263, 266, 269-270, 291-295, 301-303, 309-321, 331-343, 359-364, 372-373, 385-390, 398, 408-409, 415, 421-424, 447-473, 505-737, 780, 805-808, 873-891, 915, 938-939, 959-967, 975-983, 991-1006, 1031, 1043-1052, 1059, 1065, 1081-1084, 1099-1136, 1147-1150\nsrc/trend_analysis/data.py                                 325    172    150     27    40%   36-43, 49-55, 59-65, 69-81, 124, 127-128, 131, 138->145, 147, 156, 167, 225-226, 230->236, 232->236, 237->236, 239->236, 241, 248, 264-265, 277-286, 306-320, 322->328, 331-341, 347, 360-368, 378-382, 416, 418, 435, 438-441, 452->454, 464-481, 495-551, 563, 580, 592-621\nsrc/trend_analysis/diagnostics.py                           85     38     24      3    46%   24, 31-32, 35-36, 42-44, 47-48, 51-52, 55-56, 59-60, 112, 116, 130-162\nsrc/trend_analysis/engine/__init__.py                        2      0      0      0   100%\nsrc/trend_analysis/engine/optimizer.py                     158    107     68     11    27%   40->42, 43, 51-65, 71-99, 110-138, 146-176, 187->190, 192, 198-202, 213-217, 222, 225-240, 245-247, 253-254\nsrc/trend_analysis/engine/walkforward.py                   161    130     62      0    14%   39-45, 51-68, 74-83, 89-96, 103-111, 115-141, 145-151, 192-298\nsrc/trend_analysis/export/__init__.py                     1070    984    436      0     6%   37-52, 58-59, 69-89, 97, 101, 104-107, 112-113, 116-121, 124, 127-131, 134-143, 150, 154, 159, 162-167, 180, 184, 191, 200-201, 204-208, 211, 214-218, 227-228, 231-237, 240-243, 246, 249-251, 254, 262-266, 271, 275-336, 340-407, 411-431, 443-683, 695-696, 709-710, 721-746, 758-995, 1000, 1005, 1022-1117, 1127-1132, 1146-1151, 1163-1167, 1196-1214, 1235-1237, 1242-1257, 1263-1421, 1429-1507, 1522-1581, 1587-1588, 1596-1604, 1612-1618, 1644-1664, 1672-1714, 1729-1802, 1819-1848, 1874-1955, 1965-1972\nsrc/trend_analysis/export/bundle.py                        180    165     50      0     7%   24-33, 48-414\nsrc/trend_analysis/gui/__init__.py                           5      5      0      0     0%   3-15\nsrc/trend_analysis/gui/app.py                              506    506    112      0     0%   1-937\nsrc/trend_analysis/gui/plugins.py                           15     15      4      0     0%   1-26\nsrc/trend_analysis/gui/store.py                             17     17      0      0     0%   1-27\nsrc/trend_analysis/gui/utils.py                             27     27      6      0     0%   1-44\nsrc/trend_analysis/io/__init__.py                            4      0      0      0   100%\nsrc/trend_analysis/io/market_data.py                       487    224    172     52    49%   76-112, 140-172, 191-194, 239, 241, 256, 259, 262, 273, 277-280, 286-287, 296-302, 312-314, 323-325, 338-341, 351, 385-415, 418, 444, 451-465, 471-474, 476, 478, 493, 506, 519, 531, 536-540, 542-546, 553-566, 572, 580-588, 596, 623, 626->630, 627->626, 631-635, 638->656, 641-650, 658-666, 668-673, 678-679, 683-691, 699-700, 709-716, 719-722, 746-757, 769, 773, 778, 786, 804-806, 814, 817, 822-826, 830-834, 838-840, 857, 861, 868-874, 924-939, 945-954\nsrc/trend_analysis/io/utils.py                              58     45     14      0    18%   19-26, 43-92, 101-108\nsrc/trend_analysis/io/validators.py                        164    142     56      0    10%   32-64, 80-86, 89-125, 142-156, 160-162, 175-180, 184-263, 269-286, 292-298\nsrc/trend_analysis/logging.py                               85     85     30      0     0%   1-249\nsrc/trend_analysis/logging_setup.py                         49     49     10      0     0%   3-101\nsrc/trend_analysis/metrics/__init__.py                     203     67     80     26    62%   46, 56, 93, 101-103, 110, 122, 127, 147-150, 169, 174, 182, 186-208, 221, 237, 239, 241, 266, 268, 270, 285, 291-318, 331, 334, 360, 363, 367-368, 386-388\nsrc/trend_analysis/metrics/attribution.py                   35     24     12      1    26%   65-78, 84, 90, 120-136\nsrc/trend_analysis/metrics/rolling.py                       31     26      8      0    13%   33-66\nsrc/trend_analysis/metrics/summary.py                       21     14      0      0    33%   36-61\nsrc/trend_analysis/metrics/turnover.py                      15      8      2      0    41%   25-27, 34-36, 52-53\nsrc/trend_analysis/multi_period/__init__.py                  2      2      0      0     0%   3-5\nsrc/trend_analysis/multi_period/engine.py                 1917   1917    894      0     0%   18-3920\nsrc/trend_analysis/multi_period/loaders.py                 117    117     54      0     0%   3-217\nsrc/trend_analysis/multi_period/replacer.py                116    116     48      0     0%   12-236\nsrc/trend_analysis/multi_period/scheduler.py                58     58     20      0     0%   7-140\nsrc/trend_analysis/perf/cache.py                           117     68     26      3    36%   36-38, 53, 74-80, 84-91, 94-99, 104-128, 131-132, 140, 171, 180-183, 189-190, 203-214, 238-255\nsrc/trend_analysis/perf/rolling_cache.py                   104     57     18      1    39%   24-25, 31-32, 39-45, 55, 61-80, 94, 102-104, 107, 110, 115-118, 130-176, 185, 191\nsrc/trend_analysis/perf/timing.py                           30     20     10      0    25%   34-42, 59-73\nsrc/trend_analysis/pipeline.py                             129     35     18      3    66%   131-144, 160, 164, 168, 193-201, 248-256, 332, 350, 375\nsrc/trend_analysis/pipeline_entrypoints.py                 127      9     38     14    85%   39->41, 42->45, 61-63, 69->71, 80->82, 128->134, 135->137, 152, 163, 166->168, 169->172, 188-190, 196->198, 256-263\nsrc/trend_analysis/pipeline_helpers.py                     357    279    162     15    19%   42, 55, 58-70, 76, 79, 82-83, 85, 96-111, 116-138, 151-199, 211, 214-239, 246-253, 258, 285-339, 355-378, 382, 392-437, 453->451, 460-500, 538-601, 630-642\nsrc/trend_analysis/pipeline_runner.py                       30      0      6      0   100%\nsrc/trend_analysis/plugins/__init__.py                      41      4      0      0    90%   54, 70, 129, 134\nsrc/trend_analysis/portfolio/__init__.py                     2      0      0      0   100%\nsrc/trend_analysis/portfolio/weight_policy.py               53     18     24     11    60%   17, 20, 25->27, 73, 79, 87-92, 95, 103-108, 111, 115-116, 120\nsrc/trend_analysis/presets.py                              231    231     86      0     0%   3-433\nsrc/trend_analysis/proxy/__init__.py                         2      2      0      0     0%   9-11\nsrc/trend_analysis/proxy/__main__.py                         3      3      2      0     0%   3-6\nsrc/trend_analysis/proxy/cli.py                             30     30      4      0     0%   3-76\nsrc/trend_analysis/proxy/server.py                          95     95     14      0     0%   10-282\nsrc/trend_analysis/rebalancing.py                            8      8      0      0     0%   9-46\nsrc/trend_analysis/rebalancing/__init__.py                   2      2      0      0     0%   1-14\nsrc/trend_analysis/rebalancing/strategies.py               185    185     42      0     0%   10-447\nsrc/trend_analysis/regimes.py                              285    211    130      5    20%   45-47, 66, 95, 97, 99, 123-128, 146-153, 159-170, 182-256, 269-271, 277-282, 293-332, 348-456, 485-564\nsrc/trend_analysis/reporting/__init__.py                    14     14      0      0     0%   3-34\nsrc/trend_analysis/reporting/run_artifacts.py              135    135     48      0     0%   3-286\nsrc/trend_analysis/risk.py                                 174     71     58     17    53%   55, 63, 81, 89, 94-106, 122, 128, 132, 141, 154-168, 181-190, 199-236, 259, 263, 271-272, 273->277, 276, 324\nsrc/trend_analysis/run_analysis.py                          62     62     24      0     0%   1-134\nsrc/trend_analysis/run_multi_analysis.py                    36     36      0      0     0%   1-80\nsrc/trend_analysis/schedules.py                            103    103     44      0     0%   1-213\nsrc/trend_analysis/script_logging.py                        27     27      6      0     0%   3-60\nsrc/trend_analysis/selector.py                              39     39      4      0     0%   1-66\nsrc/trend_analysis/signal_presets.py                        42     42     10      0     0%   3-137\nsrc/trend_analysis/signals.py                              132     39     36     13    65%   35, 38, 43, 45, 66, 89, 101-106, 123, 125, 127, 129, 143-146, 152-158, 165, 178-188, 192-195\nsrc/trend_analysis/stages/__init__.py                        4      0      0      0   100%\nsrc/trend_analysis/stages/portfolio.py                     318     65     70     24    74%   52-65, 203, 207-214, 231, 239-245, 264-265, 268, 296->353, 325->329, 329->333, 333->335, 348, 380, 385-386, 388->390, 392-393, 395, 414, 422-429, 440-441, 443, 448-449, 458-459, 460->463, 475, 540->555, 550-551, 574-579, 597-598, 698-700, 718\nsrc/trend_analysis/stages/preprocessing.py                 218     49     72     27    72%   36, 37->39, 40->42, 90, 102, 115-125, 133, 139, 154, 167-172, 182, 186, 189, 262, 283, 295, 307-340, 349, 355, 368-372, 404, 442, 446, 455, 459-460, 469-471, 473->475, 487\nsrc/trend_analysis/stages/selection.py                     222     79     96     29    58%   74-75, 87, 93, 104, 108->123, 117->121, 127, 139, 145, 149, 161, 166, 184, 198, 203, 215-233, 242, 285, 288, 292, 301, 308, 315, 378-392, 409->414, 426, 434-439, 443-457, 473-474, 476-503\nsrc/trend_analysis/time_utils.py                           146     69     56     16    48%   18, 23-27, 31-33, 37-40, 44-53, 75, 78, 80, 82, 84, 87, 96-110, 123, 125-135, 141, 154->159, 165-170, 176-185, 191-193, 201, 204\nsrc/trend_analysis/timefreq.py                              34     21     10      0    30%   47, 57, 69-70, 85-105\nsrc/trend_analysis/typing.py                                15     15      0      0     0%   3-34\nsrc/trend_analysis/ui/__init__.py                            0      0      0      0   100%\nsrc/trend_analysis/ui/rank_widgets.py                        9      9      0      0     0%   1-12\nsrc/trend_analysis/universe.py                             187    165     84      0     8%   24-27, 34-39, 45-81, 89-109, 113-135, 141-189, 198-226, 234-259, 288-310\nsrc/trend_analysis/universe_catalog.py                     101    101     40      0     0%   1-175\nsrc/trend_analysis/util/__init__.py                          0      0      0      0   100%\nsrc/trend_analysis/util/frequency.py                        84     19     26      8    70%   44, 47-53, 62, 64, 67-71, 81, 102, 105, 142\nsrc/trend_analysis/util/hash.py                             32     21     10      0    26%   27-29, 37, 42-46, 52-60, 69-71\nsrc/trend_analysis/util/joblib_shim.py                      13      6      0      0    54%   19-22, 26-27\nsrc/trend_analysis/util/missing.py                         120     41     32      9    59%   62, 78, 80, 82, 89-95, 103-105, 112-114, 127-136, 193-194, 198-219\nsrc/trend_analysis/util/risk_free.py                        14     14      6      0     0%   3-36\nsrc/trend_analysis/util/rolling.py                          30     30     14      0     0%   3-74\nsrc/trend_analysis/viz/__init__.py                           2      2      0      0     0%   9-18\nsrc/trend_analysis/viz/charts.py                            66     66     12      0     0%   3-133\nsrc/trend_analysis/walk_forward.py                         265    265     78      0     0%   3-412\nsrc/trend_analysis/weighting.py                            112    112     36      0     0%   1-176\nsrc/trend_analysis/weights/__init__.py                       5      0      0      0   100%\nsrc/trend_analysis/weights/equal_risk_contribution.py       66     55     18      0    13%   20-21, 24-106\nsrc/trend_analysis/weights/hierarchical_risk_parity.py      83     70     20      0    13%   17-28, 36-124\nsrc/trend_analysis/weights/risk_parity.py                   28      8      8      4    67%   21, 23, 30-33, 40-44\nsrc/trend_analysis/weights/robust_config.py                 47     12     24     10    66%   11-12, 25, 35-37, 39, 41, 43, 48, 52, 57->60, 63, 74->91\nsrc/trend_analysis/weights/robust_weighting.py             182     94     56     12    44%   26-27, 43-71, 87-113, 128, 185-200, 205-208, 224, 237, 247-251, 257, 260, 275-276, 278->288, 283, 303->315, 318-321, 340-342, 346-412\n----------------------------------------------------------------------------------------------------\nTOTAL                                                    13782  10416   4896    405    21%\n======================== 23 passed, 1 warning in 3.81s =========================\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_161","type":"reasoning","text":"**Preparing targeted coverage run for stage modules**\n\nI'm planning to run the existing subset of pipeline-related tests with coverage enabled on the entire trend_analysis package to avoid numpy reload errors. This way, I can capture coverage for the stage modules and check if it surpasses the 80% target, even though the coverage includes the whole package. I'll parse the output for the stage modules specifically."}}
{"type":"item.started","item":{"id":"item_162","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_162","type":"command_execution","command":"/bin/bash -lc 'PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py'","aggregated_output":"============================= test session starts ==============================\nplatform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /home/runner/work/Trend_Model_Project/Trend_Model_Project\nconfigfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)\nplugins: cov-7.0.0\ncollected 174 items\n\ntests/test_pipeline.py .......................                           [ 13%]\ntests/test_pipeline_branch_coverage.py .........                         [ 18%]\ntests/test_pipeline_helpers.py ..........                                [ 24%]\ntests/test_pipeline_helpers_additional.py .............................. [ 41%]\n.......................                                                  [ 54%]\ntests/test_pipeline_run_analysis_helpers.py ..........                   [ 60%]\ntests/test_pipeline_optional_features.py .........................       [ 74%]\ntests/test_pipeline_run_cache_fallbacks.py .......................       [ 87%]\ntests/test_pipeline_indices.py ...                                       [ 89%]\ntests/test_pipeline_constraints_integration.py .....                     [ 92%]\ntests/test_pipeline_stage_isolation.py .                                 [ 93%]\ntests/test_score_frame.py .....                                          [ 95%]\ntests/test_run_analysis.py .......                                       [100%]\n\n=============================== warnings summary ===============================\ntests/conftest.py:76\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/tests/conftest.py:76: PytestUnknownMarkWarning: Unknown pytest.mark.xdist_group - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    it.add_marker(pytest.mark.xdist_group(\"serial\"))\n\ntests/test_pipeline_helpers_additional.py::test_resolve_sample_split_invalid_dates_raise\n  /home/runner/work/Trend_Model_Project/Trend_Model_Project/src/trend_analysis/pipeline_helpers.py:465: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n    date_series = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================================ tests coverage ================================\n_______________ coverage: platform linux, python 3.11.14-final-0 _______________\n\nName                                                     Stmts   Miss Branch BrPart  Cover   Missing\n----------------------------------------------------------------------------------------------------\nsrc/trend_analysis/__init__.py                              86     21     18      6    70%   27, 29-30, 41-55, 69, 86-87, 90->93, 135-137, 181->186, 186->208\nsrc/trend_analysis/_autofix_probe.py                         4      4      0      0     0%   7-18\nsrc/trend_analysis/_autofix_trigger_sample.py               13     13      0      0     0%   1-35\nsrc/trend_analysis/_autofix_violation_case2.py              19     19      4      0     0%   16-59\nsrc/trend_analysis/_autofix_violation_case3.py              15     15      0      0     0%   1-36\nsrc/trend_analysis/_ci_probe_faults.py                      15     15      0      0     0%   8-36\nsrc/trend_analysis/_typing.py                               10      0      0      0   100%\nsrc/trend_analysis/api.py                                  290    290     88      0     0%   1-696\nsrc/trend_analysis/api_server/__init__.py                   24     24      2      0     0%   7-87\nsrc/trend_analysis/api_server/__main__.py                    3      3      2      0     0%   3-7\nsrc/trend_analysis/automation_multifailure.py                4      4      0      0     0%   9-16\nsrc/trend_analysis/backtesting/__init__.py                   3      0      0      0   100%\nsrc/trend_analysis/backtesting/bootstrap.py                 63     53     24      0    11%   13-15, 19-32, 45-57, 88-131\nsrc/trend_analysis/backtesting/harness.py                  417    347    180      0    12%   40-50, 54-57, 61-64, 67-72, 75, 107, 135, 177-354, 375-382, 386-400, 408-432, 436-446, 450-453, 462-514, 518-534, 538-543, 547-550, 554-565, 569-587, 593-597, 604-609, 613-615, 621-627, 637-666, 678-681, 685-696, 700-704, 708\nsrc/trend_analysis/cash_policy.py                            8      0      0      0   100%\nsrc/trend_analysis/cli.py                                  400    400    122      0     0%   1-770\nsrc/trend_analysis/config/__init__.py                        3      0      0      0   100%\nsrc/trend_analysis/config/bridge.py                         38     38      6      0     0%   3-96\nsrc/trend_analysis/config/legacy.py                         49     49     10      0     0%   3-111\nsrc/trend_analysis/config/model.py                         390    206    154     23    38%   52->55, 59-76, 80, 85, 90, 105-118, 124-137, 143-161, 191, 193->195, 200-215, 220-225, 231, 235, 241, 244, 252, 261, 265, 268-269, 277-281, 288-295, 302-304, 323-333, 340-342, 373, 375-376, 383, 391-396, 406, 408, 416-418, 428, 434-442, 447-457, 462-470, 475-485, 505, 511-517, 522-528, 548-565, 576-587, 595-600\nsrc/trend_analysis/config/models.py                        442    221    188     29    43%   126-133, 137, 141, 152-158, 168, 171, 173, 218-219, 252, 261, 317, 319, 332, 341, 351, 354, 363, 365, 369-378, 384->388, 402-561, 569, 602-605, 609-610, 634-640, 651, 662-666, 679, 689, 695-707, 712-722, 730-772, 784, 792-799, 803-826, 830, 844, 846, 852-859, 862, 870, 872-874\nsrc/trend_analysis/constants.py                              6      0      0      0   100%\nsrc/trend_analysis/core/__init__.py                          0      0      0      0   100%\nsrc/trend_analysis/core/metric_cache.py                     49     26     10      1    41%   32-37, 41-42, 50-52, 64-68, 82, 105-115\nsrc/trend_analysis/core/rank_selection.py                  520    233    198     43    48%   57-66, 72-78, 89, 93-94, 104, 108-110, 122, 144-146, 151, 156, 171-173, 175-184, 228, 232-237, 240-243, 246-252, 255-260, 263, 291-295, 301-303, 309-321, 331-343, 389-390, 398, 408-409, 415, 421-424, 450-473, 514-525, 529, 539-545, 547->552, 553, 555, 558-562, 577-579, 583-586, 606, 623, 630-635, 639-640, 643-651, 661, 664, 677, 683->693, 686, 694-699, 705, 710, 714-733, 736, 780, 807, 876, 887, 890, 915, 938-939, 959-967, 975-983, 991-1006, 1031, 1043-1052, 1059, 1065, 1081-1084, 1099-1136, 1147-1150\nsrc/trend_analysis/data.py                                 325    172    150     27    40%   36-43, 49-55, 59-65, 69-81, 124, 127-128, 131, 138->145, 147, 156, 167, 225-226, 230->236, 232->236, 237->236, 239->236, 241, 248, 264-265, 277-286, 306-320, 322->328, 331-341, 347, 360-368, 378-382, 416, 418, 435, 438-441, 452->454, 464-481, 495-551, 563, 580, 592-621\nsrc/trend_analysis/diagnostics.py                           85     36     24      4    49%   24, 31-32, 35-36, 43, 47-48, 51-52, 55-56, 59-60, 112, 116, 130-162\nsrc/trend_analysis/engine/__init__.py                        2      0      0      0   100%\nsrc/trend_analysis/engine/optimizer.py                     158     76     68     15    47%   40->42, 43, 52, 57, 61-62, 72, 74, 78, 81, 110-138, 146-176, 187->190, 192, 213-217, 227-240, 245-247, 253-254\nsrc/trend_analysis/engine/walkforward.py                   161    130     62      0    14%   39-45, 51-68, 74-83, 89-96, 103-111, 115-141, 145-151, 192-298\nsrc/trend_analysis/export/__init__.py                     1070    984    436      0     6%   37-52, 58-59, 69-89, 97, 101, 104-107, 112-113, 116-121, 124, 127-131, 134-143, 150, 154, 159, 162-167, 180, 184, 191, 200-201, 204-208, 211, 214-218, 227-228, 231-237, 240-243, 246, 249-251, 254, 262-266, 271, 275-336, 340-407, 411-431, 443-683, 695-696, 709-710, 721-746, 758-995, 1000, 1005, 1022-1117, 1127-1132, 1146-1151, 1163-1167, 1196-1214, 1235-1237, 1242-1257, 1263-1421, 1429-1507, 1522-1581, 1587-1588, 1596-1604, 1612-1618, 1644-1664, 1672-1714, 1729-1802, 1819-1848, 1874-1955, 1965-1972\nsrc/trend_analysis/export/bundle.py                        180    165     50      0     7%   24-33, 48-414\nsrc/trend_analysis/gui/__init__.py                           5      5      0      0     0%   3-15\nsrc/trend_analysis/gui/app.py                              506    506    112      0     0%   1-937\nsrc/trend_analysis/gui/plugins.py                           15     15      4      0     0%   1-26\nsrc/trend_analysis/gui/store.py                             17     17      0      0     0%   1-27\nsrc/trend_analysis/gui/utils.py                             27     27      6      0     0%   1-44\nsrc/trend_analysis/io/__init__.py                            4      0      0      0   100%\nsrc/trend_analysis/io/market_data.py                       487    224    172     52    49%   76-112, 140-172, 191-194, 239, 241, 256, 259, 262, 273, 277-280, 286-287, 296-302, 312-314, 323-325, 338-341, 351, 385-415, 418, 444, 451-465, 471-474, 476, 478, 493, 506, 519, 531, 536-540, 542-546, 553-566, 572, 580-588, 596, 623, 626->630, 627->626, 631-635, 638->656, 641-650, 658-666, 668-673, 678-679, 683-691, 699-700, 709-716, 719-722, 746-757, 769, 773, 778, 786, 804-806, 814, 817, 822-826, 830-834, 838-840, 857, 861, 868-874, 924-939, 945-954\nsrc/trend_analysis/io/utils.py                              58     45     14      0    18%   19-26, 43-92, 101-108\nsrc/trend_analysis/io/validators.py                        164    142     56      0    10%   32-64, 80-86, 89-125, 142-156, 160-162, 175-180, 184-263, 269-286, 292-298\nsrc/trend_analysis/logging.py                               85     85     30      0     0%   1-249\nsrc/trend_analysis/logging_setup.py                         49     49     10      0     0%   3-101\nsrc/trend_analysis/metrics/__init__.py                     203     53     80     17    70%   46, 93, 101-103, 110, 127, 147-150, 169, 174, 186-208, 237, 239, 241, 266, 268, 270, 296-318, 331, 334, 363\nsrc/trend_analysis/metrics/attribution.py                   35     24     12      1    26%   65-78, 84, 90, 120-136\nsrc/trend_analysis/metrics/rolling.py                       31     26      8      0    13%   33-66\nsrc/trend_analysis/metrics/summary.py                       21     14      0      0    33%   36-61\nsrc/trend_analysis/metrics/turnover.py                      15      8      2      0    41%   25-27, 34-36, 52-53\nsrc/trend_analysis/multi_period/__init__.py                  2      2      0      0     0%   3-5\nsrc/trend_analysis/multi_period/engine.py                 1917   1917    894      0     0%   18-3920\nsrc/trend_analysis/multi_period/loaders.py                 117    117     54      0     0%   3-217\nsrc/trend_analysis/multi_period/replacer.py                116    116     48      0     0%   12-236\nsrc/trend_analysis/multi_period/scheduler.py                58     58     20      0     0%   7-140\nsrc/trend_analysis/perf/cache.py                           117     68     26      3    36%   36-38, 53, 74-80, 84-91, 94-99, 104-128, 131-132, 140, 171, 180-183, 189-190, 203-214, 238-255\nsrc/trend_analysis/perf/rolling_cache.py                   104     30     18      5    66%   24-25, 31-32, 39-45, 74-78, 94, 102-104, 107, 110, 133-143, 163-176, 191\nsrc/trend_analysis/perf/timing.py                           30     18     10      1    32%   37-42, 59-73\nsrc/trend_analysis/pipeline.py                             129     11     18      3    86%   195, 197, 248-256\nsrc/trend_analysis/pipeline_entrypoints.py                 127      4     38      5    93%   80->82, 128->134, 135->137, 152, 256-263\nsrc/trend_analysis/pipeline_helpers.py                     357     45    162     21    84%   76, 79, 82-83, 85, 105-111, 118, 122, 126, 134, 137, 158-163, 166->169, 174-175, 176->179, 182-183, 184->188, 189-197, 222-223, 225, 230, 335-337, 558, 560, 583\nsrc/trend_analysis/pipeline_runner.py                       30      0      6      0   100%\nsrc/trend_analysis/plugins/__init__.py                      41      4      0      0    90%   54, 70, 129, 134\nsrc/trend_analysis/portfolio/__init__.py                     2      0      0      0   100%\nsrc/trend_analysis/portfolio/weight_policy.py               53     15     24      7    69%   20, 73, 87-92, 95, 103-108, 111, 115-116\nsrc/trend_analysis/presets.py                              231    231     86      0     0%   3-433\nsrc/trend_analysis/proxy/__init__.py                         2      2      0      0     0%   9-11\nsrc/trend_analysis/proxy/__main__.py                         3      3      2      0     0%   3-6\nsrc/trend_analysis/proxy/cli.py                             30     30      4      0     0%   3-76\nsrc/trend_analysis/proxy/server.py                          95     95     14      0     0%   10-282\nsrc/trend_analysis/rebalancing.py                            8      8      0      0     0%   9-46\nsrc/trend_analysis/rebalancing/__init__.py                   2      2      0      0     0%   1-14\nsrc/trend_analysis/rebalancing/strategies.py               185    185     42      0     0%   10-447\nsrc/trend_analysis/regimes.py                              285     58    130     33    73%   46, 95, 97, 99, 124, 127, 146-153, 159-170, 183, 187, 208-209, 212-219, 237, 240, 249-251, 254, 270, 278, 281, 295, 310, 315, 323, 328, 349, 352, 389, 397, 426, 486-489, 505-508, 514-515, 531, 538->551, 541->551, 559->558\nsrc/trend_analysis/reporting/__init__.py                    14     14      0      0     0%   3-34\nsrc/trend_analysis/reporting/run_artifacts.py              135    135     48      0     0%   3-286\nsrc/trend_analysis/risk.py                                 174     54     58     17    63%   55, 63, 81, 89, 94-106, 128, 132, 154-168, 181-190, 204, 206, 213, 225-234, 259, 263, 271-272, 273->277, 324\nsrc/trend_analysis/run_analysis.py                          62     62     24      0     0%   1-134\nsrc/trend_analysis/run_multi_analysis.py                    36     36      0      0     0%   1-80\nsrc/trend_analysis/schedules.py                            103    103     44      0     0%   1-213\nsrc/trend_analysis/script_logging.py                        27     27      6      0     0%   3-60\nsrc/trend_analysis/selector.py                              39     39      4      0     0%   1-66\nsrc/trend_analysis/signal_presets.py                        42     42     10      0     0%   3-137\nsrc/trend_analysis/signals.py                              132     39     36     13    65%   35, 38, 43, 45, 66, 89, 101-106, 123, 125, 127, 129, 143-146, 152-158, 165, 178-188, 192-195\nsrc/trend_analysis/stages/__init__.py                        4      0      0      0   100%\nsrc/trend_analysis/stages/portfolio.py                     318     28     70     13    89%   52-65, 203, 231, 239-245, 264-265, 268, 325->329, 329->333, 333->335, 348, 392-393, 395, 427, 550->555, 576->578, 578->581\nsrc/trend_analysis/stages/preprocessing.py                 218     15     72     13    90%   37->39, 125, 154, 182, 186, 189, 262, 283, 295, 328, 349, 368-372, 469->473\nsrc/trend_analysis/stages/selection.py                     222     30     96     25    81%   74-75, 87, 93, 104, 108->123, 117->121, 127, 139, 145, 149, 161, 166, 184, 198, 203, 215-233, 242, 389, 409->414, 426, 435, 454, 482->489, 489->491, 501\nsrc/trend_analysis/time_utils.py                           146     15     56     13    86%   18, 80, 82, 84, 87, 97-98, 123, 125-135, 141, 170, 182->184, 201, 204\nsrc/trend_analysis/timefreq.py                              34     21     10      0    30%   47, 57, 69-70, 85-105\nsrc/trend_analysis/typing.py                                15     15      0      0     0%   3-34\nsrc/trend_analysis/ui/__init__.py                            0      0      0      0   100%\nsrc/trend_analysis/ui/rank_widgets.py                        9      9      0      0     0%   1-12\nsrc/trend_analysis/universe.py                             187    165     84      0     8%   24-27, 34-39, 45-81, 89-109, 113-135, 141-189, 198-226, 234-259, 288-310\nsrc/trend_analysis/universe_catalog.py                     101    101     40      0     0%   1-175\nsrc/trend_analysis/util/__init__.py                          0      0      0      0   100%\nsrc/trend_analysis/util/frequency.py                        84     19     26      8    70%   44, 47-53, 62, 64, 67-71, 81, 102, 105, 142\nsrc/trend_analysis/util/hash.py                             32     21     10      0    26%   27-29, 37, 42-46, 52-60, 69-71\nsrc/trend_analysis/util/joblib_shim.py                      13      4      0      0    69%   19-22\nsrc/trend_analysis/util/missing.py                         120      9     32      7    89%   78, 80, 82, 94, 127-136, 207-208, 219\nsrc/trend_analysis/util/risk_free.py                        14     14      6      0     0%   3-36\nsrc/trend_analysis/util/rolling.py                          30     30     14      0     0%   3-74\nsrc/trend_analysis/viz/__init__.py                           2      2      0      0     0%   9-18\nsrc/trend_analysis/viz/charts.py                            66     66     12      0     0%   3-133\nsrc/trend_analysis/walk_forward.py                         265    265     78      0     0%   3-412\nsrc/trend_analysis/weighting.py                            112    112     36      0     0%   1-176\nsrc/trend_analysis/weights/__init__.py                       5      0      0      0   100%\nsrc/trend_analysis/weights/equal_risk_contribution.py       66     55     18      0    13%   20-21, 24-106\nsrc/trend_analysis/weights/hierarchical_risk_parity.py      83     70     20      0    13%   17-28, 36-124\nsrc/trend_analysis/weights/risk_parity.py                   28      8      8      4    67%   21, 23, 30-33, 40-44\nsrc/trend_analysis/weights/robust_config.py                 47     12     24     10    66%   11-12, 25, 35-37, 39, 41, 43, 48, 52, 57->60, 63, 74->91\nsrc/trend_analysis/weights/robust_weighting.py             182     94     56     12    44%   26-27, 43-71, 87-113, 128, 185-200, 205-208, 224, 237, 247-251, 257, 260, 275-276, 278->288, 283, 303->315, 318-321, 340-342, 346-412\n----------------------------------------------------------------------------------------------------\nTOTAL                                                    13782   9534   4896    431    28%\n======================= 174 passed, 2 warnings in 12.96s =======================\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_163","type":"reasoning","text":"**Summarizing test coverage results**\n\nI'll report that stage modules now have over 80% coverage and note the targeted test subset used. I'll also mention the full suite timed out at 58%, and update the plan steps as completed accordingly."}}
{"type":"item.updated","item":{"id":"item_7","type":"todo_list","items":[{"text":"Inspect pipeline.py to identify preprocessing/selection/portfolio logic boundaries and dependent helpers","completed":true},{"text":"Create stages package and move preprocessing/selection/portfolio logic into new modules with tests","completed":true},{"text":"Refactor pipeline.py to orchestrate via stages, preserve public API, and add integration test + coverage checks","completed":true}]}}
{"type":"item.completed","item":{"id":"item_164","type":"reasoning","text":"**Verifying pipeline line count**"}}
{"type":"item.started","item":{"id":"item_165","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_165","type":"command_execution","command":"/bin/bash -lc 'wc -l src/trend_analysis/pipeline.py'","aggregated_output":"379 src/trend_analysis/pipeline.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_166","type":"reasoning","text":"**Checking git status**"}}
{"type":"item.started","item":{"id":"item_167","type":"command_execution","command":"/bin/bash -lc 'git status -sb'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_167","type":"command_execution","command":"/bin/bash -lc 'git status -sb'","aggregated_output":"## codex/issue-4145...origin/codex/issue-4145\n M .workflows-lib\n M src/trend_analysis/pipeline.py\n?? codex-session-4154.jsonl\n?? src/trend_analysis/pipeline_entrypoints.py\n?? src/trend_analysis/pipeline_helpers.py\n?? src/trend_analysis/pipeline_runner.py\n?? src/trend_analysis/stages/\n?? tests/test_pipeline_stage_isolation.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_168","type":"reasoning","text":"**Summarizing changes, tests, and coverage**\n\nI'm preparing a detailed summary highlighting the refactor splitting the pipeline into stage modules under `src/trend_analysis/stages/` with specific files listed, preserving APIs, and adding integration tests. I'll include testing commands with targeted runs using `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1` due to plugin socket issues, coverage percentages for preprocessing (90%), selection (81%), and portfolio (89%), and mention that full suite runs timed out at 240 seconds. I'll also note next steps, test environment constraints, and clarify that no commits were made per the user's request."}}
{"type":"item.completed","item":{"id":"item_169","type":"agent_message","text":"Split the pipeline into stage modules and moved the heavy lifting out of `src/trend_analysis/pipeline.py`, keeping it as a thin orchestrator while preserving internal/public APIs and monkeypatch behavior. Added a stage isolation integration test and wiring helpers so stage logic can be exercised directly without changing outputs.\n\nDetails:\n- Extracted preprocessing, selection, and portfolio logic into `src/trend_analysis/stages/preprocessing.py`, `src/trend_analysis/stages/selection.py`, and `src/trend_analysis/stages/portfolio.py`, with shared exports in `src/trend_analysis/stages/__init__.py`.\n- Moved orchestration/config helpers into `src/trend_analysis/pipeline_helpers.py`, `_run_analysis*` orchestration into `src/trend_analysis/pipeline_runner.py`, and config entrypoints into `src/trend_analysis/pipeline_entrypoints.py`, keeping `src/trend_analysis/pipeline.py` under 500 lines and backward compatible.\n- Added `tests/test_pipeline_stage_isolation.py` to verify manual stage execution matches `pipeline.run_analysis` output.\n\nTests (using `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1` and `MPLCONFIGDIR=/tmp/matplotlib` to avoid rerunfailures socket issues):\n- `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis --cov-report=term-missing -m \"not slow\" -x tests/test_pipeline.py tests/test_pipeline_branch_coverage.py tests/test_pipeline_helpers.py tests/test_pipeline_helpers_additional.py tests/test_pipeline_run_analysis_helpers.py tests/test_pipeline_optional_features.py tests/test_pipeline_run_cache_fallbacks.py tests/test_pipeline_indices.py tests/test_pipeline_constraints_integration.py tests/test_pipeline_stage_isolation.py tests/test_score_frame.py tests/test_run_analysis.py`\n  - Stage coverage from this run: `trend_analysis/stages/preprocessing.py` 90%, `trend_analysis/stages/selection.py` 81%, `trend_analysis/stages/portfolio.py` 89%.\n- Attempted full suite coverage run with `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 MPLCONFIGDIR=/tmp/matplotlib pytest -p pytest_cov --cov=trend_analysis.stages.pre... --cov-report=term-missing -m \"not slow\" -x tests/` but it timed out at ~240s (about 58% progress).\n\nNext steps:\n1) If you want full-suite coverage, rerun with a longer timeout or in an environment that allows the rerunfailures plugin.  \n2) If you want the full suite without coverage, I can run `pytest -m \"not slow\" tests/` with the same plugin settings."}}
{"type":"item.completed","item":{"id":"item_7","type":"todo_list","items":[{"text":"Inspect pipeline.py to identify preprocessing/selection/portfolio logic boundaries and dependent helpers","completed":true},{"text":"Create stages package and move preprocessing/selection/portfolio logic into new modules with tests","completed":true},{"text":"Refactor pipeline.py to orchestrate via stages, preserve public API, and add integration test + coverage checks","completed":true}]}}
{"type":"turn.completed","usage":{"input_tokens":9317300,"cached_input_tokens":9132288,"output_tokens":91219}}
