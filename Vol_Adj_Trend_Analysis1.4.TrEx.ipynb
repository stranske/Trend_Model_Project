{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22994893-0193-45bc-b9e3-a97b328ecaea",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Imports, Data Loader and Rf Detector\n",
    "2. Select fund (month period logic)\n",
    "3. Weight prep\n",
    "4. Core Stats + Run Analysis\n",
    "5. Export\n",
    "6. Widget /UI\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Legacy helper and metric functions replaced by modules\n",
    "# See trend_analysis.metrics and run_analysis.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74bd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import inspect\n",
    "from collections import namedtuple\n",
    "from typing import Dict, Optional, Callable\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display, clear_output\n",
    "from trend_analysis.data import load_csv, identify_risk_free_fund\n",
    "from trend_analysis.core.rank_selection import (\n",
    "    FundSelectionConfig,\n",
    "    RiskStatsConfig,\n",
    "    select_funds,\n",
    "    register_metric,\n",
    "    METRIC_REGISTRY,\n",
    ")\n",
    "from trend_analysis.export import make_summary_formatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {},
   "source": [
    "## 2. Select Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 2 · SELECT_FUNDS  (restored ≤ 3-missing-months rule)\n",
    "# ===============================================================\n",
    "\n",
    "cfg = FundSelectionConfig(\n",
    "    max_missing_months           = 3,\n",
    "    max_consecutive_month_gap    = 6,\n",
    "    outlier_threshold            = 0.5,\n",
    "    zero_return_threshold        = 0.2,\n",
    "    enforce_monotonic_index      = True,\n",
    "    allow_duplicate_dates        = False,\n",
    "    max_missing_ratio            = 0.05,\n",
    "    max_drawdown                 = 0.3,\n",
    "    min_volatility               = 0.05,\n",
    "    max_volatility               = 1.0,\n",
    "    min_avg_return               = 0.0,\n",
    "    max_skewness                 = 3.0,\n",
    "    max_kurtosis                 = 10.0,\n",
    "    expected_freq                = \"B\",\n",
    "    max_gap_days                 = 3,\n",
    "    min_aum_usd                  = 1e7,\n",
    ")\n",
    "\n",
    "def select_funds(\n",
    "    df: pd.DataFrame,\n",
    "    rf_col: str,\n",
    "    fund_columns: list[str],\n",
    "    in_sdate: str,\n",
    "    in_edate: str,\n",
    "    out_sdate: str,\n",
    "    out_edate: str,\n",
    "    cfg: FundSelectionConfig,\n",
    "    selection_mode: str = \"all\",\n",
    "    random_n: int | None = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Select eligible funds with additional data-validity and coverage checks driven by FundSelectionConfig.\n",
    "    \"\"\"\n",
    "    # Ensure Date is sorted\n",
    "    df = df.sort_values(\"Date\")  # guarantee monotonic index\n",
    "\n",
    "    # Prepare monthly periods within analysis window\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    span = pd.period_range(\n",
    "        pd.Period(in_sdate, \"M\"), pd.Period(out_edate, \"M\"), freq=\"M\"\n",
    "    )\n",
    "\n",
    "    eligible_funds: list[str] = []\n",
    "    for f in fund_columns:\n",
    "        try:\n",
    "            ser = df.set_index(\"Date\")[f]\n",
    "            clean = ser.dropna()\n",
    "\n",
    "            # 1. Implausible value limits\n",
    "            if not clean.between(-cfg.implausible_value_limit, cfg.implausible_value_limit).all():\n",
    "                raise ValueError(f\"Values outside ±{cfg.implausible_value_limit}\")\n",
    "\n",
    "            # 2. Extreme outlier threshold\n",
    "            if (clean.abs() > cfg.outlier_threshold).any():\n",
    "                raise ValueError(f\"Outliers beyond ±{cfg.outlier_threshold}\")\n",
    "\n",
    "            # 3. Excessive zero-return rate\n",
    "            if (clean == 0).mean() > cfg.zero_return_threshold:\n",
    "                raise ValueError(f\"Zero-return proportion > {cfg.zero_return_threshold}\")\n",
    "\n",
    "            # 4. Monotonic date index\n",
    "            if cfg.enforce_monotonic_index and not clean.index.is_monotonic_increasing:\n",
    "                raise ValueError(\"Date index not monotonically increasing\")\n",
    "\n",
    "            # 5. Duplicate dates\n",
    "            if not cfg.allow_duplicate_dates and clean.index.duplicated().any():\n",
    "                raise ValueError(\"Duplicate dates detected in index\")\n",
    "\n",
    "            # 6. Coverage checks using config thresholds\n",
    "            m_ok = df.groupby(\"Month\")[f].apply(lambda col: col.notna().any())\n",
    "            mask = m_ok.reindex(span, fill_value=False).to_numpy()\n",
    "\n",
    "            # tolerance for missing months per-cfg\n",
    "            missing_count = (~mask).sum()\n",
    "            if missing_count > cfg.max_missing_months:\n",
    "                raise ValueError(f\"Missing-month count {missing_count} exceeds {cfg.max_missing_months}\")\n",
    "\n",
    "            # maximum run of consecutive missing months per-cfg with guard\n",
    "            temp = np.flatnonzero(np.r_[True, mask, True])\n",
    "            if temp.size <= 1:\n",
    "                gap = 0\n",
    "            else:\n",
    "                gap = np.diff(temp).max() - 1\n",
    "            if gap > cfg.max_consecutive_month_gap:\n",
    "                raise ValueError(f\"Consecutive-missing gap {gap} exceeds {cfg.max_consecutive_month_gap}\")\n",
    "\n",
    "            eligible_funds.append(f)\n",
    "\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Final selection-mode logic\n",
    "    if selection_mode == \"all\" or random_n is None:\n",
    "        return eligible_funds\n",
    "    if selection_mode == \"random\":\n",
    "        if random_n > len(eligible_funds):\n",
    "            raise ValueError(\n",
    "                f\"random_n exceeds eligible pool: {random_n} > {len(eligible_funds)}\"\n",
    "            )\n",
    "        return list(np.random.choice(eligible_funds, random_n, replace=False))\n",
    "\n",
    "    raise ValueError(f\"Unsupported selection_mode '{selection_mode}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 3. Weight Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  3 · WEIGHT PREP\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "def prepare_weights(selected: list[str],\n",
    "                    custom: Dict[str, int] | None) -> tuple[Dict[str, float], np.ndarray]:\n",
    "    if not custom:\n",
    "        w = {f: 1/len(selected) for f in selected}\n",
    "    else:\n",
    "        missing = [f for f in selected if f not in custom]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing weights for {missing}\")\n",
    "        w = {f: pct/100 for f, pct in custom.items()}\n",
    "        if abs(sum(w.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"Custom weights must sum to 100.\")\n",
    "    vec = np.array([w[f] for f in selected])\n",
    "    return w, vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 4. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Function definitions\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 4 · CORE STATS  +  RUN_ANALYSIS  (helpers included, weight fix)\n",
    "# ===============================================================\n",
    "\n",
    "M_PER_YEAR = 12           # constant used across helpers\n",
    "\n",
    "# ---------- helpers --------------------------------------------\n",
    "def _ensure_dt(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy whose Date column is datetime64[ns].\"\"\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3. Metric function definitions\n",
    "# === Metric Function Definitions with flexible annualization ===\n",
    "@register_metric(\"AnnualReturn\")\n",
    "def compute_annual_return(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Geometric annualized return based on periods_per_year.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    total_growth = (1 + r).prod()\n",
    "    n_periods = len(r)\n",
    "    return total_growth ** (periods_per_year / n_periods) - 1\n",
    "\n",
    "@register_metric(\"Volatility\")\n",
    "def compute_volatility(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Annualized standard deviation of returns with flexible scaling.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    return r.std(ddof=0) * np.sqrt(periods_per_year)\n",
    "\n",
    "@register_metric(\"Sharpe\")\n",
    "def compute_sharpe(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sharpe ratio using flexible annualized return and volatility.\n",
    "    \"\"\"\n",
    "    vol = compute_volatility(returns, periods_per_year=periods_per_year)\n",
    "    if vol == 0:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    return (ann_ret - risk_free) / vol\n",
    "\n",
    "@register_metric(\"Sortino\")\n",
    "def compute_sortino(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sortino ratio using flexible annualized return and downside deviation.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    # Define per-period risk-free rate\n",
    "    period_rf = risk_free / periods_per_year\n",
    "    excess = r - period_rf\n",
    "    downside = excess[excess < 0]\n",
    "    if downside.empty:\n",
    "        return np.nan\n",
    "    down_dev = np.sqrt((downside ** 2).mean()) * np.sqrt(periods_per_year)\n",
    "    if down_dev == 0:\n",
    "        return np.nan\n",
    "    return (ann_ret - risk_free) / down_dev\n",
    "\n",
    "@register_metric(\"MaxDrawdown\")\n",
    "def compute_max_drawdown(\n",
    "    returns: pd.Series,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Maximum drawdown (peak-to-trough) of cumulative returns.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    cum = (1 + r).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdown = (cum / peak) - 1\n",
    "    return float(drawdown.min())\n",
    "\n",
    "# Alias for backward compatibility\n",
    "_ann_vol = compute_volatility\n",
    "\n",
    "# === Aggregator with Centralized Error Handling ===\n",
    "\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    \"\"\"\n",
    "    Run each metric in cfg.metrics_to_run, returning a namedtuple of values.\n",
    "    Uses cfg.periods_per_year for annualization.\n",
    "    Centralized try/except ensures one failing metric doesn’t break the batch.\n",
    "    \"\"\"\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not registered\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            params = {\n",
    "                \"risk_free\": cfg.risk_free,\n",
    "                \"periods_per_year\": cfg.periods_per_year,\n",
    "                **metric_kwargs\n",
    "            }\n",
    "            valid = {k: v for k, v in params.items() if k in inspect.signature(fn).parameters}\n",
    "            val = fn(returns, **valid)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"%s: division by zero, setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"%s: invalid input (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"%s: unexpected error (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "    return Stat(*values)\n",
    "\n",
    "# ---------- main ------------------------------------------------\n",
    "def run_analysis(\n",
    "    df,\n",
    "    selected,\n",
    "    w_vec,\n",
    "    w_dict,\n",
    "    rf_col,\n",
    "    in_start,\n",
    "    in_end,\n",
    "    out_start,\n",
    "    out_end,\n",
    "    target_vol,\n",
    "    monthly_cost,\n",
    "    indices_list\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorised run_analysis with correct weight re-normalisation\n",
    "    after funds are dropped.\n",
    "    Returns the same keys used by the UI and export functions.\n",
    "    \"\"\"\n",
    "    df = _ensure_dt(df)\n",
    "\n",
    "    # ---- date masks --------------------------------------------------\n",
    "    in_s = pd.to_datetime(in_start)  + pd.offsets.MonthEnd(0)\n",
    "    in_e = pd.to_datetime(in_end)    + pd.offsets.MonthEnd(0)\n",
    "    out_s= pd.to_datetime(out_start) + pd.offsets.MonthEnd(0)\n",
    "    out_e= pd.to_datetime(out_end)   + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    m_in  = df[\"Date\"].between(in_s,  in_e)\n",
    "    m_out = df[\"Date\"].between(out_s, out_e)\n",
    "\n",
    "    in_df,  out_df  = df.loc[m_in,  selected], df.loc[m_out, selected]\n",
    "    in_rf,  out_rf  = df.loc[m_in,  rf_col],   df.loc[m_out, rf_col]\n",
    "\n",
    "    # ---- drop funds with any NaNs in either window ------------------\n",
    "    good = [f for f in selected\n",
    "            if in_df[f].notna().all() and out_df[f].notna().all()]\n",
    "    dropped = list(set(selected) - set(good))\n",
    "    if dropped:\n",
    "        logging.warning(\"Dropped funds: %s\", dropped)\n",
    "\n",
    "    selected = good\n",
    "    # >>>> new guard: kick out any accidental index columns\n",
    "    selected = [f for f in selected if f not in (indices_list or [])]\n",
    "    # <<<<\n",
    "\n",
    "    in_df, out_df = in_df[selected], out_df[selected]\n",
    "\n",
    "    # rebuild weights\n",
    "    if w_dict is None:                      # equal-weight path\n",
    "        w_dict = {f: 1/len(selected) for f in selected}\n",
    "    else:                                   # manual path → rescale\n",
    "        pct   = {f: w_dict[f]*100 for f in selected}\n",
    "        total = sum(pct.values())\n",
    "        w_dict = {f: p/total for f, p in pct.items()}\n",
    "    w_vec = np.array([w_dict[f] for f in selected])\n",
    "\n",
    "    # ---- scaling ----------------------------------------------------\n",
    "    vols = in_df.apply(compute_volatility)\n",
    "    scale = np.where(vols > 0, target_vol / vols, 1.0)\n",
    "    in_sc  = (in_df * scale) - monthly_cost\n",
    "    out_sc = (out_df * scale) - monthly_cost\n",
    "    in_sc.clip(lower=-1, inplace=True)\n",
    "    out_sc.clip(lower=-1, inplace=True)\n",
    "\n",
    "    # ---- stats ------------------------------------------------------\n",
    "    rf_value = in_rf.mean() if hasattr(in_rf, \"mean\") else float(in_rf)\n",
    "\n",
    "    # Create a RiskStatsConfig for in-sample stats\n",
    "    stats_cfg = RiskStatsConfig(risk_free=rf_value)\n",
    "\n",
    "    # Now compute stats for each scenario, always passing stats_cfg first\n",
    "    in_stat = {\n",
    "        f: _stats(in_sc[f], stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "    out_rf_value = out_rf.mean() if hasattr(out_rf, \"mean\") else float(out_rf)\n",
    "\n",
    "    # Re‐use the same config, updating only the risk_free field\n",
    "    stats_cfg.risk_free = out_rf_value\n",
    "\n",
    "    out_stat = {\n",
    "        f: _stats(out_sc[f], stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "\n",
    "    ew_vec = np.full(len(selected), 1/len(selected))\n",
    "\n",
    "    in_ew_stats  = _stats(in_sc.dot(ew_vec),  stats_cfg)\n",
    "    out_ew_stats = _stats(out_sc.dot(ew_vec), stats_cfg)\n",
    "    in_user_stats  = _stats(in_sc.dot(w_vec),  stats_cfg)\n",
    "    out_user_stats = _stats(out_sc.dot(w_vec), stats_cfg)\n",
    "\n",
    "    results = {\n",
    "        \"selected_funds\": selected,\n",
    "        \"indices_list\":   indices_list or [],\n",
    "        \"fund_weights\":   w_dict,\n",
    "        \"ew_weights\":     {f: 1/len(selected) for f in selected},\n",
    "        \"in_sample_stats\":  in_stat,\n",
    "        \"out_sample_stats\": out_stat,\n",
    "        \"in_ew_stats\":     in_ew_stats,\n",
    "        \"out_ew_stats\":    out_ew_stats,\n",
    "        \"in_user_stats\":   in_user_stats,\n",
    "        \"out_user_stats\":  out_user_stats,\n",
    "        \"dropped\":         dropped,\n",
    "    }\n",
    "\n",
    "    # ---- optional index stats ---------------------------------------\n",
    "    if indices_list:\n",
    "        idx_stats = {}\n",
    "        for col in indices_list:\n",
    "            idx_stats[col] = {\n",
    "                \"in_sample\":  _stats(df.loc[m_in,  col], stats_cfg),\n",
    "                \"out_sample\": _stats(df.loc[m_out, col], stats_cfg),\n",
    "            }\n",
    "        results[\"index_stats\"] = idx_stats\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 5. Excel Export\n",
    "Creates an Excel file with In-Sample, Out-of-Sample and Equal-weight and User-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  5 · EXPORT  (NaN-safe, weight-format fix)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# ───────── 5 · EXPORT  (final, bug-free) ───────────────────────\n",
    "# ───────── 5 · EXPORT  (self-healing index section) ───────────\n",
    "# ───────── 5 · EXPORT  (final safe version) ───────────────────\n",
    "\n",
    "def export_to_excel(\n",
    "    data: dict[str, pd.DataFrame],\n",
    "    output_path: str,\n",
    "    default_format: Optional[Callable] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Exports each DataFrame in `data` to its own sheet in `output_path`.\n",
    "    Applies a registered formatter for each category (sheet name).\n",
    "    If no formatter is found, applies `default_format` if provided.\n",
    "\n",
    "    For the Summary sheet, data is written starting at row 5 to make room for custom headers.\n",
    "    \"\"\"\n",
    "    startrows = {\"summary\": 5}\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        for category, df in data.items():\n",
    "            startrow = startrows.get(category, 0)\n",
    "            df.to_excel(writer, sheet_name=category, index=False, startrow=startrow, header=True)\n",
    "            fn = FORMATTERS_EXCEL.get(category, default_format)\n",
    "            if fn: fn(writer.sheets[category], writer.book)\n",
    "    # Workbook is auto-saved and closed by the context manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 6. Run Parameters, Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc. Also lets us use custom weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e0d59-d17a-41c8-b991-1d91d29a22d1",
   "metadata": {
    "outputId": "795bb6da-96a0-42e2-c760-7d516fd82610"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f61f0b0de1d45a4a880943a6f31decc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>1. Load data</h4>'), ToggleButtons(description='Source:', options=(('Local', 'l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#            STREAMLINED ANALYSIS UI  (phase-2 clean)\n",
    "# ===============================================================\n",
    "\n",
    "# ---------- session store ----------\n",
    "session = {\"df\": None, \"rf\": None, \"sel\": None, \"cweights\": None}\n",
    "\n",
    "# ---------- 1 · DATA LOAD ----------\n",
    "src = widgets.ToggleButtons(\n",
    "    options=[(\"Local\", \"local\"), (\"URL\", \"url\")],\n",
    "    description=\"Source:\"\n",
    ")\n",
    "\n",
    "chooser = FileChooser()\n",
    "url_box = widgets.Text(placeholder=\"https://…/file.csv\", layout={\"width\":\"70%\"})\n",
    "load_btn = widgets.Button(description=\"Load CSV\", button_style=\"success\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "def _toggle_src(c):\n",
    "    chooser.layout.display = \"block\" if c[\"new\"]==\"local\" else \"none\"\n",
    "    url_box.layout.display  = \"block\" if c[\"new\"]==\"url\"   else \"none\"\n",
    "src.observe(_toggle_src, names=\"value\"); _toggle_src({\"new\":src.value})\n",
    "\n",
    "def _load(_):\n",
    "    with load_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            path = chooser.selected if src.value==\"local\" else url_box.value.strip()\n",
    "            if not path: raise ValueError(\"choose file / URL\")\n",
    "            if src.value==\"url\" and not path.lower().endswith(\".csv\"):\n",
    "                raise ValueError(\"URL must end with .csv\")\n",
    "            df = load_csv(path)\n",
    "            if df is None:\n",
    "                print(f'❌ Failed to load data from {path}')\n",
    "                session[\"df\"] = None\n",
    "                return\n",
    "            rf = identify_risk_free_fund(df)\n",
    "            session.update(df=df, rf=rf, sel=None, cweights=None)\n",
    "            print(f\"✅ Loaded {len(df):,} rows × {df.shape[1]} cols | RF → {rf}\")\n",
    "        except Exception as e:\n",
    "            print(\"❌\", e); session[\"df\"]=None\n",
    "load_btn.on_click(_load)\n",
    "\n",
    "# ---------- 2 · PARAMS ------------\n",
    "index_cnt = widgets.BoundedIntText(0, min=0, max=10, description=\"# Indices:\")\n",
    "in_start,in_end  = widgets.Text(\"2005-07\"), widgets.Text(\"2008-06\")\n",
    "out_start,out_end= widgets.Text(\"2008-07\"), widgets.Text(\"2009-06\")\n",
    "for w,lbl in [(in_start,\"In Start:\"),(in_end,\"In End:\"),\n",
    "              (out_start,\"Out Start:\"),(out_end,\"Out End:\")]:\n",
    "    w.description = lbl\n",
    "target_vol   = widgets.FloatText(0.25,  description=\"Target Vol:\")\n",
    "monthly_cost = widgets.FloatText(0.0033, description=\"Monthly Cost:\")\n",
    "\n",
    "# ---------- 3 · SELECTION ----------\n",
    "mode_dd = widgets.Dropdown(\n",
    "    options=[(\"All\", \"all\"), (\"Random\", \"random\"), (\"Manual\", \"manual\")],\n",
    "    value=\"all\",\n",
    "    description=\"Mode:\"\n",
    ")\n",
    "rand_n   = widgets.BoundedIntText(5, min=2, max=100, description=\"Sample N:\")\n",
    "fund_table, total_lbl = widgets.VBox([]), widgets.Label(\"Total = 0 %\")\n",
    "\n",
    "def _toggle_sel(_=None):\n",
    "    rand_n.layout.display  = \"block\" if mode_dd.value==\"random\" else \"none\"\n",
    "    vis = \"block\" if mode_dd.value==\"manual\" else \"none\"\n",
    "    fund_table.layout.display = total_lbl.layout.display = vis\n",
    "mode_dd.observe(_toggle_sel, names=\"value\"); _toggle_sel()\n",
    "\n",
    "# ---------- helpers ---------------\n",
    "def _eligible_pool():\n",
    "    df, rf = session[\"df\"], session[\"rf\"]\n",
    "    if df is None:\n",
    "        print(\"⚠️ data not loaded\"); return []\n",
    "\n",
    "    # ---- date parse guard -----------------------------------\n",
    "    try:\n",
    "        in_s  = pd.to_datetime(in_start.value)+pd.offsets.MonthEnd(0)\n",
    "        in_e  = pd.to_datetime(in_end.value)  +pd.offsets.MonthEnd(0)\n",
    "        out_s = pd.to_datetime(out_start.value)+pd.offsets.MonthEnd(0)\n",
    "        out_e = pd.to_datetime(out_end.value)  +pd.offsets.MonthEnd(0)\n",
    "    except Exception:\n",
    "        print(\"❌ invalid dates\"); return []\n",
    "\n",
    "    # ---- build indices (RIGHT-most idx_n non-RF columns) ----\n",
    "    idx_n     = index_cnt.value\n",
    "    data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "    non_rf    = [c for c in data_cols if c != rf]\n",
    "    indices   = non_rf[-idx_n:] if idx_n else []          # <- fixed\n",
    "    cand      = [c for c in data_cols if c not in indices]\n",
    "\n",
    "    # ---- run select_funds ----------------------------------\n",
    "    elig = select_funds(\n",
    "        df=df,\n",
    "        rf_col=rf,\n",
    "        fund_columns=cand,\n",
    "        in_sdate=in_s,\n",
    "        in_edate=in_e,\n",
    "        out_sdate=out_s,\n",
    "        out_edate=out_e,\n",
    "        cfg=cfg,                   \n",
    "        selection_mode=\"all\",\n",
    "    )\n",
    "    # … diagnostics print unchanged …\n",
    "    return elig\n",
    "\n",
    "def _build_manual(*_):\n",
    "    if mode_dd.value!=\"manual\" or session[\"df\"] is None: return\n",
    "    valid = _eligible_pool()\n",
    "    print(\"DEBUG  eligible funds =\", len(valid))              # ← line 1\n",
    "    print(\"DEBUG  list sample   →\", valid[:25], \"…\")           # ← line 2\n",
    "    if not valid:\n",
    "        print(\"❌ No eligible funds\"); return\n",
    "    fund_table.children = []                # reset\n",
    "\n",
    "    def _update_total(*_):\n",
    "        tot = sum(r.children[1].value for r in fund_table.children\n",
    "                  if r.children[0].value)\n",
    "        total_lbl.value = f\"Total = {tot} %\"\n",
    "\n",
    "    for f in valid:\n",
    "        cb = widgets.Checkbox(description=f, layout={\"width\":\"200px\"})\n",
    "        wt = widgets.BoundedIntText(0, min=0, max=100,\n",
    "                                    layout={\"width\":\"60px\"}, disabled=True)\n",
    "        def _toggle(ch, box=wt):           # single observer\n",
    "            box.disabled = not ch[\"new\"]\n",
    "            if box.disabled: box.value = 0\n",
    "            _update_total()\n",
    "        cb.observe(_toggle, names=\"value\")\n",
    "        wt.observe(_update_total, names=\"value\")\n",
    "        fund_table.children += (widgets.HBox([cb, wt]),)\n",
    "    _update_total()\n",
    "\n",
    "mode_dd.observe(lambda ch: _build_manual() if ch[\"new\"]==\"manual\" else None,\n",
    "                names=\"value\")\n",
    "for w in (in_start,in_end,out_start,out_end): w.observe(_build_manual,names=\"value\")\n",
    "\n",
    "# ---------- 4 · RUN ---------------\n",
    "run_btn = widgets.Button(description=\"Run Analysis\", button_style=\"success\")\n",
    "run_out = widgets.Output(layout={\"border\":\"1px solid #999\",\n",
    "                                 \"height\":\"340px\",\"overflow_y\":\"auto\"})\n",
    "\n",
    "def _run(_):\n",
    "    with run_out:\n",
    "        clear_output()\n",
    "        df, rf = session[\"df\"], session[\"rf\"]\n",
    "        if df is None: print(\"⚠️ Load data first\"); return\n",
    "\n",
    "        # indices (robust)\n",
    "        idx_n     = index_cnt.value\n",
    "        data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "        non_rf    = [c for c in data_cols if c != rf]\n",
    "        indices   = non_rf[-idx_n:] if idx_n else []\n",
    "\n",
    "        # pool + selection\n",
    "        pool = _eligible_pool()\n",
    "        if not pool: print(\"❌ No eligible funds\"); return\n",
    "        if mode_dd.value==\"all\":\n",
    "            sel, custom = pool, None\n",
    "        elif mode_dd.value==\"random\":\n",
    "            if rand_n.value>len(pool): print(\"⚠️ Sample N too big\"); return\n",
    "            sel, custom = list(np.random.choice(pool, rand_n.value, replace=False)), None\n",
    "        else:\n",
    "            sel, custom = [], {}\n",
    "            if not fund_table.children: _build_manual()\n",
    "            for row in fund_table.children:\n",
    "                cb, wt = row.children\n",
    "                if cb.value: sel.append(cb.description); custom[cb.description]=wt.value\n",
    "            if sum(custom.values())!=100: print(\"⚠️ Weights ≠ 100\"); return\n",
    "\n",
    "        w_dict,w_vec = prepare_weights(sel, custom)\n",
    "\n",
    "        res = run_analysis(df, sel, w_vec, w_dict, rf,\n",
    "                           in_start.value, in_end.value,\n",
    "                           out_start.value, out_end.value,\n",
    "                           target_vol.value, monthly_cost.value,\n",
    "                           indices)\n",
    "\n",
    "        print(\"✅ analysis complete |\", len(sel), \"funds\")\n",
    "        if res[\"dropped\"]:\n",
    "            print(\"⚠️ Dropped:\", res[\"dropped\"])\n",
    "        if indices: print(\"📊 Indices:\", indices)\n",
    "\n",
    "        fname=f\"IS_{in_start.value}_{out_start.value}.xlsx\"\n",
    "        # register only the combined summary formatter\n",
    "        make_summary_formatter(\n",
    "            res,\n",
    "            in_start.value,\n",
    "            in_end.value,\n",
    "            out_start.value,\n",
    "            out_end.value\n",
    "        )\n",
    "\n",
    "        # Build a minimal data dict with just the 'summary' sheet.\n",
    "        # The formatter will populate all rows (portfolio, funds, spacer, indices).\n",
    "        data = {\n",
    "            \"summary\": pd.DataFrame()\n",
    "        }\n",
    "\n",
    "        print(\"Sheets to write:\", list(data.keys()))\n",
    "        print(\"Formatters:\", list(FORMATTERS_EXCEL.keys()))\n",
    "\n",
    "        # Export — this will call fmt_summary(ws, wb) on the 'summary' sheet.\n",
    "        export_to_excel(data, fname)\n",
    "        print(\"Workbook saved as\", fname)\n",
    "\n",
    "run_btn.on_click(_run)\n",
    "\n",
    "# ---------- DISPLAY --------------\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h4>1. Load data</h4>\"),\n",
    "    src, chooser, url_box, load_btn, load_out,\n",
    "    widgets.HTML(\"<hr><h4>2. Parameters</h4>\"),\n",
    "    widgets.HBox([index_cnt]),\n",
    "    widgets.HBox([in_start,in_end,out_start,out_end]),\n",
    "    widgets.HBox([target_vol,monthly_cost]),\n",
    "    widgets.HTML(\"<hr><h4>3. Fund selection</h4>\"),\n",
    "    widgets.HBox([mode_dd,rand_n]),\n",
    "    fund_table, total_lbl,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    run_btn,\n",
    "    run_out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d599f6a9-8055-42be-abf1-fd2ab3efee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Risk-Free Rate', 'Quantum Capital', 'Crescent Strategies', 'Echo Advisors', 'Quantum Group', 'Quantum LP', 'Meridian Capital', 'Adaptive Partners', 'Echo Strategies', 'Vista LP', 'Adaptive Group', 'Echo Group', 'Meridian Strategies', 'Axiom LP', 'Crescent Capital', 'Sentinel Management', 'Ascent Holdings', 'Sentinel Strategies', 'Ascent Partners', 'Quantum Management', 'Quantum Investments', 'Ascent LP', 'Axiom Group', 'Crescent LP', 'Echo Partners', 'Adaptive Strategies', 'Crescent Partners', 'Meridian Holdings', 'Axiom Investments', 'Sentinel Investments', 'Ascent Strategies', 'Forge Advisors', 'Vista Strategies', 'Sentinel Global', 'Ascent Capital', 'Echo Capital', 'Ascent Management', 'Echo LP', 'Axiom Management', 'Axiom Advisors', 'Crescent Advisors', 'Vista Holdings', 'Forge Management', 'Sentinel Group', 'Axiom Partners', 'Sentinel Advisors', 'Meridian LP', 'Crescent Group', 'Crescent Management', 'Adaptive Holdings', 'Vista Advisors', 'Vista Partners', 'Forge Strategies', 'Vista Capital', 'Forge Investments', 'Axiom Capital', 'Forge Partners', 'Quantum Global', 'Sentinel Holdings', 'Ascent Global', 'Vista Global', 'Quantum Strategies', 'Forge Group', 'Adaptive Investments', 'Echo Holdings', 'Axiom Strategies', 'Forge LP', 'Meridian Global', 'Adaptive Management', 'Meridian Advisors', 'Crescent Global', 'Axiom Global', 'Echo Management', 'Adaptive Advisors', 'Axiom Holdings', 'Meridian Group', 'Adaptive Capital', 'Forge Global', 'Vista Group', 'Sentinel Capital', 'Sentinel Partners', 'Forge Capital', 'Echo Investments', 'Adaptive Global', 'Quantum Partners', 'Crescent Holdings', 'Ascent Advisors', 'Quantum Advisors', 'Ascent Group', 'Quantum Holdings', 'Sentinel LP', 'Meridian Investments', 'Meridian Partners', 'Meridian Management', 'Forge Holdings', 'Echo Global', 'Ascent Investments', 'Adaptive LP', 'Crescent Investments', 'Vista Investments', 'Vista Management', 'EqualWeight_60', 'EqualWeight_40']\n"
     ]
    }
   ],
   "source": [
    "# 1. Run the cell that defines load_csv and call it\n",
    "dt = load_csv(\"/Users/teacher/Library/CloudStorage/Dropbox/Learning/Code/Trend Modeling Project/hedge_fund_returns_with_indexes.csv\")\n",
    "\n",
    "# 2. Capture all original fields (Date + fund columns)\n",
    "col_list = dt.columns.tolist()\n",
    "print(col_list)\n",
    "\n",
    "# 3.  (Optional)  Save to CSV for your spec\n",
    "import pandas as pd\n",
    "pd.DataFrame({\"ColumnName\": col_list}).to_csv(\"variable_spec.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
