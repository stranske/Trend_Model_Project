{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22994893-0193-45bc-b9e3-a97b328ecaea",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Imports, Data Loader and Rf Detector\n",
    "2. Select fund (month period logic)\n",
    "3. Weight prep\n",
    "4. Core Stats + Run Analysis\n",
    "5. Export\n",
    "6. Widget /UI\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#      VOL-ADJ TREND ANALYSIS  –  SINGLE-FILE VERSION\n",
    "# ===============================================================\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  0 · IMPORTS  (all in one place)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from collections import namedtuple\n",
    "import xlsxwriter\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "from typing import List, Dict, Optional, Callable\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  1 · Class Configurations\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "@dataclass\n",
    "class FundSelectionConfig:\n",
    "    max_missing_months:         int = 3   # used to replace the “<=3 missing” rule\n",
    "    max_consecutive_month_gap:  int = 6   # used to replace the “<=6 gap” ruleimplausible_value_limit: float = 1.0\n",
    "    outlier_threshold: float = 0.5\n",
    "    zero_return_threshold: float = 0.2\n",
    "    enforce_monotonic_index: bool = True\n",
    "    allow_duplicate_dates: bool = False\n",
    "    max_missing_ratio: float      = 0.05\n",
    "    max_drawdown: float           = 0.3\n",
    "    min_volatility: float         = 0.05\n",
    "    max_volatility: float         = 1.0\n",
    "    min_avg_return: float         = 0.0\n",
    "    max_skewness: float           = 3.0\n",
    "    max_kurtosis: float           = 10.0\n",
    "    expected_freq: str            = \"B\"\n",
    "    max_gap_days: int             = 3\n",
    "    min_aum_usd: float            = 1e7\n",
    "\n",
    "# 1. Registry and decorator\n",
    "METRIC_REGISTRY: dict[str, callable] = {}\n",
    "\n",
    "def register_metric(name: str):\n",
    "    def decorator(fn: callable):\n",
    "        METRIC_REGISTRY[name] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "# 2. Configuration dataclass\n",
    "@dataclass\n",
    "class RiskStatsConfig:\n",
    "    metrics_to_run: list[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"AnnualReturn\",\n",
    "            \"Volatility\",\n",
    "            \"Sharpe\",\n",
    "            \"MaxDrawdown\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class FundSelectionConfig:\n",
    "    implausible_value_limit: float = 1.0\n",
    "    outlier_threshold: float = 0.5\n",
    "    zero_return_threshold: float = 0.2\n",
    "    enforce_monotonic_index: bool = True\n",
    "    allow_duplicate_dates: bool = False\n",
    "    # Coverage rules now driven by config\n",
    "    max_missing_months: int = 3\n",
    "    max_consecutive_month_gap: int = 6\n",
    "    \n",
    "METRIC_REGISTRY: dict[str, Callable] = {}\n",
    "\n",
    "def register_metric(name: str):\n",
    "    def decorator(fn: Callable):\n",
    "        METRIC_REGISTRY[name] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "# 2. Configuration dataclass\n",
    "@dataclass\n",
    "class RiskStatsConfig:\n",
    "    metrics_to_run: list[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"AnnualReturn\",\n",
    "            \"Volatility\",\n",
    "            \"Sharpe\",\n",
    "            \"MaxDrawdown\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  2 · CSV LOADER + RF DETECTOR\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(f\"No data in file: {path}\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Parsing error in {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"Date\" not in df.columns:\n",
    "        logger.error(f\"Validation failed ({path}): missing 'Date' column\")\n",
    "        return None\n",
    "\n",
    "    # Optionally check for NaNs in 'Date' column\n",
    "    if df[\"Date\"].isnull().any():\n",
    "        logger.warning(f\"Null values found in 'Date' column of {path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_risk_free_fund(df: pd.DataFrame) -> str:\n",
    "    returns = df.drop(columns=\"Date\", errors=\"ignore\")\n",
    "    stdevs  = returns.std(skipna=True, ddof=0)\n",
    "    return stdevs.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93582c5f-d5f9-4bc8-8083-b54fe6ea2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Aggregator with centralized try/except (Approach A)\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    \"\"\"\n",
    "    Runs each metric in cfg.metrics_to_run with centralized exception handling.\n",
    "    Returns a namedtuple of values in the same order as metrics_to_run.\n",
    "    \"\"\"\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not found in registry\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            val = fn(returns, **metric_kwargs)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"[%s] division by zero → setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"[%s] input error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except (FloatingPointError, OverflowError) as e:\n",
    "            logging.warning(\"[%s] numeric overflow/error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"[%s] unexpected error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "\n",
    "    return Stat(*values)\n",
    "\n",
    "def export_to_excel(\n",
    "    data: dict[str, pd.DataFrame],\n",
    "    output_path: str,\n",
    "    default_format: Optional[Callable] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Exports each DataFrame in `data` to its own sheet in `output_path`.\n",
    "    Applies a registered formatter for each category (sheet name).\n",
    "    If no formatter is found, applies `default_format` if provided.\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        for category, df in data.items():\n",
    "            df.to_excel(writer, sheet_name=category, index=False)\n",
    "            fmt_fn = FORMATTERS_EXCEL.get(category)\n",
    "            if fmt_fn:\n",
    "                fmt_fn(writer.sheets[category], writer.book)\n",
    "            elif default_format:\n",
    "                default_format(writer.sheets[category], writer.book)\n",
    "    # context manager auto-saves and closes the workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {},
   "source": [
    "## 2. Select Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 2 · SELECT_FUNDS  (restored ≤ 3-missing-months rule)\n",
    "# ===============================================================\n",
    "\n",
    "cfg = FundSelectionConfig(\n",
    "    implausible_value_limit=1.0,\n",
    "    outlier_threshold=0.5,\n",
    "    zero_return_threshold=0.2,\n",
    "    enforce_monotonic_index=True,\n",
    "    allow_duplicate_dates=False,\n",
    "    max_missing_months=3,\n",
    "    max_consecutive_month_gap=6,\n",
    ")\n",
    "\n",
    "def select_funds(\n",
    "    df: pd.DataFrame,\n",
    "    rf_col: str,\n",
    "    fund_columns: list[str],\n",
    "    in_sdate: str,\n",
    "    in_edate: str,\n",
    "    out_sdate: str,\n",
    "    out_edate: str,\n",
    "    cfg: FundSelectionConfig,\n",
    "    selection_mode: str = \"all\",\n",
    "    random_n: int | None = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Select eligible funds with additional data-validity checks driven by FundSelectionConfig.\n",
    "    \"\"\"\n",
    "    # Coerce Date column if needed\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        df = df.copy()\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"Date\"], inplace=True)\n",
    "\n",
    "    # Prepare monthly periods within analysis window\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    span = pd.period_range(\n",
    "        pd.Period(in_sdate, \"M\"), pd.Period(out_edate, \"M\"), freq=\"M\"\n",
    "    )\n",
    "\n",
    "    eligible: list[str] = []\n",
    "    for f in fund_columns:\n",
    "        try:\n",
    "            ser = df.set_index(\"Date\")[f]\n",
    "            clean = ser.dropna()\n",
    "\n",
    "            # 1. Implausible value limits\n",
    "            if not clean.between(-cfg.implausible_value_limit, cfg.implausible_value_limit).all():\n",
    "                raise ValueError(f\"Values outside ±{cfg.implausible_value_limit}\")\n",
    "\n",
    "            # 2. Extreme outlier threshold\n",
    "            if (clean.abs() > cfg.outlier_threshold).any():\n",
    "                raise ValueError(f\"Outliers beyond ±{cfg.outlier_threshold}\")\n",
    "\n",
    "            # 3. Excessive zero-return rate\n",
    "            if (clean == 0).mean() > cfg.zero_return_threshold:\n",
    "                raise ValueError(f\"Zero-return proportion > {cfg.zero_return_threshold}\")\n",
    "\n",
    "            # 4. Monotonic date index\n",
    "            if cfg.enforce_monotonic_index and not clean.index.is_monotonic_increasing:\n",
    "                raise ValueError(\"Date index not monotonically increasing\")\n",
    "\n",
    "            # 5. Duplicate dates\n",
    "            if not cfg.allow_duplicate_dates and clean.index.duplicated().any():\n",
    "                raise ValueError(\"Duplicate dates detected in index\")\n",
    "\n",
    "            # 6. Coverage checks using config thresholds\n",
    "            m_ok = df.groupby(\"Month\")[f].apply(lambda col: col.notna().any())\n",
    "            mask = m_ok.reindex(span, fill_value=False).to_numpy()\n",
    "\n",
    "            # tolerance for missing months per-cfg\n",
    "            if (~mask).sum() > cfg.max_missing_months:\n",
    "                raise ValueError(f\"Missing-month count exceeds {cfg.max_missing_months}\")\n",
    "\n",
    "            # maximum run of consecutive missing months per-cfg\n",
    "            gap = np.diff(np.flatnonzero(np.r_[True, mask, True])).max() - 1\n",
    "            if gap > cfg.max_consecutive_month_gap:\n",
    "                raise ValueError(f\"Consecutive-missing gap exceeds {cfg.max_consecutive_month_gap}\")\n",
    "\n",
    "            eligible.append(f)\n",
    "\n",
    "        except ValueError as e:\n",
    "            logging.warning(\"Excluded %s: %s\", f, e)\n",
    "        except KeyError as e:\n",
    "            logging.warning(\"Missing data for %s: %s\", f, e)\n",
    "        except Exception as e:\n",
    "            logging.warning(\"Unexpected error on %s: %s\", f, e)\n",
    "\n",
    "    # Final selection-mode logic\n",
    "    if selection_mode == \"all\" or random_n is None:\n",
    "        return eligible\n",
    "    if selection_mode == \"random\":\n",
    "        if random_n > len(eligible):\n",
    "            raise ValueError(\n",
    "                f\"random_n exceeds eligible pool: {random_n} > {len(eligible)}\"\n",
    "            )\n",
    "        return list(np.random.choice(eligible, random_n, replace=False))\n",
    "\n",
    "    raise ValueError(f\"Unsupported selection_mode '{selection_mode}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 3. Weight Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  3 · WEIGHT PREP\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "def prepare_weights(selected: list[str],\n",
    "                    custom: Dict[str, int] | None) -> tuple[Dict[str, float], np.ndarray]:\n",
    "    if not custom:\n",
    "        w = {f: 1/len(selected) for f in selected}\n",
    "    else:\n",
    "        missing = [f for f in selected if f not in custom]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing weights for {missing}\")\n",
    "        w = {f: pct/100 for f, pct in custom.items()}\n",
    "        if abs(sum(w.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"Custom weights must sum to 100.\")\n",
    "    vec = np.array([w[f] for f in selected])\n",
    "    return w, vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 4. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Function definitions\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 4 · CORE STATS  +  RUN_ANALYSIS  (helpers included, weight fix)\n",
    "# ===============================================================\n",
    "\n",
    "M_PER_YEAR = 12           # constant used across helpers\n",
    "\n",
    "# ---------- helpers --------------------------------------------\n",
    "def _ensure_dt(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy whose Date column is datetime64[ns].\"\"\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3. Metric function definitions\n",
    "@register_metric(\"AnnualReturn\")\n",
    "def compute_annual_return(returns: pd.Series, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Geometric annualized return assuming 252 trading days.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        raise ValueError(\"Empty returns series for AnnualReturn\")\n",
    "    total_growth = (1 + r).prod()\n",
    "    periods = len(r)\n",
    "    return total_growth ** (252 / periods) - 1\n",
    "\n",
    "@register_metric(\"Volatility\")\n",
    "def compute_volatility(returns: pd.Series, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Annualized standard deviation (volatility) assuming 252 trading days.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    return r.std(ddof=0) * np.sqrt(252)\n",
    "\n",
    "@register_metric(\"Sharpe\")\n",
    "def compute_sharpe(returns: pd.Series, risk_free: float = 0.0, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Sharpe ratio using annualized return and volatility, risk-free rate default 0.\n",
    "    \"\"\"\n",
    "    ann_ret = METRIC_REGISTRY[\"AnnualReturn\"](returns)\n",
    "    vol = METRIC_REGISTRY[\"Volatility\"](returns)\n",
    "    if vol == 0:\n",
    "        raise ZeroDivisionError(\"Zero volatility in Sharpe ratio\")\n",
    "    return (ann_ret - risk_free) / vol\n",
    "\n",
    "@register_metric(\"MaxDrawdown\")\n",
    "def compute_max_drawdown(returns: pd.Series, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Maximum peak-to-trough drawdown.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    cum = (1 + r).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdowns = (cum / peak) - 1\n",
    "    return drawdowns.min()\n",
    "\n",
    "# ---------- main ------------------------------------------------\n",
    "def run_analysis(\n",
    "    df: pd.DataFrame,\n",
    "    selected: list[str],\n",
    "    w_vec: np.ndarray,\n",
    "    w_dict: dict[str, float] | None,\n",
    "    rf_col: str,\n",
    "    in_start: str,\n",
    "    in_end: str,\n",
    "    out_start: str,\n",
    "    out_end: str,\n",
    "    target_vol: float = 0.25,\n",
    "    monthly_cost: float = 0.0033,\n",
    "    indices_list: Optional[list[str]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorised run_analysis with correct weight re-normalisation\n",
    "    after funds are dropped.\n",
    "    Returns the same keys used by the UI and export functions.\n",
    "    \"\"\"\n",
    "    df = _ensure_dt(df)\n",
    "\n",
    "    # ---- date masks --------------------------------------------------\n",
    "    in_s = pd.to_datetime(in_start)  + pd.offsets.MonthEnd(0)\n",
    "    in_e = pd.to_datetime(in_end)    + pd.offsets.MonthEnd(0)\n",
    "    out_s= pd.to_datetime(out_start) + pd.offsets.MonthEnd(0)\n",
    "    out_e= pd.to_datetime(out_end)   + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    m_in  = df[\"Date\"].between(in_s,  in_e)\n",
    "    m_out = df[\"Date\"].between(out_s, out_e)\n",
    "\n",
    "    in_df,  out_df  = df.loc[m_in,  selected], df.loc[m_out, selected]\n",
    "    in_rf,  out_rf  = df.loc[m_in,  rf_col],   df.loc[m_out, rf_col]\n",
    "\n",
    "    # ---- drop funds with any NaNs in either window ------------------\n",
    "    good = [f for f in selected\n",
    "            if in_df[f].notna().all() and out_df[f].notna().all()]\n",
    "    dropped = list(set(selected) - set(good))\n",
    "    if dropped:\n",
    "        logging.warning(\"Dropped funds: %s\", dropped)\n",
    "\n",
    "    selected = good\n",
    "    # >>>> new guard: kick out any accidental index columns\n",
    "    selected = [f for f in selected if f not in (indices_list or [])]\n",
    "    # <<<<\n",
    "\n",
    "    in_df, out_df = in_df[selected], out_df[selected]\n",
    "\n",
    "    # rebuild weights\n",
    "    if w_dict is None:                      # equal-weight path\n",
    "        w_dict = {f: 1/len(selected) for f in selected}\n",
    "    else:                                   # manual path → rescale\n",
    "        pct   = {f: w_dict[f]*100 for f in selected}\n",
    "        total = sum(pct.values())\n",
    "        w_dict = {f: p/total for f, p in pct.items()}\n",
    "    w_vec = np.array([w_dict[f] for f in selected])\n",
    "\n",
    "    # ---- scaling ----------------------------------------------------\n",
    "    vols = in_df.apply(_ann_vol)\n",
    "    scale = np.where(vols > 0, target_vol / vols, 1.0)\n",
    "    in_sc  = (in_df * scale) - monthly_cost\n",
    "    out_sc = (out_df * scale) - monthly_cost\n",
    "    in_sc.clip(lower=-1, inplace=True)\n",
    "    out_sc.clip(lower=-1, inplace=True)\n",
    "\n",
    "    # ---- stats ------------------------------------------------------\n",
    "    in_stat  = {f: _stats(in_sc[f],  in_rf) for f in selected}\n",
    "    out_stat = {f: _stats(out_sc[f], out_rf) for f in selected}\n",
    "\n",
    "    ew_vec = np.full(len(selected), 1/len(selected))\n",
    "\n",
    "    results = {\n",
    "        \"selected_funds\": selected,\n",
    "        \"indices_list\":   indices_list or [],\n",
    "        \"fund_weights\":   w_dict,\n",
    "        \"ew_weights\":     {f: 1/len(selected) for f in selected},\n",
    "        \"in_sample_stats\":  in_stat,\n",
    "        \"out_sample_stats\": out_stat,\n",
    "        \"in_ew_stats\":     _stats(in_sc.dot(ew_vec), in_rf),\n",
    "        \"out_ew_stats\":    _stats(out_sc.dot(ew_vec), out_rf),\n",
    "        \"in_user_stats\":   _stats(in_sc.dot(w_vec),  in_rf),\n",
    "        \"out_user_stats\":  _stats(out_sc.dot(w_vec), out_rf),\n",
    "        \"dropped\":         dropped,\n",
    "    }\n",
    "\n",
    "    # ---- optional index stats ---------------------------------------\n",
    "    if indices_list:\n",
    "        idx_stats = {}\n",
    "        for col in indices_list:\n",
    "            idx_stats[col] = {\n",
    "                \"in_sample\":  _stats(df.loc[m_in,  col], in_rf),\n",
    "                \"out_sample\": _stats(df.loc[m_out, col], out_rf),\n",
    "            }\n",
    "        results[\"index_stats\"] = idx_stats\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 5. Excel Export\n",
    "Creates an Excel file with In-Sample, Out-of-Sample and Equal-weight and User-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  5 · EXPORT  (NaN-safe, weight-format fix)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# ───────── 5 · EXPORT  (final, bug-free) ───────────────────────\n",
    "# ───────── 5 · EXPORT  (self-healing index section) ───────────\n",
    "# ───────── 5 · EXPORT  (final safe version) ───────────────────\n",
    "\n",
    "# 1. Registry and decorator for risk metrics\n",
    "\n",
    "# 3. Metric function definitions\n",
    "@register_metric(\"AnnualReturn\")\n",
    "def compute_annual_return(returns: pd.Series, **kwargs) -> float:\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        raise ValueError(\"Empty returns series for AnnualReturn\")\n",
    "    total_growth = (1 + r).prod()\n",
    "    periods = len(r)\n",
    "    return total_growth ** (252 / periods) - 1\n",
    "\n",
    "@register_metric(\"Volatility\")\n",
    "def compute_volatility(returns: pd.Series, **kwargs) -> float:\n",
    "    r = returns.dropna()\n",
    "    return r.std(ddof=0) * np.sqrt(252)\n",
    "\n",
    "@register_metric(\"Sharpe\")\n",
    "def compute_sharpe(returns: pd.Series, risk_free: float = 0.0, **kwargs) -> float:\n",
    "    ann_ret = METRIC_REGISTRY[\"AnnualReturn\"](returns)\n",
    "    vol = METRIC_REGISTRY[\"Volatility\"](returns)\n",
    "    if vol == 0:\n",
    "        raise ZeroDivisionError(\"Zero volatility in Sharpe ratio\")\n",
    "    return (ann_ret - risk_free) / vol\n",
    "\n",
    "@register_metric(\"MaxDrawdown\")\n",
    "def compute_max_drawdown(returns: pd.Series, **kwargs) -> float:\n",
    "    r = returns.dropna()\n",
    "    cum = (1 + r).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdowns = (cum / peak) - 1\n",
    "    return drawdowns.min()\n",
    "\n",
    "# 4. Aggregator with centralized try/except (Approach A)\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not found in registry\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            val = fn(returns, **metric_kwargs)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"[%s] division by zero → setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"[%s] input error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except (FloatingPointError, OverflowError) as e:\n",
    "            logging.warning(\"[%s] numeric overflow/error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"[%s] unexpected error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "    return Stat(*values)\n",
    "\n",
    "# 5. Registry for Excel formatting\n",
    "FORMATTERS_EXCEL: dict[str, Callable] = {}\n",
    "\n",
    "def register_formatter_excel(category: str):\n",
    "    def decorator(fn: Callable):\n",
    "        FORMATTERS_EXCEL[category] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "# Example formatters (extend as needed)\n",
    "@register_formatter_excel(\"portfolio\")\n",
    "def fmt_portfolio(ws, wb):\n",
    "    header_fmt = wb.add_format({\"bold\": True, \"bottom\": 2})\n",
    "    ws.set_row(0, None, header_fmt)\n",
    "\n",
    "@register_formatter_excel(\"indices\")\n",
    "def fmt_indices(ws, wb):\n",
    "    box_fmt = wb.add_format({\"border\": 1})\n",
    "    rows = ws.dim_rowmax\n",
    "    cols = ws.dim_colmax\n",
    "    ws.conditional_format(0, 0, rows, cols, {\"type\": \"no_errors\", \"format\": box_fmt})\n",
    "\n",
    "# 6. Export to Excel using registry-based formatting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 6. Run Parameters,Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48de568-962e-4690-a6fc-be7a4ec0a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94343b0ce994d84ab683797c28acba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>1. Load data</h4>'), ToggleButtons(description='Source:', options=(('Local', 'l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#            STREAMLINED ANALYSIS UI  (phase-2 clean)\n",
    "# ===============================================================\n",
    "\n",
    "# ---------- session store ----------\n",
    "session = {\"df\": None, \"rf\": None, \"sel\": None, \"cweights\": None}\n",
    "\n",
    "# ---------- 1 · DATA LOAD ----------\n",
    "src = widgets.ToggleButtons(\n",
    "    options=[(\"Local\", \"local\"), (\"URL\", \"url\")],\n",
    "    description=\"Source:\"\n",
    ")\n",
    "\n",
    "chooser = FileChooser()\n",
    "url_box = widgets.Text(placeholder=\"https://…/file.csv\", layout={\"width\":\"70%\"})\n",
    "load_btn = widgets.Button(description=\"Load CSV\", button_style=\"success\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "def _toggle_src(c):\n",
    "    chooser.layout.display = \"block\" if c[\"new\"]==\"local\" else \"none\"\n",
    "    url_box.layout.display  = \"block\" if c[\"new\"]==\"url\"   else \"none\"\n",
    "src.observe(_toggle_src, names=\"value\"); _toggle_src({\"new\":src.value})\n",
    "\n",
    "def _load(_):\n",
    "    with load_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            path = chooser.selected if src.value==\"local\" else url_box.value.strip()\n",
    "            if not path: raise ValueError(\"choose file / URL\")\n",
    "            if src.value==\"url\" and not path.lower().endswith(\".csv\"):\n",
    "                raise ValueError(\"URL must end with .csv\")\n",
    "            df = load_csv(path)\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")  # single coercion\n",
    "            rf = identify_risk_free_fund(df)\n",
    "            session.update(df=df, rf=rf, sel=None, cweights=None)\n",
    "            print(f\"✅ Loaded {len(df):,} rows × {df.shape[1]} cols | RF → {rf}\")\n",
    "        except Exception as e:\n",
    "            print(\"❌\", e); session[\"df\"]=None\n",
    "load_btn.on_click(_load)\n",
    "\n",
    "# ---------- 2 · PARAMS ------------\n",
    "index_cnt = widgets.BoundedIntText(0, min=0, max=10, description=\"# Indices:\")\n",
    "in_start,in_end  = widgets.Text(\"2005-07\"), widgets.Text(\"2008-06\")\n",
    "out_start,out_end= widgets.Text(\"2008-07\"), widgets.Text(\"2009-06\")\n",
    "for w,lbl in [(in_start,\"In Start:\"),(in_end,\"In End:\"),\n",
    "              (out_start,\"Out Start:\"),(out_end,\"Out End:\")]:\n",
    "    w.description = lbl\n",
    "target_vol   = widgets.FloatText(0.25,  description=\"Target Vol:\")\n",
    "monthly_cost = widgets.FloatText(0.0033, description=\"Monthly Cost:\")\n",
    "\n",
    "# ---------- 3 · SELECTION ----------\n",
    "mode_dd = widgets.Dropdown(\n",
    "    options=[(\"All\", \"all\"), (\"Random\", \"random\"), (\"Manual\", \"manual\")],\n",
    "    value=\"all\",\n",
    "    description=\"Mode:\"\n",
    ")\n",
    "rand_n   = widgets.BoundedIntText(5, min=2, max=100, description=\"Sample N:\")\n",
    "fund_table, total_lbl = widgets.VBox([]), widgets.Label(\"Total = 0 %\")\n",
    "\n",
    "def _toggle_sel(_=None):\n",
    "    rand_n.layout.display  = \"block\" if mode_dd.value==\"random\" else \"none\"\n",
    "    vis = \"block\" if mode_dd.value==\"manual\" else \"none\"\n",
    "    fund_table.layout.display = total_lbl.layout.display = vis\n",
    "mode_dd.observe(_toggle_sel, names=\"value\"); _toggle_sel()\n",
    "\n",
    "# ---------- helpers ---------------\n",
    "def _eligible_pool():\n",
    "    df, rf = session[\"df\"], session[\"rf\"]\n",
    "    if df is None: \n",
    "        print(\"⚠️ data not loaded\"); return []\n",
    "\n",
    "    # ---- date parse guard -----------------------------------\n",
    "    try:\n",
    "        in_s  = pd.to_datetime(in_start.value)+pd.offsets.MonthEnd(0)\n",
    "        in_e  = pd.to_datetime(in_end.value)  +pd.offsets.MonthEnd(0)\n",
    "        out_s = pd.to_datetime(out_start.value)+pd.offsets.MonthEnd(0)\n",
    "        out_e = pd.to_datetime(out_end.value)  +pd.offsets.MonthEnd(0)\n",
    "    except Exception:\n",
    "        print(\"❌ invalid dates\"); return []\n",
    "\n",
    "    # ---- build indices (RIGHT-most idx_n non-RF columns) ----\n",
    "    idx_n     = index_cnt.value\n",
    "    data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "    non_rf    = [c for c in data_cols if c != rf]\n",
    "    indices   = non_rf[-idx_n:] if idx_n else []          # <- fixed\n",
    "    cand      = [c for c in data_cols if c not in indices]\n",
    "\n",
    "    # ---- run select_funds ----------------------------------\n",
    "    elig = select_funds(\n",
    "        df=df,\n",
    "        rf_col=rf,\n",
    "        fund_columns=cand,\n",
    "        in_sdate=in_s,\n",
    "        in_edate=in_e,\n",
    "        out_sdate=out_s,\n",
    "        out_edate=out_e,\n",
    "        cfg=cfg,                     # ← Explicitly supply your config here\n",
    "        selection_mode=\"all\",\n",
    "    )\n",
    "    # … diagnostics print unchanged …\n",
    "    return elig\n",
    "\n",
    "def _build_manual(*_):\n",
    "    if mode_dd.value!=\"manual\" or session[\"df\"] is None: return\n",
    "    valid = _eligible_pool()\n",
    "    print(\"DEBUG  eligible funds =\", len(valid))              # ← line 1\n",
    "    print(\"DEBUG  list sample   →\", valid[:25], \"…\")           # ← line 2\n",
    "    if not valid:\n",
    "        print(\"❌ No eligible funds\"); return \n",
    "    fund_table.children = []                # reset\n",
    "\n",
    "    def _update_total(*_):\n",
    "        tot = sum(r.children[1].value for r in fund_table.children\n",
    "                  if r.children[0].value)\n",
    "        total_lbl.value = f\"Total = {tot} %\"\n",
    "\n",
    "    for f in valid:\n",
    "        cb = widgets.Checkbox(description=f, layout={\"width\":\"200px\"})\n",
    "        wt = widgets.BoundedIntText(0, min=0, max=100,\n",
    "                                    layout={\"width\":\"60px\"}, disabled=True)\n",
    "        def _toggle(ch, box=wt):           # single observer\n",
    "            box.disabled = not ch[\"new\"]\n",
    "            if box.disabled: box.value = 0\n",
    "            _update_total()\n",
    "        cb.observe(_toggle, names=\"value\")\n",
    "        wt.observe(_update_total, names=\"value\")\n",
    "        fund_table.children += (widgets.HBox([cb, wt]),)\n",
    "    _update_total()\n",
    "\n",
    "mode_dd.observe(lambda ch: _build_manual() if ch[\"new\"]==\"manual\" else None,\n",
    "                names=\"value\")\n",
    "for w in (in_start,in_end,out_start,out_end): w.observe(_build_manual,names=\"value\")\n",
    "\n",
    "# ---------- 4 · RUN ---------------\n",
    "run_btn = widgets.Button(description=\"Run Analysis\", button_style=\"success\")\n",
    "run_out = widgets.Output(layout={\"border\":\"1px solid #999\",\n",
    "                                 \"height\":\"340px\",\"overflow_y\":\"auto\"})\n",
    "\n",
    "def _run(_):\n",
    "    with run_out:\n",
    "        clear_output()\n",
    "        df, rf = session[\"df\"], session[\"rf\"]\n",
    "        if df is None: print(\"⚠️ Load data first\"); return\n",
    "\n",
    "        # indices (robust)\n",
    "        idx_n     = index_cnt.value\n",
    "        data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "        non_rf    = [c for c in data_cols if c != rf]\n",
    "        indices   = non_rf[-idx_n:] if idx_n else [] \n",
    "\n",
    "        # pool + selection\n",
    "        pool = _eligible_pool()\n",
    "        if not pool: print(\"❌ No eligible funds\"); return\n",
    "        if mode_dd.value==\"all\":\n",
    "            sel, custom = pool, None\n",
    "        elif mode_dd.value==\"random\":\n",
    "            if rand_n.value>len(pool): print(\"⚠️ Sample N too big\"); return\n",
    "            sel, custom = list(np.random.choice(pool, rand_n.value, replace=False)), None\n",
    "        else:\n",
    "            sel, custom = [], {}\n",
    "            if not fund_table.children: _build_manual()\n",
    "            for row in fund_table.children:\n",
    "                cb, wt = row.children\n",
    "                if cb.value: sel.append(cb.description); custom[cb.description]=wt.value\n",
    "            if sum(custom.values())!=100: print(\"⚠️ Weights ≠ 100\"); return\n",
    "\n",
    "        w_dict,w_vec = prepare_weights(sel, custom)\n",
    "\n",
    "        res = run_analysis(df, sel, w_vec, w_dict, rf,\n",
    "                           in_start.value, in_end.value,\n",
    "                           out_start.value, out_end.value,\n",
    "                           target_vol.value, monthly_cost.value,\n",
    "                           indices)\n",
    "\n",
    "        print(\"✅ analysis complete |\", len(sel), \"funds\")\n",
    "        if res[\"dropped\"]:\n",
    "            print(\"⚠️ Dropped:\", res[\"dropped\"])\n",
    "        if indices: print(\"📊 Indices:\", indices)\n",
    "\n",
    "        fname=f\"IS_{in_start.value}_{out_start.value}.xlsx\"\n",
    "        export_to_excel(res, df, fname,\n",
    "                        in_start.value,in_end.value,\n",
    "                        out_start.value,out_end.value)\n",
    "        print(\"Workbook saved as\", fname)\n",
    "\n",
    "run_btn.on_click(_run)\n",
    "\n",
    "# ---------- DISPLAY --------------\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h4>1. Load data</h4>\"),\n",
    "    src, chooser, url_box, load_btn, load_out,\n",
    "    widgets.HTML(\"<hr><h4>2. Parameters</h4>\"),\n",
    "    widgets.HBox([index_cnt]),\n",
    "    widgets.HBox([in_start,in_end,out_start,out_end]),\n",
    "    widgets.HBox([target_vol,monthly_cost]),\n",
    "    widgets.HTML(\"<hr><h4>3. Fund selection</h4>\"),\n",
    "    widgets.HBox([mode_dd,rand_n]),\n",
    "    fund_table, total_lbl,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    run_btn,\n",
    "    run_out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b797fd-513c-42a7-b825-3fd5cae034be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
