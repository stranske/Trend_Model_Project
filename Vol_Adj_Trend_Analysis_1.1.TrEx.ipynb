{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22994893-0193-45bc-b9e3-a97b328ecaea",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Imports, Data Loader and Rf Detector\n",
    "2. Select fund (month period logic)\n",
    "3. Weight prep\n",
    "4. Core Stats + Run Analysis\n",
    "5. Export\n",
    "6. Widget /UI\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#      VOL-ADJ TREND ANALYSIS  –  SINGLE-FILE VERSION\n",
    "# ===============================================================\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  0 · IMPORTS  (all in one place)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from collections import namedtuple\n",
    "import xlsxwriter\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "from typing import List, Dict, Optional, Callable\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  1 · Class Configurations\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "@dataclass\n",
    "class FundSelectionConfig:\n",
    "    max_missing_months:         int = 3   # used to replace the “<=3 missing” rule\n",
    "    max_consecutive_month_gap:  int = 6   # used to replace the “<=6 gap” ruleimplausible_value_limit: float = 1.0\n",
    "    outlier_threshold: float = 0.5\n",
    "    zero_return_threshold: float = 0.2\n",
    "    enforce_monotonic_index: bool = True\n",
    "    allow_duplicate_dates: bool = False\n",
    "    max_missing_ratio: float      = 0.05\n",
    "    max_drawdown: float           = 0.3\n",
    "    min_volatility: float         = 0.05\n",
    "    max_volatility: float         = 1.0\n",
    "    min_avg_return: float         = 0.0\n",
    "    max_skewness: float           = 3.0\n",
    "    max_kurtosis: float           = 10.0\n",
    "    expected_freq: str            = \"B\"\n",
    "    max_gap_days: int             = 3\n",
    "    min_aum_usd: float            = 1e7\n",
    "\n",
    "# Configuration dataclass\n",
    "@dataclass\n",
    "class RiskStatsConfig:\n",
    "    \"\"\"\n",
    "    Configuration for which metrics to run, risk-free rate, and data frequency.\n",
    "    periods_per_year specifies the number of data points per year (e.g., 12 for monthly).\n",
    "    \"\"\"\n",
    "    metrics_to_run: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"AnnualReturn\",\n",
    "            \"Volatility\",\n",
    "            \"Sharpe\",\n",
    "            \"Sortino\",\n",
    "            \"MaxDrawdown\",\n",
    "        ]\n",
    "    )\n",
    "    # Annualized risk-free rate for ratio computations\n",
    "    risk_free: float = 0.0\n",
    "    # Number of periods per year (e.g., 12 for monthly, 252 for daily)\n",
    "    periods_per_year: int = 12\n",
    "\n",
    "# 2. Registry and decorator\n",
    "METRIC_REGISTRY: Dict[str, Callable[..., float]] = {}\n",
    "\n",
    "def register_metric(name: str):\n",
    "    \"\"\"\n",
    "    Decorator to register a metric function under a given name.\n",
    "    \"\"\"\n",
    "    def decorator(fn: Callable[..., float]):\n",
    "        METRIC_REGISTRY[name] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "FORMATTERS_EXCEL: dict[str, Callable] = {}\n",
    "def register_formatter_excel(category: str):\n",
    "    def decorator(fn: Callable):\n",
    "        FORMATTERS_EXCEL[category] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "# Example formatters (extend as needed)\n",
    "@register_formatter_excel(\"portfolio\")\n",
    "def fmt_portfolio(ws, wb):\n",
    "    header_fmt = wb.add_format({\"bold\": True, \"bottom\": 2})\n",
    "    ws.set_row(0, None, header_fmt)\n",
    "\n",
    "@register_formatter_excel(\"indices\")\n",
    "def fmt_indices(ws, wb):\n",
    "    box_fmt = wb.add_format({\"border\": 1})\n",
    "    rows = ws.dim_rowmax\n",
    "    cols = ws.dim_colmax\n",
    "    ws.conditional_format(0, 0, rows, cols, {\"type\": \"no_errors\", \"format\": box_fmt})\n",
    "\n",
    "# Custom summary sheet formatter to match old presentation\n",
    "@register_formatter_excel(\"Summary\")\n",
    "def fmt_summary(ws, wb):\n",
    "    # Define commonly used formats\n",
    "    bold = wb.add_format({\"bold\": True})\n",
    "    int0 = wb.add_format({\"num_format\": \"0\"})\n",
    "    num2 = wb.add_format({\"num_format\": \"0.00\"})\n",
    "    red  = wb.add_format({\"num_format\": \"0.00\", \"font_color\": \"red\"})\n",
    "\n",
    "    # Helper functions\n",
    "    safe = lambda v: \"\" if (pd.isna(v) or not np.isfinite(v)) else v\n",
    "    pct  = lambda t: [t[0]*100, t[1]*100, t[2], t[3], t[4]*100]\n",
    "\n",
    "    # Write header rows\n",
    "    ws.write_row(0, 0, [\"Vol-Adj Trend Analysis\"], bold)\n",
    "    ws.write_row(1, 0, [f\"In:  {{in_start}} → {{in_end}}\"])\n",
    "    ws.write_row(2, 0, [f\"Out: {{out_start}} → {{out_end}}\"])\n",
    "\n",
    "    # Column headers at row 4\n",
    "    hdr = [\n",
    "        \"Name\", \"Weight %\",\n",
    "        \"R (IN)%\", \"V (IN)%\", \"Sharpe\", \"Sortino\", \"MDD (IN)%\",\n",
    "        \"R (OUT)%\", \"V (OUT)%\", \"Sharpe\", \"Sortino\", \"MDD (OUT)%\"\n",
    "    ]\n",
    "    ws.write_row(4, 0, hdr, bold)\n",
    "\n",
    "    # Note: DataFrame rows should start at row index 5 via export_to_excel startrow\n",
    "    \n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  2 · CSV LOADER + RF DETECTOR\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(f\"No data in file: {path}\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Parsing error in {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"Date\" not in df.columns:\n",
    "        logger.error(f\"Validation failed ({path}): missing 'Date' column\")\n",
    "        return None\n",
    "\n",
    "    # Optionally check for NaNs in 'Date' column\n",
    "    if df[\"Date\"].isnull().any():\n",
    "        logger.warning(f\"Null values found in 'Date' column of {path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_risk_free_fund(df: pd.DataFrame) -> str:\n",
    "    returns = df.drop(columns=\"Date\", errors=\"ignore\")\n",
    "    stdevs  = returns.std(skipna=True, ddof=0)\n",
    "    return stdevs.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93582c5f-d5f9-4bc8-8083-b54fe6ea2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Aggregator with centralized try/except (Approach A)\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    \"\"\"\n",
    "    Runs each metric in cfg.metrics_to_run with centralized exception handling.\n",
    "    Returns a namedtuple of values in the same order as metrics_to_run.\n",
    "    \"\"\"\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not found in registry\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            val = fn(returns, **metric_kwargs)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"[%s] division by zero → setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"[%s] input error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except (FloatingPointError, OverflowError) as e:\n",
    "            logging.warning(\"[%s] numeric overflow/error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"[%s] unexpected error: %s → setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "\n",
    "    return Stat(*values)\n",
    "\n",
    "def export_to_excel(\n",
    "    data: dict[str, pd.DataFrame],\n",
    "    output_path: str,\n",
    "    default_format: Optional[Callable] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Exports each DataFrame in `data` to its own sheet in `output_path`.\n",
    "    Applies a registered formatter for each category (sheet name).\n",
    "    If no formatter is found, applies `default_format` if provided.\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        for category, df in data.items():\n",
    "            df.to_excel(writer, sheet_name=category, index=False)\n",
    "            fmt_fn = FORMATTERS_EXCEL.get(category)\n",
    "            if fmt_fn:\n",
    "                fmt_fn(writer.sheets[category], writer.book)\n",
    "            elif default_format:\n",
    "                default_format(writer.sheets[category], writer.book)\n",
    "    # context manager auto-saves and closes the workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {},
   "source": [
    "## 2. Select Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 2 · SELECT_FUNDS  (restored ≤ 3-missing-months rule)\n",
    "# ===============================================================\n",
    "\n",
    "cfg = FundSelectionConfig(\n",
    "    implausible_value_limit=1.0,\n",
    "    outlier_threshold=0.5,\n",
    "    zero_return_threshold=0.2,\n",
    "    enforce_monotonic_index=True,\n",
    "    allow_duplicate_dates=False,\n",
    "    max_missing_months=3,\n",
    "    max_consecutive_month_gap=6,\n",
    ")\n",
    "\n",
    "def select_funds(\n",
    "    df: pd.DataFrame,\n",
    "    rf_col: str,\n",
    "    fund_columns: list[str],\n",
    "    in_sdate: str,\n",
    "    in_edate: str,\n",
    "    out_sdate: str,\n",
    "    out_edate: str,\n",
    "    cfg: FundSelectionConfig,\n",
    "    selection_mode: str = \"all\",\n",
    "    random_n: int | None = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Select eligible funds with additional data-validity and coverage checks driven by FundSelectionConfig.\n",
    "    \"\"\"\n",
    "    # Ensure Date is datetime and sorted\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        df = df.copy()\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    df = df.sort_values(\"Date\")  # guarantee monotonic index\n",
    "\n",
    "    # Prepare monthly periods within analysis window\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    span = pd.period_range(\n",
    "        pd.Period(in_sdate, \"M\"), pd.Period(out_edate, \"M\"), freq=\"M\"\n",
    "    )\n",
    "\n",
    "    eligible_funds: list[str] = []\n",
    "    for f in fund_columns:\n",
    "        try:\n",
    "            ser = df.set_index(\"Date\")[f]\n",
    "            clean = ser.dropna()\n",
    "\n",
    "            # 1. Implausible value limits\n",
    "            if not clean.between(-cfg.implausible_value_limit, cfg.implausible_value_limit).all():\n",
    "                raise ValueError(f\"Values outside ±{cfg.implausible_value_limit}\")\n",
    "\n",
    "            # 2. Extreme outlier threshold\n",
    "            if (clean.abs() > cfg.outlier_threshold).any():\n",
    "                raise ValueError(f\"Outliers beyond ±{cfg.outlier_threshold}\")\n",
    "\n",
    "            # 3. Excessive zero-return rate\n",
    "            if (clean == 0).mean() > cfg.zero_return_threshold:\n",
    "                raise ValueError(f\"Zero-return proportion > {cfg.zero_return_threshold}\")\n",
    "\n",
    "            # 4. Monotonic date index\n",
    "            if cfg.enforce_monotonic_index and not clean.index.is_monotonic_increasing:\n",
    "                raise ValueError(\"Date index not monotonically increasing\")\n",
    "\n",
    "            # 5. Duplicate dates\n",
    "            if not cfg.allow_duplicate_dates and clean.index.duplicated().any():\n",
    "                raise ValueError(\"Duplicate dates detected in index\")\n",
    "\n",
    "            # 6. Coverage checks using config thresholds\n",
    "            m_ok = df.groupby(\"Month\")[f].apply(lambda col: col.notna().any())\n",
    "            mask = m_ok.reindex(span, fill_value=False).to_numpy()\n",
    "\n",
    "            # tolerance for missing months per-cfg\n",
    "            missing_count = (~mask).sum()\n",
    "            if missing_count > cfg.max_missing_months:\n",
    "                raise ValueError(f\"Missing-month count {missing_count} exceeds {cfg.max_missing_months}\")\n",
    "\n",
    "            # maximum run of consecutive missing months per-cfg with guard\n",
    "            temp = np.flatnonzero(np.r_[True, mask, True])\n",
    "            if temp.size <= 1:\n",
    "                gap = 0\n",
    "            else:\n",
    "                gap = np.diff(temp).max() - 1\n",
    "            if gap > cfg.max_consecutive_month_gap:\n",
    "                raise ValueError(f\"Consecutive-missing gap {gap} exceeds {cfg.max_consecutive_month_gap}\")\n",
    "\n",
    "            eligible_funds.append(f)\n",
    "\n",
    "        except ValueError as e:\n",
    "            logging.warning(\"Excluded %s: %s\", f, e)\n",
    "        except KeyError as e:\n",
    "            logging.warning(\"Missing data for %s: %s\", f, e)\n",
    "        except Exception as e:\n",
    "            logging.warning(\"Unexpected error on %s: %s\", f, e)\n",
    "\n",
    "    # Final selection-mode logic\n",
    "    if selection_mode == \"all\" or random_n is None:\n",
    "        return eligible_funds\n",
    "    if selection_mode == \"random\":\n",
    "        if random_n > len(eligible_funds):\n",
    "            raise ValueError(\n",
    "                f\"random_n exceeds eligible pool: {random_n} > {len(eligible_funds)}\"\n",
    "            )\n",
    "        return list(np.random.choice(eligible_funds, random_n, replace=False))\n",
    "\n",
    "    raise ValueError(f\"Unsupported selection_mode '{selection_mode}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 3. Weight Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  3 · WEIGHT PREP\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "def prepare_weights(selected: list[str],\n",
    "                    custom: Dict[str, int] | None) -> tuple[Dict[str, float], np.ndarray]:\n",
    "    if not custom:\n",
    "        w = {f: 1/len(selected) for f in selected}\n",
    "    else:\n",
    "        missing = [f for f in selected if f not in custom]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing weights for {missing}\")\n",
    "        w = {f: pct/100 for f, pct in custom.items()}\n",
    "        if abs(sum(w.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"Custom weights must sum to 100.\")\n",
    "    vec = np.array([w[f] for f in selected])\n",
    "    return w, vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 4. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Function definitions\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 4 · CORE STATS  +  RUN_ANALYSIS  (helpers included, weight fix)\n",
    "# ===============================================================\n",
    "\n",
    "M_PER_YEAR = 12           # constant used across helpers\n",
    "\n",
    "# ---------- helpers --------------------------------------------\n",
    "def _ensure_dt(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy whose Date column is datetime64[ns].\"\"\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3. Metric function definitions\n",
    "# === Metric Function Definitions with flexible annualization ===\n",
    "@register_metric(\"AnnualReturn\")\n",
    "def compute_annual_return(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Geometric annualized return based on periods_per_year.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    total_growth = (1 + r).prod()\n",
    "    n_periods = len(r)\n",
    "    return total_growth ** (periods_per_year / n_periods) - 1\n",
    "\n",
    "@register_metric(\"Volatility\")\n",
    "def compute_volatility(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Annualized standard deviation of returns with flexible scaling.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    return r.std(ddof=0) * np.sqrt(periods_per_year)\n",
    "\n",
    "@register_metric(\"Sharpe\")\n",
    "def compute_sharpe(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sharpe ratio using flexible annualized return and volatility.\n",
    "    \"\"\"\n",
    "    vol = compute_volatility(returns, periods_per_year=periods_per_year)\n",
    "    if vol == 0:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    return (ann_ret - risk_free) / vol\n",
    "\n",
    "@register_metric(\"Sortino\")\n",
    "def compute_sortino(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sortino ratio using flexible annualized return and downside deviation.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    # Define per-period risk-free rate\n",
    "    period_rf = risk_free / periods_per_year\n",
    "    excess = r - period_rf\n",
    "    downside = excess[excess < 0]\n",
    "    if downside.empty:\n",
    "        return np.nan\n",
    "    down_dev = np.sqrt((downside ** 2).mean()) * np.sqrt(periods_per_year)\n",
    "    if down_dev == 0:\n",
    "        return np.nan\n",
    "    return (ann_ret - risk_free) / down_dev\n",
    "\n",
    "@register_metric(\"MaxDrawdown\")\n",
    "def compute_max_drawdown(\n",
    "    returns: pd.Series,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Maximum drawdown (peak-to-trough) of cumulative returns.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    cum = (1 + r).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdown = (cum / peak) - 1\n",
    "    return float(drawdown.min())\n",
    "\n",
    "# Alias for backward compatibility\n",
    "_ann_vol = compute_volatility\n",
    "\n",
    "# === Aggregator with Centralized Error Handling ===\n",
    "\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    \"\"\"\n",
    "    Run each metric in cfg.metrics_to_run, returning a namedtuple of values.\n",
    "    Uses cfg.periods_per_year for annualization.\n",
    "    Centralized try/except ensures one failing metric doesn’t break the batch.\n",
    "    \"\"\"\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not registered\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            params = {\n",
    "                \"risk_free\": cfg.risk_free,\n",
    "                \"periods_per_year\": cfg.periods_per_year,\n",
    "                **metric_kwargs\n",
    "            }\n",
    "            val = fn(returns, **params)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"%s: division by zero, setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"%s: invalid input (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"%s: unexpected error (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "    return Stat(*values)\n",
    "\n",
    "# ---------- main ------------------------------------------------\n",
    "def run_analysis(\n",
    "    df,\n",
    "    selected,\n",
    "    w_vec,\n",
    "    w_dict,\n",
    "    rf_col,\n",
    "    in_start,\n",
    "    in_end,\n",
    "    out_start,\n",
    "    out_end,\n",
    "    target_vol,\n",
    "    monthly_cost,\n",
    "    indices_list\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorised run_analysis with correct weight re-normalisation\n",
    "    after funds are dropped.\n",
    "    Returns the same keys used by the UI and export functions.\n",
    "    \"\"\"\n",
    "    df = _ensure_dt(df)\n",
    "\n",
    "    # ---- date masks --------------------------------------------------\n",
    "    in_s = pd.to_datetime(in_start)  + pd.offsets.MonthEnd(0)\n",
    "    in_e = pd.to_datetime(in_end)    + pd.offsets.MonthEnd(0)\n",
    "    out_s= pd.to_datetime(out_start) + pd.offsets.MonthEnd(0)\n",
    "    out_e= pd.to_datetime(out_end)   + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    m_in  = df[\"Date\"].between(in_s,  in_e)\n",
    "    m_out = df[\"Date\"].between(out_s, out_e)\n",
    "\n",
    "    in_df,  out_df  = df.loc[m_in,  selected], df.loc[m_out, selected]\n",
    "    in_rf,  out_rf  = df.loc[m_in,  rf_col],   df.loc[m_out, rf_col]\n",
    "\n",
    "    # ---- drop funds with any NaNs in either window ------------------\n",
    "    good = [f for f in selected\n",
    "            if in_df[f].notna().all() and out_df[f].notna().all()]\n",
    "    dropped = list(set(selected) - set(good))\n",
    "    if dropped:\n",
    "        logging.warning(\"Dropped funds: %s\", dropped)\n",
    "\n",
    "    selected = good\n",
    "    # >>>> new guard: kick out any accidental index columns\n",
    "    selected = [f for f in selected if f not in (indices_list or [])]\n",
    "    # <<<<\n",
    "\n",
    "    in_df, out_df = in_df[selected], out_df[selected]\n",
    "\n",
    "    # rebuild weights\n",
    "    if w_dict is None:                      # equal-weight path\n",
    "        w_dict = {f: 1/len(selected) for f in selected}\n",
    "    else:                                   # manual path → rescale\n",
    "        pct   = {f: w_dict[f]*100 for f in selected}\n",
    "        total = sum(pct.values())\n",
    "        w_dict = {f: p/total for f, p in pct.items()}\n",
    "    w_vec = np.array([w_dict[f] for f in selected])\n",
    "\n",
    "    # ---- scaling ----------------------------------------------------\n",
    "    vols = in_df.apply(compute_volatility)\n",
    "    scale = np.where(vols > 0, target_vol / vols, 1.0)\n",
    "    in_sc  = (in_df * scale) - monthly_cost\n",
    "    out_sc = (out_df * scale) - monthly_cost\n",
    "    in_sc.clip(lower=-1, inplace=True)\n",
    "    out_sc.clip(lower=-1, inplace=True)\n",
    "\n",
    "    # ---- stats ------------------------------------------------------\n",
    "    rf_value = in_rf.mean() if hasattr(in_rf, \"mean\") else float(in_rf)\n",
    "\n",
    "    # Create a RiskStatsConfig for in-sample stats\n",
    "    stats_cfg = RiskStatsConfig(\n",
    "        risk_free       = rf_value,\n",
    "        periods_per_year= cfg.periods_per_year  # if you want to carry over freq\n",
    "    )\n",
    "    \n",
    "    # Now compute stats for each scenario, always passing stats_cfg first\n",
    "    in_stat = {\n",
    "        f: _stats(in_sc[f],     stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "    out_rf_value = out_rf.mean() if hasattr(out_rf, \"mean\") else float(out_rf)\n",
    "    \n",
    "    # Re‐use the same config, updating only the risk_free field\n",
    "    stats_cfg.risk_free = out_rf_value\n",
    "    \n",
    "    out_stat = {\n",
    "        f: _stats(out_sc[f],    stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "\n",
    "    ew_vec = np.full(len(selected), 1/len(selected))\n",
    "    w_vec = np.full(len(selected), 1/len(selected))\n",
    "\n",
    "    in_ew_stats  = _stats(in_sc.dot(ew_vec),  stats_cfg)\n",
    "    out_ew_stats = _stats(out_sc.dot(ew_vec), stats_cfg)\n",
    "    in_user_stats  = _stats(in_sc.dot(w_vec),  stats_cfg)\n",
    "    out_user_stats = _stats(out_sc.dot(w_vec), stats_cfg)\n",
    "\n",
    "    results = {\n",
    "        \"selected_funds\": selected,\n",
    "        \"indices_list\":   indices_list or [],\n",
    "        \"fund_weights\":   w_dict,\n",
    "        \"ew_weights\":     {f: 1/len(selected) for f in selected},\n",
    "        \"in_sample_stats\":  in_stat,\n",
    "        \"out_sample_stats\": out_stat,\n",
    "        \"in_ew_stats\":     in_ew_stats,\n",
    "        \"out_ew_stats\":    out_ew_stats,\n",
    "        \"in_user_stats\":   in_user_stats,\n",
    "        \"out_user_stats\":  out_user_stats,\n",
    "        \"dropped\":         dropped,\n",
    "    }\n",
    "\n",
    "    # ---- optional index stats ---------------------------------------\n",
    "    if indices_list:\n",
    "        idx_stats = {}\n",
    "        for col in indices_list:\n",
    "            idx_stats[col] = {\n",
    "                \"in_sample\":  _stats(df.loc[m_in,  col], in_rf),\n",
    "                \"out_sample\": _stats(df.loc[m_out, col], out_rf),\n",
    "            }\n",
    "        results[\"index_stats\"] = idx_stats\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 5. Excel Export\n",
    "Creates an Excel file with In-Sample, Out-of-Sample and Equal-weight and User-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  5 · EXPORT  (NaN-safe, weight-format fix)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# ───────── 5 · EXPORT  (final, bug-free) ───────────────────────\n",
    "# ───────── 5 · EXPORT  (self-healing index section) ───────────\n",
    "# ───────── 5 · EXPORT  (final safe version) ───────────────────\n",
    "\n",
    "def export_to_excel(\n",
    "    data: dict[str, pd.DataFrame],\n",
    "    output_path: str,\n",
    "    default_format: Optional[Callable] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Exports each DataFrame in `data` to its own sheet in `output_path`.\n",
    "    Applies a registered formatter for each category (sheet name).\n",
    "    If no formatter is found, applies `default_format` if provided.\n",
    "\n",
    "    For the Summary sheet, data is written starting at row 5 to make room for custom headers.\n",
    "    \"\"\"\n",
    "    startrows = {\"Summary\": 5}\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        for category, df in data.items():\n",
    "            startrow = startrows.get(category, 0)\n",
    "            df.to_excel(writer, sheet_name=category, index=False, startrow=startrow)\n",
    "            fmt_fn = FORMATTERS_EXCEL.get(category)\n",
    "            if fmt_fn:\n",
    "                fmt_fn(writer.sheets[category], writer.book)\n",
    "            elif default_format:\n",
    "                default_format(writer.sheets[category], writer.book)\n",
    "    # Workbook is auto-saved and closed by the context manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 6. Run Parameters,Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48de568-962e-4690-a6fc-be7a4ec0a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf9de680a994704bfa186baf6ca388a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>1. Load data</h4>'), ToggleButtons(description='Source:', options=(('Local', 'l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#            STREAMLINED ANALYSIS UI  (phase-2 clean)\n",
    "# ===============================================================\n",
    "\n",
    "# ---------- session store ----------\n",
    "session = {\"df\": None, \"rf\": None, \"sel\": None, \"cweights\": None}\n",
    "\n",
    "# ---------- 1 · DATA LOAD ----------\n",
    "src = widgets.ToggleButtons(\n",
    "    options=[(\"Local\", \"local\"), (\"URL\", \"url\")],\n",
    "    description=\"Source:\"\n",
    ")\n",
    "\n",
    "chooser = FileChooser()\n",
    "url_box = widgets.Text(placeholder=\"https://…/file.csv\", layout={\"width\":\"70%\"})\n",
    "load_btn = widgets.Button(description=\"Load CSV\", button_style=\"success\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "def _toggle_src(c):\n",
    "    chooser.layout.display = \"block\" if c[\"new\"]==\"local\" else \"none\"\n",
    "    url_box.layout.display  = \"block\" if c[\"new\"]==\"url\"   else \"none\"\n",
    "src.observe(_toggle_src, names=\"value\"); _toggle_src({\"new\":src.value})\n",
    "\n",
    "def _load(_):\n",
    "    with load_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            path = chooser.selected if src.value==\"local\" else url_box.value.strip()\n",
    "            if not path: raise ValueError(\"choose file / URL\")\n",
    "            if src.value==\"url\" and not path.lower().endswith(\".csv\"):\n",
    "                raise ValueError(\"URL must end with .csv\")\n",
    "            df = load_csv(path)\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")  # single coercion\n",
    "            rf = identify_risk_free_fund(df)\n",
    "            session.update(df=df, rf=rf, sel=None, cweights=None)\n",
    "            print(f\"✅ Loaded {len(df):,} rows × {df.shape[1]} cols | RF → {rf}\")\n",
    "        except Exception as e:\n",
    "            print(\"❌\", e); session[\"df\"]=None\n",
    "load_btn.on_click(_load)\n",
    "\n",
    "# ---------- 2 · PARAMS ------------\n",
    "index_cnt = widgets.BoundedIntText(0, min=0, max=10, description=\"# Indices:\")\n",
    "in_start,in_end  = widgets.Text(\"2005-07\"), widgets.Text(\"2008-06\")\n",
    "out_start,out_end= widgets.Text(\"2008-07\"), widgets.Text(\"2009-06\")\n",
    "for w,lbl in [(in_start,\"In Start:\"),(in_end,\"In End:\"),\n",
    "              (out_start,\"Out Start:\"),(out_end,\"Out End:\")]:\n",
    "    w.description = lbl\n",
    "target_vol   = widgets.FloatText(0.25,  description=\"Target Vol:\")\n",
    "monthly_cost = widgets.FloatText(0.0033, description=\"Monthly Cost:\")\n",
    "\n",
    "# ---------- 3 · SELECTION ----------\n",
    "mode_dd = widgets.Dropdown(\n",
    "    options=[(\"All\", \"all\"), (\"Random\", \"random\"), (\"Manual\", \"manual\")],\n",
    "    value=\"all\",\n",
    "    description=\"Mode:\"\n",
    ")\n",
    "rand_n   = widgets.BoundedIntText(5, min=2, max=100, description=\"Sample N:\")\n",
    "fund_table, total_lbl = widgets.VBox([]), widgets.Label(\"Total = 0 %\")\n",
    "\n",
    "def _toggle_sel(_=None):\n",
    "    rand_n.layout.display  = \"block\" if mode_dd.value==\"random\" else \"none\"\n",
    "    vis = \"block\" if mode_dd.value==\"manual\" else \"none\"\n",
    "    fund_table.layout.display = total_lbl.layout.display = vis\n",
    "mode_dd.observe(_toggle_sel, names=\"value\"); _toggle_sel()\n",
    "\n",
    "# ---------- helpers ---------------\n",
    "def _eligible_pool():\n",
    "    df, rf = session[\"df\"], session[\"rf\"]\n",
    "    if df is None: \n",
    "        print(\"⚠️ data not loaded\"); return []\n",
    "\n",
    "    # ---- date parse guard -----------------------------------\n",
    "    try:\n",
    "        in_s  = pd.to_datetime(in_start.value)+pd.offsets.MonthEnd(0)\n",
    "        in_e  = pd.to_datetime(in_end.value)  +pd.offsets.MonthEnd(0)\n",
    "        out_s = pd.to_datetime(out_start.value)+pd.offsets.MonthEnd(0)\n",
    "        out_e = pd.to_datetime(out_end.value)  +pd.offsets.MonthEnd(0)\n",
    "    except Exception:\n",
    "        print(\"❌ invalid dates\"); return []\n",
    "\n",
    "    # ---- build indices (RIGHT-most idx_n non-RF columns) ----\n",
    "    idx_n     = index_cnt.value\n",
    "    data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "    non_rf    = [c for c in data_cols if c != rf]\n",
    "    indices   = non_rf[-idx_n:] if idx_n else []          # <- fixed\n",
    "    cand      = [c for c in data_cols if c not in indices]\n",
    "\n",
    "    # ---- run select_funds ----------------------------------\n",
    "    elig = select_funds(\n",
    "        df=df,\n",
    "        rf_col=rf,\n",
    "        fund_columns=cand,\n",
    "        in_sdate=in_s,\n",
    "        in_edate=in_e,\n",
    "        out_sdate=out_s,\n",
    "        out_edate=out_e,\n",
    "        cfg=cfg,                     # ← Explicitly supply your config here\n",
    "        selection_mode=\"all\",\n",
    "    )\n",
    "    # … diagnostics print unchanged …\n",
    "    return elig\n",
    "\n",
    "def _build_manual(*_):\n",
    "    if mode_dd.value!=\"manual\" or session[\"df\"] is None: return\n",
    "    valid = _eligible_pool()\n",
    "    print(\"DEBUG  eligible funds =\", len(valid))              # ← line 1\n",
    "    print(\"DEBUG  list sample   →\", valid[:25], \"…\")           # ← line 2\n",
    "    if not valid:\n",
    "        print(\"❌ No eligible funds\"); return \n",
    "    fund_table.children = []                # reset\n",
    "\n",
    "    def _update_total(*_):\n",
    "        tot = sum(r.children[1].value for r in fund_table.children\n",
    "                  if r.children[0].value)\n",
    "        total_lbl.value = f\"Total = {tot} %\"\n",
    "\n",
    "    for f in valid:\n",
    "        cb = widgets.Checkbox(description=f, layout={\"width\":\"200px\"})\n",
    "        wt = widgets.BoundedIntText(0, min=0, max=100,\n",
    "                                    layout={\"width\":\"60px\"}, disabled=True)\n",
    "        def _toggle(ch, box=wt):           # single observer\n",
    "            box.disabled = not ch[\"new\"]\n",
    "            if box.disabled: box.value = 0\n",
    "            _update_total()\n",
    "        cb.observe(_toggle, names=\"value\")\n",
    "        wt.observe(_update_total, names=\"value\")\n",
    "        fund_table.children += (widgets.HBox([cb, wt]),)\n",
    "    _update_total()\n",
    "\n",
    "mode_dd.observe(lambda ch: _build_manual() if ch[\"new\"]==\"manual\" else None,\n",
    "                names=\"value\")\n",
    "for w in (in_start,in_end,out_start,out_end): w.observe(_build_manual,names=\"value\")\n",
    "\n",
    "# ---------- 4 · RUN ---------------\n",
    "run_btn = widgets.Button(description=\"Run Analysis\", button_style=\"success\")\n",
    "run_out = widgets.Output(layout={\"border\":\"1px solid #999\",\n",
    "                                 \"height\":\"340px\",\"overflow_y\":\"auto\"})\n",
    "\n",
    "def _run(_):\n",
    "    with run_out:\n",
    "        clear_output()\n",
    "        df, rf = session[\"df\"], session[\"rf\"]\n",
    "        if df is None: print(\"⚠️ Load data first\"); return\n",
    "\n",
    "        # indices (robust)\n",
    "        idx_n     = index_cnt.value\n",
    "        data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "        non_rf    = [c for c in data_cols if c != rf]\n",
    "        indices   = non_rf[-idx_n:] if idx_n else [] \n",
    "\n",
    "        # pool + selection\n",
    "        pool = _eligible_pool()\n",
    "        if not pool: print(\"❌ No eligible funds\"); return\n",
    "        if mode_dd.value==\"all\":\n",
    "            sel, custom = pool, None\n",
    "        elif mode_dd.value==\"random\":\n",
    "            if rand_n.value>len(pool): print(\"⚠️ Sample N too big\"); return\n",
    "            sel, custom = list(np.random.choice(pool, rand_n.value, replace=False)), None\n",
    "        else:\n",
    "            sel, custom = [], {}\n",
    "            if not fund_table.children: _build_manual()\n",
    "            for row in fund_table.children:\n",
    "                cb, wt = row.children\n",
    "                if cb.value: sel.append(cb.description); custom[cb.description]=wt.value\n",
    "            if sum(custom.values())!=100: print(\"⚠️ Weights ≠ 100\"); return\n",
    "\n",
    "        w_dict,w_vec = prepare_weights(sel, custom)\n",
    "\n",
    "        res = run_analysis(df, sel, w_vec, w_dict, rf,\n",
    "                           in_start.value, in_end.value,\n",
    "                           out_start.value, out_end.value,\n",
    "                           target_vol.value, monthly_cost.value,\n",
    "                           indices)\n",
    "\n",
    "        print(\"✅ analysis complete |\", len(sel), \"funds\")\n",
    "        if res[\"dropped\"]:\n",
    "            print(\"⚠️ Dropped:\", res[\"dropped\"])\n",
    "        if indices: print(\"📊 Indices:\", indices)\n",
    "\n",
    "        fname=f\"IS_{in_start.value}_{out_start.value}.xlsx\"\n",
    "        export_to_excel(res, df, fname,\n",
    "                        in_start.value,in_end.value,\n",
    "                        out_start.value,out_end.value)\n",
    "        print(\"Workbook saved as\", fname)\n",
    "\n",
    "run_btn.on_click(_run)\n",
    "\n",
    "# ---------- DISPLAY --------------\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h4>1. Load data</h4>\"),\n",
    "    src, chooser, url_box, load_btn, load_out,\n",
    "    widgets.HTML(\"<hr><h4>2. Parameters</h4>\"),\n",
    "    widgets.HBox([index_cnt]),\n",
    "    widgets.HBox([in_start,in_end,out_start,out_end]),\n",
    "    widgets.HBox([target_vol,monthly_cost]),\n",
    "    widgets.HTML(\"<hr><h4>3. Fund selection</h4>\"),\n",
    "    widgets.HBox([mode_dd,rand_n]),\n",
    "    fund_table, total_lbl,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    run_btn,\n",
    "    run_out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b797fd-513c-42a7-b825-3fd5cae034be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
