{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22994893-0193-45bc-b9e3-a97b328ecaea",
   "metadata": {
    "id": "22994893-0193-45bc-b9e3-a97b328ecaea"
   },
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Imports, Data Loader and Rf Detector\n",
    "2. Select fund (month period logic)\n",
    "3. Weight prep\n",
    "4. Core Stats + Run Analysis\n",
    "5. Export\n",
    "6. Widget /UI\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea203f",
   "metadata": {
    "id": "30ea203f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#      VOL-ADJ TREND ANALYSIS  –  SINGLE-FILE VERSION\n",
    "# ===============================================================\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  0 · IMPORTS  (all in one place)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from collections import namedtuple\n",
    "# import xlsxwriter\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "from typing import List, Dict, Optional, Callable\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  1 · Class Configurations\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "@dataclass\n",
    "class FundSelectionConfig:\n",
    "    max_missing_months:         int = 3   # used to replace the “<=3 missing” rule\n",
    "    max_consecutive_month_gap:  int = 6   # used to replace the “<=6 gap” ruleimplausible_value_limit: float = 1.0\n",
    "    implausible_value_limit: float  = 1\n",
    "    outlier_threshold: float = 0.5\n",
    "    zero_return_threshold: float = 0.2\n",
    "    enforce_monotonic_index: bool = True\n",
    "    allow_duplicate_dates: bool = False\n",
    "    max_missing_ratio: float      = 0.05\n",
    "    max_drawdown: float           = 0.3\n",
    "    min_volatility: float         = 0.05\n",
    "    max_volatility: float         = 1.0\n",
    "    min_avg_return: float         = 0.0\n",
    "    max_skewness: float           = 3.0\n",
    "    max_kurtosis: float           = 10.0\n",
    "    expected_freq: str            = \"B\"\n",
    "    max_gap_days: int             = 3\n",
    "    min_aum_usd: float            = 1e7\n",
    "\n",
    "# Configuration dataclass\n",
    "@dataclass\n",
    "class RiskStatsConfig:\n",
    "    \"\"\"\n",
    "    Configuration for which metrics to run, risk-free rate, and data frequency.\n",
    "    periods_per_year specifies the number of data points per year (e.g., 12 for monthly).\n",
    "    \"\"\"\n",
    "    metrics_to_run: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"AnnualReturn\",\n",
    "            \"Volatility\",\n",
    "            \"Sharpe\",\n",
    "            \"Sortino\",\n",
    "            \"MaxDrawdown\",\n",
    "        ]\n",
    "    )\n",
    "    # Annualized risk-free rate for ratio computations\n",
    "    risk_free: float = 0.0\n",
    "    # Number of periods per year (e.g., 12 for monthly, 252 for daily)\n",
    "    periods_per_year: int = 12\n",
    "\n",
    "# 2. Registry and decorator\n",
    "METRIC_REGISTRY: Dict[str, Callable[..., float]] = {}\n",
    "\n",
    "def register_metric(name: str):\n",
    "    \"\"\"\n",
    "    Decorator to register a metric function under a given name.\n",
    "    \"\"\"\n",
    "    def decorator(fn: Callable[..., float]):\n",
    "        METRIC_REGISTRY[name] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "FORMATTERS_EXCEL: dict[str, Callable] = {}\n",
    "def register_formatter_excel(category: str):\n",
    "    def decorator(fn: Callable):\n",
    "        FORMATTERS_EXCEL[category] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "# Example formatters (extend as needed)\n",
    "@register_formatter_excel(\"portfolio\")\n",
    "def fmt_portfolio(ws, wb):\n",
    "    header_fmt = wb.add_format({\"bold\": True, \"bottom\": 2})\n",
    "    ws.set_row(0, None, header_fmt)\n",
    "\n",
    "@register_formatter_excel(\"indices\")\n",
    "def fmt_indices(ws, wb):\n",
    "    \"\"\"\n",
    "    Formatter for the indices sheet: inserts a blank column where 'Weight' would be,\n",
    "    then draws a border around the entire table.\n",
    "    \"\"\"\n",
    "    # 1. Insert a blank column at position 1 (after the 'Name' column)\n",
    "    #    This creates the space where fund weights would sit for other sheets.\n",
    "    ws.set_column(1, 1, 5)  # width 5 (or adjust as needed)\n",
    "\n",
    "    # 2. Apply a border around all non-blank cells\n",
    "    box_fmt = wb.add_format({\"border\": 1})\n",
    "    max_row = ws.dim_rowmax\n",
    "    max_col = ws.dim_colmax\n",
    "    ws.conditional_format(0, 0, max_row, max_col, {\"type\": \"no_errors\", \"format\": box_fmt})\n",
    "    box = wb.add_format({\"border\": 1}); r,c = ws.dim_rowmax, ws.dim_colmax\n",
    "    ws.conditional_format(0, 0, r, c, {\"type\":\"no_errors\",\"format\":box})\n",
    "\n",
    "    # Note: DataFrame rows should start at row index 5 via export_to_excel startrow\n",
    "def make_summary_formatter(summary_df, in_start, in_end, out_start, out_end, in_stat, out_stat, weights):\n",
    "    @register_formatter_excel(\"Summary\")\n",
    "    def fmt_summary(ws, wb):\n",
    "        bold = wb.add_format({\"bold\": True})\n",
    "        int0 = wb.add_format({\"num_format\": \"0\"})\n",
    "        num2 = wb.add_format({\"num_format\": \"0.00\"})\n",
    "        red  = wb.add_format({\"num_format\": \"0.00\", \"font_color\": \"red\"})\n",
    "        safe = lambda v: \"\" if (pd.isna(v) or not np.isfinite(v)) else v\n",
    "        pct  = lambda t: [t[0]*100, t[1]*100, t[2], t[3], t[4]*100]\n",
    "\n",
    "        # Write your static headers:\n",
    "        ws.write_row(0, 0, [\"Vol-Adj Trend Analysis\"], bold)\n",
    "        ws.write_row(1, 0, [f\"In:  {in_start} → {in_end}\"])\n",
    "        ws.write_row(2, 0, [f\"Out: {out_start} → {out_end}\"])\n",
    "\n",
    "        # Column headers:\n",
    "        hdr = [...]\n",
    "        ws.write_row(4, 0, hdr, bold)\n",
    "\n",
    "        # Now the manual loop, using the _captured_ summary_df, in_stat, etc:\n",
    "        row = 5\n",
    "        for fund in summary_df[\"Name\"]:\n",
    "            tin = in_stat[fund]\n",
    "            tout= out_stat[fund]\n",
    "            wt  = weights[fund]\n",
    "            # write name & weight\n",
    "            ws.write(row, 0, fund, bold)\n",
    "            ws.write(row, 1, safe(wt * 100), int0)\n",
    "            vals = pct(tuple(tin)) + pct(tuple(tout))\n",
    "            fmts = [num2, num2, num2, num2, red] * 2\n",
    "            for i, (v, fmt) in enumerate(zip(vals, fmts), start=2):\n",
    "                ws.write(row, i, safe(v), fmt)\n",
    "            row += 1\n",
    "\n",
    "    return fmt_summary\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "#  2 · CSV LOADER + RF DETECTOR\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(f\"No data in file: {path}\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Parsing error in {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"Date\" not in df.columns:\n",
    "        logger.error(f\"Validation failed ({path}): missing 'Date' column\")\n",
    "        return None\n",
    "\n",
    "    # Optionally check for NaNs in 'Date' column\n",
    "    if df[\"Date\"].isnull().any():\n",
    "        logger.warning(f\"Null values found in 'Date' column of {path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_risk_free_fund(df: pd.DataFrame) -> str:\n",
    "    returns = df.drop(columns=\"Date\", errors=\"ignore\")\n",
    "    stdevs  = returns.std(skipna=True, ddof=0)\n",
    "    return stdevs.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {
    "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c"
   },
   "source": [
    "## 2. Select Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {
    "id": "ff528d69-5a52-4b75-8af4-17974826f4ab"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 2 · SELECT_FUNDS  (restored ≤ 3-missing-months rule)\n",
    "# ===============================================================\n",
    "\n",
    "cfg = FundSelectionConfig(\n",
    "    max_missing_months           = 3,\n",
    "    max_consecutive_month_gap    = 6,\n",
    "    outlier_threshold            = 0.5,\n",
    "    zero_return_threshold        = 0.2,\n",
    "    enforce_monotonic_index      = True,\n",
    "    allow_duplicate_dates        = False,\n",
    "    max_missing_ratio            = 0.05,\n",
    "    max_drawdown                 = 0.3,\n",
    "    min_volatility               = 0.05,\n",
    "    max_volatility               = 1.0,\n",
    "    min_avg_return               = 0.0,\n",
    "    max_skewness                 = 3.0,\n",
    "    max_kurtosis                 = 10.0,\n",
    "    expected_freq                = \"B\",\n",
    "    max_gap_days                 = 3,\n",
    "    min_aum_usd                  = 1e7,\n",
    ")\n",
    "\n",
    "def select_funds(\n",
    "    df: pd.DataFrame,\n",
    "    rf_col: str,\n",
    "    fund_columns: list[str],\n",
    "    in_sdate: str,\n",
    "    in_edate: str,\n",
    "    out_sdate: str,\n",
    "    out_edate: str,\n",
    "    cfg: FundSelectionConfig,\n",
    "    selection_mode: str = \"all\",\n",
    "    random_n: int | None = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Select eligible funds with additional data-validity and coverage checks driven by FundSelectionConfig.\n",
    "    \"\"\"\n",
    "    # Ensure Date is datetime and sorted\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        df = df.copy()\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    df = df.sort_values(\"Date\")  # guarantee monotonic index\n",
    "\n",
    "    # Prepare monthly periods within analysis window\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    span = pd.period_range(\n",
    "        pd.Period(in_sdate, \"M\"), pd.Period(out_edate, \"M\"), freq=\"M\"\n",
    "    )\n",
    "\n",
    "    eligible_funds: list[str] = []\n",
    "    for f in fund_columns:\n",
    "        try:\n",
    "            ser = df.set_index(\"Date\")[f]\n",
    "            clean = ser.dropna()\n",
    "\n",
    "            # 1. Implausible value limits\n",
    "            if not clean.between(-cfg.implausible_value_limit, cfg.implausible_value_limit).all():\n",
    "                raise ValueError(f\"Values outside ±{cfg.implausible_value_limit}\")\n",
    "\n",
    "            # 2. Extreme outlier threshold\n",
    "            if (clean.abs() > cfg.outlier_threshold).any():\n",
    "                raise ValueError(f\"Outliers beyond ±{cfg.outlier_threshold}\")\n",
    "\n",
    "            # 3. Excessive zero-return rate\n",
    "            if (clean == 0).mean() > cfg.zero_return_threshold:\n",
    "                raise ValueError(f\"Zero-return proportion > {cfg.zero_return_threshold}\")\n",
    "\n",
    "            # 4. Monotonic date index\n",
    "            if cfg.enforce_monotonic_index and not clean.index.is_monotonic_increasing:\n",
    "                raise ValueError(\"Date index not monotonically increasing\")\n",
    "\n",
    "            # 5. Duplicate dates\n",
    "            if not cfg.allow_duplicate_dates and clean.index.duplicated().any():\n",
    "                raise ValueError(\"Duplicate dates detected in index\")\n",
    "\n",
    "            # 6. Coverage checks using config thresholds\n",
    "            m_ok = df.groupby(\"Month\")[f].apply(lambda col: col.notna().any())\n",
    "            mask = m_ok.reindex(span, fill_value=False).to_numpy()\n",
    "\n",
    "            # tolerance for missing months per-cfg\n",
    "            missing_count = (~mask).sum()\n",
    "            if missing_count > cfg.max_missing_months:\n",
    "                raise ValueError(f\"Missing-month count {missing_count} exceeds {cfg.max_missing_months}\")\n",
    "\n",
    "            # maximum run of consecutive missing months per-cfg with guard\n",
    "            temp = np.flatnonzero(np.r_[True, mask, True])\n",
    "            if temp.size <= 1:\n",
    "                gap = 0\n",
    "            else:\n",
    "                gap = np.diff(temp).max() - 1\n",
    "            if gap > cfg.max_consecutive_month_gap:\n",
    "                raise ValueError(f\"Consecutive-missing gap {gap} exceeds {cfg.max_consecutive_month_gap}\")\n",
    "\n",
    "            eligible_funds.append(f)\n",
    "\n",
    "        except ValueError as e:\n",
    "            logging.warning(\"Excluded %s: %s\", f, e)\n",
    "        except KeyError as e:\n",
    "            logging.warning(\"Missing data for %s: %s\", f, e)\n",
    "        except Exception as e:\n",
    "            logging.warning(\"Unexpected error on %s: %s\", f, e)\n",
    "\n",
    "    # Final selection-mode logic\n",
    "    if selection_mode == \"all\" or random_n is None:\n",
    "        return eligible_funds\n",
    "    if selection_mode == \"random\":\n",
    "        if random_n > len(eligible_funds):\n",
    "            raise ValueError(\n",
    "                f\"random_n exceeds eligible pool: {random_n} > {len(eligible_funds)}\"\n",
    "            )\n",
    "        return list(np.random.choice(eligible_funds, random_n, replace=False))\n",
    "\n",
    "    raise ValueError(f\"Unsupported selection_mode '{selection_mode}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {
    "id": "ac53bc18"
   },
   "source": [
    "## 3. Weight Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9bf13",
   "metadata": {
    "id": "59a9bf13"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  3 · WEIGHT PREP\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "def prepare_weights(selected: list[str],\n",
    "                    custom: Dict[str, int] | None) -> tuple[Dict[str, float], np.ndarray]:\n",
    "    if not custom:\n",
    "        w = {f: 1/len(selected) for f in selected}\n",
    "    else:\n",
    "        missing = [f for f in selected if f not in custom]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing weights for {missing}\")\n",
    "        w = {f: pct/100 for f, pct in custom.items()}\n",
    "        if abs(sum(w.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"Custom weights must sum to 100.\")\n",
    "    vec = np.array([w[f] for f in selected])\n",
    "    return w, vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {
    "id": "b3666a84"
   },
   "source": [
    "## 4. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Function definitions\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44",
   "metadata": {
    "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 4 · CORE STATS  +  RUN_ANALYSIS  (helpers included, weight fix)\n",
    "# ===============================================================\n",
    "\n",
    "M_PER_YEAR = 12           # constant used across helpers\n",
    "\n",
    "# ---------- helpers --------------------------------------------\n",
    "def _ensure_dt(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy whose Date column is datetime64[ns].\"\"\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3. Metric function definitions\n",
    "# === Metric Function Definitions with flexible annualization ===\n",
    "@register_metric(\"AnnualReturn\")\n",
    "def compute_annual_return(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Geometric annualized return based on periods_per_year.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    total_growth = (1 + r).prod()\n",
    "    n_periods = len(r)\n",
    "    return total_growth ** (periods_per_year / n_periods) - 1\n",
    "\n",
    "@register_metric(\"Volatility\")\n",
    "def compute_volatility(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Annualized standard deviation of returns with flexible scaling.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    return r.std(ddof=0) * np.sqrt(periods_per_year)\n",
    "\n",
    "@register_metric(\"Sharpe\")\n",
    "def compute_sharpe(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sharpe ratio using flexible annualized return and volatility.\n",
    "    \"\"\"\n",
    "    vol = compute_volatility(returns, periods_per_year=periods_per_year)\n",
    "    if vol == 0:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    return (ann_ret - risk_free) / vol\n",
    "\n",
    "@register_metric(\"Sortino\")\n",
    "def compute_sortino(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sortino ratio using flexible annualized return and downside deviation.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    # Define per-period risk-free rate\n",
    "    period_rf = risk_free / periods_per_year\n",
    "    excess = r - period_rf\n",
    "    downside = excess[excess < 0]\n",
    "    if downside.empty:\n",
    "        return np.nan\n",
    "    down_dev = np.sqrt((downside ** 2).mean()) * np.sqrt(periods_per_year)\n",
    "    if down_dev == 0:\n",
    "        return np.nan\n",
    "    return (ann_ret - risk_free) / down_dev\n",
    "\n",
    "@register_metric(\"MaxDrawdown\")\n",
    "def compute_max_drawdown(\n",
    "    returns: pd.Series,\n",
    "    **kwargs\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Maximum drawdown (peak-to-trough) of cumulative returns.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    cum = (1 + r).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdown = (cum / peak) - 1\n",
    "    return float(drawdown.min())\n",
    "\n",
    "# Alias for backward compatibility\n",
    "_ann_vol = compute_volatility\n",
    "\n",
    "# === Aggregator with Centralized Error Handling ===\n",
    "\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    \"\"\"\n",
    "    Run each metric in cfg.metrics_to_run, returning a namedtuple of values.\n",
    "    Uses cfg.periods_per_year for annualization.\n",
    "    Centralized try/except ensures one failing metric doesn’t break the batch.\n",
    "    \"\"\"\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not registered\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            params = {\n",
    "                \"risk_free\": cfg.risk_free,\n",
    "                \"periods_per_year\": cfg.periods_per_year,\n",
    "                **metric_kwargs\n",
    "            }\n",
    "            val = fn(returns, **params)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"%s: division by zero, setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"%s: invalid input (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"%s: unexpected error (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "    return Stat(*values)\n",
    "\n",
    "# ---------- main ------------------------------------------------\n",
    "def run_analysis(\n",
    "    df,\n",
    "    selected,\n",
    "    w_vec,\n",
    "    w_dict,\n",
    "    rf_col,\n",
    "    in_start,\n",
    "    in_end,\n",
    "    out_start,\n",
    "    out_end,\n",
    "    target_vol,\n",
    "    monthly_cost,\n",
    "    indices_list\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorised run_analysis with correct weight re-normalisation\n",
    "    after funds are dropped.\n",
    "    Returns the same keys used by the UI and export functions.\n",
    "    \"\"\"\n",
    "    df = _ensure_dt(df)\n",
    "\n",
    "    # ---- date masks --------------------------------------------------\n",
    "    in_s = pd.to_datetime(in_start)  + pd.offsets.MonthEnd(0)\n",
    "    in_e = pd.to_datetime(in_end)    + pd.offsets.MonthEnd(0)\n",
    "    out_s= pd.to_datetime(out_start) + pd.offsets.MonthEnd(0)\n",
    "    out_e= pd.to_datetime(out_end)   + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    m_in  = df[\"Date\"].between(in_s,  in_e)\n",
    "    m_out = df[\"Date\"].between(out_s, out_e)\n",
    "\n",
    "    in_df,  out_df  = df.loc[m_in,  selected], df.loc[m_out, selected]\n",
    "    in_rf,  out_rf  = df.loc[m_in,  rf_col],   df.loc[m_out, rf_col]\n",
    "\n",
    "    # ---- drop funds with any NaNs in either window ------------------\n",
    "    good = [f for f in selected\n",
    "            if in_df[f].notna().all() and out_df[f].notna().all()]\n",
    "    dropped = list(set(selected) - set(good))\n",
    "    if dropped:\n",
    "        logging.warning(\"Dropped funds: %s\", dropped)\n",
    "\n",
    "    selected = good\n",
    "    # >>>> new guard: kick out any accidental index columns\n",
    "    selected = [f for f in selected if f not in (indices_list or [])]\n",
    "    # <<<<\n",
    "\n",
    "    in_df, out_df = in_df[selected], out_df[selected]\n",
    "\n",
    "    # rebuild weights\n",
    "    if w_dict is None:                      # equal-weight path\n",
    "        w_dict = {f: 1/len(selected) for f in selected}\n",
    "    else:                                   # manual path → rescale\n",
    "        pct   = {f: w_dict[f]*100 for f in selected}\n",
    "        total = sum(pct.values())\n",
    "        w_dict = {f: p/total for f, p in pct.items()}\n",
    "    w_vec = np.array([w_dict[f] for f in selected])\n",
    "\n",
    "    # ---- scaling ----------------------------------------------------\n",
    "    vols = in_df.apply(compute_volatility)\n",
    "    scale = np.where(vols > 0, target_vol / vols, 1.0)\n",
    "    in_sc  = (in_df * scale) - monthly_cost\n",
    "    out_sc = (out_df * scale) - monthly_cost\n",
    "    in_sc.clip(lower=-1, inplace=True)\n",
    "    out_sc.clip(lower=-1, inplace=True)\n",
    "\n",
    "    # ---- stats ------------------------------------------------------\n",
    "    rf_value = in_rf.mean() if hasattr(in_rf, \"mean\") else float(in_rf)\n",
    "\n",
    "    # Create a RiskStatsConfig for in-sample stats\n",
    "    stats_cfg = RiskStatsConfig(risk_free=rf_value)\n",
    "\n",
    "    # Now compute stats for each scenario, always passing stats_cfg first\n",
    "    in_stat = {\n",
    "        f: _stats(in_sc[f], stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "    out_rf_value = out_rf.mean() if hasattr(out_rf, \"mean\") else float(out_rf)\n",
    "\n",
    "    # Re‐use the same config, updating only the risk_free field\n",
    "    stats_cfg.risk_free = out_rf_value\n",
    "\n",
    "    out_stat = {\n",
    "        f: _stats(out_sc[f], stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "\n",
    "    ew_vec = np.full(len(selected), 1/len(selected))\n",
    "    w_vec = np.full(len(selected), 1/len(selected))\n",
    "\n",
    "    in_ew_stats  = _stats(in_sc.dot(ew_vec),  stats_cfg)\n",
    "    out_ew_stats = _stats(out_sc.dot(ew_vec), stats_cfg)\n",
    "    in_user_stats  = _stats(in_sc.dot(w_vec),  stats_cfg)\n",
    "    out_user_stats = _stats(out_sc.dot(w_vec), stats_cfg)\n",
    "\n",
    "    results = {\n",
    "        \"selected_funds\": selected,\n",
    "        \"indices_list\":   indices_list or [],\n",
    "        \"fund_weights\":   w_dict,\n",
    "        \"ew_weights\":     {f: 1/len(selected) for f in selected},\n",
    "        \"in_sample_stats\":  in_stat,\n",
    "        \"out_sample_stats\": out_stat,\n",
    "        \"in_ew_stats\":     in_ew_stats,\n",
    "        \"out_ew_stats\":    out_ew_stats,\n",
    "        \"in_user_stats\":   in_user_stats,\n",
    "        \"out_user_stats\":  out_user_stats,\n",
    "        \"dropped\":         dropped,\n",
    "    }\n",
    "\n",
    "    # ---- optional index stats ---------------------------------------\n",
    "    if indices_list:\n",
    "        idx_stats = {}\n",
    "        for col in indices_list:\n",
    "            idx_stats[col] = {\n",
    "                \"in_sample\":  _stats(df.loc[m_in,  col], stats_cfg),\n",
    "                \"out_sample\": _stats(df.loc[m_out, col], stats_cfg),\n",
    "            }\n",
    "        results[\"index_stats\"] = idx_stats\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {
    "id": "183dc5df"
   },
   "source": [
    "## 5. Excel Export\n",
    "Creates an Excel file with In-Sample, Out-of-Sample and Equal-weight and User-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cce23",
   "metadata": {
    "id": "8e2cce23"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "#  5 · EXPORT  (NaN-safe, weight-format fix)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# ───────── 5 · EXPORT  (final, bug-free) ───────────────────────\n",
    "# ───────── 5 · EXPORT  (self-healing index section) ───────────\n",
    "# ───────── 5 · EXPORT  (final safe version) ───────────────────\n",
    "\n",
    "def export_to_excel(\n",
    "    data: dict[str, pd.DataFrame],\n",
    "    output_path: str,\n",
    "    default_format: Optional[Callable] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Exports each DataFrame in `data` to its own sheet in `output_path`.\n",
    "    Applies a registered formatter for each category (sheet name).\n",
    "    If no formatter is found, applies `default_format` if provided.\n",
    "\n",
    "    For the Summary sheet, data is written starting at row 5 to make room for custom headers.\n",
    "    \"\"\"\n",
    "    startrows = {\"summary\": 5}\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        for category, df in data.items():\n",
    "            startrow = startrows.get(category, 0)\n",
    "            df.to_excel(writer, sheet_name=category, index=False, startrow=startrow)\n",
    "            fmt_fn = FORMATTERS_EXCEL.get(category)\n",
    "            if fmt_fn:\n",
    "                fmt_fn(writer.sheets[category], writer.book)\n",
    "            elif default_format:\n",
    "                default_format(writer.sheets[category], writer.book)\n",
    "    # Workbook is auto-saved and closed by the context manager\n",
    "\n",
    "    def export_to_excel(data: Dict[str, pd.DataFrame], output_path: str, default_format: Optional[Callable]=None) -> None:\n",
    "      startrows = {\"Summary\":5}\n",
    "      with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "          for cat, df in data.items():\n",
    "              sr = startrows.get(cat, 0)\n",
    "              df.to_excel(writer, sheet_name=cat, index=False, startrow=sr)\n",
    "              fn = FORMATTERS_EXCEL.get(cat, default_format)\n",
    "              if fn: fn(writer.sheets[cat], writer.book)\n",
    "    # context manager handles closing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {
    "id": "ee8c2c6d"
   },
   "source": [
    "## 6. Run Parameters, Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc. Also lets us use custom weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {
    "id": "86794206"
   },
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48de568-962e-4690-a6fc-be7a4ec0a3c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896,
     "referenced_widgets": [
      "1a0b07248ffc4a13b1d57c5ea7234e6c",
      "e32127cdcad948bba6675ee248cf8674",
      "f8e3aa4f5a4c4fb8ba3244fd4b5ff228",
      "617ae31f378e456985332388e0e10b44",
      "e346462f78d54b82b69390c4d140d919",
      "329849dda0e84747b08e069b7488bdc4",
      "40bddde3b05c476381c4129063033dc3",
      "b71e162f24ac49cb81a9ad092e879545",
      "6de7686160284f56a8c4bb468eab3275",
      "599b4d76e1224e59810ff7b57f6b848d",
      "370815559a26479d8a28a87c47642263",
      "7579b5d2e8d740f894abc4ad908a28bf",
      "0e72ab4fffbf4e319fdf8d81e9a74d0b",
      "268f0eba89254b70af2728f29529e514",
      "d80492a8c66a456f9a0d1664887fda4f",
      "4439bd6f418445629558ac84ad0f881c",
      "bc5cb1aaf257482ca38a83858e7b7301",
      "a6a642fa138e4561b582644641f272a2",
      "bb5bb1dc7e554e78a518520be6e8b608",
      "2bc4035bf0eb4285bd9b5be4c816cd07",
      "92cf106bc2ce48d38ca1b2943fbbd9d7",
      "e053d71e6bea43c9a9c9f048f0369603",
      "9002119461b841ef967ee0badf486392",
      "8c4cd1fcb8994f27b91c1d155d8324c9",
      "7911fb906cf34900911564cef66b6916",
      "448e53ce7dab427fa35628f7a4a06ad3",
      "d1d1cd39b4564ec2abfbc8aa27772db9",
      "e76aa028bd544f82a12cf73ed1252cc0",
      "9fdd62881f674f8a83cd769e570c98ed",
      "506e5d598d4f464aa97b93821d472738",
      "7fcd9521c7fd4a24a7ee3b812adb0ad4",
      "210a9c9c17494b6fa8c06760cc570207",
      "87b8f0fdc99f4894a8de0aab1fc93389",
      "a8b7934132cc40f080fa38bc5ee79396",
      "8c6b5538c6bb42b287fb15acb0b84272",
      "fc7eb11cdbcc4f26870e11c3c231889f",
      "30882f13fcdd4e3eaefe645e2bd17ade",
      "028631bdf5c343dcb33ce200708b4e96",
      "0db721ad2fec40eebc7f8af29e60688e",
      "673708f81ef04bc7b027bf28f1b956f6",
      "dfb89be4b582436aba6987d6d1cbf96e",
      "5ebd7f4c16da479eb3f99e51c013caa7",
      "e2e7b718b49748d382c6092049deeeb4",
      "7ca1bc937d924de6a916a3b504056066",
      "43e7e77cbd0d43389b209a5283bad96f",
      "596880d842374b35ba01996d4266885c",
      "7fa15d924f2a459cb67d917773ade124",
      "83016a1e67ad4b018d93e8c427756e79",
      "4da036ee41a447f2aaee02299c2e2dd9",
      "b45777a453254935985d4792905859a5",
      "5a2aa33ee2614d69bd7365c6188c9f3d",
      "efdc20e7cbd14c50be7ea55000643c8c",
      "bd4e9a93bc344d5eb118187334470f64",
      "e33b4c9646b54c35abe4f357e3bec10a",
      "824569c31653458dad69a99956c70f19",
      "baabdf1381e048cfbcb4313418cb69ba",
      "b9a7c593cffb4ce4a0edbff03874cdad",
      "25c65642186144c6800af42d088ab306",
      "bcf4592d6a9a403a85d885109340bbb9",
      "9306b5fd79cb47a39cd25ada40b5d550",
      "9c3d6e4388d745128be73beb98357583",
      "bed7dfd8776a4f52b070c882784b1ffd",
      "7cfaef3d820542038fe8fe7b4431bd24",
      "c2da42ab6b094470979c18d003a62413",
      "2e32dbd73e904629b0dc0e4c955d2cd5",
      "820ad1d0054b470784676c5031ff2b2d",
      "20b00b15f6494e16bbe091362162f677",
      "57d335c59255496a80229fbf226b48d4",
      "e1b701615c224ba98303a7657475115b",
      "eed136944539429ab3917c7514be51b4",
      "249b15a8723c4289a19df3965dc7a703",
      "05f6977e59c64d2b85f403d8d8cea691",
      "13f26e8385634fe789910a4430673bb9",
      "62fbc903736b4153aac317dd476a1fe5",
      "06b39a99991a49059e8905ffad07f3d0",
      "1b41d80e180e47629a22629471a50455",
      "d2fa858d9a01499f912811ce57486af1",
      "3a547a7706da425ab87cd60d49e82e0e",
      "2bd34acd2f4044da81b7dbc00b6b5982",
      "05dfd21f6eb94ac2b5035193e49baeca",
      "0b9d22f299694ea4a3ad5dc83959a9c1",
      "3babdee73e2d49c3b1c254e336f15d7b",
      "f424f4e0ab2a4e298ded3f636f2506d2",
      "9fac17587b934e029e8ff5e9ba9f8823",
      "fb3953641c5c4565afad4781997cb380",
      "24fd4f77f302442a9a643e473a70b83b",
      "1a19ab5395724ecaa4b2053d86f5c27a",
      "a01e0dcbf0b8436092b7717e45c3670c",
      "48d1949041bf4cc49dfe798f549e76f2",
      "debed40a9bb24d18b1b5896a023ffac7",
      "168c1cdadf604314bcfba4d3c993b050",
      "257a4b498b25453d85b7e06efc5a03ff",
      "77580d32af63422ab643d75c62e69acd",
      "1e16cc9103f64f6bb6857f68c0dd0138",
      "1c622ba1ea8b4e91840ccf5e30c79c4d",
      "3e9ca63aab9045d8899c4079dd1c3fc7",
      "1b2309faf8764d89940a242f667fd751",
      "dde8f24f8fe24e2faea2727880d555b6",
      "0c40e44367fe4e16876551aa0065ba18"
     ]
    },
    "id": "e48de568-962e-4690-a6fc-be7a4ec0a3c6",
    "outputId": "891c17e7-a15b-4894-de38-2b99be7657cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0b07248ffc4a13b1d57c5ea7234e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>1. Load data</h4>'), ToggleButtons(description='Source:', options=(('Local', 'l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#            STREAMLINED ANALYSIS UI  (phase-2 clean)\n",
    "# ===============================================================\n",
    "import nbformat\n",
    "# ---------- session store ----------\n",
    "session = {\"df\": None, \"rf\": None, \"sel\": None, \"cweights\": None}\n",
    "\n",
    "# ---------- 1 · DATA LOAD ----------\n",
    "src = widgets.ToggleButtons(\n",
    "    options=[(\"Local\", \"local\"), (\"URL\", \"url\")],\n",
    "    description=\"Source:\"\n",
    ")\n",
    "\n",
    "chooser = FileChooser()\n",
    "url_box = widgets.Text(placeholder=\"https://…/file.csv\", layout={\"width\":\"70%\"})\n",
    "load_btn = widgets.Button(description=\"Load CSV\", button_style=\"success\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "def _toggle_src(c):\n",
    "    chooser.layout.display = \"block\" if c[\"new\"]==\"local\" else \"none\"\n",
    "    url_box.layout.display  = \"block\" if c[\"new\"]==\"url\"   else \"none\"\n",
    "src.observe(_toggle_src, names=\"value\"); _toggle_src({\"new\":src.value})\n",
    "\n",
    "def _load(_):\n",
    "    with load_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            path = chooser.selected if src.value==\"local\" else url_box.value.strip()\n",
    "            if not path: raise ValueError(\"choose file / URL\")\n",
    "            if src.value==\"url\" and not path.lower().endswith(\".csv\"):\n",
    "                raise ValueError(\"URL must end with .csv\")\n",
    "            df = load_csv(path)\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")  # single coercion\n",
    "            rf = identify_risk_free_fund(df)\n",
    "            session.update(df=df, rf=rf, sel=None, cweights=None)\n",
    "            print(f\"✅ Loaded {len(df):,} rows × {df.shape[1]} cols | RF → {rf}\")\n",
    "        except Exception as e:\n",
    "            print(\"❌\", e); session[\"df\"]=None\n",
    "load_btn.on_click(_load)\n",
    "\n",
    "# ---------- 2 · PARAMS ------------\n",
    "index_cnt = widgets.BoundedIntText(0, min=0, max=10, description=\"# Indices:\")\n",
    "in_start,in_end  = widgets.Text(\"2005-07\"), widgets.Text(\"2008-06\")\n",
    "out_start,out_end= widgets.Text(\"2008-07\"), widgets.Text(\"2009-06\")\n",
    "for w,lbl in [(in_start,\"In Start:\"),(in_end,\"In End:\"),\n",
    "              (out_start,\"Out Start:\"),(out_end,\"Out End:\")]:\n",
    "    w.description = lbl\n",
    "target_vol   = widgets.FloatText(0.25,  description=\"Target Vol:\")\n",
    "monthly_cost = widgets.FloatText(0.0033, description=\"Monthly Cost:\")\n",
    "\n",
    "# ---------- 3 · SELECTION ----------\n",
    "mode_dd = widgets.Dropdown(\n",
    "    options=[(\"All\", \"all\"), (\"Random\", \"random\"), (\"Manual\", \"manual\")],\n",
    "    value=\"all\",\n",
    "    description=\"Mode:\"\n",
    ")\n",
    "rand_n   = widgets.BoundedIntText(5, min=2, max=100, description=\"Sample N:\")\n",
    "fund_table, total_lbl = widgets.VBox([]), widgets.Label(\"Total = 0 %\")\n",
    "\n",
    "def _toggle_sel(_=None):\n",
    "    rand_n.layout.display  = \"block\" if mode_dd.value==\"random\" else \"none\"\n",
    "    vis = \"block\" if mode_dd.value==\"manual\" else \"none\"\n",
    "    fund_table.layout.display = total_lbl.layout.display = vis\n",
    "mode_dd.observe(_toggle_sel, names=\"value\"); _toggle_sel()\n",
    "\n",
    "# ---------- helpers ---------------\n",
    "def _eligible_pool():\n",
    "    df, rf = session[\"df\"], session[\"rf\"]\n",
    "    if df is None:\n",
    "        print(\"⚠️ data not loaded\"); return []\n",
    "\n",
    "    # ---- date parse guard -----------------------------------\n",
    "    try:\n",
    "        in_s  = pd.to_datetime(in_start.value)+pd.offsets.MonthEnd(0)\n",
    "        in_e  = pd.to_datetime(in_end.value)  +pd.offsets.MonthEnd(0)\n",
    "        out_s = pd.to_datetime(out_start.value)+pd.offsets.MonthEnd(0)\n",
    "        out_e = pd.to_datetime(out_end.value)  +pd.offsets.MonthEnd(0)\n",
    "    except Exception:\n",
    "        print(\"❌ invalid dates\"); return []\n",
    "\n",
    "    # ---- build indices (RIGHT-most idx_n non-RF columns) ----\n",
    "    idx_n     = index_cnt.value\n",
    "    data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "    non_rf    = [c for c in data_cols if c != rf]\n",
    "    indices   = non_rf[-idx_n:] if idx_n else []          # <- fixed\n",
    "    cand      = [c for c in data_cols if c not in indices]\n",
    "\n",
    "    # ---- run select_funds ----------------------------------\n",
    "    elig = select_funds(\n",
    "        df=df,\n",
    "        rf_col=rf,\n",
    "        fund_columns=cand,\n",
    "        in_sdate=in_s,\n",
    "        in_edate=in_e,\n",
    "        out_sdate=out_s,\n",
    "        out_edate=out_e,\n",
    "        cfg=cfg,                     # ← Explicitly supply your config here\n",
    "        selection_mode=\"all\",\n",
    "    )\n",
    "    # … diagnostics print unchanged …\n",
    "    return elig\n",
    "\n",
    "def _build_manual(*_):\n",
    "    if mode_dd.value!=\"manual\" or session[\"df\"] is None: return\n",
    "    valid = _eligible_pool()\n",
    "    print(\"DEBUG  eligible funds =\", len(valid))              # ← line 1\n",
    "    print(\"DEBUG  list sample   →\", valid[:25], \"…\")           # ← line 2\n",
    "    if not valid:\n",
    "        print(\"❌ No eligible funds\"); return\n",
    "    fund_table.children = []                # reset\n",
    "\n",
    "    def _update_total(*_):\n",
    "        tot = sum(r.children[1].value for r in fund_table.children\n",
    "                  if r.children[0].value)\n",
    "        total_lbl.value = f\"Total = {tot} %\"\n",
    "\n",
    "    for f in valid:\n",
    "        cb = widgets.Checkbox(description=f, layout={\"width\":\"200px\"})\n",
    "        wt = widgets.BoundedIntText(0, min=0, max=100,\n",
    "                                    layout={\"width\":\"60px\"}, disabled=True)\n",
    "        def _toggle(ch, box=wt):           # single observer\n",
    "            box.disabled = not ch[\"new\"]\n",
    "            if box.disabled: box.value = 0\n",
    "            _update_total()\n",
    "        cb.observe(_toggle, names=\"value\")\n",
    "        wt.observe(_update_total, names=\"value\")\n",
    "        fund_table.children += (widgets.HBox([cb, wt]),)\n",
    "    _update_total()\n",
    "\n",
    "mode_dd.observe(lambda ch: _build_manual() if ch[\"new\"]==\"manual\" else None,\n",
    "                names=\"value\")\n",
    "for w in (in_start,in_end,out_start,out_end): w.observe(_build_manual,names=\"value\")\n",
    "\n",
    "# ---------- 4 · RUN ---------------\n",
    "run_btn = widgets.Button(description=\"Run Analysis\", button_style=\"success\")\n",
    "run_out = widgets.Output(layout={\"border\":\"1px solid #999\",\n",
    "                                 \"height\":\"340px\",\"overflow_y\":\"auto\"})\n",
    "\n",
    "def _run(_):\n",
    "    with run_out:\n",
    "        clear_output()\n",
    "        df, rf = session[\"df\"], session[\"rf\"]\n",
    "        if df is None: print(\"⚠️ Load data first\"); return\n",
    "\n",
    "        # indices (robust)\n",
    "        idx_n     = index_cnt.value\n",
    "        data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "        non_rf    = [c for c in data_cols if c != rf]\n",
    "        indices   = non_rf[-idx_n:] if idx_n else []\n",
    "\n",
    "        # pool + selection\n",
    "        pool = _eligible_pool()\n",
    "        if not pool: print(\"❌ No eligible funds\"); return\n",
    "        if mode_dd.value==\"all\":\n",
    "            sel, custom = pool, None\n",
    "        elif mode_dd.value==\"random\":\n",
    "            if rand_n.value>len(pool): print(\"⚠️ Sample N too big\"); return\n",
    "            sel, custom = list(np.random.choice(pool, rand_n.value, replace=False)), None\n",
    "        else:\n",
    "            sel, custom = [], {}\n",
    "            if not fund_table.children: _build_manual()\n",
    "            for row in fund_table.children:\n",
    "                cb, wt = row.children\n",
    "                if cb.value: sel.append(cb.description); custom[cb.description]=wt.value\n",
    "            if sum(custom.values())!=100: print(\"⚠️ Weights ≠ 100\"); return\n",
    "\n",
    "        w_dict,w_vec = prepare_weights(sel, custom)\n",
    "\n",
    "        res = run_analysis(df, sel, w_vec, w_dict, rf,\n",
    "                           in_start.value, in_end.value,\n",
    "                           out_start.value, out_end.value,\n",
    "                           target_vol.value, monthly_cost.value,\n",
    "                           indices)\n",
    "\n",
    "        print(\"✅ analysis complete |\", len(sel), \"funds\")\n",
    "        if res[\"dropped\"]:\n",
    "            print(\"⚠️ Dropped:\", res[\"dropped\"])\n",
    "        if indices: print(\"📊 Indices:\", indices)\n",
    "\n",
    "        fname=f\"IS_{in_start.value}_{out_start.value}.xlsx\"\n",
    "        fund_weights = res[\"fund_weights\"]\n",
    "        in_stat = res[\"in_sample_stats\"]\n",
    "        out_stat = res[\"out_sample_stats\"]\n",
    "\n",
    "        summary_rows = []\n",
    "        for fund, stats_in in res[\"in_sample_stats\"].items():\n",
    "            stats_out = res[\"out_sample_stats\"][fund]\n",
    "            w_user    = res[\"fund_weights\"][fund]    # your custom weights\n",
    "            w_ew      = res[\"ew_weights\"][fund]      # the equal-weight\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"Name\":      fund,\n",
    "                \"Weight %\":  w_user,\n",
    "                \"EW %\":      w_ew,\n",
    "                # in-sample metrics:\n",
    "                \"R (IN)%\":   stats_in.AnnualReturn,\n",
    "                \"V (IN)%\":   stats_in.Volatility,\n",
    "                \"Sharpe (IN)\": stats_in.Sharpe,\n",
    "                \"Sortino (IN)\":stats_in.Sortino,\n",
    "                \"MDD (IN)%\": stats_in.MaxDrawdown,\n",
    "                # out-sample metrics:\n",
    "                \"R (OUT)%\":  stats_out.AnnualReturn,\n",
    "                \"V (OUT)%\":  stats_out.Volatility,\n",
    "                \"Sharpe (OUT)\": stats_out.Sharpe,\n",
    "                \"Sortino (OUT)\":stats_out.Sortino,\n",
    "                \"MDD (OUT)%\": stats_out.MaxDrawdown,\n",
    "                })\n",
    "            summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "        # Now this is rectangular—each dict has the same keys:\n",
    "\n",
    "        idx_rows = []\n",
    "        for idx, idx_pair in res.get(\"index_stats\", {}).items():\n",
    "            idx_rows.append({\n",
    "                \"Index\": idx,\n",
    "                \"R (IN)%\": idx_pair[\"in_sample\"].AnnualReturn,\n",
    "                \"V (IN)%\":   stats_in.Volatility,\n",
    "                \"Sharpe (IN)\": stats_in.Sharpe,\n",
    "                \"Sortino (IN)\":stats_in.Sortino,\n",
    "                \"MDD (IN)%\": stats_in.MaxDrawdown,\n",
    "                # out-sample metrics:\n",
    "                \"R (OUT)%\":  stats_out.AnnualReturn,\n",
    "                \"V (OUT)%\":  stats_out.Volatility,\n",
    "                \"Sharpe (OUT)\": stats_out.Sharpe,\n",
    "                \"Sortino (OUT)\":stats_out.Sortino,\n",
    "                \"MDD (OUT)%\": stats_out.MaxDrawdown,\n",
    "                })\n",
    "        indices_df = pd.DataFrame(idx_rows)\n",
    "        data = {\n",
    "            \"summary\": summary_df\n",
    "            # \"Funds\":   funds_df,\n",
    "            # \"Indices\": idx_df, (if you want output on separate sheets)\n",
    "            }\n",
    "        # … build your summary_df, in_stat, out_stat, weights …\n",
    "        make_summary_formatter(summary_df, in_start, in_end, out_start, out_end, in_stat, out_stat, w_dict)\n",
    "\n",
    "\n",
    "\n",
    "        nb_path = \"vol_adj_trend_analysis_1_3_trex.ipynb\"  # Replace with your notebook filename\n",
    "\n",
    "        with open(nb_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "        if \"widgets\" in nb.metadata:\n",
    "            del nb.metadata[\"widgets\"]\n",
    "            print(\"Removed 'widgets' from metadata.\")\n",
    "\n",
    "        with open(nb_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            nbformat.write(nb, f)\n",
    "\n",
    "\n",
    "\n",
    "        export_to_excel(data, fname)\n",
    "        print(\"Workbook saved as\", fname)\n",
    "\n",
    "run_btn.on_click(_run)\n",
    "\n",
    "# ---------- DISPLAY --------------\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h4>1. Load data</h4>\"),\n",
    "    src, chooser, url_box, load_btn, load_out,\n",
    "    widgets.HTML(\"<hr><h4>2. Parameters</h4>\"),\n",
    "    widgets.HBox([index_cnt]),\n",
    "    widgets.HBox([in_start,in_end,out_start,out_end]),\n",
    "    widgets.HBox([target_vol,monthly_cost]),\n",
    "    widgets.HTML(\"<hr><h4>3. Fund selection</h4>\"),\n",
    "    widgets.HBox([mode_dd,rand_n]),\n",
    "    fund_table, total_lbl,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    run_btn,\n",
    "    run_out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kwVCu-oYjUgN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "kwVCu-oYjUgN",
    "outputId": "e2532cdb-7897-4ca3-bc15-16cab711c2c1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Vol_Adj_Trend_Analysis_1_1_TrEx.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-422e8b4f2193>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. Remove widgets metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Vol_Adj_Trend_Analysis_1_1_TrEx.ipynb'"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "import os\n",
    "\n",
    "# 1. Get the current notebook name (Colab shows it at the top). Enter manually:\n",
    "original_nb = 'Vol_Adj_Trend_Analysis_1_1_TrEx.ipynb'  # Replace with your actual notebook name as shown at the top of Colab\n",
    "clean_nb = 'Vol_Adj_Trend_Analysis_1_3_TrEx.ipynb'\n",
    "\n",
    "# 2. Remove widgets metadata\n",
    "with open(original_nb, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "if \"widgets\" in nb.metadata:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "    print(\"Removed 'widgets' from metadata.\")\n",
    "\n",
    "with open(clean_nb, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"Cleaned notebook saved as {clean_nb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mSW4mXWujaBn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "mSW4mXWujaBn",
    "outputId": "cdb7d934-2949-4ecb-a33b-cdc12b60d405"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4afd32f26217>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Notebook saved as {notebook_name} in /content/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msave_current_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-4afd32f26217>\u001b[0m in \u001b[0;36msave_current_notebook\u001b[0;34m(notebook_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get_ipynb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mipynb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ipynb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ipynb'"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import requests\n",
    "\n",
    "notebook_name = 'cleaned_notebook.ipynb'  # Name your export\n",
    "\n",
    "def save_current_notebook(notebook_name):\n",
    "    from google.colab import _message\n",
    "    import json\n",
    "    import urllib.parse\n",
    "\n",
    "    session = _message.blocking_request('get_ipynb', {})\n",
    "    ipynb = session['ipynb']\n",
    "\n",
    "    with open(notebook_name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(ipynb, f)\n",
    "    print(f\"Notebook saved as {notebook_name} in /content/\")\n",
    "\n",
    "save_current_notebook(notebook_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
