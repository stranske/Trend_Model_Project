{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4984b33",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and validate data.\n",
    "2. Handle missing data (short vs. long gaps).\n",
    "3. Adjust returns to a target volatility in-sample, then apply the same scaling out-of-sample.\n",
    "4. Compute Sharpe, Sortino, Max Drawdown.\n",
    "5. Provide multiple fund selection modes (all, random sample, manual).\n",
    "6. Calculate portfolio results (equal-weight and custom-weight).\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting.\n",
    "\n",
    "**Note**: The manual fund selection and custom weights features are partially implemented. In a real interactive workflow, you would wire widget selections and weights into the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging started. Volatility Scaling & Portfolio Analysis Notebook initialized.\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# ============ 1. SETUP CELL ============\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, VBox, HBox\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# If you need to install these packages on your environment, uncomment:\n",
    "!{sys.executable} -m pip install --quiet ipywidgets openpyxl xlsxwriter\n",
    "\n",
    "# For exporting to Excel with styling\n",
    "import xlsxwriter\n",
    "\n",
    "# Set up logging to console\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s: %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Logging started. Volatility Scaling & Portfolio Analysis Notebook initialized.\")\n",
    "\n",
    "# (Optional) If widgets aren't enabled, run:\n",
    "# !jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Here we create options to load a dataset from a local file or a GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054d824fb37e43e3a30402263a0564df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Data Source:', options=('Local', 'GitHub'), value='Local'), FileChooser(p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Helper to read a local CSV robustly (handles BOMs and minor parsing issues)\n",
    "# ------------------------------------------------------------------------------\n",
    "def robust_read_csv(path):\n",
    "    \"\"\"\n",
    "    Try loading `path` as CSV in three ways:\n",
    "    1. Default C engine\n",
    "    2. BOM-stripped with the Python engine\n",
    "    3. Skip bad lines with the Python engine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e1:\n",
    "        print(\"Default read_csv failed:\", e1)\n",
    "\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=\",\", encoding=\"utf-8-sig\", engine=\"python\")\n",
    "    except Exception as e2:\n",
    "        print(\"utf-8-sig + python engine failed:\", e2)\n",
    "\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        sep=\",\",\n",
    "        engine=\"python\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        skip_blank_lines=True,\n",
    "        on_bad_lines=\"skip\",    # for pandas ≥ 1.3\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Build the widgets\n",
    "# ------------------------------------------------------------------------------\n",
    "source_dropdown = widgets.Dropdown(\n",
    "    options=[\"Local\", \"GitHub\"],\n",
    "    value=\"Local\",\n",
    "    description=\"Data Source:\",\n",
    ")\n",
    "\n",
    "# FileChooser for Local mode\n",
    "fc = FileChooser(os.getcwd())\n",
    "fc.title = \"<b>Select local CSV file</b>\"\n",
    "\n",
    "# Text box for GitHub raw URL\n",
    "github_text = widgets.Text(\n",
    "    value=(\n",
    "        \"https://raw.githubusercontent.com/stranske/Trend_Model_Project/\"\n",
    "        \"main/data/TrendData.csv\"\n",
    "    ),\n",
    "    description=\"GitHub URL:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "# Load button\n",
    "load_button = widgets.Button(description=\"Load Data\", button_style=\"success\")\n",
    "\n",
    "# Output area for status and debug prints\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Show/hide widgets depending on source selection\n",
    "# ------------------------------------------------------------------------------\n",
    "def on_source_change(change):\n",
    "    if change[\"new\"] == \"Local\":\n",
    "        fc.layout.display = \"block\"\n",
    "        github_text.layout.display = \"none\"\n",
    "    else:\n",
    "        fc.layout.display = \"none\"\n",
    "        github_text.layout.display = \"block\"\n",
    "\n",
    "# Initially, GitHub textbox is hidden; FileChooser is visible\n",
    "github_text.layout.display = \"none\"\n",
    "fc.layout.display = \"block\"\n",
    "\n",
    "source_dropdown.observe(on_source_change, names=\"value\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Callback for the Load button (auto-detect date format)\n",
    "# ------------------------------------------------------------------------------\n",
    "def on_load_clicked(_):\n",
    "    global df                              # declare df as global\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        src = source_dropdown.value\n",
    "\n",
    "        # 4a) Load the DataFrame\n",
    "        if src == \"Local\":\n",
    "            local_path = fc.selected\n",
    "            if not local_path or not os.path.exists(local_path):\n",
    "                print(f\"Error: Local file not found or not selected:\\n    {local_path}\")\n",
    "                return\n",
    "            print(f\"Loading from local file:\\n    {local_path}\")\n",
    "            try:\n",
    "                df = robust_read_csv(local_path)  # now stores into global df\n",
    "            except Exception as e:\n",
    "                print(\"Failed to parse local CSV:\", e)\n",
    "                return\n",
    "\n",
    "        else:  # GitHub\n",
    "            github_url = github_text.value.strip()\n",
    "            if not github_url:\n",
    "                print(\"Error: Please enter a GitHub raw URL.\")\n",
    "                return\n",
    "            print(f\"Loading from GitHub URL:\\n    {github_url}\")\n",
    "            try:\n",
    "                df = pd.read_csv(github_url)       # stores into global df\n",
    "            except Exception as e:\n",
    "                print(\"Failed to read from GitHub URL:\", e)\n",
    "                return\n",
    "\n",
    "        # 4b) Debug: print columns & a few rows\n",
    "        print(\"Columns found in DataFrame:\", df.columns.tolist())\n",
    "        display(df.head(3))\n",
    "\n",
    "        # 4c) Identify which column is the date\n",
    "        date_col = None\n",
    "        for candidate in [\"Date\", \"DATE\", \"date\"]:\n",
    "            if candidate in df.columns:\n",
    "                date_col = candidate\n",
    "                break\n",
    "\n",
    "        if date_col is None:\n",
    "            print(\"Error: No column named 'Date' / 'DATE' / 'date' found.\")\n",
    "            print(\"Please check the column names above and adjust code accordingly.\")\n",
    "            return\n",
    "\n",
    "        # 1) Show the first few raw date strings (un‐parsed) so we can inspect them\n",
    "        raw_samples = df[date_col].dropna().astype(str).head(10).tolist()\n",
    "        print(f\"Raw {date_col} samples (first 10 non‐null): {raw_samples!r}\")\n",
    "\n",
    "        # 2) Strip leading/trailing whitespace from every entry\n",
    "        df[date_col] = df[date_col].astype(str).str.strip()\n",
    "\n",
    "        # 3) Now attempt strict \"%m/%d/%Y\" parsing\n",
    "        parsed = pd.to_datetime(df[date_col], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "        num_valid = parsed.notna().sum()\n",
    "        print(f\"Number of rows matching '%m/%d/%Y' exactly: {num_valid} / {len(df)}\")\n",
    "\n",
    "        if num_valid > 0:\n",
    "            df[date_col] = parsed\n",
    "            print(f\"Parsing with '%m/%d/%Y' succeeded for {num_valid} rows.\")\n",
    "        else:\n",
    "            print(\n",
    "                \"Warning: No rows matched '%m/%d/%Y'. \"\n",
    "                \"Falling back to generic pd.to_datetime(...).\"\n",
    "            )\n",
    "            df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "        # 5) Drop any rows where parsing still failed\n",
    "        before_drop = len(df)\n",
    "        df.dropna(subset=[date_col], inplace=True)\n",
    "        dropped = before_drop - len(df)\n",
    "        if dropped:\n",
    "            print(f\"Dropped {dropped} rows where '{date_col}' could not be parsed.\")\n",
    "        \n",
    "        # 6) Sort and reset index\n",
    "        df.sort_values(by=date_col, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # 7) Show the final parsed dates\n",
    "        print(f\"After parsing, first 3 {date_col} values:\")\n",
    "        print(df[[date_col]].head(3))\n",
    "        print(f\"Loaded {len(df)} rows successfully.\")\n",
    "\n",
    "        # 8) Confirm that df is now in global scope\n",
    "        print(\">> df defined with\", len(df), \"rows and columns:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "# 5) Wire up and display the UI\n",
    "load_button.on_click(on_load_clicked)\n",
    "\n",
    "ui = widgets.VBox([source_dropdown, fc, github_text, load_button, output_area])\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 3. Utility Functions\n",
    "Here we define date parsing, consecutive gap checks, data filling, risk-free identification, return calculations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def consecutive_gaps(series, threshold=3):\n",
    "    \"\"\"\n",
    "    Check if a series (sorted chronologically) has >= threshold consecutive NaNs.\n",
    "    Return True if such a gap exists, False otherwise.\n",
    "    \"\"\"\n",
    "    consecutive = 0\n",
    "    for val in series:\n",
    "        if pd.isna(val):\n",
    "            consecutive += 1\n",
    "        else:\n",
    "            consecutive = 0\n",
    "        if consecutive >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fill_short_gaps_with_zero(series, max_short_gap=2):\n",
    "    \"\"\"\n",
    "    Replace missing values (NaN) with 0 if they appear in runs of <= max_short_gap.\n",
    "    Longer runs remain NaN.\n",
    "    \"\"\"\n",
    "    filled = series.copy()\n",
    "    n = len(series)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if pd.isna(filled[i]):\n",
    "            run_start = i\n",
    "            while i < n and pd.isna(filled[i]):\n",
    "                i += 1\n",
    "            run_end = i  # first non-NaN after run\n",
    "            gap_length = run_end - run_start\n",
    "            if gap_length <= max_short_gap:\n",
    "                filled[run_start:run_end] = 0.0\n",
    "        else:\n",
    "            i += 1\n",
    "    return filled\n",
    "\n",
    "def identify_risk_free_fund(df):\n",
    "    \"\"\"\n",
    "    Identify which column (after 'Date') is the risk-free rate by smallest stdev among columns.\n",
    "    \"\"\"\n",
    "    numeric_cols = df.columns[1:]  # skip the Date column\n",
    "    stdevs = {}\n",
    "    for col in numeric_cols:\n",
    "        vals = df[col].dropna()\n",
    "        if len(vals) > 0:\n",
    "            stdevs[col] = vals.std()\n",
    "        else:\n",
    "            stdevs[col] = np.inf\n",
    "\n",
    "    rf_col = min(stdevs, key=stdevs.get)\n",
    "    logging.info(f\"Identified '{rf_col}' as the risk-free column (lowest stdev).\")\n",
    "    return rf_col\n",
    "\n",
    "def annualize_return(monthly_returns):\n",
    "    \"\"\"\n",
    "    Annualized (geometric) return from monthly returns in decimal form.\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) == 0:\n",
    "        return np.nan\n",
    "    growth_factor = (1 + valid_rets).prod()\n",
    "    n_months = len(valid_rets)\n",
    "    if growth_factor <= 0:\n",
    "        return -1.0\n",
    "    ann_ret = growth_factor**(12.0 / n_months) - 1\n",
    "    return ann_ret\n",
    "\n",
    "def annualize_volatility(monthly_returns):\n",
    "    \"\"\"\n",
    "    Annualized stdev of monthly returns, i.e. stdev * sqrt(12).\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) < 2:\n",
    "        return np.nan\n",
    "    return valid_rets.std() * np.sqrt(12)\n",
    "\n",
    "def sharpe_ratio(monthly_returns, rf_series):\n",
    "    \"\"\"\n",
    "    Annualized Sharpe ratio = (annual_excess_return) / (annual_excess_vol).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'r': monthly_returns, 'rf': rf_series}).dropna()\n",
    "    if len(df) < 2:\n",
    "        return np.nan\n",
    "    excess = df['r'] - df['rf']\n",
    "    growth_factor = (1 + excess).prod()\n",
    "    n_months = len(excess)\n",
    "    if growth_factor <= 0:\n",
    "        return np.nan\n",
    "    ann_excess_ret = growth_factor**(12.0 / n_months) - 1\n",
    "    ann_excess_vol = excess.std() * np.sqrt(12)\n",
    "    if ann_excess_vol == 0:\n",
    "        return np.nan\n",
    "    return ann_excess_ret / ann_excess_vol\n",
    "\n",
    "def sortino_ratio(monthly_returns, rf_series):\n",
    "    \"\"\"\n",
    "    Annualized Sortino ratio = (annual_excess_return) / (annual_downside_stdev).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'r': monthly_returns, 'rf': rf_series}).dropna()\n",
    "    if len(df) < 2:\n",
    "        return np.nan\n",
    "    excess = df['r'] - df['rf']\n",
    "\n",
    "    growth_factor = (1 + excess).prod()\n",
    "    n_months = len(excess)\n",
    "    if growth_factor <= 0:\n",
    "        return np.nan\n",
    "    ann_excess_ret = growth_factor**(12.0 / n_months) - 1\n",
    "\n",
    "    negative_mask = excess < 0\n",
    "    negative_returns = excess[negative_mask]\n",
    "    if len(negative_returns) == 0:\n",
    "        return np.inf  # no negative => infinite sortino\n",
    "    downside_stdev = negative_returns.std() * np.sqrt(12)\n",
    "    return ann_excess_ret / downside_stdev\n",
    "\n",
    "def max_drawdown(monthly_returns):\n",
    "    \"\"\"\n",
    "    Compute max drawdown from monthly returns in decimal form.\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) == 0:\n",
    "        return np.nan\n",
    "    wealth_index = (1 + valid_rets).cumprod()\n",
    "    rolling_max = wealth_index.cummax()\n",
    "    dd_series = 1 - (wealth_index / rolling_max)\n",
    "    return dd_series.max()\n",
    "\n",
    "def calc_portfolio_returns(weights, df_returns):\n",
    "    \"\"\"\n",
    "    Compute monthly portfolio returns (Series) as weighted sum of columns in df_returns.\n",
    "    \"\"\"\n",
    "    return (df_returns * weights).sum(axis=1)\n",
    "\n",
    "print(\"Utility functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1619c9",
   "metadata": {},
   "source": [
    "## 4. Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffad994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widgets defined. Use 'display(ui_inputs)' in a cell to show them after other functions run\n"
     ]
    }
   ],
   "source": [
    "# ─────────────── Widget Setup + Callback ───────────────\n",
    "\n",
    "# (A) Build widgets\n",
    "in_sample_start = widgets.Text(value='2003-01', description='In-Sample Start:')\n",
    "in_sample_end   = widgets.Text(value='2005-12', description='In-Sample End:')\n",
    "out_sample_start= widgets.Text(value='2006-01', description='Out-Sample Start:')\n",
    "out_sample_end  = widgets.Text(value='2010-12', description='Out-Sample End:')\n",
    "\n",
    "target_vol_widget   = widgets.FloatText(value=0.10,  description='Target Vol:')\n",
    "monthly_cost_widget = widgets.FloatText(value=0.002, description='Monthly Cost:')\n",
    "\n",
    "selection_mode_widget = widgets.Dropdown(\n",
    "    options=[('All Funds','all'), ('Random Sample','random'), ('Manual','manual')],\n",
    "    value='all',\n",
    "    description='Mode:'\n",
    ")\n",
    "random_sample_size_widget = widgets.IntText(value=5, description='Sample Size:')\n",
    "\n",
    "apply_button = widgets.Button(description='Run Analysis', button_style='success')\n",
    "\n",
    "ui_inputs = widgets.VBox([\n",
    "    in_sample_start, in_sample_end,\n",
    "    out_sample_start, out_sample_end,\n",
    "    target_vol_widget, monthly_cost_widget,\n",
    "    selection_mode_widget, random_sample_size_widget,\n",
    "    apply_button\n",
    "])\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# (B) Define the callback that reads widget values and calls run_analysis\n",
    "def on_apply_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        # 1) Read values from widgets\n",
    "        in_start_val   = in_sample_start.value.strip()\n",
    "        in_end_val     = in_sample_end.value.strip()\n",
    "        out_start_val  = out_sample_start.value.strip()\n",
    "        out_end_val    = out_sample_end.value.strip()\n",
    "        target_vol_val = target_vol_widget.value\n",
    "        monthly_cost_val = monthly_cost_widget.value\n",
    "        mode_val       = selection_mode_widget.value\n",
    "        rnd_n_val      = random_sample_size_widget.value\n",
    "        \n",
    "        # 2) Basic sanity prints\n",
    "        print(\"Running analysis with parameters:\")\n",
    "        print(f\"  In-Sample:  {in_start_val} → {in_end_val}\")\n",
    "        print(f\"  Out-Sample: {out_start_val} → {out_end_val}\")\n",
    "        print(f\"  Target Volatility: {target_vol_val}\")\n",
    "        print(f\"  Monthly Cost: {monthly_cost_val}\")\n",
    "        print(f\"  Selection Mode: {mode_val}\")\n",
    "        if mode_val == 'random':\n",
    "            print(f\"  Random Sample Size: {rnd_n_val}\")\n",
    "        \n",
    "        # 3) Call run_analysis (df must already exist from your data‐loading cell)\n",
    "        try:\n",
    "            results = run_analysis(\n",
    "                df,\n",
    "                in_start=in_start_val,\n",
    "                in_end=in_end_val,\n",
    "                out_start=out_start_val,\n",
    "                out_end=out_end_val,\n",
    "                target_vol=target_vol_val,\n",
    "                monthly_cost=monthly_cost_val,\n",
    "                selection_mode=mode_val,\n",
    "                random_n=rnd_n_val\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Error inside run_analysis():\", e)\n",
    "            return\n",
    "        \n",
    "        if results is None:\n",
    "            print(\"run_analysis returned None—check your inputs or data.\")\n",
    "            return\n",
    "        \n",
    "        # 4) Show a brief summary\n",
    "        print(\"Analysis complete. Summary:\")\n",
    "        if 'selected_funds' in results:\n",
    "            print(f\"  Funds selected: {len(results['selected_funds'])}\")\n",
    "        if 'in_ew_stats' in results:\n",
    "            ir, iv, isr, _, _ = results['in_ew_stats']\n",
    "            print(f\"  In-Sample EW → Return: {ir*100:.2f}%, Vol: {iv*100:.2f}%, Sharpe: {isr:.2f}\")\n",
    "        if 'out_ew_stats' in results:\n",
    "            or_, ov, osr, _, _ = results['out_ew_stats']\n",
    "            print(f\"  Out-Sample EW → Return: {or_*100:.2f}%, Vol: {ov*100:.2f}%, Sharpe: {osr:.2f}\")\n",
    "        \n",
    "        # 5) (Optional) Write results to Excel\n",
    "        export_to_excel(results, \"InteractiveOutput.xlsx\")\n",
    "        print(\"Results exported to InteractiveOutput.xlsx\")\n",
    "\n",
    "print(\"Widgets defined. Use 'display(ui_inputs)' in a cell to show them after other functions run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08caa0-d758-41e1-907b-a073e3aaba21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e3eb165",
   "metadata": {},
   "source": [
    "## 5. Fund Selection\n",
    "Filters out columns that represent the risk-free rate or contain \"index\" in the name, then handles the selection mode (all, random, or manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e571d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_funds function ready.\n"
     ]
    }
   ],
   "source": [
    "def select_funds(df, rf_col, selection_mode='all', random_n=5):\n",
    "    \"\"\"\n",
    "    Exclude the risk-free col and any 'index' columns from the fund list.\n",
    "    Then filter out funds that have >=3 consecutive missing months.\n",
    "    Then apply the specified selection_mode.\n",
    "    \"\"\"\n",
    "    possible_funds = [c for c in df.columns if c not in ['Date', rf_col]]\n",
    "    \n",
    "    funds_only = []\n",
    "    for col in possible_funds:\n",
    "        if 'index' in col.lower():\n",
    "            continue\n",
    "        funds_only.append(col)\n",
    "    \n",
    "    valid_funds = []\n",
    "    for col in funds_only:\n",
    "        if not consecutive_gaps(df[col], threshold=3):\n",
    "            valid_funds.append(col)\n",
    "    \n",
    "    if selection_mode == 'all':\n",
    "        return valid_funds\n",
    "    elif selection_mode == 'random':\n",
    "        if len(valid_funds) <= random_n:\n",
    "            warnings.warn(f\"Fewer valid funds ({len(valid_funds)}) than sample size ({random_n}). Returning all.\")\n",
    "            return valid_funds\n",
    "        else:\n",
    "            return random.sample(valid_funds, random_n)\n",
    "    else:\n",
    "        # manual selection widget placeholder\n",
    "        # In a real notebook, you'd display a multi-select widget.\n",
    "        # For simplicity, just return all valid funds here.\n",
    "        return valid_funds\n",
    "\n",
    "print(\"select_funds function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c60582",
   "metadata": {},
   "source": [
    "## 6. Custom Weights\n",
    "Displays an integer text widget for each fund, requiring the sum of weights to be 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a404c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_custom_weights function ready.\n"
     ]
    }
   ],
   "source": [
    "def get_custom_weights(selected_funds):\n",
    "    \"\"\"\n",
    "    Display widgets for each fund to enter weights. Validate sum=100.\n",
    "    Returns dict {fund: weight_decimal}.\n",
    "    \"\"\"\n",
    "    weight_widgets = {}\n",
    "    for fund in selected_funds:\n",
    "        w = widgets.BoundedIntText(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description=f\"{fund}\",\n",
    "            layout=widgets.Layout(width='250px')\n",
    "        )\n",
    "        weight_widgets[fund] = w\n",
    "    \n",
    "    confirm_button = widgets.Button(\n",
    "        description='Confirm Weights',\n",
    "        button_style='success'\n",
    "    )\n",
    "    error_label = widgets.Label(value='', layout=widgets.Layout(color='red'))\n",
    "    \n",
    "    box = VBox(list(weight_widgets.values()) + [confirm_button, error_label])\n",
    "    display(box)\n",
    "    \n",
    "    weights_container = {}\n",
    "    \n",
    "    def on_confirm_clicked(_):\n",
    "        total = sum(w.value for w in weight_widgets.values())\n",
    "        if total != 100:\n",
    "            error_label.value = f\"Error: Weights sum to {total}, must be 100.\"\n",
    "            weights_container.clear()\n",
    "        else:\n",
    "            for fund, wdg in weight_widgets.items():\n",
    "                weights_container[fund] = wdg.value / 100.0\n",
    "            error_label.value = \"Weights confirmed!\"\n",
    "    \n",
    "    confirm_button.on_click(on_confirm_clicked)\n",
    "    return weights_container\n",
    "\n",
    "print(\"get_custom_weights function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 7. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0696a436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_analysis function ready.\n"
     ]
    }
   ],
   "source": [
    "def run_analysis(df, \n",
    "                 in_start, in_end, out_start, out_end, \n",
    "                 target_vol, monthly_cost,\n",
    "                 selection_mode='all', random_n=5):\n",
    "    \"\"\"\n",
    "    Orchestrate the analysis:\n",
    "    1) Validate date inputs\n",
    "    2) Convert 'Date' col\n",
    "    3) Identify risk-free\n",
    "    4) Fill short gaps, filter by 3+ gap\n",
    "    5) Select funds\n",
    "    6) Scale returns in-sample, apply factor + monthly cost OOS\n",
    "    7) Compute stats + portfolio metrics\n",
    "    8) Return a dictionary of results\n",
    "    \"\"\"\n",
    "    in_sdate = pd.to_datetime(in_start, errors='coerce')\n",
    "    in_edate = pd.to_datetime(in_end, errors='coerce')\n",
    "    out_sdate = pd.to_datetime(out_start, errors='coerce')\n",
    "    out_edate = pd.to_datetime(out_end, errors='coerce')\n",
    "    \n",
    "    if None in [in_sdate, in_edate, out_sdate, out_edate]:\n",
    "        logging.error(\"Invalid date format. Please use YYYY-MM or recognized format.\")\n",
    "        print(\"Please fix date inputs and try again.\")\n",
    "        return None\n",
    "    \n",
    "    if not (in_sdate < in_edate <= out_sdate < out_edate):\n",
    "        logging.warning(\"Date ranges might be overlapping or out of order. Proceed with caution.\")\n",
    "        print(\"Warning: The date range might be incorrect. Please verify.\")\n",
    "    \n",
    "    # Convert 'Date' to datetime\n",
    "    if not np.issubdtype(df['Date'].dtype, np.datetime64):\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "    df.sort_values(by='Date', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # Identify risk-free column\n",
    "    rf_col = identify_risk_free_fund(df)\n",
    "    \n",
    "    # Fill short gaps\n",
    "    for col in df.columns:\n",
    "        if col != 'Date':\n",
    "            df[col] = fill_short_gaps_with_zero(df[col])\n",
    "    \n",
    "    # Select funds\n",
    "    selected_funds = select_funds(df, rf_col, selection_mode, random_n)\n",
    "    if len(selected_funds) == 0:\n",
    "        logging.warning(\"No valid funds remain after filtering.\")\n",
    "        print(\"Warning: No valid funds. Try adjusting your selection or data filters.\")\n",
    "        return None\n",
    "    \n",
    "    # Separate in-sample, out-of-sample\n",
    "    in_sample_mask = (df['Date'] >= in_sdate) & (df['Date'] <= in_edate)\n",
    "    out_sample_mask = (df['Date'] >= out_sdate) & (df['Date'] <= out_edate)\n",
    "    \n",
    "    in_sample_df = df.loc[in_sample_mask].copy()\n",
    "    out_sample_df = df.loc[out_sample_mask].copy()\n",
    "    \n",
    "    in_sample_rf = in_sample_df[rf_col]\n",
    "    out_sample_rf = out_sample_df[rf_col]\n",
    "    \n",
    "    # Compute scale factors in-sample\n",
    "    scale_factors = {}\n",
    "    in_sample_scaled = pd.DataFrame(index=in_sample_df.index, columns=selected_funds)\n",
    "    out_sample_scaled = pd.DataFrame(index=out_sample_df.index, columns=selected_funds)\n",
    "    \n",
    "    for fund in selected_funds:\n",
    "        fund_in_rets = in_sample_df[fund].dropna()\n",
    "        current_vol = annualize_volatility(fund_in_rets)\n",
    "        if pd.isna(current_vol) or current_vol == 0:\n",
    "            scale_factors[fund] = 1.0\n",
    "            continue\n",
    "        scale_factors[fund] = target_vol / current_vol\n",
    "    \n",
    "    # Apply scaling in-sample & out-of-sample\n",
    "    for fund in selected_funds:\n",
    "        sf = scale_factors[fund]\n",
    "        # In-sample\n",
    "        adj_in = in_sample_df[fund] * sf - monthly_cost\n",
    "        adj_in[adj_in < -1.0] = -1.0\n",
    "        in_sample_scaled[fund] = adj_in\n",
    "        \n",
    "        # Out-of-sample\n",
    "        if out_sample_df.shape[0] > 0:\n",
    "            adj_out = out_sample_df[fund] * sf - monthly_cost\n",
    "            adj_out[adj_out < -1.0] = -1.0\n",
    "            out_sample_scaled[fund] = adj_out\n",
    "    \n",
    "    # Helper function for stats\n",
    "    def compute_stats(series, rf_series):\n",
    "        r = annualize_return(series)\n",
    "        v = annualize_volatility(series)\n",
    "        sr = sharpe_ratio(series, rf_series)\n",
    "        so = sortino_ratio(series, rf_series)\n",
    "        mdd = max_drawdown(series)\n",
    "        return (r, v, sr, so, mdd)\n",
    "    \n",
    "    in_sample_stats = {}\n",
    "    for fund in selected_funds:\n",
    "        in_sample_stats[fund] = compute_stats(in_sample_scaled[fund], in_sample_rf)\n",
    "    \n",
    "    out_sample_stats = {}\n",
    "    for fund in selected_funds:\n",
    "        out_sample_stats[fund] = compute_stats(out_sample_scaled[fund], out_sample_rf)\n",
    "    \n",
    "    out_sample_stats_raw = {}\n",
    "    for fund in selected_funds:\n",
    "        out_sample_stats_raw[fund] = compute_stats(out_sample_df[fund], out_sample_rf)\n",
    "    \n",
    "    # Portfolio (equal-weight)\n",
    "    ew_w = np.array([1.0/len(selected_funds)]*len(selected_funds))\n",
    "    in_ew_port = calc_portfolio_returns(ew_w, in_sample_scaled[selected_funds])\n",
    "    out_ew_port = calc_portfolio_returns(ew_w, out_sample_scaled[selected_funds])\n",
    "    out_ew_port_raw = calc_portfolio_returns(ew_w, out_sample_df[selected_funds])\n",
    "    \n",
    "    in_ew_stats = compute_stats(in_ew_port, in_sample_rf)\n",
    "    out_ew_stats = compute_stats(out_ew_port, out_sample_rf)\n",
    "    out_ew_stats_raw = compute_stats(out_ew_port_raw, out_sample_rf)\n",
    "    \n",
    "    # Portfolio (user-weighted) - placeholder\n",
    "    user_weight_dict = {f: 1.0/len(selected_funds) for f in selected_funds}\n",
    "    custom_w = np.array([user_weight_dict[f] for f in selected_funds])\n",
    "    in_user_port = calc_portfolio_returns(custom_w, in_sample_scaled[selected_funds])\n",
    "    out_user_port = calc_portfolio_returns(custom_w, out_sample_scaled[selected_funds])\n",
    "    out_user_port_raw = calc_portfolio_returns(custom_w, out_sample_df[selected_funds])\n",
    "    \n",
    "    in_user_stats = compute_stats(in_user_port, in_sample_rf)\n",
    "    out_user_stats = compute_stats(out_user_port, out_sample_rf)\n",
    "    out_user_stats_raw = compute_stats(out_user_port_raw, out_sample_rf)\n",
    "    \n",
    "    results = {\n",
    "        'selected_funds': selected_funds,\n",
    "        'in_sample_scaled': in_sample_scaled,\n",
    "        'out_sample_scaled': out_sample_scaled,\n",
    "        'in_sample_stats': in_sample_stats,\n",
    "        'out_sample_stats': out_sample_stats,\n",
    "        'out_sample_stats_raw': out_sample_stats_raw,\n",
    "        'in_ew_stats': in_ew_stats,\n",
    "        'out_ew_stats': out_ew_stats,\n",
    "        'out_ew_stats_raw': out_ew_stats_raw,\n",
    "        'in_user_stats': in_user_stats,\n",
    "        'out_user_stats': out_user_stats,\n",
    "        'out_user_stats_raw': out_user_stats_raw\n",
    "    }\n",
    "    logging.info(\"Analysis complete.\")\n",
    "    return results\n",
    "\n",
    "print(\"run_analysis function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 8. Excel Export\n",
    "Creates an Excel file with two sheets (In-Sample, Out-of-Sample) and two tables per sheet (Equal-weight and User-weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_to_excel function ready.\n"
     ]
    }
   ],
   "source": [
    "def export_to_excel(results_dict, output_filename=\"AnalysisOutput.xlsx\"):\n",
    "    \"\"\"\n",
    "    Create an Excel file with two tabs: In-Sample, Out-of-Sample.\n",
    "    Each has two tables: (1) Equal-Weight, (2) User-Weighted.\n",
    "    Columns for Return(%), Vol(%), Sharpe, Sortino, MaxDD(%).\n",
    "    For OOS, also show 'before scaling' vs. 'after scaling' returns/vol.\n",
    "    \"\"\"\n",
    "    selected_funds = results_dict['selected_funds']\n",
    "    in_sample_stats = results_dict['in_sample_stats']\n",
    "    out_sample_stats_scaled = results_dict['out_sample_stats']\n",
    "    out_sample_stats_raw = results_dict['out_sample_stats_raw']\n",
    "\n",
    "    in_ew_stats = results_dict['in_ew_stats']\n",
    "    out_ew_stats_scaled = results_dict['out_ew_stats']\n",
    "    out_ew_stats_raw = results_dict['out_ew_stats_raw']\n",
    "\n",
    "    in_user_stats = results_dict['in_user_stats']\n",
    "    out_user_stats_scaled = results_dict['out_user_stats']\n",
    "    out_user_stats_raw = results_dict['out_user_stats_raw']\n",
    "\n",
    "    # --- In-Sample DataFrames ---\n",
    "    in_eq_data = []\n",
    "    in_user_data = []\n",
    "    for fund in selected_funds:\n",
    "        r, v, s, so, mdd = in_sample_stats[fund]\n",
    "        in_eq_data.append([fund, r*100, v*100, s, so, mdd*100])\n",
    "        in_user_data.append([fund, r*100, v*100, s, so, mdd*100])\n",
    "\n",
    "    in_eq_data.append([\n",
    "        'Equal-Weight Portfolio',\n",
    "        in_ew_stats[0]*100,\n",
    "        in_ew_stats[1]*100,\n",
    "        in_ew_stats[2],\n",
    "        in_ew_stats[3],\n",
    "        in_ew_stats[4]*100\n",
    "    ])\n",
    "    in_user_data.append([\n",
    "        'User-Weighted Portfolio',\n",
    "        in_user_stats[0]*100,\n",
    "        in_user_stats[1]*100,\n",
    "        in_user_stats[2],\n",
    "        in_user_stats[3],\n",
    "        in_user_stats[4]*100\n",
    "    ])\n",
    "\n",
    "    in_eq_df = pd.DataFrame(\n",
    "        in_eq_data,\n",
    "        columns=['Fund', 'Return (%)', 'Volatility (%)', 'Sharpe', 'Sortino', 'MaxDD (%)']\n",
    "    )\n",
    "    in_user_df = pd.DataFrame(\n",
    "        in_user_data,\n",
    "        columns=['Fund', 'Return (%)', 'Volatility (%)', 'Sharpe', 'Sortino', 'MaxDD (%)']\n",
    "    )\n",
    "\n",
    "    # --- Out-of-Sample DataFrames ---\n",
    "    # columns: [Fund, RetBefore(%), VolBefore(%), RetAfter(%), VolAfter(%), Sharpe(After), Sortino(After), MaxDD(After)(%)]\n",
    "    out_eq_data = []\n",
    "    out_user_data = []\n",
    "\n",
    "    for fund in selected_funds:\n",
    "        r_raw, v_raw, _, _, _ = out_sample_stats_raw[fund]\n",
    "        r_scaled, v_scaled, s_scaled, so_scaled, mdd_scaled = out_sample_stats_scaled[fund]\n",
    "        out_eq_data.append([\n",
    "            fund,\n",
    "            r_raw*100,\n",
    "            v_raw*100,\n",
    "            r_scaled*100,\n",
    "            v_scaled*100,\n",
    "            s_scaled,\n",
    "            so_scaled,\n",
    "            mdd_scaled*100\n",
    "        ])\n",
    "        out_user_data.append([\n",
    "            fund,\n",
    "            r_raw*100,\n",
    "            v_raw*100,\n",
    "            r_scaled*100,\n",
    "            v_scaled*100,\n",
    "            s_scaled,\n",
    "            so_scaled,\n",
    "            mdd_scaled*100\n",
    "        ])\n",
    "\n",
    "    r_ew_raw, v_ew_raw, _, _, _ = out_ew_stats_raw\n",
    "    r_ew_scaled, v_ew_scaled, s_ew_scaled, so_ew_scaled, mdd_ew_scaled = out_ew_stats_scaled\n",
    "    out_eq_data.append([\n",
    "        'Equal-Weight Portfolio',\n",
    "        r_ew_raw*100,\n",
    "        v_ew_raw*100,\n",
    "        r_ew_scaled*100,\n",
    "        v_ew_scaled*100,\n",
    "        s_ew_scaled,\n",
    "        so_ew_scaled,\n",
    "        mdd_ew_scaled*100\n",
    "    ])\n",
    "\n",
    "    r_user_raw, v_user_raw, _, _, _ = out_user_stats_raw\n",
    "    r_user_scaled, v_user_scaled, s_user_scaled, so_user_scaled, mdd_user_scaled = out_user_stats_scaled\n",
    "    out_user_data.append([\n",
    "        'User-Weighted Portfolio',\n",
    "        r_user_raw*100,\n",
    "        v_user_raw*100,\n",
    "        r_user_scaled*100,\n",
    "        v_user_scaled*100,\n",
    "        s_user_scaled,\n",
    "        so_user_scaled,\n",
    "        mdd_user_scaled*100\n",
    "    ])\n",
    "\n",
    "    out_eq_df = pd.DataFrame(\n",
    "        out_eq_data,\n",
    "        columns=['Fund', 'RetBefore(%)', 'VolBefore(%)', 'RetAfter(%)', 'VolAfter(%)', 'Sharpe(After)', 'Sortino(After)', 'MaxDD(After)(%)']\n",
    "    )\n",
    "    out_user_df = pd.DataFrame(\n",
    "        out_user_data,\n",
    "        columns=['Fund', 'RetBefore(%)', 'VolBefore(%)', 'RetAfter(%)', 'VolAfter(%)', 'Sharpe(After)', 'Sortino(After)', 'MaxDD(After)(%)']\n",
    "    )\n",
    "\n",
    "    writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "\n",
    "    # In-Sample Sheet\n",
    "    in_eq_df.to_excel(writer, sheet_name='In-Sample', startrow=0, index=False)\n",
    "    in_user_df.to_excel(writer, sheet_name='In-Sample', startrow=len(in_eq_df)+3, index=False)\n",
    "\n",
    "    # Out-of-Sample Sheet\n",
    "    out_eq_df.to_excel(writer, sheet_name='Out-of-Sample', startrow=0, index=False)\n",
    "    out_user_df.to_excel(writer, sheet_name='Out-of-Sample', startrow=len(out_eq_df)+3, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    pct_format = workbook.add_format({'num_format': '0.00%'})\n",
    "    bold_format = workbook.add_format({'bold': True})\n",
    "\n",
    "    # Format In-Sample\n",
    "    in_sample_ws = writer.sheets['In-Sample']\n",
    "    in_sample_ws.set_column(0, 0, 28)  # Fund column\n",
    "    in_sample_ws.set_column(1, 5, 15, pct_format)\n",
    "    # Bold headers\n",
    "    for colx in range(in_eq_df.shape[1]):\n",
    "        in_sample_ws.write(0, colx, in_eq_df.columns[colx], bold_format)\n",
    "    for colx in range(in_user_df.shape[1]):\n",
    "        in_sample_ws.write(len(in_eq_df)+3, colx, in_user_df.columns[colx], bold_format)\n",
    "\n",
    "    # Format Out-of-Sample\n",
    "    out_sample_ws = writer.sheets['Out-of-Sample']\n",
    "    out_sample_ws.set_column(0, 0, 28)\n",
    "    out_sample_ws.set_column(1, 7, 15, pct_format)\n",
    "    for colx in range(out_eq_df.shape[1]):\n",
    "        out_sample_ws.write(0, colx, out_eq_df.columns[colx], bold_format)\n",
    "    for colx in range(out_user_df.shape[1]):\n",
    "        out_sample_ws.write(len(out_eq_df)+3, colx, out_user_df.columns[colx], bold_format)\n",
    "\n",
    "    writer.close()\n",
    "    logging.info(f\"Exported analysis to {output_filename} successfully.\")\n",
    "    print(f\"Excel file created: {output_filename}\")\n",
    "\n",
    "print(\"export_to_excel function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 8. Demo Run\n",
    "The `demo_run()` function creates a small dummy dataset, runs the analysis, and exports the results to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d89721c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_run function ready. Call 'demo_run()' to test.\n"
     ]
    }
   ],
   "source": [
    "def demo_run():\n",
    "    \"\"\"\n",
    "    Create a small dummy dataset, run analysis, export results.\n",
    "    \"\"\"\n",
    "    # Create monthly date range\n",
    "    rng = pd.date_range(start='2003-01-01', end='2010-12-01', freq='MS')\n",
    "    df_demo = pd.DataFrame({'Date': rng})\n",
    "\n",
    "    np.random.seed(42)\n",
    "    rf_values = np.random.normal(loc=0.002, scale=0.0001, size=len(rng))\n",
    "    df_demo['RF'] = rf_values\n",
    "\n",
    "    # Random funds with missing data\n",
    "    for i in range(1, 6):\n",
    "        fund_name = f\"Fund_{i}\"\n",
    "        mean_r = 0.01 * i / 10.0\n",
    "        stdev_r = 0.02 * (i / 5.0)\n",
    "        rets = np.random.normal(loc=mean_r, scale=stdev_r, size=len(rng))\n",
    "\n",
    "        # Introduce random short or long gaps\n",
    "        if i == 3:\n",
    "            missing_idx = np.random.choice(len(rng), 2, replace=False)\n",
    "            for idx in missing_idx:\n",
    "                rets[idx] = np.nan\n",
    "        if i == 4:\n",
    "            rets[10:13] = np.nan  # 3 consecutive -> exclude\n",
    "\n",
    "        df_demo[fund_name] = rets\n",
    "\n",
    "    # Shuffle rows to test sorting\n",
    "    df_demo = df_demo.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    results = run_analysis(\n",
    "        df_demo,\n",
    "        in_start='2003-01', in_end='2005-12',\n",
    "        out_start='2006-01', out_end='2010-12',\n",
    "        target_vol=0.10,\n",
    "        monthly_cost=0.002,\n",
    "        selection_mode='all',\n",
    "        random_n=2\n",
    "    )\n",
    "\n",
    "    if results is not None:\n",
    "        export_to_excel(results, \"DemoAnalysisOutput.xlsx\")\n",
    "        print(\"Demo run complete.\")\n",
    "\n",
    "print(\"demo_run function ready. Call 'demo_run()' to test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b7c730-225c-4c69-9dbf-d1ec9971a26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfd354513874426b590b69b3cc1543f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='2003-01', description='In-Sample Start:'), Text(value='2005-12', description='In-Sa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bc8aa89ee34b778e8a1324ffbec468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (C) Wire the button and display\n",
    "apply_button.on_click(on_apply_clicked)\n",
    "display(ui_inputs, output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
