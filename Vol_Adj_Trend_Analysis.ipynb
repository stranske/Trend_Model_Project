{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4984b33",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and validate data.\n",
    "2. Handle missing data (short vs. long gaps).\n",
    "3. Adjust returns to a target volatility in-sample, then apply the same scaling out-of-sample.\n",
    "4. Compute Sharpe, Sortino, Max Drawdown.\n",
    "5. Provide multiple fund selection modes (all, random sample, manual).\n",
    "6. Calculate portfolio results (equal-weight and custom-weight).\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting.\n",
    "\n",
    "**Note**: The manual fund selection and custom weights features are partially implemented. In a real interactive workflow, you would wire widget selections and weights into the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging started. Volatility Scaling & Portfolio Analysis Notebook initialized.\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# ============ 1. SETUP CELL ============\n",
    "\n",
    "import sys\n",
    "\n",
    "# If you need to install these packages on your environment, uncomment:\n",
    "!{sys.executable} -m pip install --quiet ipywidgets openpyxl xlsxwriter\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, VBox, HBox\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# For exporting to Excel with styling\n",
    "import xlsxwriter\n",
    "\n",
    "# Set up logging to console\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s: %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Logging started. Volatility Scaling & Portfolio Analysis Notebook initialized.\")\n",
    "\n",
    "# (Optional) If widgets aren't enabled, run:\n",
    "# !jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 2. Utility Functions\n",
    "Here we define date parsing, consecutive gap checks, data filling, risk-free identification, return calculations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded.\n"
     ]
    }
   ],
   "source": [
    "def parse_dates(date_str):\n",
    "    \"\"\"\n",
    "    Attempt to parse a date string into a Python datetime.date object.\n",
    "    Return None if parsing fails.\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    possible_formats = [\"%Y-%m\", \"%Y-%m-%d\", \"%b-%Y\", \"%m/%d/%Y\", \"%Y/%m/%d\"]\n",
    "    for fmt in possible_formats:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_str, fmt).date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def consecutive_gaps(series, threshold=3):\n",
    "    \"\"\"\n",
    "    Check if a series (sorted chronologically) has >= threshold consecutive NaNs.\n",
    "    Return True if such a gap exists, False otherwise.\n",
    "    \"\"\"\n",
    "    consecutive = 0\n",
    "    for val in series:\n",
    "        if pd.isna(val):\n",
    "            consecutive += 1\n",
    "        else:\n",
    "            consecutive = 0\n",
    "        if consecutive >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fill_short_gaps_with_zero(series, max_short_gap=2):\n",
    "    \"\"\"\n",
    "    Replace missing values (NaN) with 0 if they appear in runs of <= max_short_gap.\n",
    "    Longer runs remain NaN.\n",
    "    \"\"\"\n",
    "    filled = series.copy()\n",
    "    n = len(series)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if pd.isna(filled[i]):\n",
    "            run_start = i\n",
    "            while i < n and pd.isna(filled[i]):\n",
    "                i += 1\n",
    "            run_end = i  # first non-NaN after run\n",
    "            gap_length = run_end - run_start\n",
    "            if gap_length <= max_short_gap:\n",
    "                filled[run_start:run_end] = 0.0\n",
    "        else:\n",
    "            i += 1\n",
    "    return filled\n",
    "\n",
    "def identify_risk_free_fund(df):\n",
    "    \"\"\"\n",
    "    Identify which column (after 'Date') is the risk-free rate by smallest stdev among columns.\n",
    "    \"\"\"\n",
    "    numeric_cols = df.columns[1:]  # skip the Date column\n",
    "    stdevs = {}\n",
    "    for col in numeric_cols:\n",
    "        vals = df[col].dropna()\n",
    "        if len(vals) > 0:\n",
    "            stdevs[col] = vals.std()\n",
    "        else:\n",
    "            stdevs[col] = np.inf\n",
    "\n",
    "    rf_col = min(stdevs, key=stdevs.get)\n",
    "    logging.info(f\"Identified '{rf_col}' as the risk-free column (lowest stdev).\")\n",
    "    return rf_col\n",
    "\n",
    "def annualize_return(monthly_returns):\n",
    "    \"\"\"\n",
    "    Annualized (geometric) return from monthly returns in decimal form.\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) == 0:\n",
    "        return np.nan\n",
    "    growth_factor = (1 + valid_rets).prod()\n",
    "    n_months = len(valid_rets)\n",
    "    if growth_factor <= 0:\n",
    "        return -1.0\n",
    "    ann_ret = growth_factor**(12.0 / n_months) - 1\n",
    "    return ann_ret\n",
    "\n",
    "def annualize_volatility(monthly_returns):\n",
    "    \"\"\"\n",
    "    Annualized stdev of monthly returns, i.e. stdev * sqrt(12).\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) < 2:\n",
    "        return np.nan\n",
    "    return valid_rets.std() * np.sqrt(12)\n",
    "\n",
    "def sharpe_ratio(monthly_returns, rf_series):\n",
    "    \"\"\"\n",
    "    Annualized Sharpe ratio = (annual_excess_return) / (annual_excess_vol).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'r': monthly_returns, 'rf': rf_series}).dropna()\n",
    "    if len(df) < 2:\n",
    "        return np.nan\n",
    "    excess = df['r'] - df['rf']\n",
    "    growth_factor = (1 + excess).prod()\n",
    "    n_months = len(excess)\n",
    "    if growth_factor <= 0:\n",
    "        return np.nan\n",
    "    ann_excess_ret = growth_factor**(12.0 / n_months) - 1\n",
    "    ann_excess_vol = excess.std() * np.sqrt(12)\n",
    "    if ann_excess_vol == 0:\n",
    "        return np.nan\n",
    "    return ann_excess_ret / ann_excess_vol\n",
    "\n",
    "def sortino_ratio(monthly_returns, rf_series):\n",
    "    \"\"\"\n",
    "    Annualized Sortino ratio = (annual_excess_return) / (annual_downside_stdev).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'r': monthly_returns, 'rf': rf_series}).dropna()\n",
    "    if len(df) < 2:\n",
    "        return np.nan\n",
    "    excess = df['r'] - df['rf']\n",
    "\n",
    "    growth_factor = (1 + excess).prod()\n",
    "    n_months = len(excess)\n",
    "    if growth_factor <= 0:\n",
    "        return np.nan\n",
    "    ann_excess_ret = growth_factor**(12.0 / n_months) - 1\n",
    "\n",
    "    negative_mask = excess < 0\n",
    "    negative_returns = excess[negative_mask]\n",
    "    if len(negative_returns) == 0:\n",
    "        return np.inf  # no negative => infinite sortino\n",
    "    downside_stdev = negative_returns.std() * np.sqrt(12)\n",
    "    return ann_excess_ret / downside_stdev\n",
    "\n",
    "def max_drawdown(monthly_returns):\n",
    "    \"\"\"\n",
    "    Compute max drawdown from monthly returns in decimal form.\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) == 0:\n",
    "        return np.nan\n",
    "    wealth_index = (1 + valid_rets).cumprod()\n",
    "    rolling_max = wealth_index.cummax()\n",
    "    dd_series = 1 - (wealth_index / rolling_max)\n",
    "    return dd_series.max()\n",
    "\n",
    "def calc_portfolio_returns(weights, df_returns):\n",
    "    \"\"\"\n",
    "    Compute monthly portfolio returns (Series) as weighted sum of columns in df_returns.\n",
    "    \"\"\"\n",
    "    return (df_returns * weights).sum(axis=1)\n",
    "\n",
    "print(\"Utility functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1619c9",
   "metadata": {},
   "source": [
    "## 3. Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffad994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widgets defined. Use 'display(ui_inputs)' in a cell to show them.\n"
     ]
    }
   ],
   "source": [
    "in_sample_start = widgets.Text(\n",
    "    value='2003-01',\n",
    "    description='In-Sample Start (YYYY-MM):',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "in_sample_end = widgets.Text(\n",
    "    value='2008-12',\n",
    "    description='In-Sample End (YYYY-MM):',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "out_sample_start = widgets.Text(\n",
    "    value='2009-01',\n",
    "    description='Out-Sample Start (YYYY-MM):',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "out_sample_end = widgets.Text(\n",
    "    value='2010-12',\n",
    "    description='Out-Sample End (YYYY-MM):',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "target_vol_widget = widgets.FloatText(\n",
    "    value=0.10,\n",
    "    description='Target Vol (annual):',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "monthly_cost_widget = widgets.FloatText(\n",
    "    value=0.002,\n",
    "    description='Monthly Cost:',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "selection_mode_widget = widgets.Dropdown(\n",
    "    options=[('All Funds', 'all'),\n",
    "             ('Random Sample', 'random'),\n",
    "             ('Manual Selection', 'manual')],\n",
    "    value='all',\n",
    "    description='Selection Mode:'\n",
    ")\n",
    "\n",
    "random_sample_size_widget = widgets.IntText(\n",
    "    value=5,\n",
    "    description='Sample Size:',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "apply_button = widgets.Button(\n",
    "    description='Run Analysis',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "ui_inputs = VBox([\n",
    "    in_sample_start, in_sample_end,\n",
    "    out_sample_start, out_sample_end,\n",
    "    target_vol_widget, monthly_cost_widget,\n",
    "    selection_mode_widget, random_sample_size_widget,\n",
    "    apply_button\n",
    "])\n",
    "\n",
    "print(\"Widgets defined. Use 'display(ui_inputs)' in a cell to show them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb08caa0-d758-41e1-907b-a073e3aaba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f19915cdd24ed287a17a015407593f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='2003-01', description='In-Sample Start (YYYY-MM):', layout=Layout(width='300px')), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eb165",
   "metadata": {},
   "source": [
    "## 4. Fund Selection\n",
    "Filters out columns that represent the risk-free rate or contain \"index\" in the name, then handles the selection mode (all, random, or manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e571d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_funds function ready.\n"
     ]
    }
   ],
   "source": [
    "def select_funds(df, rf_col, selection_mode='all', random_n=5):\n",
    "    \"\"\"\n",
    "    Exclude the risk-free col and any 'index' columns from the fund list.\n",
    "    Then filter out funds that have >=3 consecutive missing months.\n",
    "    Then apply the specified selection_mode.\n",
    "    \"\"\"\n",
    "    possible_funds = [c for c in df.columns if c not in ['Date', rf_col]]\n",
    "    \n",
    "    funds_only = []\n",
    "    for col in possible_funds:\n",
    "        if 'index' in col.lower():\n",
    "            continue\n",
    "        funds_only.append(col)\n",
    "    \n",
    "    valid_funds = []\n",
    "    for col in funds_only:\n",
    "        if not consecutive_gaps(df[col], threshold=3):\n",
    "            valid_funds.append(col)\n",
    "    \n",
    "    if selection_mode == 'all':\n",
    "        return valid_funds\n",
    "    elif selection_mode == 'random':\n",
    "        if len(valid_funds) <= random_n:\n",
    "            warnings.warn(f\"Fewer valid funds ({len(valid_funds)}) than sample size ({random_n}). Returning all.\")\n",
    "            return valid_funds\n",
    "        else:\n",
    "            return random.sample(valid_funds, random_n)\n",
    "    else:\n",
    "        # manual selection widget placeholder\n",
    "        # In a real notebook, you'd display a multi-select widget.\n",
    "        # For simplicity, just return all valid funds here.\n",
    "        return valid_funds\n",
    "\n",
    "print(\"select_funds function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c60582",
   "metadata": {},
   "source": [
    "## 5. Custom Weights\n",
    "Displays an integer text widget for each fund, requiring the sum of weights to be 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a404c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_custom_weights function ready.\n"
     ]
    }
   ],
   "source": [
    "def get_custom_weights(selected_funds):\n",
    "    \"\"\"\n",
    "    Display widgets for each fund to enter weights. Validate sum=100.\n",
    "    Returns dict {fund: weight_decimal}.\n",
    "    \"\"\"\n",
    "    weight_widgets = {}\n",
    "    for fund in selected_funds:\n",
    "        w = widgets.BoundedIntText(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description=f\"{fund}\",\n",
    "            layout=widgets.Layout(width='250px')\n",
    "        )\n",
    "        weight_widgets[fund] = w\n",
    "    \n",
    "    confirm_button = widgets.Button(\n",
    "        description='Confirm Weights',\n",
    "        button_style='success'\n",
    "    )\n",
    "    error_label = widgets.Label(value='', layout=widgets.Layout(color='red'))\n",
    "    \n",
    "    box = VBox(list(weight_widgets.values()) + [confirm_button, error_label])\n",
    "    display(box)\n",
    "    \n",
    "    weights_container = {}\n",
    "    \n",
    "    def on_confirm_clicked(_):\n",
    "        total = sum(w.value for w in weight_widgets.values())\n",
    "        if total != 100:\n",
    "            error_label.value = f\"Error: Weights sum to {total}, must be 100.\"\n",
    "            weights_container.clear()\n",
    "        else:\n",
    "            for fund, wdg in weight_widgets.items():\n",
    "                weights_container[fund] = wdg.value / 100.0\n",
    "            error_label.value = \"Weights confirmed!\"\n",
    "    \n",
    "    confirm_button.on_click(on_confirm_clicked)\n",
    "    return weights_container\n",
    "\n",
    "print(\"get_custom_weights function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 6. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0696a436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_analysis function ready.\n"
     ]
    }
   ],
   "source": [
    "def run_analysis(df, \n",
    "                 in_start, in_end, out_start, out_end, \n",
    "                 target_vol, monthly_cost,\n",
    "                 selection_mode='all', random_n=5):\n",
    "    \"\"\"\n",
    "    Orchestrate the analysis:\n",
    "    1) Validate date inputs\n",
    "    2) Convert 'Date' col\n",
    "    3) Identify risk-free\n",
    "    4) Fill short gaps, filter by 3+ gap\n",
    "    5) Select funds\n",
    "    6) Scale returns in-sample, apply factor + monthly cost OOS\n",
    "    7) Compute stats + portfolio metrics\n",
    "    8) Return a dictionary of results\n",
    "    \"\"\"\n",
    "    in_sdate = parse_dates(in_start)\n",
    "    in_edate = parse_dates(in_end)\n",
    "    out_sdate = parse_dates(out_start)\n",
    "    out_edate = parse_dates(out_end)\n",
    "    \n",
    "    if None in [in_sdate, in_edate, out_sdate, out_edate]:\n",
    "        logging.error(\"Invalid date format. Please use YYYY-MM or recognized format.\")\n",
    "        print(\"Please fix date inputs and try again.\")\n",
    "        return None\n",
    "    \n",
    "    if not (in_sdate < in_edate <= out_sdate < out_edate):\n",
    "        logging.warning(\"Date ranges might be overlapping or out of order. Proceed with caution.\")\n",
    "        print(\"Warning: The date range might be incorrect. Please verify.\")\n",
    "    \n",
    "    # Convert 'Date' to datetime\n",
    "    if not np.issubdtype(df['Date'].dtype, np.datetime64):\n",
    "        df['Date'] = df['Date'].apply(parse_dates)\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "    df.sort_values(by='Date', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Identify risk-free column\n",
    "    rf_col = identify_risk_free_fund(df)\n",
    "    \n",
    "    # Fill short gaps\n",
    "    for col in df.columns:\n",
    "        if col != 'Date':\n",
    "            df[col] = fill_short_gaps_with_zero(df[col])\n",
    "    \n",
    "    # Select funds\n",
    "    selected_funds = select_funds(df, rf_col, selection_mode, random_n)\n",
    "    if len(selected_funds) == 0:\n",
    "        logging.warning(\"No valid funds remain after filtering.\")\n",
    "        print(\"Warning: No valid funds. Try adjusting your selection or data filters.\")\n",
    "        return None\n",
    "    \n",
    "    # Separate in-sample, out-of-sample\n",
    "    in_sample_mask = (df['Date'] >= in_sdate) & (df['Date'] <= in_edate)\n",
    "    out_sample_mask = (df['Date'] >= out_sdate) & (df['Date'] <= out_edate)\n",
    "    \n",
    "    in_sample_df = df.loc[in_sample_mask].copy()\n",
    "    out_sample_df = df.loc[out_sample_mask].copy()\n",
    "    \n",
    "    in_sample_rf = in_sample_df[rf_col]\n",
    "    out_sample_rf = out_sample_df[rf_col]\n",
    "    \n",
    "    # Compute scale factors in-sample\n",
    "    scale_factors = {}\n",
    "    in_sample_scaled = pd.DataFrame(index=in_sample_df.index, columns=selected_funds)\n",
    "    out_sample_scaled = pd.DataFrame(index=out_sample_df.index, columns=selected_funds)\n",
    "    \n",
    "    for fund in selected_funds:\n",
    "        fund_in_rets = in_sample_df[fund].dropna()\n",
    "        current_vol = annualize_volatility(fund_in_rets)\n",
    "        if pd.isna(current_vol) or current_vol == 0:\n",
    "            scale_factors[fund] = 1.0\n",
    "            continue\n",
    "        scale_factors[fund] = target_vol / current_vol\n",
    "    \n",
    "    # Apply scaling in-sample & out-of-sample\n",
    "    for fund in selected_funds:\n",
    "        sf = scale_factors[fund]\n",
    "        # In-sample\n",
    "        adj_in = in_sample_df[fund] * sf - monthly_cost\n",
    "        adj_in[adj_in < -1.0] = -1.0\n",
    "        in_sample_scaled[fund] = adj_in\n",
    "        \n",
    "        # Out-of-sample\n",
    "        if out_sample_df.shape[0] > 0:\n",
    "            adj_out = out_sample_df[fund] * sf - monthly_cost\n",
    "            adj_out[adj_out < -1.0] = -1.0\n",
    "            out_sample_scaled[fund] = adj_out\n",
    "    \n",
    "    # Helper function for stats\n",
    "    def compute_stats(series, rf_series):\n",
    "        r = annualize_return(series)\n",
    "        v = annualize_volatility(series)\n",
    "        sr = sharpe_ratio(series, rf_series)\n",
    "        so = sortino_ratio(series, rf_series)\n",
    "        mdd = max_drawdown(series)\n",
    "        return (r, v, sr, so, mdd)\n",
    "    \n",
    "    in_sample_stats = {}\n",
    "    for fund in selected_funds:\n",
    "        in_sample_stats[fund] = compute_stats(in_sample_scaled[fund], in_sample_rf)\n",
    "    \n",
    "    out_sample_stats = {}\n",
    "    for fund in selected_funds:\n",
    "        out_sample_stats[fund] = compute_stats(out_sample_scaled[fund], out_sample_rf)\n",
    "    \n",
    "    out_sample_stats_raw = {}\n",
    "    for fund in selected_funds:\n",
    "        out_sample_stats_raw[fund] = compute_stats(out_sample_df[fund], out_sample_rf)\n",
    "    \n",
    "    # Portfolio (equal-weight)\n",
    "    ew_w = np.array([1.0/len(selected_funds)]*len(selected_funds))\n",
    "    in_ew_port = calc_portfolio_returns(ew_w, in_sample_scaled[selected_funds])\n",
    "    out_ew_port = calc_portfolio_returns(ew_w, out_sample_scaled[selected_funds])\n",
    "    out_ew_port_raw = calc_portfolio_returns(ew_w, out_sample_df[selected_funds])\n",
    "    \n",
    "    in_ew_stats = compute_stats(in_ew_port, in_sample_rf)\n",
    "    out_ew_stats = compute_stats(out_ew_port, out_sample_rf)\n",
    "    out_ew_stats_raw = compute_stats(out_ew_port_raw, out_sample_rf)\n",
    "    \n",
    "    # Portfolio (user-weighted) - placeholder\n",
    "    user_weight_dict = {f: 1.0/len(selected_funds) for f in selected_funds}\n",
    "    custom_w = np.array([user_weight_dict[f] for f in selected_funds])\n",
    "    in_user_port = calc_portfolio_returns(custom_w, in_sample_scaled[selected_funds])\n",
    "    out_user_port = calc_portfolio_returns(custom_w, out_sample_scaled[selected_funds])\n",
    "    out_user_port_raw = calc_portfolio_returns(custom_w, out_sample_df[selected_funds])\n",
    "    \n",
    "    in_user_stats = compute_stats(in_user_port, in_sample_rf)\n",
    "    out_user_stats = compute_stats(out_user_port, out_sample_rf)\n",
    "    out_user_stats_raw = compute_stats(out_user_port_raw, out_sample_rf)\n",
    "    \n",
    "    results = {\n",
    "        'selected_funds': selected_funds,\n",
    "        'in_sample_scaled': in_sample_scaled,\n",
    "        'out_sample_scaled': out_sample_scaled,\n",
    "        'in_sample_stats': in_sample_stats,\n",
    "        'out_sample_stats': out_sample_stats,\n",
    "        'out_sample_stats_raw': out_sample_stats_raw,\n",
    "        'in_ew_stats': in_ew_stats,\n",
    "        'out_ew_stats': out_ew_stats,\n",
    "        'out_ew_stats_raw': out_ew_stats_raw,\n",
    "        'in_user_stats': in_user_stats,\n",
    "        'out_user_stats': out_user_stats,\n",
    "        'out_user_stats_raw': out_user_stats_raw\n",
    "    }\n",
    "    logging.info(\"Analysis complete.\")\n",
    "    return results\n",
    "\n",
    "print(\"run_analysis function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 7. Excel Export\n",
    "Creates an Excel file with two sheets (In-Sample, Out-of-Sample) and two tables per sheet (Equal-weight and User-weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_excel(results_dict, output_filename=\"AnalysisOutput.xlsx\"):\n",
    "    \"\"\"\n",
    "    Create an Excel file with two tabs: In-Sample, Out-of-Sample.\n",
    "    Each has two tables: (1) Equal-Weight, (2) User-Weighted.\n",
    "    Columns for Return(%), Vol(%), Sharpe, Sortino, MaxDD(%).\n",
    "    For OOS, also show 'before scaling' vs. 'after scaling' returns/vol.\n",
    "    \"\"\"\n",
    "    selected_funds = results_dict['selected_funds']\n",
    "    in_sample_stats = results_dict['in_sample_stats']\n",
    "    out_sample_stats_scaled = results_dict['out_sample_stats']\n",
    "    out_sample_stats_raw = results_dict['out_sample_stats_raw']\n",
    "\n",
    "    in_ew_stats = results_dict['in_ew_stats']\n",
    "    out_ew_stats_scaled = results_dict['out_ew_stats']\n",
    "    out_ew_stats_raw = results_dict['out_ew_stats_raw']\n",
    "\n",
    "    in_user_stats = results_dict['in_user_stats']\n",
    "    out_user_stats_scaled = results_dict['out_user_stats']\n",
    "    out_user_stats_raw = results_dict['out_user_stats_raw']\n",
    "\n",
    "    # --- In-Sample DataFrames ---\n",
    "    in_eq_data = []\n",
    "    in_user_data = []\n",
    "    for fund in selected_funds:\n",
    "        r, v, s, so, mdd = in_sample_stats[fund]\n",
    "        in_eq_data.append([fund, r*100, v*100, s, so, mdd*100])\n",
    "        in_user_data.append([fund, r*100, v*100, s, so, mdd*100])\n",
    "\n",
    "    in_eq_data.append([\n",
    "        'Equal-Weight Portfolio',\n",
    "        in_ew_stats[0]*100,\n",
    "        in_ew_stats[1]*100,\n",
    "        in_ew_stats[2],\n",
    "        in_ew_stats[3],\n",
    "        in_ew_stats[4]*100\n",
    "    ])\n",
    "    in_user_data.append([\n",
    "        'User-Weighted Portfolio',\n",
    "        in_user_stats[0]*100,\n",
    "        in_user_stats[1]*100,\n",
    "        in_user_stats[2],\n",
    "        in_user_stats[3],\n",
    "        in_user_stats[4]*100\n",
    "    ])\n",
    "\n",
    "    in_eq_df = pd.DataFrame(\n",
    "        in_eq_data,\n",
    "        columns=['Fund', 'Return (%)', 'Volatility (%)', 'Sharpe', 'Sortino', 'MaxDD (%)']\n",
    "    )\n",
    "    in_user_df = pd.DataFrame(\n",
    "        in_user_data,\n",
    "        columns=['Fund', 'Return (%)', 'Volatility (%)', 'Sharpe', 'Sortino', 'MaxDD (%)']\n",
    "    )\n",
    "\n",
    "    # --- Out-of-Sample DataFrames ---\n",
    "    # columns: [Fund, RetBefore(%), VolBefore(%), RetAfter(%), VolAfter(%), Sharpe(After), Sortino(After), MaxDD(After)(%)]\n",
    "    out_eq_data = []\n",
    "    out_user_data = []\n",
    "\n",
    "    for fund in selected_funds:\n",
    "        r_raw, v_raw, _, _, _ = out_sample_stats_raw[fund]\n",
    "        r_scaled, v_scaled, s_scaled, so_scaled, mdd_scaled = out_sample_stats_scaled[fund]\n",
    "        out_eq_data.append([\n",
    "            fund,\n",
    "            r_raw*100,\n",
    "            v_raw*100,\n",
    "            r_scaled*100,\n",
    "            v_scaled*100,\n",
    "            s_scaled,\n",
    "            so_scaled,\n",
    "            mdd_scaled*100\n",
    "        ])\n",
    "        out_user_data.append([\n",
    "            fund,\n",
    "            r_raw*100,\n",
    "            v_raw*100,\n",
    "            r_scaled*100,\n",
    "            v_scaled*100,\n",
    "            s_scaled,\n",
    "            so_scaled,\n",
    "            mdd_scaled*100\n",
    "        ])\n",
    "\n",
    "    r_ew_raw, v_ew_raw, _, _, _ = out_ew_stats_raw\n",
    "    r_ew_scaled, v_ew_scaled, s_ew_scaled, so_ew_scaled, mdd_ew_scaled = out_ew_stats_scaled\n",
    "    out_eq_data.append([\n",
    "        'Equal-Weight Portfolio',\n",
    "        r_ew_raw*100,\n",
    "        v_ew_raw*100,\n",
    "        r_ew_scaled*100,\n",
    "        v_ew_scaled*100,\n",
    "        s_ew_scaled,\n",
    "        so_ew_scaled,\n",
    "        mdd_ew_scaled*100\n",
    "    ])\n",
    "\n",
    "    r_user_raw, v_user_raw, _, _, _ = out_user_stats_raw\n",
    "    r_user_scaled, v_user_scaled, s_user_scaled, so_user_scaled, mdd_user_scaled = out_user_stats_scaled\n",
    "    out_user_data.append([\n",
    "        'User-Weighted Portfolio',\n",
    "        r_user_raw*100,\n",
    "        v_user_raw*100,\n",
    "        r_user_scaled*100,\n",
    "        v_user_scaled*100,\n",
    "        s_user_scaled,\n",
    "        so_user_scaled,\n",
    "        mdd_user_scaled*100\n",
    "    ])\n",
    "\n",
    "    out_eq_df = pd.DataFrame(\n",
    "        out_eq_data,\n",
    "        columns=['Fund', 'RetBefore(%)', 'VolBefore(%)', 'RetAfter(%)', 'VolAfter(%)', 'Sharpe(After)', 'Sortino(After)', 'MaxDD(After)(%)']\n",
    "    )\n",
    "    out_user_df = pd.DataFrame(\n",
    "        out_user_data,\n",
    "        columns=['Fund', 'RetBefore(%)', 'VolBefore(%)', 'RetAfter(%)', 'VolAfter(%)', 'Sharpe(After)', 'Sortino(After)', 'MaxDD(After)(%)']\n",
    "    )\n",
    "\n",
    "    writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "\n",
    "    # In-Sample Sheet\n",
    "    in_eq_df.to_excel(writer, sheet_name='In-Sample', startrow=0, index=False)\n",
    "    in_user_df.to_excel(writer, sheet_name='In-Sample', startrow=len(in_eq_df)+3, index=False)\n",
    "\n",
    "    # Out-of-Sample Sheet\n",
    "    out_eq_df.to_excel(writer, sheet_name='Out-of-Sample', startrow=0, index=False)\n",
    "    out_user_df.to_excel(writer, sheet_name='Out-of-Sample', startrow=len(out_eq_df)+3, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    pct_format = workbook.add_format({'num_format': '0.00%'})\n",
    "    bold_format = workbook.add_format({'bold': True})\n",
    "\n",
    "    # Format In-Sample\n",
    "    in_sample_ws = writer.sheets['In-Sample']\n",
    "    in_sample_ws.set_column(0, 0, 28)  # Fund column\n",
    "    in_sample_ws.set_column(1, 5, 15, pct_format)\n",
    "    # Bold headers\n",
    "    for colx in range(in_eq_df.shape[1]):\n",
    "        in_sample_ws.write(0, colx, in_eq_df.columns[colx], bold_format)\n",
    "    for colx in range(in_user_df.shape[1]):\n",
    "        in_sample_ws.write(len(in_eq_df)+3, colx, in_user_df.columns[colx], bold_format)\n",
    "\n",
    "    # Format Out-of-Sample\n",
    "    out_sample_ws = writer.sheets['Out-of-Sample']\n",
    "    out_sample_ws.set_column(0, 0, 28)\n",
    "    out_sample_ws.set_column(1, 7, 15, pct_format)\n",
    "    for colx in range(out_eq_df.shape[1]):\n",
    "        out_sample_ws.write(0, colx, out_eq_df.columns[colx], bold_format)\n",
    "    for colx in range(out_user_df.shape[1]):\n",
    "        out_sample_ws.write(len(out_eq_df)+3, colx, out_user_df.columns[colx], bold_format)\n",
    "\n",
    "    writer.save()\n",
    "    logging.info(f\"Exported analysis to {output_filename} successfully.\")\n",
    "    print(f\"Excel file created: {output_filename}\")\n",
    "\n",
    "print(\"export_to_excel function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 8. Demo Run\n",
    "The `demo_run()` function creates a small dummy dataset, runs the analysis, and exports the results to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89721c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_run function ready. Call 'demo_run()' to test.\n"
     ]
    }
   ],
   "source": [
    "def demo_run():\n",
    "    \"\"\"\n",
    "    Create a small dummy dataset, run analysis, export results.\n",
    "    \"\"\"\n",
    "    # Create monthly date range\n",
    "    rng = pd.date_range(start='2003-01-01', end='2010-12-01', freq='MS')\n",
    "    df_demo = pd.DataFrame({'Date': rng})\n",
    "\n",
    "    np.random.seed(42)\n",
    "    rf_values = np.random.normal(loc=0.002, scale=0.0001, size=len(rng))\n",
    "    df_demo['RF'] = rf_values\n",
    "\n",
    "    # Random funds with missing data\n",
    "    for i in range(1, 6):\n",
    "        fund_name = f\"Fund_{i}\"\n",
    "        mean_r = 0.01 * i / 10.0\n",
    "        stdev_r = 0.02 * (i / 5.0)\n",
    "        rets = np.random.normal(loc=mean_r, scale=stdev_r, size=len(rng))\n",
    "\n",
    "        # Introduce random short or long gaps\n",
    "        if i == 3:\n",
    "            missing_idx = np.random.choice(len(rng), 2, replace=False)\n",
    "            for idx in missing_idx:\n",
    "                rets[idx] = np.nan\n",
    "        if i == 4:\n",
    "            rets[10:13] = np.nan  # 3 consecutive -> exclude\n",
    "\n",
    "        df_demo[fund_name] = rets\n",
    "\n",
    "    # Shuffle rows to test sorting\n",
    "    df_demo = df_demo.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    results = run_analysis(\n",
    "        df_demo,\n",
    "        in_start='2003-01', in_end='2005-12',\n",
    "        out_start='2006-01', out_end='2010-12',\n",
    "        target_vol=0.10,\n",
    "        monthly_cost=0.002,\n",
    "        selection_mode='all',\n",
    "        random_n=2\n",
    "    )\n",
    "\n",
    "    if results is not None:\n",
    "        export_to_excel(results, \"DemoAnalysisOutput.xlsx\")\n",
    "        print(\"Demo run complete.\")\n",
    "\n",
    "print(\"demo_run function ready. Call 'demo_run()' to test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b7c730-225c-4c69-9dbf-d1ec9971a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Identified 'RF' as the risk-free column (lowest stdev).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=datetime64[ns] and date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidComparison\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/datetimelike.py:983\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_comparison_value(other)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/datetimelike.py:542\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(other):\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidComparison(other)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(other) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mInvalidComparison\u001b[0m: 2003-01-01",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m demo_run()\n",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m, in \u001b[0;36mdemo_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Shuffle rows to test sorting\u001b[39;00m\n\u001b[1;32m     31\u001b[0m df_demo \u001b[38;5;241m=\u001b[39m df_demo\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 33\u001b[0m results \u001b[38;5;241m=\u001b[39m run_analysis(\n\u001b[1;32m     34\u001b[0m     df_demo,\n\u001b[1;32m     35\u001b[0m     in_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2003-01\u001b[39m\u001b[38;5;124m'\u001b[39m, in_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2005-12\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m     out_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2006-01\u001b[39m\u001b[38;5;124m'\u001b[39m, out_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2010-12\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m     target_vol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.10\u001b[39m,\n\u001b[1;32m     38\u001b[0m     monthly_cost\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m,\n\u001b[1;32m     39\u001b[0m     selection_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     40\u001b[0m     random_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     export_to_excel(results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDemoAnalysisOutput.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mrun_analysis\u001b[0;34m(df, in_start, in_end, out_start, out_end, target_vol, monthly_cost, selection_mode, random_n)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Separate in-sample, out-of-sample\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m in_sample_mask \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m in_sdate) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m in_edate)\n\u001b[1;32m     54\u001b[0m out_sample_mask \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m out_sdate) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m out_edate)\n\u001b[1;32m     56\u001b[0m in_sample_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[in_sample_mask]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mge)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:330\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    328\u001b[0m ):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mge)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/datetimelike.py:985\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    983\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_comparison_value(other)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n\u001b[0;32m--> 985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(\u001b[38;5;28mself\u001b[39m, other, op)\n\u001b[1;32m    987\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# We have to use comp_method_OBJECT_ARRAY instead of numpy\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m#  comparison otherwise it would raise when comparing to None\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/invalid.py:40\u001b[0m, in \u001b[0;36minvalid_comparison\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(right)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid comparison between dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid comparison between dtype=datetime64[ns] and date"
     ]
    }
   ],
   "source": [
    "demo_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
