{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22994893-0193-45bc-b9e3-a97b328ecaea",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Imports, Data Loader and Rf Detector\n",
    "2. Select fund (month period logic)\n",
    "3. Weight prep\n",
    "4. Core Stats + Run Analysis\n",
    "5. Export\n",
    "6. Widget /UI\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#      VOL-ADJ TREND ANALYSIS  ‚Äì  SINGLE-FILE VERSION\n",
    "# ===============================================================\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  0 ¬∑ IMPORTS  (all in one place)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from collections import namedtuple\n",
    "import inspect\n",
    "import xlsxwriter\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "from typing import List, Dict, Optional, Callable\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  1 ¬∑ Class Configurations\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "@dataclass\n",
    "class FundSelectionConfig:\n",
    "    max_missing_months:         int = 3\n",
    "    max_consecutive_month_gap:  int = 6\n",
    "    implausible_value_limit: float  = 1\n",
    "    outlier_threshold: float = 0.5\n",
    "    zero_return_threshold: float = 0.2\n",
    "    enforce_monotonic_index: bool = True\n",
    "    allow_duplicate_dates: bool = False\n",
    "    max_missing_ratio: float      = 0.05\n",
    "    max_drawdown: float           = 0.3\n",
    "    min_volatility: float         = 0.05\n",
    "    max_volatility: float         = 1.0\n",
    "    min_avg_return: float         = 0.0\n",
    "    max_skewness: float           = 3.0\n",
    "    max_kurtosis: float           = 10.0\n",
    "    expected_freq: str            = \"B\"\n",
    "    max_gap_days: int             = 3\n",
    "    min_aum_usd: float            = 1e7\n",
    "\n",
    "# Configuration dataclass\n",
    "@dataclass\n",
    "class RiskStatsConfig:\n",
    "    metrics_to_run: List[str] = field(default_factory=lambda: [\n",
    "        \"AnnualReturn\", \"Volatility\", \"Sharpe\", \"Sortino\", \"MaxDrawdown\"\n",
    "    ])\n",
    "    risk_free: float = 0.0\n",
    "    periods_per_year: int = 12\n",
    "\n",
    "# 2. Registry and decorator\n",
    "METRIC_REGISTRY: Dict[str, Callable[..., float]] = {}\n",
    "\n",
    "def register_metric(name: str):\n",
    "    \"\"\"\n",
    "    Decorator to register a metric function under a given name.\n",
    "    \"\"\"\n",
    "    def decorator(fn: Callable[[pd.Series], float]):\n",
    "        METRIC_REGISTRY[name] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "FORMATTERS_EXCEL: dict[str, Callable] = {}\n",
    "def register_formatter_excel(category: str):\n",
    "    def decorator(fn: Callable):\n",
    "        FORMATTERS_EXCEL[category] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "# Example formatters (extend as needed)\n",
    "def safe(v):\n",
    "    \"\"\"\n",
    "    Return blank string for missing/non-finite values; else return the value.\n",
    "    \"\"\"\n",
    "    if v == \"\" or pd.isna(v):\n",
    "        return \"\"\n",
    "    if isinstance(v, (int, float, np.generic)):\n",
    "        return v if np.isfinite(v) else \"\"\n",
    "    return \"\"\n",
    "\n",
    "def pct(t: tuple[float, float, float, float, float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Convert a Stat tuple of five elements into a list of values scaled as percentages for\n",
    "    the 1st, 2nd, and 5th elements.\n",
    "    \"\"\"\n",
    "    return [t[0]*100, t[1]*100, t[2], t[3], t[4]*100]\n",
    "\n",
    "# Consolidated Summary Formatter Factory\n",
    "\n",
    "def make_summary_formatter(\n",
    "    res: dict,\n",
    "    in_start: str,\n",
    "    in_end: str,\n",
    "    out_start: str,\n",
    "    out_end: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Registers a single 'summary' sheet formatter that writes:\n",
    "      1. Portfolio rows (Equal & User weight),\n",
    "      2. Blank spacer,\n",
    "      3. Fund rows,\n",
    "      4. Blank spacer,\n",
    "      5. Index rows\n",
    "    using the data in `res`.\n",
    "    \"\"\"\n",
    "    @register_formatter_excel(\"summary\")\n",
    "    def fmt_summary(ws, wb):\n",
    "        # Predefine formats\n",
    "        bold = wb.add_format({\"bold\": True})\n",
    "        headers = [\n",
    "            \"Name\", \"Weight %\", \"EW %\",\n",
    "            \"R (IN)%\", \"V (IN)%\", \"Sharpe (IN)\", \"Sortino (IN)\", \"MDD (IN)%\",\n",
    "            \"R (OUT)%\", \"V (OUT)%\", \"Sharpe (OUT)\", \"Sortino (OUT)\", \"MDD (OUT)%\"\n",
    "        ]\n",
    "        bold_title  = wb.add_format({\"bold\": True, \"font_size\": 14})\n",
    "        bold_header = wb.add_format({\"bold\": True})\n",
    "        title = \"Vol-Adj Trend Analysis\"\n",
    "        ws.merge_range(0, 0, 0, len(headers)-1, \"Vol-Adj Trend Analysis\", bold_title)\n",
    "        ws.write_row(4, 0, headers, bold_header)\n",
    "        \n",
    "        # ---------------------------------\n",
    "        int0 = wb.add_format({\"num_format\": \"0\"})\n",
    "        num2 = wb.add_format({\"num_format\": \"0.00\"})\n",
    "        red  = wb.add_format({\"num_format\": \"0.00\", \"font_color\": \"red\"})\n",
    "        pct  = lambda t: [t[0]*100, t[1]*100, t[2], t[3], t[4]*100]\n",
    "\n",
    "        # Write static headers\n",
    "        ws.write_row(0, 0, [\"Vol-Adj Trend Analysis\"], bold)\n",
    "        ws.write_row(1, 0, [f\"In:  {in_start} ‚Üí {in_end}\"], bold)\n",
    "        ws.write_row(2, 0, [f\"Out: {out_start} ‚Üí {out_end}\"], bold)\n",
    "\n",
    "        row = 5                             # start after headers\n",
    "        # 1. Portfolio rows\n",
    "        for label, in_s, out_s in [\n",
    "            (\"Equal Weight\", res[\"in_ew_stats\"], res[\"out_ew_stats\"]),\n",
    "            (\"User Weight\",  res[\"in_user_stats\"], res[\"out_user_stats\"])\n",
    "        ]:\n",
    "            ws.write(row, 0, label, bold)\n",
    "            ws.write(row, 1, safe(\"\") if True else int0)\n",
    "            vals = pct(tuple(in_s)) + pct(tuple(out_s))\n",
    "            fmts = ([num2]*4 + [red]) * 2\n",
    "            for col, (v, fmt) in enumerate(zip(vals, fmts), start=2):\n",
    "                ws.write(row, col, safe(v), fmt)\n",
    "            row += 1\n",
    "\n",
    "        # spacer\n",
    "        row += 1\n",
    "\n",
    "        # 2. Fund rows\n",
    "        for fund, stat_in in res[\"in_sample_stats\"].items():\n",
    "            stat_out = res[\"out_sample_stats\"][fund]\n",
    "            ws.write(row, 0, fund, bold)\n",
    "            wt = res[\"fund_weights\"][fund]\n",
    "            ws.write(row, 1, safe(wt*100), int0)\n",
    "            vals = pct(tuple(stat_in)) + pct(tuple(stat_out))\n",
    "            fmts = ([num2]*4 + [red]) * 2\n",
    "            for col, (v, fmt) in enumerate(zip(vals, fmts), start=2):\n",
    "                ws.write(row, col, safe(v), fmt)\n",
    "            row += 1\n",
    "\n",
    "        # spacer\n",
    "        row += 1\n",
    "\n",
    "        # 3. Index rows\n",
    "        for idx, pair in res.get(\"index_stats\", {}).items():\n",
    "            in_idx = pair[\"in_sample\"]\n",
    "            out_idx= pair[\"out_sample\"]\n",
    "            ws.write(row, 0, idx, bold)\n",
    "            ws.write(row, 1, safe(\"\") if True else int0)\n",
    "            vals = pct(tuple(in_idx)) + pct(tuple(out_idx))\n",
    "            fmts = ([num2]*4 + [red]) * 2\n",
    "            for col, (v, fmt) in enumerate(zip(vals, fmts), start=2):\n",
    "                ws.write(row, col, safe(v), fmt)\n",
    "            row += 1\n",
    "\n",
    "    return fmt_summary\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  2 ¬∑ CSV LOADER + RF DETECTOR\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=['Date'])\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(f\"No data in file: {path}\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Parsing error in {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"Date\" not in df.columns:\n",
    "        logger.error(f\"Validation failed ({path}): missing 'Date' column\")\n",
    "        return None\n",
    "\n",
    "    # Optionally check for NaNs in 'Date' column\n",
    "    if df[\"Date\"].isnull().any():\n",
    "        logger.warning(f\"Null values found in 'Date' column of {path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_risk_free_fund(df: pd.DataFrame) -> str:\n",
    "    returns = df.drop(columns=\"Date\", errors=\"ignore\")\n",
    "    stdevs  = returns.std(skipna=True, ddof=0)\n",
    "    return stdevs.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {},
   "source": [
    "## 2. Select Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 2 ¬∑ SELECT_FUNDS  (restored ‚â§ 3-missing-months rule)\n",
    "# ===============================================================\n",
    "\n",
    "cfg = FundSelectionConfig(\n",
    "    max_missing_months           = 3,\n",
    "    max_consecutive_month_gap    = 6,\n",
    "    outlier_threshold            = 0.5,\n",
    "    zero_return_threshold        = 0.2,\n",
    "    enforce_monotonic_index      = True,\n",
    "    allow_duplicate_dates        = False,\n",
    "    max_missing_ratio            = 0.05,\n",
    "    max_drawdown                 = 0.3,\n",
    "    min_volatility               = 0.05,\n",
    "    max_volatility               = 1.0,\n",
    "    min_avg_return               = 0.0,\n",
    "    max_skewness                 = 3.0,\n",
    "    max_kurtosis                 = 10.0,\n",
    "    expected_freq                = \"B\",\n",
    "    max_gap_days                 = 3,\n",
    "    min_aum_usd                  = 1e7,\n",
    ")\n",
    "\n",
    "def select_funds(\n",
    "    df: pd.DataFrame,\n",
    "    rf_col: str,\n",
    "    fund_columns: list[str],\n",
    "    in_sdate: str,\n",
    "    in_edate: str,\n",
    "    out_sdate: str,\n",
    "    out_edate: str,\n",
    "    cfg: FundSelectionConfig,\n",
    "    selection_mode: str = \"all\",\n",
    "    random_n: int | None = None\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Select eligible funds with additional data-validity and coverage checks driven by FundSelectionConfig.\n",
    "    \"\"\"\n",
    "    # Ensure Date is sorted\n",
    "    df = df.sort_values(\"Date\")  # guarantee monotonic index\n",
    "\n",
    "    # Prepare monthly periods within analysis window\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    span = pd.period_range(\n",
    "        pd.Period(in_sdate, \"M\"), pd.Period(out_edate, \"M\"), freq=\"M\"\n",
    "    )\n",
    "\n",
    "    eligible_funds: list[str] = []\n",
    "    for f in fund_columns:\n",
    "        try:\n",
    "            ser = df.set_index(\"Date\")[f]\n",
    "            clean = ser.dropna()\n",
    "\n",
    "            # 1. Implausible value limits\n",
    "            if not clean.between(-cfg.implausible_value_limit, cfg.implausible_value_limit).all():\n",
    "                raise ValueError(f\"Values outside ¬±{cfg.implausible_value_limit}\")\n",
    "\n",
    "            # 2. Extreme outlier threshold\n",
    "            if (clean.abs() > cfg.outlier_threshold).any():\n",
    "                raise ValueError(f\"Outliers beyond ¬±{cfg.outlier_threshold}\")\n",
    "\n",
    "            # 3. Excessive zero-return rate\n",
    "            if (clean == 0).mean() > cfg.zero_return_threshold:\n",
    "                raise ValueError(f\"Zero-return proportion > {cfg.zero_return_threshold}\")\n",
    "\n",
    "            # 4. Monotonic date index\n",
    "            if cfg.enforce_monotonic_index and not clean.index.is_monotonic_increasing:\n",
    "                raise ValueError(\"Date index not monotonically increasing\")\n",
    "\n",
    "            # 5. Duplicate dates\n",
    "            if not cfg.allow_duplicate_dates and clean.index.duplicated().any():\n",
    "                raise ValueError(\"Duplicate dates detected in index\")\n",
    "\n",
    "            # 6. Coverage checks using config thresholds\n",
    "            m_ok = df.groupby(\"Month\")[f].apply(lambda col: col.notna().any())\n",
    "            mask = m_ok.reindex(span, fill_value=False).to_numpy()\n",
    "\n",
    "            # tolerance for missing months per-cfg\n",
    "            missing_count = (~mask).sum()\n",
    "            if missing_count > cfg.max_missing_months:\n",
    "                raise ValueError(f\"Missing-month count {missing_count} exceeds {cfg.max_missing_months}\")\n",
    "\n",
    "            # maximum run of consecutive missing months per-cfg with guard\n",
    "            temp = np.flatnonzero(np.r_[True, mask, True])\n",
    "            if temp.size <= 1:\n",
    "                gap = 0\n",
    "            else:\n",
    "                gap = np.diff(temp).max() - 1\n",
    "            if gap > cfg.max_consecutive_month_gap:\n",
    "                raise ValueError(f\"Consecutive-missing gap {gap} exceeds {cfg.max_consecutive_month_gap}\")\n",
    "\n",
    "            eligible_funds.append(f)\n",
    "\n",
    "        except ValueError as e:\n",
    "            logging.warning(\"Excluded %s: %s\", f, e)\n",
    "        except KeyError as e:\n",
    "            logging.warning(\"Missing data for %s: %s\", f, e)\n",
    "        except Exception as e:\n",
    "            logging.warning(\"Unexpected error on %s: %s\", f, e)\n",
    "\n",
    "    # Final selection-mode logic\n",
    "    if selection_mode == \"all\" or random_n is None:\n",
    "        return eligible_funds\n",
    "    if selection_mode == \"random\":\n",
    "        if random_n > len(eligible_funds):\n",
    "            raise ValueError(\n",
    "                f\"random_n exceeds eligible pool: {random_n} > {len(eligible_funds)}\"\n",
    "            )\n",
    "        return list(np.random.choice(eligible_funds, random_n, replace=False))\n",
    "\n",
    "    raise ValueError(f\"Unsupported selection_mode '{selection_mode}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 3. Weight Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  3 ¬∑ WEIGHT PREP\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def prepare_weights(selected: list[str],\n",
    "                    custom: Dict[str, int] | None) -> tuple[Dict[str, float], np.ndarray]:\n",
    "    if not custom:\n",
    "        w = {f: 1/len(selected) for f in selected}\n",
    "    else:\n",
    "        missing = [f for f in selected if f not in custom]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing weights for {missing}\")\n",
    "        w = {f: pct/100 for f, pct in custom.items()}\n",
    "        if abs(sum(w.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"Custom weights must sum to 100.\")\n",
    "    vec = np.array([w[f] for f in selected])\n",
    "    return w, vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 4. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Function definitions\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 4 ¬∑ CORE STATS  +  RUN_ANALYSIS  (helpers included, weight fix)\n",
    "# ===============================================================\n",
    "\n",
    "M_PER_YEAR = 12           # constant used across helpers\n",
    "\n",
    "# ---------- helpers --------------------------------------------\n",
    "def _ensure_dt(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy whose Date column is datetime64[ns].\"\"\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3. Metric function definitions\n",
    "# === Metric Function Definitions with flexible annualization ===\n",
    "@register_metric(\"AnnualReturn\")\n",
    "def compute_annual_return(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Geometric annualized return based on periods_per_year.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    total_growth = (1 + r).prod()\n",
    "    n_periods = len(r)\n",
    "    return total_growth ** (periods_per_year / n_periods) - 1\n",
    "\n",
    "@register_metric(\"Volatility\")\n",
    "def compute_volatility(\n",
    "    returns: pd.Series,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Annualized standard deviation of returns with flexible scaling.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    return r.std(ddof=0) * np.sqrt(periods_per_year)\n",
    "\n",
    "@register_metric(\"Sharpe\")\n",
    "def compute_sharpe(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sharpe ratio using flexible annualized return and volatility.\n",
    "    \"\"\"\n",
    "    vol = compute_volatility(returns, periods_per_year=periods_per_year)\n",
    "    if vol == 0:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    return (ann_ret - risk_free) / vol\n",
    "\n",
    "@register_metric(\"Sortino\")\n",
    "def compute_sortino(\n",
    "    returns: pd.Series,\n",
    "    risk_free: float = 0.0,\n",
    "    periods_per_year: int = 252,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Sortino ratio using flexible annualized return and downside deviation.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return np.nan\n",
    "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
    "    # Define per-period risk-free rate\n",
    "    period_rf = risk_free / periods_per_year\n",
    "    excess = r - period_rf\n",
    "    downside = excess[excess < 0]\n",
    "    if downside.empty:\n",
    "        return np.nan\n",
    "    down_dev = np.sqrt((downside ** 2).mean()) * np.sqrt(periods_per_year)\n",
    "    if down_dev == 0:\n",
    "        return np.nan\n",
    "    return (ann_ret - risk_free) / down_dev\n",
    "\n",
    "@register_metric(\"MaxDrawdown\")\n",
    "def compute_max_drawdown(\n",
    "    returns: pd.Series,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Maximum drawdown (peak-to-trough) of cumulative returns.\n",
    "    \"\"\"\n",
    "    r = returns.dropna()\n",
    "    if r.empty:\n",
    "        return 0.0\n",
    "    cum = (1 + r).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdown = (cum / peak) - 1\n",
    "    return float(drawdown.min())\n",
    "\n",
    "# Alias for backward compatibility\n",
    "_ann_vol = compute_volatility\n",
    "\n",
    "# === Aggregator with Centralized Error Handling ===\n",
    "\n",
    "def _stats(\n",
    "    returns: pd.Series,\n",
    "    cfg: RiskStatsConfig,\n",
    "    **metric_kwargs\n",
    ") -> namedtuple:\n",
    "    \"\"\"\n",
    "    Run each metric in cfg.metrics_to_run, returning a namedtuple of values.\n",
    "    Uses cfg.periods_per_year for annualization.\n",
    "    Centralized try/except ensures one failing metric doesn‚Äôt break the batch.\n",
    "    \"\"\"\n",
    "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
    "    values: list[float] = []\n",
    "    for name in cfg.metrics_to_run:\n",
    "        fn = METRIC_REGISTRY.get(name)\n",
    "        if fn is None:\n",
    "            logging.error(\"Metric '%s' not registered\", name)\n",
    "            values.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            params = {\n",
    "                \"risk_free\": cfg.risk_free,\n",
    "                \"periods_per_year\": cfg.periods_per_year,\n",
    "                **metric_kwargs\n",
    "            }\n",
    "            valid = {k: v for k, v in params.items() if k in inspect.signature(fn).parameters}\n",
    "            val = fn(returns, **valid)\n",
    "        except ZeroDivisionError:\n",
    "            logging.warning(\"%s: division by zero, setting NaN\", name)\n",
    "            val = np.nan\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logging.warning(\"%s: invalid input (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        except Exception as e:\n",
    "            logging.error(\"%s: unexpected error (%s), setting NaN\", name, e)\n",
    "            val = np.nan\n",
    "        values.append(val)\n",
    "    return Stat(*values)\n",
    "\n",
    "# ---------- main ------------------------------------------------\n",
    "def run_analysis(\n",
    "    df,\n",
    "    selected,\n",
    "    w_vec,\n",
    "    w_dict,\n",
    "    rf_col,\n",
    "    in_start,\n",
    "    in_end,\n",
    "    out_start,\n",
    "    out_end,\n",
    "    target_vol,\n",
    "    monthly_cost,\n",
    "    indices_list\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorised run_analysis with correct weight re-normalisation\n",
    "    after funds are dropped.\n",
    "    Returns the same keys used by the UI and export functions.\n",
    "    \"\"\"\n",
    "    df = _ensure_dt(df)\n",
    "\n",
    "    # ---- date masks --------------------------------------------------\n",
    "    in_s = pd.to_datetime(in_start)  + pd.offsets.MonthEnd(0)\n",
    "    in_e = pd.to_datetime(in_end)    + pd.offsets.MonthEnd(0)\n",
    "    out_s= pd.to_datetime(out_start) + pd.offsets.MonthEnd(0)\n",
    "    out_e= pd.to_datetime(out_end)   + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    m_in  = df[\"Date\"].between(in_s,  in_e)\n",
    "    m_out = df[\"Date\"].between(out_s, out_e)\n",
    "\n",
    "    in_df,  out_df  = df.loc[m_in,  selected], df.loc[m_out, selected]\n",
    "    in_rf,  out_rf  = df.loc[m_in,  rf_col],   df.loc[m_out, rf_col]\n",
    "\n",
    "    # ---- drop funds with any NaNs in either window ------------------\n",
    "    good = [f for f in selected\n",
    "            if in_df[f].notna().all() and out_df[f].notna().all()]\n",
    "    dropped = list(set(selected) - set(good))\n",
    "    if dropped:\n",
    "        logging.warning(\"Dropped funds: %s\", dropped)\n",
    "\n",
    "    selected = good\n",
    "    # >>>> new guard: kick out any accidental index columns\n",
    "    selected = [f for f in selected if f not in (indices_list or [])]\n",
    "    # <<<<\n",
    "\n",
    "    in_df, out_df = in_df[selected], out_df[selected]\n",
    "\n",
    "    # rebuild weights\n",
    "    if w_dict is None:                      # equal-weight path\n",
    "        w_dict = {f: 1/len(selected) for f in selected}\n",
    "    else:                                   # manual path ‚Üí rescale\n",
    "        pct   = {f: w_dict[f]*100 for f in selected}\n",
    "        total = sum(pct.values())\n",
    "        w_dict = {f: p/total for f, p in pct.items()}\n",
    "    w_vec = np.array([w_dict[f] for f in selected])\n",
    "\n",
    "    # ---- scaling ----------------------------------------------------\n",
    "    vols = in_df.apply(compute_volatility)\n",
    "    scale = np.where(vols > 0, target_vol / vols, 1.0)\n",
    "    in_sc  = (in_df * scale) - monthly_cost\n",
    "    out_sc = (out_df * scale) - monthly_cost\n",
    "    in_sc.clip(lower=-1, inplace=True)\n",
    "    out_sc.clip(lower=-1, inplace=True)\n",
    "\n",
    "    # ---- stats ------------------------------------------------------\n",
    "    rf_value = in_rf.mean() if hasattr(in_rf, \"mean\") else float(in_rf)\n",
    "\n",
    "    # Create a RiskStatsConfig for in-sample stats\n",
    "    stats_cfg = RiskStatsConfig(risk_free=rf_value)\n",
    "\n",
    "    # Now compute stats for each scenario, always passing stats_cfg first\n",
    "    in_stat = {\n",
    "        f: _stats(in_sc[f], stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "    out_rf_value = out_rf.mean() if hasattr(out_rf, \"mean\") else float(out_rf)\n",
    "\n",
    "    # Re‚Äêuse the same config, updating only the risk_free field\n",
    "    stats_cfg.risk_free = out_rf_value\n",
    "\n",
    "    out_stat = {\n",
    "        f: _stats(out_sc[f], stats_cfg)\n",
    "        for f in selected\n",
    "    }\n",
    "\n",
    "    ew_vec = np.full(len(selected), 1/len(selected))\n",
    "\n",
    "    in_ew_stats  = _stats(in_sc.dot(ew_vec),  stats_cfg)\n",
    "    out_ew_stats = _stats(out_sc.dot(ew_vec), stats_cfg)\n",
    "    in_user_stats  = _stats(in_sc.dot(w_vec),  stats_cfg)\n",
    "    out_user_stats = _stats(out_sc.dot(w_vec), stats_cfg)\n",
    "\n",
    "    results = {\n",
    "        \"selected_funds\": selected,\n",
    "        \"indices_list\":   indices_list or [],\n",
    "        \"fund_weights\":   w_dict,\n",
    "        \"ew_weights\":     {f: 1/len(selected) for f in selected},\n",
    "        \"in_sample_stats\":  in_stat,\n",
    "        \"out_sample_stats\": out_stat,\n",
    "        \"in_ew_stats\":     in_ew_stats,\n",
    "        \"out_ew_stats\":    out_ew_stats,\n",
    "        \"in_user_stats\":   in_user_stats,\n",
    "        \"out_user_stats\":  out_user_stats,\n",
    "        \"dropped\":         dropped,\n",
    "    }\n",
    "\n",
    "    # ---- optional index stats ---------------------------------------\n",
    "    if indices_list:\n",
    "        idx_stats = {}\n",
    "        for col in indices_list:\n",
    "            idx_stats[col] = {\n",
    "                \"in_sample\":  _stats(df.loc[m_in,  col], stats_cfg),\n",
    "                \"out_sample\": _stats(df.loc[m_out, col], stats_cfg),\n",
    "            }\n",
    "        results[\"index_stats\"] = idx_stats\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 5. Excel Export\n",
    "Creates an Excel file with In-Sample, Out-of-Sample and Equal-weight and User-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  5 ¬∑ EXPORT  (NaN-safe, weight-format fix)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5 ¬∑ EXPORT  (final, bug-free) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5 ¬∑ EXPORT  (self-healing index section) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5 ¬∑ EXPORT  (final safe version) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def export_to_excel(\n",
    "    data: dict[str, pd.DataFrame],\n",
    "    output_path: str,\n",
    "    default_format: Optional[Callable] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Exports each DataFrame in `data` to its own sheet in `output_path`.\n",
    "    Applies a registered formatter for each category (sheet name).\n",
    "    If no formatter is found, applies `default_format` if provided.\n",
    "\n",
    "    For the Summary sheet, data is written starting at row 5 to make room for custom headers.\n",
    "    \"\"\"\n",
    "    startrows = {\"summary\": 5}\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        for category, df in data.items():\n",
    "            startrow = startrows.get(category, 0)\n",
    "            df.to_excel(writer, sheet_name=category, index=False, startrow=startrow, header=True)\n",
    "            fn = FORMATTERS_EXCEL.get(category, default_format)\n",
    "            if fn: fn(writer.sheets[category], writer.book)\n",
    "    # Workbook is auto-saved and closed by the context manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 6. Run Parameters, Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc. Also lets us use custom weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e0d59-d17a-41c8-b991-1d91d29a22d1",
   "metadata": {
    "outputId": "795bb6da-96a0-42e2-c760-7d516fd82610"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#            STREAMLINED ANALYSIS UI  (phase-2 clean)\n",
    "# ===============================================================\n",
    "\n",
    "# ---------- session store ----------\n",
    "session = {\"df\": None, \"rf\": None, \"sel\": None, \"cweights\": None}\n",
    "\n",
    "# ---------- 1 ¬∑ DATA LOAD ----------\n",
    "src = widgets.ToggleButtons(\n",
    "    options=[(\"Local\", \"local\"), (\"URL\", \"url\")],\n",
    "    description=\"Source:\"\n",
    ")\n",
    "\n",
    "chooser = FileChooser()\n",
    "url_box = widgets.Text(placeholder=\"https://‚Ä¶/file.csv\", layout={\"width\":\"70%\"})\n",
    "load_btn = widgets.Button(description=\"Load CSV\", button_style=\"success\")\n",
    "load_out = widgets.Output()\n",
    "\n",
    "def _toggle_src(c):\n",
    "    chooser.layout.display = \"block\" if c[\"new\"]==\"local\" else \"none\"\n",
    "    url_box.layout.display  = \"block\" if c[\"new\"]==\"url\"   else \"none\"\n",
    "src.observe(_toggle_src, names=\"value\"); _toggle_src({\"new\":src.value})\n",
    "\n",
    "def _load(_):\n",
    "    with load_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            path = chooser.selected if src.value==\"local\" else url_box.value.strip()\n",
    "            if not path: raise ValueError(\"choose file / URL\")\n",
    "            if src.value==\"url\" and not path.lower().endswith(\".csv\"):\n",
    "                raise ValueError(\"URL must end with .csv\")\n",
    "            df = load_csv(path)\n",
    "            if df is None:\n",
    "                print(f'‚ùå Failed to load data from {path}')\n",
    "                session[\"df\"] = None\n",
    "                return\n",
    "            rf = identify_risk_free_fund(df)\n",
    "            session.update(df=df, rf=rf, sel=None, cweights=None)\n",
    "            print(f\"‚úÖ Loaded {len(df):,} rows √ó {df.shape[1]} cols | RF ‚Üí {rf}\")\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå\", e); session[\"df\"]=None\n",
    "load_btn.on_click(_load)\n",
    "\n",
    "# ---------- 2 ¬∑ PARAMS ------------\n",
    "index_cnt = widgets.BoundedIntText(0, min=0, max=10, description=\"# Indices:\")\n",
    "in_start,in_end  = widgets.Text(\"2005-07\"), widgets.Text(\"2008-06\")\n",
    "out_start,out_end= widgets.Text(\"2008-07\"), widgets.Text(\"2009-06\")\n",
    "for w,lbl in [(in_start,\"In Start:\"),(in_end,\"In End:\"),\n",
    "              (out_start,\"Out Start:\"),(out_end,\"Out End:\")]:\n",
    "    w.description = lbl\n",
    "target_vol   = widgets.FloatText(0.25,  description=\"Target Vol:\")\n",
    "monthly_cost = widgets.FloatText(0.0033, description=\"Monthly Cost:\")\n",
    "\n",
    "# ---------- 3 ¬∑ SELECTION ----------\n",
    "mode_dd = widgets.Dropdown(\n",
    "    options=[(\"All\", \"all\"), (\"Random\", \"random\"), (\"Manual\", \"manual\")],\n",
    "    value=\"all\",\n",
    "    description=\"Mode:\"\n",
    ")\n",
    "rand_n   = widgets.BoundedIntText(5, min=2, max=100, description=\"Sample N:\")\n",
    "fund_table, total_lbl = widgets.VBox([]), widgets.Label(\"Total = 0 %\")\n",
    "\n",
    "def _toggle_sel(_=None):\n",
    "    rand_n.layout.display  = \"block\" if mode_dd.value==\"random\" else \"none\"\n",
    "    vis = \"block\" if mode_dd.value==\"manual\" else \"none\"\n",
    "    fund_table.layout.display = total_lbl.layout.display = vis\n",
    "mode_dd.observe(_toggle_sel, names=\"value\"); _toggle_sel()\n",
    "\n",
    "# ---------- helpers ---------------\n",
    "def _eligible_pool():\n",
    "    df, rf = session[\"df\"], session[\"rf\"]\n",
    "    if df is None:\n",
    "        print(\"‚ö†Ô∏è data not loaded\"); return []\n",
    "\n",
    "    # ---- date parse guard -----------------------------------\n",
    "    try:\n",
    "        in_s  = pd.to_datetime(in_start.value)+pd.offsets.MonthEnd(0)\n",
    "        in_e  = pd.to_datetime(in_end.value)  +pd.offsets.MonthEnd(0)\n",
    "        out_s = pd.to_datetime(out_start.value)+pd.offsets.MonthEnd(0)\n",
    "        out_e = pd.to_datetime(out_end.value)  +pd.offsets.MonthEnd(0)\n",
    "    except Exception:\n",
    "        print(\"‚ùå invalid dates\"); return []\n",
    "\n",
    "    # ---- build indices (RIGHT-most idx_n non-RF columns) ----\n",
    "    idx_n     = index_cnt.value\n",
    "    data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "    non_rf    = [c for c in data_cols if c != rf]\n",
    "    indices   = non_rf[-idx_n:] if idx_n else []          # <- fixed\n",
    "    cand      = [c for c in data_cols if c not in indices]\n",
    "\n",
    "    # ---- run select_funds ----------------------------------\n",
    "    elig = select_funds(\n",
    "        df=df,\n",
    "        rf_col=rf,\n",
    "        fund_columns=cand,\n",
    "        in_sdate=in_s,\n",
    "        in_edate=in_e,\n",
    "        out_sdate=out_s,\n",
    "        out_edate=out_e,\n",
    "        cfg=cfg,                   \n",
    "        selection_mode=\"all\",\n",
    "    )\n",
    "    # ‚Ä¶ diagnostics print unchanged ‚Ä¶\n",
    "    return elig\n",
    "\n",
    "def _build_manual(*_):\n",
    "    if mode_dd.value!=\"manual\" or session[\"df\"] is None: return\n",
    "    valid = _eligible_pool()\n",
    "    print(\"DEBUG  eligible funds =\", len(valid))              # ‚Üê line 1\n",
    "    print(\"DEBUG  list sample   ‚Üí\", valid[:25], \"‚Ä¶\")           # ‚Üê line 2\n",
    "    if not valid:\n",
    "        print(\"‚ùå No eligible funds\"); return\n",
    "    fund_table.children = []                # reset\n",
    "\n",
    "    def _update_total(*_):\n",
    "        tot = sum(r.children[1].value for r in fund_table.children\n",
    "                  if r.children[0].value)\n",
    "        total_lbl.value = f\"Total = {tot} %\"\n",
    "\n",
    "    for f in valid:\n",
    "        cb = widgets.Checkbox(description=f, layout={\"width\":\"200px\"})\n",
    "        wt = widgets.BoundedIntText(0, min=0, max=100,\n",
    "                                    layout={\"width\":\"60px\"}, disabled=True)\n",
    "        def _toggle(ch, box=wt):           # single observer\n",
    "            box.disabled = not ch[\"new\"]\n",
    "            if box.disabled: box.value = 0\n",
    "            _update_total()\n",
    "        cb.observe(_toggle, names=\"value\")\n",
    "        wt.observe(_update_total, names=\"value\")\n",
    "        fund_table.children += (widgets.HBox([cb, wt]),)\n",
    "    _update_total()\n",
    "\n",
    "mode_dd.observe(lambda ch: _build_manual() if ch[\"new\"]==\"manual\" else None,\n",
    "                names=\"value\")\n",
    "for w in (in_start,in_end,out_start,out_end): w.observe(_build_manual,names=\"value\")\n",
    "\n",
    "# ---------- 4 ¬∑ RUN ---------------\n",
    "run_btn = widgets.Button(description=\"Run Analysis\", button_style=\"success\")\n",
    "run_out = widgets.Output(layout={\"border\":\"1px solid #999\",\n",
    "                                 \"height\":\"340px\",\"overflow_y\":\"auto\"})\n",
    "\n",
    "def _run(_):\n",
    "    with run_out:\n",
    "        clear_output()\n",
    "        df, rf = session[\"df\"], session[\"rf\"]\n",
    "        if df is None: print(\"‚ö†Ô∏è Load data first\"); return\n",
    "\n",
    "        # indices (robust)\n",
    "        idx_n     = index_cnt.value\n",
    "        data_cols = [c for c in df.columns if c not in [\"Date\", rf, \"Month\"]]\n",
    "        non_rf    = [c for c in data_cols if c != rf]\n",
    "        indices   = non_rf[-idx_n:] if idx_n else []\n",
    "\n",
    "        # pool + selection\n",
    "        pool = _eligible_pool()\n",
    "        if not pool: print(\"‚ùå No eligible funds\"); return\n",
    "        if mode_dd.value==\"all\":\n",
    "            sel, custom = pool, None\n",
    "        elif mode_dd.value==\"random\":\n",
    "            if rand_n.value>len(pool): print(\"‚ö†Ô∏è Sample N too big\"); return\n",
    "            sel, custom = list(np.random.choice(pool, rand_n.value, replace=False)), None\n",
    "        else:\n",
    "            sel, custom = [], {}\n",
    "            if not fund_table.children: _build_manual()\n",
    "            for row in fund_table.children:\n",
    "                cb, wt = row.children\n",
    "                if cb.value: sel.append(cb.description); custom[cb.description]=wt.value\n",
    "            if sum(custom.values())!=100: print(\"‚ö†Ô∏è Weights ‚â† 100\"); return\n",
    "\n",
    "        w_dict,w_vec = prepare_weights(sel, custom)\n",
    "\n",
    "        res = run_analysis(df, sel, w_vec, w_dict, rf,\n",
    "                           in_start.value, in_end.value,\n",
    "                           out_start.value, out_end.value,\n",
    "                           target_vol.value, monthly_cost.value,\n",
    "                           indices)\n",
    "\n",
    "        print(\"‚úÖ analysis complete |\", len(sel), \"funds\")\n",
    "        if res[\"dropped\"]:\n",
    "            print(\"‚ö†Ô∏è Dropped:\", res[\"dropped\"])\n",
    "        if indices: print(\"üìä Indices:\", indices)\n",
    "\n",
    "        fname=f\"IS_{in_start.value}_{out_start.value}.xlsx\"\n",
    "        # register only the combined summary formatter\n",
    "        make_summary_formatter(\n",
    "            res,\n",
    "            in_start.value,\n",
    "            in_end.value,\n",
    "            out_start.value,\n",
    "            out_end.value\n",
    "        )\n",
    "\n",
    "        # Build a minimal data dict with just the 'summary' sheet.\n",
    "        # The formatter will populate all rows (portfolio, funds, spacer, indices).\n",
    "        data = {\n",
    "            \"summary\": pd.DataFrame()\n",
    "        }\n",
    "\n",
    "        print(\"Sheets to write:\", list(data.keys()))\n",
    "        print(\"Formatters:\", list(FORMATTERS_EXCEL.keys()))\n",
    "\n",
    "        # Export ‚Äî this will call fmt_summary(ws, wb) on the 'summary' sheet.\n",
    "        export_to_excel(data, fname)\n",
    "        print(\"Workbook saved as\", fname)\n",
    "\n",
    "run_btn.on_click(_run)\n",
    "\n",
    "# ---------- DISPLAY --------------\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h4>1. Load data</h4>\"),\n",
    "    src, chooser, url_box, load_btn, load_out,\n",
    "    widgets.HTML(\"<hr><h4>2. Parameters</h4>\"),\n",
    "    widgets.HBox([index_cnt]),\n",
    "    widgets.HBox([in_start,in_end,out_start,out_end]),\n",
    "    widgets.HBox([target_vol,monthly_cost]),\n",
    "    widgets.HTML(\"<hr><h4>3. Fund selection</h4>\"),\n",
    "    widgets.HBox([mode_dd,rand_n]),\n",
    "    fund_table, total_lbl,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    run_btn,\n",
    "    run_out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599f6a9-8055-42be-abf1-fd2ab3efee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run the cell that defines load_csv and call it\n",
    "dt = load_csv(\"/Users/teacher/Library/CloudStorage/Dropbox/Learning/Code/Trend Modeling Project/hedge_fund_returns_with_indexes.csv\")\n",
    "\n",
    "# 2. Capture all original fields (Date + fund columns)\n",
    "col_list = dt.columns.tolist()\n",
    "print(col_list)\n",
    "\n",
    "# 3.  (Optional)  Save to CSV for your spec\n",
    "import pandas as pd\n",
    "pd.DataFrame({\"ColumnName\": col_list}).to_csv(\"variable_spec.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
