{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed15037-f989-4fff-9388-9cf03ea986aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_funds (replaced) is ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings, random\n",
    "import pandas as pd\n",
    "\n",
    "def fill_short_gaps_with_zero(series):\n",
    "    \"\"\"\n",
    "    Given a pandas Series indexed by Date (month‐ends), wherever there is\n",
    "    a run of 1 or 2 consecutive NaNs, replace them with 0.0. If a run of 3\n",
    "    or more NaNs appears, leave those NaNs intact.\n",
    "    \"\"\"\n",
    "    isnan = series.isna().astype(int)\n",
    "    run_lengths = isnan.groupby((isnan == 0).cumsum()).transform('sum')\n",
    "    filled = series.copy()\n",
    "    mask_short = (isnan == 1) & (run_lengths <= 2)\n",
    "    filled[mask_short] = 0.0\n",
    "    return filled\n",
    "    \n",
    "import warnings\n",
    "import random\n",
    "\n",
    "def select_funds(\n",
    "    df,                 # full DataFrame with datetime64 ‘Date’\n",
    "    rf_col,             # name of risk‐free column\n",
    "    fund_columns,       # list of candidate funds (should be your 27)\n",
    "    in_sdate, in_edate, # pd.Timestamps for in‐sample window\n",
    "    out_sdate, out_edate,# pd.Timestamps for out‐sample window\n",
    "    selection_mode='all',\n",
    "    random_n=5\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Start from fund_columns.  \n",
    "    2) Filter out any that contain 'index' in name.  \n",
    "    3) Keep only those with no NaN anywhere in both windows.  \n",
    "    4) Keep only those with < 3 consecutive NaNs in each window.  \n",
    "    5) Return based on selection_mode.\n",
    "    \"\"\"\n",
    "    # Step 1: base list\n",
    "    candidates = fund_columns.copy()\n",
    "    print(f\"DEBUG [select_funds]: initial candidates (n={len(candidates)}): {candidates}\")\n",
    "\n",
    "    # Step 2: drop any with “index” in name (case‐insensitive)\n",
    "    no_index = [f for f in candidates if 'index' not in f.lower()]\n",
    "    print(f\"DEBUG [select_funds]: after dropping 'index' (n={len(no_index)}): {no_index}\")\n",
    "\n",
    "    # Step 3: full‐history check (no NaN at all in each window)\n",
    "    full_hist = []\n",
    "    for f in no_index:\n",
    "        in_sub  = df[(df['Date'] >= in_sdate)  & (df['Date'] <= in_edate)][f]\n",
    "        out_sub = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)][f]\n",
    "        if in_sub.notna().all() and out_sub.notna().all():\n",
    "            full_hist.append(f)\n",
    "    print(f\"DEBUG [select_funds]: after full‐history check (n={len(full_hist)}): {full_hist}\")\n",
    "\n",
    "    # Step 4: no 3‐consecutive‐NaNs check\n",
    "    after_run_check = []\n",
    "    for f in full_hist:\n",
    "        # In‐sample gap runs\n",
    "        sub_in   = df[(df['Date'] >= in_sdate) & (df['Date'] <= in_edate)][f]\n",
    "        isnan_in = sub_in.isna().astype(int)\n",
    "        run_len_in = isnan_in.groupby((isnan_in == 0).cumsum()).sum()\n",
    "        max_run_in = run_len_in.max() if not run_len_in.empty else 0\n",
    "\n",
    "        # Out‐sample gap runs\n",
    "        sub_out   = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)][f]\n",
    "        isnan_out = sub_out.isna().astype(int)\n",
    "        run_len_out = isnan_out.groupby((isnan_out == 0).cumsum()).sum()\n",
    "        max_run_out = run_len_out.max() if not run_len_out.empty else 0\n",
    "\n",
    "        # Keep only if both max runs < 3\n",
    "        if max_run_in < 3 and max_run_out < 3:\n",
    "            after_run_check.append(f)\n",
    "\n",
    "    print(f\"DEBUG [select_funds]: after run‐length check (n={len(after_run_check)}): {after_run_check}\")\n",
    "\n",
    "    # Step 5: selection_mode\n",
    "    if selection_mode == 'all':\n",
    "        return after_run_check\n",
    "\n",
    "    if selection_mode == 'random':\n",
    "        if len(after_run_check) <= random_n:\n",
    "            warnings.warn(\n",
    "                f\"Fewer valid funds ({len(after_run_check)}) than sample size ({random_n}). Returning all.\"\n",
    "            )\n",
    "            return after_run_check\n",
    "        return random.sample(after_run_check, random_n)\n",
    "\n",
    "    # (Placeholder for manual widget selection, if you implement it later)\n",
    "    return after_run_check\n",
    "\n",
    "print(\"select_funds (replaced) is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134577d-8bbf-4933-95f2-0d032ac87a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings, random\n",
    "import pandas as pd\n",
    "\n",
    "def fill_short_gaps_with_zero(series):\n",
    "    \"\"\"\n",
    "    Given a pandas Series indexed by Date (month‐ends), wherever there is\n",
    "    a run of 1 or 2 consecutive NaNs, replace them with 0.0. If a run of 3\n",
    "    or more NaNs appears, leave those NaNs intact.\n",
    "    \"\"\"\n",
    "    isnan = series.isna().astype(int)\n",
    "    run_lengths = isnan.groupby((isnan == 0).cumsum()).transform('sum')\n",
    "    filled = series.copy()\n",
    "    mask_short = (isnan == 1) & (run_lengths <= 2)\n",
    "    filled[mask_short] = 0.0\n",
    "    return filled\n",
    "\n",
    "def select_funds(\n",
    "    df, rf_col, fund_columns,\n",
    "    in_sdate, in_edate, out_sdate, out_edate,\n",
    "    selection_mode, random_n\n",
    "):\n",
    "    \"\"\"\n",
    "    df             : DataFrame (with 'Date' as datetime64[ns])\n",
    "    rf_col         : name of the risk-free column (string)\n",
    "    fund_columns   : list of actual fund names (no Date, no rf_col, no indices)\n",
    "    in_sdate       : pd.Timestamp for in-sample start (first day of month)\n",
    "    in_edate       : pd.Timestamp for in-sample end (last day of month)\n",
    "    out_sdate      : pd.Timestamp for out-sample start (first day of month)\n",
    "    out_edate      : pd.Timestamp for out-sample end (last day of month)\n",
    "    selection_mode : 'all' / 'random' / 'manual'\n",
    "    random_n       : integer for random sampling if mode == 'random'\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Initial fund candidates\n",
    "    all_fund_cols = fund_columns.copy()\n",
    "    print(f\"DEBUG [select_funds]: initial candidates (n={len(all_fund_cols)}): {all_fund_cols}\")\n",
    "\n",
    "    # 2) Extract in‐sample & out‐sample DataFrames (just the Date + fund columns)\n",
    "    in_df  = df[(df['Date'] >= in_sdate)  & (df['Date'] <= in_edate)].copy()\n",
    "    out_df = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)].copy()\n",
    "\n",
    "    # 3) For each fund, fill short gaps ≤2 months in both windows, then check for any remaining run ≥ 3\n",
    "    funds_after_run_check = []\n",
    "    for f in all_fund_cols:\n",
    "        # 3a) Pull the in‐sample return series for this fund, indexed by Date\n",
    "        ser_in = in_df.set_index('Date')[f]\n",
    "\n",
    "        # 3b) Fill any 1–2 consecutive NaNs → 0\n",
    "        filled_in = fill_short_gaps_with_zero(ser_in)\n",
    "\n",
    "        # 3c) Check longest run of NaNs left in in‐sample\n",
    "        mask_in = filled_in.isna().astype(int)\n",
    "        run_len_in = (\n",
    "            mask_in.groupby((mask_in == 0).cumsum())\n",
    "                   .sum()\n",
    "        )\n",
    "        max_run_in = run_len_in.max() if not run_len_in.empty else 0\n",
    "\n",
    "        # 3d) Do the same for out‐sample\n",
    "        ser_out = out_df.set_index('Date')[f]\n",
    "        filled_out = fill_short_gaps_with_zero(ser_out)\n",
    "        mask_out = filled_out.isna().astype(int)\n",
    "        run_len_out = (\n",
    "            mask_out.groupby((mask_out == 0).cumsum())\n",
    "                    .sum()\n",
    "        )\n",
    "        max_run_out = run_len_out.max() if not run_len_out.empty else 0\n",
    "\n",
    "        # 3e) Print debug so you see if any fund truly has a run ≥3 inside the window\n",
    "        print(f\"DEBUG [select_funds]: '{f}' max consecutive NaNs in in-sample = {max_run_in}\")\n",
    "        print(f\"DEBUG [select_funds]: '{f}' max consecutive NaNs in out-sample = {max_run_out}\")\n",
    "\n",
    "        # 3f) Only keep the fund if BOTH windows have max_run < 3\n",
    "        if (max_run_in < 3) and (max_run_out < 3):\n",
    "            funds_after_run_check.append(f)\n",
    "\n",
    "    print(f\"DEBUG [select_funds]: after run‐length check (n={len(funds_after_run_check)}): {funds_after_run_check}\")\n",
    "\n",
    "    # 4) Apply selection_mode\n",
    "    if selection_mode == 'all':\n",
    "        return funds_after_run_check\n",
    "\n",
    "    if selection_mode == 'random':\n",
    "        if len(funds_after_run_check) <= random_n:\n",
    "            warnings.warn(\n",
    "                f\"Fewer valid funds ({len(funds_after_run_check)}) than sample size ({random_n}). Returning all.\"\n",
    "            )\n",
    "            return funds_after_run_check\n",
    "        return random.sample(funds_after_run_check, random_n)\n",
    "\n",
    "    # 5) Manual selection (widget) would be implemented here if desired.\n",
    "    return funds_after_run_check\n",
    "\n",
    "print(\"select_funds (gap‐filled, windowed) is defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367bab83-272d-4e85-a416-335980903119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_analysis (with checkpoints) is defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def run_analysis(\n",
    "    df, in_start, in_end, out_start, out_end,\n",
    "    target_vol, monthly_cost,\n",
    "    selection_mode='all', random_n=5\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Parse/validate date inputs\n",
    "    2) Convert Date column if needed\n",
    "    3) Identify rf_col\n",
    "    4) Prepare in/out sample DataFrames\n",
    "    5) CALL select_funds (with debug) and print checkpoints\n",
    "    6) Compute scale_factors and wrap stats in try/except\n",
    "    \"\"\"\n",
    "\n",
    "    # (1) Parse input dates\n",
    "    in_sdate  = pd.to_datetime(in_start + \"-01\", errors='coerce')\n",
    "    in_edate  = pd.to_datetime(in_end   + \"-01\", errors='coerce') + pd.offsets.MonthEnd(0)\n",
    "    out_sdate = pd.to_datetime(out_start + \"-01\", errors='coerce')\n",
    "    out_edate = pd.to_datetime(out_end   + \"-01\", errors='coerce') + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    # checkpoint A\n",
    "    print(\"CHECKPOINT A: Dates parsed:\", in_sdate, in_edate, out_sdate, out_edate)\n",
    "\n",
    "    # (2) Ensure Date is datetime64\n",
    "    if not np.issubdtype(df['Date'].dtype, np.datetime64):\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df.dropna(subset=['Date'], inplace=True)\n",
    "        df.sort_values(by='Date', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # checkpoint B\n",
    "    print(\"CHECKPOINT B: Date column is datetime64, first dates:\", df['Date'].iloc[0], df['Date'].iloc[-1])\n",
    "\n",
    "    # (3) Identify risk-free column\n",
    "    rf_col = identify_risk_free_fund(df)\n",
    "    print(f\"INFO: Identified '{rf_col}' as the risk-free column (lowest stdev).\")\n",
    "\n",
    "    # (4) Build in-sample & out-sample slices\n",
    "    in_sample_df  = df[(df['Date'] >= in_sdate)  & (df['Date'] <= in_edate)].copy()\n",
    "    out_sample_df = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)].copy()\n",
    "    in_sample_rf  = in_sample_df[rf_col]\n",
    "    out_sample_rf = out_sample_df[rf_col]\n",
    "\n",
    "    print(f\"CHECKPOINT C: in_sample rows = {len(in_sample_df)}, out_sample rows = {len(out_sample_df)}\")\n",
    "\n",
    "    # (5) Assemble fund_cols and call select_funds\n",
    "    all_fund_cols = fund_cols.copy()\n",
    "    print(f\"CHECKPOINT D: about to call select_funds with {len(all_fund_cols)} candidates\")\n",
    "\n",
    "    selected_funds = select_funds(\n",
    "        df,\n",
    "        rf_col,\n",
    "        fund_columns=all_fund_cols,\n",
    "        in_sdate=in_sdate,\n",
    "        in_edate=in_edate,\n",
    "        out_sdate=out_sdate,\n",
    "        out_edate=out_edate,\n",
    "        selection_mode=selection_mode,\n",
    "        random_n=random_n\n",
    "    )\n",
    "\n",
    "    print(f\"CHECKPOINT E: select_funds returned {len(selected_funds)} funds → {selected_funds}\")\n",
    "\n",
    "    if not selected_funds:\n",
    "        print(\"No valid funds after select_funds. Exiting run_analysis.\")\n",
    "        return None\n",
    "\n",
    "    # (6) Compute scale_factors BEFORE entering stats‐try/except\n",
    "    scale_factors = {}\n",
    "    for fund in selected_funds:\n",
    "        fund_in_rets = in_sample_df[fund].dropna()\n",
    "        current_vol  = annualize_volatility(fund_in_rets)\n",
    "        if pd.isna(current_vol) or current_vol == 0:\n",
    "            scale_factors[fund] = 1.0\n",
    "        else:\n",
    "            scale_factors[fund] = target_vol / current_vol\n",
    "\n",
    "    print(\"CHECKPOINT F: scale_factors computed (showing first 5):\", \n",
    "          {f: scale_factors[f] for f in selected_funds[:5]})\n",
    "\n",
    "    # Pre-allocate DataFrames for scaled returns\n",
    "    in_sample_scaled  = pd.DataFrame(index=in_sample_df.index, columns=selected_funds)\n",
    "    out_sample_scaled = pd.DataFrame(index=out_sample_df.index, columns=selected_funds)\n",
    "\n",
    "    # ────── TRY/EXCEPT AROUND ONLY THE “STATS” PORTION ──────\n",
    "    try:\n",
    "        # Scale returns (with cost)\n",
    "        for fund in selected_funds:\n",
    "            sf = scale_factors[fund]\n",
    "            adj_in  = in_sample_df[fund] * sf - monthly_cost\n",
    "            adj_in[adj_in < -1.0] = -1.0\n",
    "            in_sample_scaled[fund] = adj_in\n",
    "\n",
    "            if not out_sample_df.empty:\n",
    "                adj_out = out_sample_df[fund] * sf - monthly_cost\n",
    "                adj_out[adj_out < -1.0] = -1.0\n",
    "                out_sample_scaled[fund] = adj_out\n",
    "\n",
    "        # Helper for stats\n",
    "        def compute_stats(series, rf_series):\n",
    "            r   = annualize_return(series)\n",
    "            v   = annualize_volatility(series)\n",
    "            sr  = sharpe_ratio(series, rf_series)\n",
    "            so  = sortino_ratio(series, rf_series)\n",
    "            mdd = max_drawdown(series)\n",
    "            return (r, v, sr, so, mdd)\n",
    "\n",
    "        # In-sample per-fund stats\n",
    "        in_sample_stats = {}\n",
    "        for fund in selected_funds:\n",
    "            in_sample_stats[fund] = compute_stats(in_sample_scaled[fund], in_sample_rf)\n",
    "\n",
    "        # Out-sample per-fund (adjusted) stats\n",
    "        out_sample_stats = {}\n",
    "        for fund in selected_funds:\n",
    "            out_sample_stats[fund] = compute_stats(out_sample_scaled[fund], out_sample_rf)\n",
    "\n",
    "        # Out-sample per-fund (raw) stats\n",
    "        out_sample_stats_raw = {}\n",
    "        for fund in selected_funds:\n",
    "            out_sample_stats_raw[fund] = compute_stats(out_sample_df[fund], out_sample_rf)\n",
    "\n",
    "        # Equal-weight portfolio\n",
    "        ew_w = np.array([1.0/len(selected_funds)] * len(selected_funds))\n",
    "        in_ew_port      = calc_portfolio_returns(ew_w, in_sample_scaled[selected_funds])\n",
    "        out_ew_port     = calc_portfolio_returns(ew_w, out_sample_scaled[selected_funds])\n",
    "        out_ew_port_raw = calc_portfolio_returns(ew_w, out_sample_df[selected_funds])\n",
    "\n",
    "        in_ew_stats      = compute_stats(in_ew_port, in_sample_rf)\n",
    "        out_ew_stats     = compute_stats(out_ew_port, out_sample_rf)\n",
    "        out_ew_stats_raw = compute_stats(out_ew_port_raw, out_sample_rf)\n",
    "\n",
    "        # User‐weight placeholder\n",
    "        user_weight_dict = {f: 1.0/len(selected_funds) for f in selected_funds}\n",
    "        custom_w = np.array([user_weight_dict[f] for f in selected_funds])\n",
    "\n",
    "        in_user_port      = calc_portfolio_returns(custom_w, in_sample_scaled[selected_funds])\n",
    "        out_user_port     = calc_portfolio_returns(custom_w, out_sample_scaled[selected_funds])\n",
    "        out_user_port_raw = calc_portfolio_returns(custom_w, out_sample_df[selected_funds])\n",
    "\n",
    "        in_user_stats      = compute_stats(in_user_port, in_sample_rf)\n",
    "        out_user_stats     = compute_stats(out_user_port, out_sample_rf)\n",
    "        out_user_stats_raw = compute_stats(out_user_port_raw, out_sample_rf)\n",
    "\n",
    "        results = {\n",
    "            'selected_funds':       selected_funds,\n",
    "            'in_sample_scaled':     in_sample_scaled,\n",
    "            'out_sample_scaled':    out_sample_scaled,\n",
    "            'in_sample_stats':      in_sample_stats,\n",
    "            'out_sample_stats':     out_sample_stats,\n",
    "            'out_sample_stats_raw': out_sample_stats_raw,\n",
    "            'in_ew_stats':          in_ew_stats,\n",
    "            'out_ew_stats':         out_ew_stats,\n",
    "            'out_ew_stats_raw':     out_ew_stats_raw,\n",
    "            'in_user_stats':        in_user_stats,\n",
    "            'out_user_stats':       out_user_stats,\n",
    "            'out_user_stats_raw':   out_user_stats_raw\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR inside stats-block:\", e)\n",
    "        return None\n",
    "\n",
    "    # Everything succeeded\n",
    "    return results\n",
    "\n",
    "print(\"run_analysis (with checkpoints) is defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cd88ee-a255-4282-b722-f34e34b95d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Analysis callback is now wired.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from IPython.utils.capture import capture_output\n",
    "\n",
    "def on_apply_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        # 1) Read widget values\n",
    "        in_start_val     = in_sample_start.value.strip()\n",
    "        in_end_val       = in_sample_end.value.strip()\n",
    "        out_start_val    = out_sample_start.value.strip()\n",
    "        out_end_val      = out_sample_end.value.strip()\n",
    "        target_vol_val   = target_vol_widget.value\n",
    "        monthly_cost_val = monthly_cost_widget.value\n",
    "        mode_val         = selection_mode_widget.value\n",
    "        rnd_n_val        = random_sample_size_widget.value\n",
    "\n",
    "        # 2) Print parameter summary\n",
    "        print(\"Running analysis with parameters:\")\n",
    "        print(f\"  In-Sample:  {in_start_val} → {in_end_val}\")\n",
    "        print(f\"  Out-Sample: {out_start_val} → {out_end_val}\")\n",
    "        print(f\"  Target Volatility: {target_vol_val}\")\n",
    "        print(f\"  Monthly Cost: {monthly_cost_val}\")\n",
    "        print(f\"  Selection Mode: {mode_val}\")\n",
    "        if mode_val == 'random':\n",
    "            print(f\"  Random Sample Size: {rnd_n_val}\")\n",
    "\n",
    "        # 3) Capture everything printed by run_analysis (and select_funds)\n",
    "        with capture_output() as cap:\n",
    "            try:\n",
    "                results = run_analysis(\n",
    "                    df,\n",
    "                    in_start=in_start_val,\n",
    "                    in_end=in_end_val,\n",
    "                    out_start=out_start_val,\n",
    "                    out_end=out_end_val,\n",
    "                    target_vol=target_vol_val,\n",
    "                    monthly_cost=monthly_cost_val,\n",
    "                    selection_mode=mode_val,\n",
    "                    random_n=rnd_n_val\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"Error inside run_analysis():\", e)\n",
    "                return\n",
    "\n",
    "        # 4) Print the captured debug/info text\n",
    "        print(cap.stdout)\n",
    "\n",
    "        # 5) If no funds survived, warn\n",
    "        if results is None or ('selected_funds' in results and not results['selected_funds']):\n",
    "            print(\"No valid funds remain after filtering. Check your date range or data.\")\n",
    "            return\n",
    "\n",
    "        # 6) Summary\n",
    "        print(\"Analysis complete. Summary:\")\n",
    "        sf = results['selected_funds']\n",
    "        if 'selected_funds' in results:\n",
    "            print(f\"  Funds selected: {len(results['selected_funds'])}\")\n",
    "        if 'in_ew_stats' in results:\n",
    "            ir, iv, isr, _, _ = results['in_ew_stats']\n",
    "            print(f\"  In-Sample EW → Return: {ir*100:.2f}%, Vol: {iv*100:.2f}%, Sharpe: {isr:.2f}\")\n",
    "        if 'out_ew_stats' in results:\n",
    "            or_, ov, osr, _, _ = results['out_ew_stats']\n",
    "            print(f\"  Out-Sample EW → Return: {or_*100:.2f}%, Vol: {ov*100:.2f}%, Sharpe: {osr:.2f}\")\n",
    "        print(f\"  Funds selected: {len(sf)} → {sf}\")\n",
    "        \n",
    "        export_to_excel(results, \"InteractiveOutput.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# Wire the button once (after all definitions are loaded)\n",
    "\n",
    "print(\"Run Analysis callback is now wired.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5b060-852c-4755-aa9b-7b3f0919f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for fund in selected_funds:\n",
    "        sf = scale_factors[fund]\n",
    "        # In-sample\n",
    "        adj_in = in_sample_df[fund] * sf - monthly_cost\n",
    "        adj_in[adj_in < -1.0] = -1.0\n",
    "        in_sample_scaled[fund] = adj_in\n",
    "        \n",
    "        # Out-of-sample\n",
    "        if out_sample_df.shape[0] > 0:\n",
    "            adj_out = out_sample_df[fund] * sf - monthly_cost\n",
    "            adj_out[adj_out < -1.0] = -1.0\n",
    "            out_sample_scaled[fund] = adj_out\n",
    "    \n",
    "    # Helper function for stats\n",
    "    def compute_stats(series, rf_series):\n",
    "        r = annualize_return(series)\n",
    "        v = annualize_volatility(series)\n",
    "        sr = sharpe_ratio(series, rf_series)\n",
    "        so = sortino_ratio(series, rf_series)\n",
    "        mdd = max_drawdown(series)\n",
    "        return (r, v, sr, so, mdd)\n",
    "    \n",
    "    in_sample_stats = {}\n",
    "    for fund in selected_funds:\n",
    "        in_sample_stats[fund] = compute_stats(in_sample_scaled[fund], in_sample_rf)\n",
    "    \n",
    "    out_sample_stats = {}\n",
    "    for fund in selected_funds:\n",
    "        out_sample_stats[fund] = compute_stats(out_sample_scaled[fund], out_sample_rf)\n",
    "    \n",
    "    out_sample_stats_raw = {}\n",
    "    for fund in selected_funds:\n",
    "        out_sample_stats_raw[fund] = compute_stats(out_sample_df[fund], out_sample_rf)\n",
    "    \n",
    "    # Portfolio (equal-weight)\n",
    "    ew_w = np.array([1.0/len(selected_funds)]*len(selected_funds))\n",
    "    in_ew_port = calc_portfolio_returns(ew_w, in_sample_scaled[selected_funds])\n",
    "    out_ew_port = calc_portfolio_returns(ew_w, out_sample_scaled[selected_funds])\n",
    "    out_ew_port_raw = calc_portfolio_returns(ew_w, out_sample_df[selected_funds])\n",
    "    \n",
    "    in_ew_stats = compute_stats(in_ew_port, in_sample_rf)\n",
    "    out_ew_stats = compute_stats(out_ew_port, out_sample_rf)\n",
    "    out_ew_stats_raw = compute_stats(out_ew_port_raw, out_sample_rf)\n",
    "    \n",
    "    # Portfolio (user-weighted) - placeholder\n",
    "    user_weight_dict = {f: 1.0/len(selected_funds) for f in selected_funds}\n",
    "    custom_w = np.array([user_weight_dict[f] for f in selected_funds])\n",
    "    in_user_port = calc_portfolio_returns(custom_w, in_sample_scaled[selected_funds])\n",
    "    out_user_port = calc_portfolio_returns(custom_w, out_sample_scaled[selected_funds])\n",
    "    out_user_port_raw = calc_portfolio_returns(custom_w, out_sample_df[selected_funds])\n",
    "    \n",
    "    in_user_stats = compute_stats(in_user_port, in_sample_rf)\n",
    "    out_user_stats = compute_stats(out_user_port, out_sample_rf)\n",
    "    out_user_stats_raw = compute_stats(out_user_port_raw, out_sample_rf)\n",
    "    \n",
    "    results = {\n",
    "        'selected_funds': selected_funds,\n",
    "        'in_sample_scaled': in_sample_scaled,\n",
    "        'out_sample_scaled': out_sample_scaled,\n",
    "        'in_sample_stats': in_sample_stats,\n",
    "        'out_sample_stats': out_sample_stats,\n",
    "        'out_sample_stats_raw': out_sample_stats_raw,\n",
    "        'in_ew_stats': in_ew_stats,\n",
    "        'out_ew_stats': out_ew_stats,\n",
    "        'out_ew_stats_raw': out_ew_stats_raw,\n",
    "        'in_user_stats': in_user_stats,\n",
    "        'out_user_stats': out_user_stats,\n",
    "        'out_user_stats_raw': out_user_stats_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4984b33",
   "metadata": {},
   "source": [
    "# Volatility Scaling & Portfolio Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and validate data.\n",
    "2. Handle missing data (short vs. long gaps).\n",
    "3. Adjust returns to a target volatility in-sample, then apply the same scaling out-of-sample.\n",
    "4. Compute Sharpe, Sortino, Max Drawdown.\n",
    "5. Provide multiple fund selection modes (all, random sample, manual).\n",
    "6. Calculate portfolio results (equal-weight and custom-weight).\n",
    "7. Output in-sample and out-of-sample results to Excel with formatting.\n",
    "\n",
    "**Note**: The manual fund selection and custom weights features are partially implemented. In a real interactive workflow, you would wire widget selections and weights into the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ea203f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging started. Volatility Scaling & Portfolio Analysis Notebook initialized.\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# ============ 1. SETUP CELL ============\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, VBox, HBox\n",
    "from IPython.display import display, clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# If you need to install these packages on your environment, uncomment:\n",
    "!{sys.executable} -m pip install --quiet ipywidgets openpyxl xlsxwriter\n",
    "\n",
    "# For exporting to Excel with styling\n",
    "import xlsxwriter\n",
    "\n",
    "# Set up logging to console\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s: %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Logging started. Volatility Scaling & Portfolio Analysis Notebook initialized.\")\n",
    "\n",
    "# (Optional) If widgets aren't enabled, run:\n",
    "# !jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Here we create options to load a dataset from a local file or a GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b324bc9ef84efb9c2a9af6361744d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Step 1: Choose your CSV</b><br><i>Remember:</i> If you included any index column…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def identify_risk_free_fund(df):\n",
    "    \"\"\"\n",
    "    Identify which column (after 'Date') is the risk-free rate by smallest stdev among columns.\n",
    "    \"\"\"\n",
    "    numeric_cols = df.columns[1:]  # skip the Date column\n",
    "    stdevs = {}\n",
    "    for col in numeric_cols:\n",
    "        vals = df[col].dropna()\n",
    "        if len(vals) > 0:\n",
    "            stdevs[col] = vals.std()\n",
    "        else:\n",
    "            stdevs[col] = np.inf\n",
    "\n",
    "    rf_col = min(stdevs, key=stdevs.get)\n",
    "    logging.info(f\"Identified '{rf_col}' as the risk-free column (lowest stdev).\")\n",
    "    return rf_col\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Helper to read a local CSV robustly (handles BOMs and minor parsing issues)\n",
    "# ------------------------------------------------------------------------------\n",
    "def robust_read_csv(path):\n",
    "    \"\"\"\n",
    "    Try loading `path` as CSV in three ways:\n",
    "    1. Default C engine\n",
    "    2. BOM-stripped with the Python engine\n",
    "    3. Skip bad lines with the Python engine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e1:\n",
    "        print(\"Default read_csv failed:\", e1)\n",
    "\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=\",\", encoding=\"utf-8-sig\", engine=\"python\")\n",
    "    except Exception as e2:\n",
    "        print(\"utf-8-sig + python engine failed:\", e2)\n",
    "\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        sep=\",\",\n",
    "        engine=\"python\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        skip_blank_lines=True,\n",
    "        on_bad_lines=\"skip\",    # for pandas ≥ 1.3\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Build the widgets\n",
    "# ------------------------------------------------------------------------------\n",
    "source_info = widgets.HTML(\n",
    "    \"<b>Step 1: Choose your CSV</b><br>\"\n",
    "    \"<i>Remember:</i> If you included any index columns (e.g. S&P 500, MSCI World, SG Trend), they \"\n",
    "    \"must appear to the right of all fund columns in your sheet.\"\n",
    ")\n",
    "\n",
    "\n",
    "source_dropdown = widgets.Dropdown(\n",
    "    options=['Local', 'GitHub'],\n",
    "    value='Local',\n",
    "    description='Data Source:',\n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "\n",
    "# FileChooser for Local mode\n",
    "fc = FileChooser(os.getcwd())\n",
    "fc.title = \"<b>Select local CSV file</b>\"\n",
    "\n",
    "# Text box for GitHub raw URL\n",
    "github_text = widgets.Text(\n",
    "    value=(\n",
    "        \"https://raw.githubusercontent.com/stranske/Trend_Model_Project/\"\n",
    "        \"main/data/TrendData.csv\"\n",
    "    ),\n",
    "    description=\"GitHub URL:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "# Ask how many index columns are on the far right\n",
    "n_indices_widget = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10,  # adjust if you expect more than 10 indices\n",
    "    description='# Index cols:',\n",
    "    style={'description_width': '120px'},\n",
    "    tooltip=\"Enter the number of index columns at the far right of your CSV\"\n",
    ")\n",
    "\n",
    "# Load button\n",
    "load_button = widgets.Button(description=\"Load Data\", button_style=\"success\")\n",
    "\n",
    "# Output area for status and debug prints\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Show/hide widgets depending on source selection\n",
    "# ------------------------------------------------------------------------------\n",
    "def on_source_change(change):\n",
    "    if change[\"new\"] == \"Local\":\n",
    "        fc.layout.display = \"block\"\n",
    "        github_text.layout.display = \"none\"\n",
    "    else:\n",
    "        fc.layout.display = \"none\"\n",
    "        github_text.layout.display = \"block\"\n",
    "\n",
    "# Initially, GitHub textbox is hidden; FileChooser is visible\n",
    "github_text.layout.display = \"none\"\n",
    "fc.layout.display = \"block\"\n",
    "\n",
    "source_dropdown.observe(on_source_change, names=\"value\")\n",
    "\n",
    "ui_load = widgets.VBox([\n",
    "    source_info,\n",
    "    source_dropdown,\n",
    "    fc,\n",
    "    github_text,\n",
    "    n_indices_widget,   # ← new widget here\n",
    "    load_button,\n",
    "    output_area\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Callback for the Load button (auto-detect date format)\n",
    "# ------------------------------------------------------------------------------\n",
    "def on_load_clicked(_):\n",
    "    global df, fund_cols, indices_list, rf_col            # declare df as global\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        src_choice = source_dropdown.value\n",
    "        n_indices = int(n_indices_widget.value)\n",
    "\n",
    "        # 4a) Load the DataFrame\n",
    "        try:\n",
    "            if src_choice == 'Local':\n",
    "                local_path = fc.selected  # FileChooser’s selected path\n",
    "                if not local_path or not os.path.exists(local_path):\n",
    "                    print(f\"Error: Local file not found:\\n  {local_path}\")\n",
    "                    return\n",
    "                print(f\"Loading from local file:\\n  {local_path}\")\n",
    "                df = pd.read_csv(local_path)\n",
    "            else:\n",
    "                github_url = github_text.value.strip()\n",
    "                if not github_url:\n",
    "                    print(\"Error: Please enter a valid GitHub raw URL.\")\n",
    "                    return\n",
    "                print(f\"Loading from GitHub URL:\\n  {github_url}\")\n",
    "                df = pd.read_csv(github_url)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load CSV:\", e)\n",
    "            return\n",
    "\n",
    "        # 4b) Debug: print columns & a few rows\n",
    "        print(\"Columns found in DataFrame:\", df.columns.tolist())\n",
    "        display(df.head(3))\n",
    "\n",
    "        # 4c) Identify which column is the date\n",
    "        date_col = None\n",
    "        for candidate in [\"Date\", \"DATE\", \"date\"]:\n",
    "            if candidate in df.columns:\n",
    "                date_col = candidate\n",
    "                break\n",
    "\n",
    "        if date_col is None:\n",
    "            print(\"Error: No column named 'Date' / 'DATE' / 'date' found.\")\n",
    "            print(\"Please check the column names above and adjust code accordingly.\")\n",
    "            return\n",
    "\n",
    "        date_col = 'Date'\n",
    "\n",
    "        # 1) Show the first few raw date strings (un‐parsed) so we can inspect them\n",
    "        raw_samples = df[date_col].dropna().astype(str).head(10).tolist()\n",
    "        print(f\"Raw {date_col} samples (first 10 non‐null): {raw_samples!r}\")\n",
    "\n",
    "        # 2) Strip leading/trailing whitespace from every entry\n",
    "        df[date_col] = df[date_col].astype(str).str.strip()\n",
    "\n",
    "        # 3) Now attempt strict \"%m/%d/%Y\" parsing\n",
    "        parsed = pd.to_datetime(df[date_col], format=\"%m/%d/%Y\", errors=\"coerce\", infer_datetime_format=True)\n",
    "        num_valid = parsed.notna().sum()\n",
    "        print(f\"Number of rows matching '%m/%d/%Y' exactly: {num_valid} / {len(df)}\")\n",
    "\n",
    "        if num_valid > 0:\n",
    "            df[date_col] = parsed\n",
    "            print(f\"Parsing with '%m/%d/%Y' succeeded for {num_valid} rows.\")\n",
    "        else:\n",
    "            print(\n",
    "                \"Warning: No rows matched '%m/%d/%Y'. \"\n",
    "                \"Falling back to generic pd.to_datetime(...).\"\n",
    "            )\n",
    "            df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "        # 5) Drop any rows where parsing still failed\n",
    "        before_drop = len(df)\n",
    "        df.dropna(subset=[date_col], inplace=True)\n",
    "        dropped = before_drop - len(df)\n",
    "        if dropped:\n",
    "            print(f\"Dropped {dropped} rows where '{date_col}' could not be parsed.\")\n",
    "        \n",
    "        # 6) Sort and reset index\n",
    "        df.sort_values(by=date_col, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # 7) Show the final parsed dates\n",
    "        print(f\"After parsing, first 3 {date_col} values:\")\n",
    "        print(df[[date_col]].head(3))\n",
    "        print(f\"Loaded {len(df)} rows successfully.\")\n",
    "\n",
    "\n",
    "        # 4d) Identify risk-free column\n",
    "        try:\n",
    "            rf_col = identify_risk_free_fund(df)\n",
    "            print(f\"Identified risk-free column as: '{rf_col}'\")\n",
    "        except Exception as e:\n",
    "            print(\"Error identifying risk-free column:\", e)\n",
    "            return\n",
    "\n",
    "        # 4f) Determine fund_cols vs indices_list based on n_indices\n",
    "        all_cols = df.columns.tolist()\n",
    "        # We assume “Date” and rf_col are present. Everything else is a candidate.\n",
    "        if 'Date' not in all_cols or rf_col not in all_cols:\n",
    "            print(\"Error: 'Date' or risk-free column not found in DataFrame columns.\")\n",
    "            return\n",
    "        \n",
    "        # Build list of all columns except 'Date' and rf_col\n",
    "        remaining = [c for c in all_cols if c not in ['Date', rf_col]]\n",
    "        \n",
    "        if n_indices > len(remaining):\n",
    "            print(\n",
    "                f\"Error: You asked for {n_indices} index columns, but only \"\n",
    "                f\"{len(remaining)} columns remain after 'Date' and '{rf_col}'.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        if n_indices > 0:\n",
    "            indices_list = remaining[-n_indices:]\n",
    "            fund_cols    = remaining[:-n_indices]\n",
    "        else:\n",
    "            indices_list = []\n",
    "            fund_cols    = remaining[:]\n",
    "        print(\"\\n>> Debug (post‐load): fund_cols =\", fund_cols)\n",
    "        print(\">> Debug (post‐load): indices_list =\", indices_list, \"\\n\")\n",
    "        \n",
    "        # 2F) Print out what we found\n",
    "        print(f\"Detected fund columns ({len(fund_cols)}): {fund_cols}\")\n",
    "        print(f\"Detected index columns ({len(indices_list)}): {indices_list}\")\n",
    "        print(\n",
    "            \"Data loaded and classified successfully.\\n\"\n",
    "            \"Proceed to Step 2 (Run Analysis).\"\n",
    "        )\n",
    "\n",
    " \n",
    "        # 8) Confirm that df is now in global scope\n",
    "        print(\">> df defined with\", len(df), \"rows and columns:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "# 5) Wire up and display the UI\n",
    "load_button.on_click(on_load_clicked)\n",
    "\n",
    "\n",
    "display(ui_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982ef5a9-d579-4289-bb9c-59e1378e15d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Funds with absolutely no NaNs over both windows (count = 27):\n",
      "['Quantum Capital', 'Quantum Group', 'Echo Strategies', 'Echo Group', 'Meridian Strategies', 'Axiom LP', 'Crescent Partners', 'Forge Advisors', 'Sentinel Global', 'Axiom Advisors', 'Vista Holdings', 'Sentinel Advisors', 'Crescent Group', 'Adaptive Holdings', 'Vista Capital', 'Forge Investments', 'Ascent Global', 'Vista Global', 'Forge Group', 'Axiom Holdings', 'Adaptive Global', 'Ascent Advisors', 'Quantum Advisors', 'Ascent Group', 'Quantum Holdings', 'Sentinel LP', 'Adaptive LP']\n",
      "\n",
      "None of the post‐full‐history funds has a run of ≥ 3 NaNs in either window.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ────────────── 1) Re‐compute in_sdate, in_edate, out_sdate, out_edate ──────────────\n",
    "in_sdate  = pd.to_datetime(\"2005-07-01\", errors=\"coerce\")\n",
    "in_edate  = pd.to_datetime(\"2008-06-01\", errors=\"coerce\") + pd.offsets.MonthEnd(0)\n",
    "out_sdate = pd.to_datetime(\"2008-07-01\", errors=\"coerce\")\n",
    "out_edate = pd.to_datetime(\"2009-06-01\", errors=\"coerce\") + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# ────────────── 2) Build the full‐history list (no NaNs anywhere in each window) ──────────────\n",
    "#    We assume that 'rf_col' is already defined and holds the risk‐free column name.\n",
    "#    We also assume that any index columns are in a list called 'indices_list'.\n",
    "all_candidates = [\n",
    "    c for c in df.columns \n",
    "    if c not in [\"Date\", rf_col] + indices_list\n",
    "]\n",
    "\n",
    "# (A) Select only those f where in‐sample AND out‐sample both have no NaNs anywhere:\n",
    "post_full_history_funds = []\n",
    "for f in all_candidates:\n",
    "    in_sub  = df[(df['Date'] >= in_sdate) & (df['Date'] <= in_edate)][f]\n",
    "    out_sub = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)][f]\n",
    "    if in_sub.notna().all() and out_sub.notna().all():\n",
    "        post_full_history_funds.append(f)\n",
    "\n",
    "print(f\"(1) Funds with absolutely no NaNs over both windows (count = {len(post_full_history_funds)}):\")\n",
    "print(post_full_history_funds)\n",
    "\n",
    "\n",
    "# ────────────── 3) Now run the “3+ consecutive NaNs” check only on that list ──────────────\n",
    "flagged_exact = []  # will hold (fund_name, window_name, max_consecutive_nans)\n",
    "for f in post_full_history_funds:\n",
    "    # In‐sample gap‐runs\n",
    "    sub_in   = df[(df['Date'] >= in_sdate) & (df['Date'] <= in_edate)][f]\n",
    "    isnan_in = sub_in.isna().astype(int)\n",
    "    run_len_in = isnan_in.groupby((isnan_in == 0).cumsum()).sum()\n",
    "    max_run_in = run_len_in.max() if not run_len_in.empty else 0\n",
    "    if max_run_in >= 3:\n",
    "        flagged_exact.append((f, \"in-sample\", int(max_run_in)))\n",
    "\n",
    "    # Out‐sample gap‐runs\n",
    "    sub_out   = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)][f]\n",
    "    isnan_out = sub_out.isna().astype(int)\n",
    "    run_len_out = isnan_out.groupby((isnan_out == 0).cumsum()).sum()\n",
    "    max_run_out = run_len_out.max() if not run_len_out.empty else 0\n",
    "    if max_run_out >= 3:\n",
    "        flagged_exact.append((f, \"out-sample\", int(max_run_out)))\n",
    "\n",
    "\n",
    "# ────────────── 4) Report results ──────────────\n",
    "if flagged_exact:\n",
    "    print(\"\\nFunds that actually *do* have 3+ consecutive NaNs inside one of the windows:\")\n",
    "    for (fund_name, window_name, length) in flagged_exact:\n",
    "        print(f\"  • {fund_name!r} → {length} consecutive NaNs in {window_name}\")\n",
    "else:\n",
    "    print(\"\\nNone of the post‐full‐history funds has a run of ≥ 3 NaNs in either window.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53bc18",
   "metadata": {},
   "source": [
    "## 3. Utility Functions\n",
    "Here we define date parsing, consecutive gap checks, data filling, risk-free identification, return calculations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e697c-eeb3-4e0f-b29e-43597a05e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ─────────── Define your date boundaries ───────────\n",
    "in_sdate  = pd.to_datetime(\"2005-07-01\", errors=\"coerce\")\n",
    "in_edate  = pd.to_datetime(\"2008-06-01\", errors=\"coerce\") + pd.offsets.MonthEnd(0)\n",
    "out_sdate = pd.to_datetime(\"2008-07-01\", errors=\"coerce\")\n",
    "out_edate = pd.to_datetime(\"2009-06-01\", errors=\"coerce\") + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# (Also ensure 'df' and 'fund_cols' are already defined above this cell.)\n",
    "\n",
    "flagged = []  # will hold (fund_name, window_name, max_consecutive_nans) tuples\n",
    "\n",
    "for f in fund_cols:\n",
    "    # ─── In‐sample window check ───\n",
    "    sub_in = df[(df['Date'] >= in_sdate) & (df['Date'] <= in_edate)][f]\n",
    "    isnan_in = sub_in.isna().astype(int)                         # 1 where NaN, 0 otherwise\n",
    "    # group by cumulative “not-NaN” runs to measure each NaN‐block length\n",
    "    run_len_in = isnan_in.groupby((isnan_in == 0).cumsum()).sum()\n",
    "    max_run_in = run_len_in.max() if not run_len_in.empty else 0\n",
    "    if max_run_in >= 3:\n",
    "        flagged.append((f, 'in-sample', int(max_run_in)))\n",
    "    \n",
    "    # ─── Out‐sample window check ───\n",
    "    sub_out = df[(df['Date'] >= out_sdate) & (df['Date'] <= out_edate)][f]\n",
    "    isnan_out = sub_out.isna().astype(int)\n",
    "    run_len_out = isnan_out.groupby((isnan_out == 0).cumsum()).sum()\n",
    "    max_run_out = run_len_out.max() if not run_len_out.empty else 0\n",
    "    if max_run_out >= 3:\n",
    "        flagged.append((f, 'out-sample', int(max_run_out)))\n",
    "\n",
    "# Finally, print any funds with ≥ 3 consecutive NaNs\n",
    "if flagged:\n",
    "    print(\"Funds with a 3+ consecutive‐NaN run inside one of the windows:\")\n",
    "    for (fund_name, window_name, length) in flagged:\n",
    "        print(f\"  • {fund_name!r} has {length} consecutive NaNs in the {window_name} window\")\n",
    "else:\n",
    "    print(\"All funds have at most 2 consecutive NaNs in both in‐sample and out‐sample windows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a9bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def consecutive_gaps(series, threshold=3):\n",
    "    \"\"\"\n",
    "    Check if a series (sorted chronologically) has >= threshold consecutive NaNs.\n",
    "    Return True if such a gap exists, False otherwise.\n",
    "    \"\"\"\n",
    "    consecutive = 0\n",
    "    for val in series:\n",
    "        if pd.isna(val):\n",
    "            consecutive += 1\n",
    "        else:\n",
    "            consecutive = 0\n",
    "        if consecutive >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fill_short_gaps_with_zero(series, max_short_gap=2):\n",
    "    \"\"\"\n",
    "    Replace missing values (NaN) with 0 if they appear in runs of <= max_short_gap.\n",
    "    Longer runs remain NaN.\n",
    "    \"\"\"\n",
    "    filled = series.copy()\n",
    "    n = len(series)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if pd.isna(filled[i]):\n",
    "            run_start = i\n",
    "            while i < n and pd.isna(filled[i]):\n",
    "                i += 1\n",
    "            run_end = i  # first non-NaN after run\n",
    "            gap_length = run_end - run_start\n",
    "            if gap_length <= max_short_gap:\n",
    "                filled[run_start:run_end] = 0.0\n",
    "        else:\n",
    "            i += 1\n",
    "    return filled\n",
    "\n",
    "\n",
    "def annualize_return(monthly_returns):\n",
    "    \"\"\"\n",
    "    Annualized (geometric) return from monthly returns in decimal form.\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) == 0:\n",
    "        return np.nan\n",
    "    growth_factor = (1 + valid_rets).prod()\n",
    "    n_months = len(valid_rets)\n",
    "    if growth_factor <= 0:\n",
    "        return -1.0\n",
    "    ann_ret = growth_factor**(12.0 / n_months) - 1\n",
    "    return ann_ret\n",
    "\n",
    "def annualize_volatility(monthly_returns):\n",
    "    \"\"\"\n",
    "    Annualized stdev of monthly returns, i.e. stdev * sqrt(12).\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) < 2:\n",
    "        return np.nan\n",
    "    return valid_rets.std() * np.sqrt(12)\n",
    "\n",
    "def sharpe_ratio(monthly_returns, rf_series):\n",
    "    \"\"\"\n",
    "    Annualized Sharpe ratio = (annual_excess_return) / (annual_excess_vol).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'r': monthly_returns, 'rf': rf_series}).dropna()\n",
    "    if len(df) < 2:\n",
    "        return np.nan\n",
    "    excess = df['r'] - df['rf']\n",
    "    growth_factor = (1 + excess).prod()\n",
    "    n_months = len(excess)\n",
    "    if growth_factor <= 0:\n",
    "        return np.nan\n",
    "    ann_excess_ret = growth_factor**(12.0 / n_months) - 1\n",
    "    ann_excess_vol = excess.std() * np.sqrt(12)\n",
    "    if ann_excess_vol == 0:\n",
    "        return np.nan\n",
    "    return ann_excess_ret / ann_excess_vol\n",
    "\n",
    "def sortino_ratio(monthly_returns, rf_series):\n",
    "    \"\"\"\n",
    "    Annualized Sortino ratio = (annual_excess_return) / (annual_downside_stdev).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'r': monthly_returns, 'rf': rf_series}).dropna()\n",
    "    if len(df) < 2:\n",
    "        return np.nan\n",
    "    excess = df['r'] - df['rf']\n",
    "\n",
    "    growth_factor = (1 + excess).prod()\n",
    "    n_months = len(excess)\n",
    "    if growth_factor <= 0:\n",
    "        return np.nan\n",
    "    ann_excess_ret = growth_factor**(12.0 / n_months) - 1\n",
    "\n",
    "    negative_mask = excess < 0\n",
    "    negative_returns = excess[negative_mask]\n",
    "    if len(negative_returns) == 0:\n",
    "        return np.inf  # no negative => infinite sortino\n",
    "    downside_stdev = negative_returns.std() * np.sqrt(12)\n",
    "    return ann_excess_ret / downside_stdev\n",
    "\n",
    "def max_drawdown(monthly_returns):\n",
    "    \"\"\"\n",
    "    Compute max drawdown from monthly returns in decimal form.\n",
    "    \"\"\"\n",
    "    valid_rets = monthly_returns.dropna()\n",
    "    if len(valid_rets) == 0:\n",
    "        return np.nan\n",
    "    wealth_index = (1 + valid_rets).cumprod()\n",
    "    rolling_max = wealth_index.cummax()\n",
    "    dd_series = 1 - (wealth_index / rolling_max)\n",
    "    return dd_series.max()\n",
    "\n",
    "def calc_portfolio_returns(weights, df_returns):\n",
    "    \"\"\"\n",
    "    Compute monthly portfolio returns (Series) as weighted sum of columns in df_returns.\n",
    "    \"\"\"\n",
    "    return (df_returns * weights).sum(axis=1)\n",
    "\n",
    "print(\"Utility functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1619c9",
   "metadata": {},
   "source": [
    "## 4. Widgets & User Inputs\n",
    "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eb165",
   "metadata": {},
   "source": [
    "## 5. Fund Selection\n",
    "Filters out columns that represent the risk-free rate or contain \"index\" in the name, then handles the selection mode (all, random, or manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffad994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────── Widget Setup + Callback ───────────────\n",
    "\n",
    "# (A) Build widgets\n",
    "in_sample_start = widgets.Text(value='2003-01', description='In-Sample Start:')\n",
    "in_sample_end   = widgets.Text(value='2005-12', description='In-Sample End:')\n",
    "out_sample_start= widgets.Text(value='2006-01', description='Out-Sample Start:')\n",
    "out_sample_end  = widgets.Text(value='2010-12', description='Out-Sample End:')\n",
    "\n",
    "target_vol_widget   = widgets.FloatText(value=0.10,  description='Target Vol:')\n",
    "monthly_cost_widget = widgets.FloatText(value=0.002, description='Monthly Cost:')\n",
    "\n",
    "selection_mode_widget = widgets.Dropdown(\n",
    "    options=[('All Funds','all'), ('Random Sample','random'), ('Manual','manual')],\n",
    "    value='all',\n",
    "    description='Mode:'\n",
    ")\n",
    "random_sample_size_widget = widgets.IntText(value=5, description='Sample Size:')\n",
    "\n",
    "apply_button = widgets.Button(description='Run Analysis', button_style='success')\n",
    "\n",
    "ui_inputs = widgets.VBox([\n",
    "    in_sample_start, in_sample_end,\n",
    "    out_sample_start, out_sample_end,\n",
    "    target_vol_widget, monthly_cost_widget,\n",
    "    selection_mode_widget, random_sample_size_widget,\n",
    "    apply_button\n",
    "])\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107d43e-d54e-4a9f-83c6-d6ffcc0a3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # 6) Show a brief summary\n",
    "        print(\"Analysis complete. Summary:\")\n",
    "        sf = results['selected_funds']\n",
    "        print(f\"  Funds selected: {len(sf)} → {sf}\")\n",
    "        if 'selected_funds' in results:\n",
    "            print(f\"  Funds selected: {len(results['selected_funds'])}\")\n",
    "        if 'in_ew_stats' in results:\n",
    "            ir, iv, isr, _, _ = results['in_ew_stats']\n",
    "            print(f\"  In-Sample EW → Return: {ir*100:.2f}%, Vol: {iv*100:.2f}%, Sharpe: {isr:.2f}\")\n",
    "        if 'out_ew_stats' in results:\n",
    "            or_, ov, osr, _, _ = results['out_ew_stats']\n",
    "            print(f\"  Out-Sample EW → Return: {or_*100:.2f}%, Vol: {ov*100:.2f}%, Sharpe: {osr:.2f}\")\n",
    "        \n",
    "\n",
    "print(\"Widgets defined. Use 'display(ui_inputs)' in a cell to show them after other functions run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c60582",
   "metadata": {},
   "source": [
    "## 6. Custom Weights\n",
    "Displays an integer text widget for each fund, requiring the sum of weights to be 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a404c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_custom_weights function ready.\n"
     ]
    }
   ],
   "source": [
    "def get_custom_weights(selected_funds):\n",
    "    \"\"\"\n",
    "    Display widgets for each fund to enter weights. Validate sum=100.\n",
    "    Returns dict {fund: weight_decimal}.\n",
    "    \"\"\"\n",
    "    weight_widgets = {}\n",
    "    for fund in selected_funds:\n",
    "        w = widgets.BoundedIntText(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description=f\"{fund}\",\n",
    "            layout=widgets.Layout(width='250px')\n",
    "        )\n",
    "        weight_widgets[fund] = w\n",
    "    \n",
    "    confirm_button = widgets.Button(\n",
    "        description='Confirm Weights',\n",
    "        button_style='success'\n",
    "    )\n",
    "    error_label = widgets.Label(value='', layout=widgets.Layout(color='red'))\n",
    "    \n",
    "    box = VBox(list(weight_widgets.values()) + [confirm_button, error_label])\n",
    "    display(box)\n",
    "    \n",
    "    weights_container = {}\n",
    "    \n",
    "    def on_confirm_clicked(_):\n",
    "        total = sum(w.value for w in weight_widgets.values())\n",
    "        if total != 100:\n",
    "            error_label.value = f\"Error: Weights sum to {total}, must be 100.\"\n",
    "            weights_container.clear()\n",
    "        else:\n",
    "            for fund, wdg in weight_widgets.items():\n",
    "                weights_container[fund] = wdg.value / 100.0\n",
    "            error_label.value = \"Weights confirmed!\"\n",
    "    \n",
    "    confirm_button.on_click(on_confirm_clicked)\n",
    "    return weights_container\n",
    "\n",
    "print(\"get_custom_weights function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3666a84",
   "metadata": {},
   "source": [
    "## 7. Analysis (In-Sample & Out-of-Sample)\n",
    "The `run_analysis` function orchestrates the entire process:\n",
    "- Validates date inputs.\n",
    "- Converts 'Date' column.\n",
    "- Identifies risk-free column.\n",
    "- Fills short gaps.\n",
    "- Selects funds.\n",
    "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
    "- Computes individual fund stats and portfolio stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dc5df",
   "metadata": {},
   "source": [
    "## 8. Excel Export\n",
    "Creates an Excel file with two sheets (In-Sample, Out-of-Sample) and two tables per sheet (Equal-weight and User-weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e2cce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_to_excel function ready.\n"
     ]
    }
   ],
   "source": [
    "def export_to_excel(results_dict, output_filename=\"AnalysisOutput.xlsx\"):\n",
    "    \"\"\"\n",
    "    Create an Excel file with two tabs: In-Sample, Out-of-Sample.\n",
    "    Each has two tables: (1) Equal-Weight, (2) User-Weighted.\n",
    "    Columns for Return(%), Vol(%), Sharpe, Sortino, MaxDD(%).\n",
    "    For OOS, also show 'before scaling' vs. 'after scaling' returns/vol.\n",
    "    \"\"\"\n",
    "    selected_funds = results_dict['selected_funds']\n",
    "    in_sample_stats = results_dict['in_sample_stats']\n",
    "    out_sample_stats_scaled = results_dict['out_sample_stats']\n",
    "    out_sample_stats_raw = results_dict['out_sample_stats_raw']\n",
    "\n",
    "    in_ew_stats = results_dict['in_ew_stats']\n",
    "    out_ew_stats_scaled = results_dict['out_ew_stats']\n",
    "    out_ew_stats_raw = results_dict['out_ew_stats_raw']\n",
    "\n",
    "    in_user_stats = results_dict['in_user_stats']\n",
    "    out_user_stats_scaled = results_dict['out_user_stats']\n",
    "    out_user_stats_raw = results_dict['out_user_stats_raw']\n",
    "\n",
    "    # --- In-Sample DataFrames ---\n",
    "    in_eq_data = []\n",
    "    in_user_data = []\n",
    "    for fund in selected_funds:\n",
    "        r, v, s, so, mdd = in_sample_stats[fund]\n",
    "        in_eq_data.append([fund, r, v, s, so, mdd])\n",
    "        in_user_data.append([fund, r, v, s, so, mdd])\n",
    "\n",
    "    in_eq_data.append([\n",
    "        'Equal-Weight Portfolio',\n",
    "        in_ew_stats[0],\n",
    "        in_ew_stats[1],\n",
    "        in_ew_stats[2],\n",
    "        in_ew_stats[3],\n",
    "        in_ew_stats[4]\n",
    "    ])\n",
    "    in_user_data.append([\n",
    "        'User-Weighted Portfolio',\n",
    "        in_user_stats[0],\n",
    "        in_user_stats[1],\n",
    "        in_user_stats[2],\n",
    "        in_user_stats[3],\n",
    "        in_user_stats[4]\n",
    "    ])\n",
    "\n",
    "    in_eq_df = pd.DataFrame(\n",
    "        in_eq_data,\n",
    "        columns=['Fund', 'Return (%)', 'Volatility (%)', 'Sharpe', 'Sortino', 'MaxDD (%)']\n",
    "    )\n",
    "    in_user_df = pd.DataFrame(\n",
    "        in_user_data,\n",
    "        columns=['Fund', 'Return (%)', 'Volatility (%)', 'Sharpe', 'Sortino', 'MaxDD (%)']\n",
    "    )\n",
    "\n",
    "    # --- Out-of-Sample DataFrames ---\n",
    "    # columns: [Fund, RetBefore(%), VolBefore(%), RetAfter(%), VolAfter(%), Sharpe(After), Sortino(After), MaxDD(After)(%)]\n",
    "    out_eq_data = []\n",
    "    out_user_data = []\n",
    "\n",
    "    for fund in selected_funds:\n",
    "        r_raw, v_raw, _, _, _ = out_sample_stats_raw[fund]\n",
    "        r_scaled, v_scaled, s_scaled, so_scaled, mdd_scaled = out_sample_stats_scaled[fund]\n",
    "        out_eq_data.append([\n",
    "            fund,\n",
    "            r_raw,\n",
    "            v_raw,\n",
    "            r_scaled,\n",
    "            v_scaled,\n",
    "            s_scaled,\n",
    "            so_scaled,\n",
    "            mdd_scaled\n",
    "        ])\n",
    "        out_user_data.append([\n",
    "            fund,\n",
    "            r_raw,\n",
    "            v_raw,\n",
    "            r_scaled,\n",
    "            v_scaled,\n",
    "            s_scaled,\n",
    "            so_scaled,\n",
    "            mdd_scaled\n",
    "        ])\n",
    "\n",
    "    r_ew_raw, v_ew_raw, _, _, _ = out_ew_stats_raw\n",
    "    r_ew_scaled, v_ew_scaled, s_ew_scaled, so_ew_scaled, mdd_ew_scaled = out_ew_stats_scaled\n",
    "    out_eq_data.append([\n",
    "        'Equal-Weight Portfolio',\n",
    "        r_ew_raw,\n",
    "        v_ew_raw,\n",
    "        r_ew_scaled,\n",
    "        v_ew_scaled,\n",
    "        s_ew_scaled,\n",
    "        so_ew_scaled,\n",
    "        mdd_ew_scaled\n",
    "    ])\n",
    "\n",
    "    r_user_raw, v_user_raw, _, _, _ = out_user_stats_raw\n",
    "    r_user_scaled, v_user_scaled, s_user_scaled, so_user_scaled, mdd_user_scaled = out_user_stats_scaled\n",
    "    out_user_data.append([\n",
    "        'User-Weighted Portfolio',\n",
    "        r_user_raw,\n",
    "        v_user_raw,\n",
    "        r_user_scaled,\n",
    "        v_user_scaled,\n",
    "        s_user_scaled,\n",
    "        so_user_scaled,\n",
    "        mdd_user_scaled\n",
    "    ])\n",
    "\n",
    "    out_eq_df = pd.DataFrame(\n",
    "        out_eq_data,\n",
    "        columns=['Fund', 'RetBefore(%)', 'VolBefore(%)', 'RetAfter(%)', 'VolAfter(%)', 'Sharpe(After)', 'Sortino(After)', 'MaxDD(After)(%)']\n",
    "    )\n",
    "    out_user_df = pd.DataFrame(\n",
    "        out_user_data,\n",
    "        columns=['Fund', 'RetBefore(%)', 'VolBefore(%)', 'RetAfter(%)', 'VolAfter(%)', 'Sharpe(After)', 'Sortino(After)', 'MaxDD(After)(%)']\n",
    "    )\n",
    "\n",
    "    writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "\n",
    "    # In-Sample Sheet\n",
    "    in_eq_df.to_excel(writer, sheet_name='In-Sample', startrow=0, index=False)\n",
    "    in_user_df.to_excel(writer, sheet_name='In-Sample', startrow=len(in_eq_df)+3, index=False)\n",
    "\n",
    "    # Out-of-Sample Sheet\n",
    "    out_eq_df.to_excel(writer, sheet_name='Out-of-Sample', startrow=0, index=False)\n",
    "    out_user_df.to_excel(writer, sheet_name='Out-of-Sample', startrow=len(out_eq_df)+3, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    pct_format = workbook.add_format({'num_format': '0.0%'})\n",
    "    decimal_format = workbook.add_format({'num_format': '0.00'})  # for non-percent columns\n",
    "    bold_format = workbook.add_format({'bold': True})\n",
    "\n",
    "    # Format In-Sample\n",
    "    in_sample_ws = writer.sheets['In-Sample']\n",
    "    in_sample_ws.set_column(0, 0, 28)  # Fund column\n",
    "    in_sample_ws.set_column(1, 2, 8, pct_format)\n",
    "    in_sample_ws.set_column(3, 4, 8, decimal_format)\n",
    "    in_sample_ws.set_column(5, 5, 8, pct_format)\n",
    "    \n",
    "    # Bold headers\n",
    "    for colx in range(in_eq_df.shape[1]):\n",
    "        in_sample_ws.write(0, colx, in_eq_df.columns[colx], bold_format)\n",
    "    for colx in range(in_user_df.shape[1]):\n",
    "        in_sample_ws.write(len(in_eq_df)+3, colx, in_user_df.columns[colx], bold_format)\n",
    "\n",
    "    # Format Out-of-Sample\n",
    "    out_sample_ws = writer.sheets['Out-of-Sample']\n",
    "    out_sample_ws.set_column(0, 0, 28)\n",
    "    out_sample_ws.set_column(1, 7, 15, pct_format)\n",
    "    for colx in range(out_eq_df.shape[1]):\n",
    "        out_sample_ws.write(0, colx, out_eq_df.columns[colx], bold_format)\n",
    "    for colx in range(out_user_df.shape[1]):\n",
    "        out_sample_ws.write(len(out_eq_df)+3, colx, out_user_df.columns[colx], bold_format)\n",
    "\n",
    "    writer.close()\n",
    "    logging.info(f\"Exported analysis to {output_filename} successfully.\")\n",
    "    print(f\"Excel file created: {output_filename}\")\n",
    "\n",
    "print(\"export_to_excel function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2c6d",
   "metadata": {},
   "source": [
    "## 8. Demo Run\n",
    "The `demo_run()` function creates a small dummy dataset, runs the analysis, and exports the results to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89721c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def demo_run():\n",
    "    \"\"\"\n",
    "    Create a small dummy dataset, run analysis, export results.\n",
    "    \"\"\"\n",
    "    # Create monthly date range\n",
    "    rng = pd.date_range(start='2003-01-01', end='2010-12-01', freq='MS')\n",
    "    df_demo = pd.DataFrame({'Date': rng})\n",
    "\n",
    "    np.random.seed(42)\n",
    "    rf_values = np.random.normal(loc=0.002, scale=0.0001, size=len(rng))\n",
    "    df_demo['RF'] = rf_values\n",
    "\n",
    "    # Random funds with missing data\n",
    "    for i in range(1, 6):\n",
    "        fund_name = f\"Fund_{i}\"\n",
    "        mean_r = 0.01 * i / 10.0\n",
    "        stdev_r = 0.02 * (i / 5.0)\n",
    "        rets = np.random.normal(loc=mean_r, scale=stdev_r, size=len(rng))\n",
    "\n",
    "        # Introduce random short or long gaps\n",
    "        if i == 3:\n",
    "            missing_idx = np.random.choice(len(rng), 2, replace=False)\n",
    "            for idx in missing_idx:\n",
    "                rets[idx] = np.nan\n",
    "        if i == 4:\n",
    "            rets[10:13] = np.nan  # 3 consecutive -> exclude\n",
    "\n",
    "        df_demo[fund_name] = rets\n",
    "\n",
    "    # Shuffle rows to test sorting\n",
    "    df_demo = df_demo.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    " \n",
    "    results = run_analysis(\n",
    "        df_demo,\n",
    "        in_start='2003-01', in_end='2005-12',\n",
    "        out_start='2006-01', out_end='2010-12',\n",
    "        target_vol=0.10,\n",
    "        monthly_cost=0.002,\n",
    "        selection_mode='all',\n",
    "        random_n=2\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    if results is not None:\n",
    "        export_to_excel(results, \"DemoAnalysisOutput.xlsx\")\n",
    "        print(\"Demo run complete.\")\n",
    "\n",
    "print(\"demo_run function ready. Call 'demo_run()' to test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b7c730-225c-4c69-9dbf-d1ec9971a26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d65155741c4205a9fd8566d9388150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='2003-01', description='In-Sample Start:'), Text(value='2005-12', description='In-Sa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86311365b69b4b95b6a83fc3ac7cde41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (C) Wire the button and display\n",
    "apply_button.on_click(on_apply_clicked)\n",
    "display(ui_inputs, output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794206",
   "metadata": {},
   "source": [
    "### Using This Notebook\n",
    "1. Run all cells.\n",
    "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
    "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
    "4. For interactive selection, do:\n",
    "   ```python\n",
    "   display(ui_inputs)\n",
    "   ```\n",
    "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
    "5. For custom weights, call:\n",
    "   ```python\n",
    "   my_weights = get_custom_weights(selected_funds)\n",
    "   ```\n",
    "   Then pass `my_weights` into your logic.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
