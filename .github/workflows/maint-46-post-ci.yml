name: Maint 46 Post CI

'on':
  workflow_run:
    workflows: ["Gate"]
    types: [completed]

concurrency:
  group: >-
    maint-46-post-ci-${{
      (
        github.event.workflow_run.pull_requests &&
        github.event.workflow_run.pull_requests[0] &&
        github.event.workflow_run.pull_requests[0].number
      ) ||
      github.event.workflow_run.head_sha ||
      github.event.workflow_run.id ||
      github.run_id
    }}
  cancel-in-progress: true

permissions:
  contents: write
  pull-requests: write
  checks: read
  actions: read
  issues: write
  statuses: write

env:
  COMMIT_PREFIX: ${{ vars.AUTOFIX_COMMIT_PREFIX || 'chore(autofix):' }}

jobs:
  summarize:
    if: >
      github.event.workflow_run.event == 'pull_request' &&
      github.event.workflow_run.head_sha != ''
    runs-on: ubuntu-latest
    outputs:
      summary_body: ${{ steps.prep.outputs.body }}
      head_sha: ${{ steps.gather.outputs.head_sha }}
      runs: ${{ steps.gather.outputs.runs }}
      coverage_stats: ${{ steps.coverage_stats.outputs.stats_json }}
      coverage_section: ${{ steps.coverage_summary.outputs.body }}
      coverage_delta: ${{ steps.coverage_stats.outputs.delta_json }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Discover workflow runs for head SHA
        id: gather
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const path = require('path');
            const { discoverWorkflowRuns } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await discoverWorkflowRuns({ github, context, core });
      - name: Download coverage summary
        if: ${{ steps.gather.outputs.ci_run_id }}
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: gate-coverage-summary
          run-id: ${{ steps.gather.outputs.ci_run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          path: artifacts/coverage-summary
      - name: Download coverage trend
        if: ${{ steps.gather.outputs.ci_run_id }}
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          run-id: ${{ steps.gather.outputs.ci_run_id }}
          pattern: '*'
          merge-multiple: true
          path: summary_artifacts
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download coverage payloads
        if: ${{ steps.gather.outputs.ci_run_id }}
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          run-id: ${{ steps.gather.outputs.ci_run_id }}
          pattern: 'gate-coverage-3.*'
          path: summary_artifacts/coverage-runtimes
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Load coverage summary snippet
        id: coverage_summary
        run: |
          set -euo pipefail
          mkdir -p summary_artifacts
          python <<'PY'
          import os
          from pathlib import Path

          output_path = os.environ.get('GITHUB_OUTPUT')
          root = Path('summary_artifacts')
          search_roots = [root, Path('artifacts')]

          summary_path: Path | None = None
          candidates = []
          for base in search_roots:
              if not base.exists():
                  continue
              candidates.extend(base.rglob('coverage-summary.md'))
          if candidates:
              # Prefer files in earlier search_roots; if multiple, pick the first found
              summary_path = candidates[0]

          if summary_path is None:
              print('No coverage summary markdown found; continuing without it.')
          else:
              text = summary_path.read_text(encoding='utf-8')
              dest = root / 'coverage-summary.md'
              dest.write_text(text, encoding='utf-8')
              if output_path:
                  with Path(output_path).open('a', encoding='utf-8') as handle:
                      handle.write('body<<EOF\n')
                      handle.write(text)
                      if not text.endswith('\n'):
                          handle.write('\n')
                      handle.write('EOF\n')
              print(f'Embedded coverage summary from {summary_path}')
          PY

      - name: Compute coverage stats
        id: coverage_stats
        uses: actions/github-script@v7
        with:
          script: |
            const { computeCoverageStats } = require(`${process.env.GITHUB_WORKSPACE}/.github/scripts/coverage-normalize`);
            const result = await computeCoverageStats({ core });
            core.setOutput('stats_json', JSON.stringify(result.stats));
            if (result.deltaPayload) {
              core.setOutput('delta_json', JSON.stringify(result.deltaPayload));
            }
      - name: Prepare summary body
        id: prep
        run: |
          python tools/post_ci_summary.py
        env:
          RUNS_JSON: ${{ steps.gather.outputs.runs }}
          HEAD_SHA: ${{ steps.gather.outputs.head_sha }}
          COVERAGE_SECTION: ${{ steps.coverage_summary.outputs.body }}
          COVERAGE_STATS: ${{ steps.coverage_stats.outputs.stats_json }}
          COVERAGE_DELTA: ${{ steps.coverage_stats.outputs.delta_json }}
          REQUIRED_JOB_GROUPS_JSON: ${{ env.REQUIRED_JOB_GROUPS_JSON }}
      - name: Persist summary preview
        run: |
          mkdir -p summary_artifacts
          if [ -n "${SUMMARY_BODY}" ]; then
            printf '%s\n' "${SUMMARY_BODY}" > summary_artifacts/summary_preview.md
          else
            echo "Summary body empty; skipping preview persistence."
          fi
        env:
          SUMMARY_BODY: ${{ steps.prep.outputs.body }}
      - name: Upload coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-summary
          path: |
            summary_artifacts/coverage-summary.md
            coverage-stats.json
            summary_artifacts/summary_preview.md
          if-no-files-found: ignore
      - name: Publish run summary
        run: |
          python <<'PY'
          import os
          import re

          summary_path = os.environ.get("GITHUB_STEP_SUMMARY")
          raw_body = os.environ.get("SUMMARY_BODY") or ""
          body = raw_body.strip()
          is_empty = False
          if not body:
              is_empty = True
              body = "## Automated Status Summary\nAutomated status summary was empty."

          if not summary_path:
              raise SystemExit("GITHUB_STEP_SUMMARY environment variable is not set")

          existing = ""
          if os.path.exists(summary_path):
              with open(summary_path, "r", encoding="utf-8") as handle:
                  existing = handle.read()

          marker = "## Automated Status Summary"
          pattern = re.compile(rf"\n?{re.escape(marker)}.*?(?=\n## |\Z)", re.DOTALL)
          cleaned = pattern.sub("", existing).strip()

          parts = [segment for segment in (cleaned, body) if segment]

          with open(summary_path, "w", encoding="utf-8") as handle:
              if parts:
                  handle.write("\n\n".join(parts))
                  handle.write("\n")

          if is_empty:
              print("Automated status summary was empty.")
          PY
        env:
          SUMMARY_BODY: ${{ steps.prep.outputs.body }}

      - name: Propagate Gate commit status
        if: ${{ steps.gather.outputs.head_sha != '' }}
        uses: actions/github-script@v7
        env:
          HEAD_SHA: ${{ steps.gather.outputs.head_sha }}
          RUN_CONCLUSION: ${{ github.event.workflow_run.conclusion || '' }}
          RUN_STATUS: ${{ github.event.workflow_run.status || '' }}
          GATE_RUN_URL: ${{ github.event.workflow_run.html_url || '' }}
        with:
          script: |
            const path = require('path');
            const { propagateGateCommitStatus } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await propagateGateCommitStatus({ github, context, core });

  context:
    name: Gather context
    if: >
      github.event.workflow_run.event == 'pull_request' &&
      github.event.workflow_run.head_sha != ''
    runs-on: ubuntu-latest
    outputs:
      found: ${{ steps.info.outputs.found }}
      pr: ${{ steps.info.outputs.pr }}
      head_ref: ${{ steps.info.outputs.head_ref }}
      head_sha: ${{ steps.info.outputs.head_sha }}
      title: ${{ steps.info.outputs.title }}
      same_repo: ${{ steps.info.outputs.same_repo }}
      loop_skip: ${{ steps.info.outputs.loop_skip }}
      small_eligible: ${{ steps.info.outputs.small_eligible }}
      file_count: ${{ steps.info.outputs.file_count }}
      change_count: ${{ steps.info.outputs.change_count }}
      safe_paths: ${{ steps.info.outputs.safe_paths }}
      unsafe_paths: ${{ steps.info.outputs.unsafe_paths }}
      safe_file_count: ${{ steps.info.outputs.safe_file_count }}
      unsafe_file_count: ${{ steps.info.outputs.unsafe_file_count }}
      safe_change_count: ${{ steps.info.outputs.safe_change_count }}
      unsafe_change_count: ${{ steps.info.outputs.unsafe_change_count }}
      all_safe: ${{ steps.info.outputs.all_safe }}
      has_opt_in: ${{ steps.info.outputs.has_opt_in }}
      has_patch_label: ${{ steps.info.outputs.has_patch_label }}
      labels_json: ${{ steps.info.outputs.labels_json }}
      is_draft: ${{ steps.info.outputs.is_draft }}
      run_conclusion: ${{ steps.info.outputs.run_conclusion }}
      actor: ${{ steps.info.outputs.actor }}
      head_subject: ${{ steps.info.outputs.head_subject }}
      failure_tracker_skip: ${{ steps.info.outputs.failure_tracker_skip }}
      pat_available: ${{ steps.pat.outputs.available }}
      trivial_failure: ${{ steps.failure.outputs.trivial }}
      failing_jobs: ${{ steps.failure.outputs.names }}
      failing_count: ${{ steps.failure.outputs.count }}
      failure_incomplete: ${{ steps.failure.outputs.incomplete }}
      failure_has_jobs: ${{ steps.failure.outputs.has_jobs }}
      autofix_skip: ${{ steps.autofix_guard.outputs.skip }}
      autofix_skip_reason: ${{ steps.autofix_guard.outputs.reason }}
    env:
      AUTOFIX_OPT_IN_LABEL: ${{ vars.AUTOFIX_OPT_IN_LABEL || 'autofix:clean' }}
      AUTOFIX_PATCH_LABEL: ${{ vars.AUTOFIX_PATCH_LABEL || 'autofix:patch' }}
      AUTOFIX_TRIVIAL_KEYWORDS: ${{ vars.AUTOFIX_TRIVIAL_KEYWORDS || 'lint,format,style,doc,ruff,mypy,type,black,isort,label,test' }}
      AUTOFIX_MAX_FILES: ${{ vars.AUTOFIX_MAX_FILES || '40' }}
      AUTOFIX_MAX_CHANGES: ${{ vars.AUTOFIX_MAX_CHANGES || '800' }}
    steps:
      - name: Check PAT availability
        id: pat
        shell: bash
        run: |
          if [ -z "${{ secrets.SERVICE_BOT_PAT }}" ]; then
            echo "available=false" >> "$GITHUB_OUTPUT"
          else
            echo "available=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Resolve workflow context
        id: info
        uses: actions/github-script@v7
        with:
          script: |
            const path = require('path');
            const { resolveAutofixContext } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await resolveAutofixContext({ github, context, core });

      - name: Inspect failing jobs
        id: failure
        uses: actions/github-script@v7
        with:
          script: |
            const path = require('path');
            const { inspectFailingJobs } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await inspectFailingJobs({ github, context, core });

      - name: Evaluate autofix rerun guard
        id: autofix_guard
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.info.outputs.pr }}
          HEAD_SHA: ${{ steps.info.outputs.head_sha }}
          SAME_REPO: ${{ steps.info.outputs.same_repo }}
          HAS_PATCH_LABEL: ${{ steps.info.outputs.has_patch_label }}
        with:
          github-token: ${{ secrets.SERVICE_BOT_PAT || github.token }}
          script: |
            const path = require('path');
            const { evaluateAutofixRerunGuard } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await evaluateAutofixRerunGuard({ github, context, core });

      - name: Log autofix candidate summary
        if: steps.info.outputs.found == 'true'
        shell: bash
        env:
          SAFE_COUNT: ${{ steps.info.outputs.safe_file_count }}
          UNSAFE_COUNT: ${{ steps.info.outputs.unsafe_file_count }}
          SAFE_PATHS: ${{ steps.info.outputs.safe_paths }}
          UNSAFE_PATHS: ${{ steps.info.outputs.unsafe_paths }}
        run: |
          set -euo pipefail
          echo "Safe autofix file count: ${SAFE_COUNT:-0}"
          echo "Unsafe file count: ${UNSAFE_COUNT:-0}"
          echo "--- Safe paths ---"
          if [ -n "${SAFE_PATHS}" ]; then
            printf '%s\n' "${SAFE_PATHS}"
          else
            echo "(none)"
          fi
          echo "--- Skipped paths ---"
          if [ -n "${UNSAFE_PATHS}" ]; then
            printf '%s\n' "${UNSAFE_PATHS}"
          else
            echo "(none)"
          fi

  small-fixes:
    name: Small hygiene fixes
    needs: context
    if: |
      needs.context.outputs.found == 'true' &&
      needs.context.outputs.loop_skip != 'true' &&
      needs.context.outputs.small_eligible == 'true' &&
      needs.context.outputs.has_opt_in == 'true' &&
      needs.context.outputs.autofix_skip != 'true' &&
      (
        github.event.workflow_run.conclusion == 'success' ||
        (
          github.event.workflow_run.conclusion == 'failure' &&
          needs.context.outputs.trivial_failure == 'true' &&
          needs.context.outputs.failure_incomplete != 'true' &&
          needs.context.outputs.failure_has_jobs == 'true'
        )
      ) &&
      github.event.workflow_run.conclusion != 'cancelled' &&
      github.event.workflow_run.conclusion != 'timed_out' &&
      (needs.context.outputs.same_repo != 'true' || needs.context.outputs.pat_available == 'true')
    uses: ./.github/workflows/reusable-18-autofix.yml
    with:
      pr_number: ${{ fromJSON(needs.context.outputs.pr) }}
      pr_head_ref: ${{ needs.context.outputs.head_ref }}
      pr_title: ${{ needs.context.outputs.title }}
      pr_is_draft: ${{ needs.context.outputs.is_draft == 'true' }}
      pr_labels_json: ${{ needs.context.outputs.labels_json }}
      same_repo: ${{ needs.context.outputs.same_repo == 'true' }}
      caller_actor: ${{ needs.context.outputs.actor }}
      opt_in_label: ${{ vars.AUTOFIX_OPT_IN_LABEL || 'autofix:clean' }}
      clean_label: ${{ vars.AUTOFIX_OPT_IN_LABEL || 'autofix:clean' }}
      commit_prefix: ${{ vars.AUTOFIX_COMMIT_PREFIX || 'chore(autofix):' }}
      applied_label: ${{ vars.AUTOFIX_APPLIED_LABEL || 'autofix:applied' }}
      patch_label: ${{ vars.AUTOFIX_PATCH_LABEL || 'autofix:patch' }}
      trigger_conclusion: ${{ github.event.workflow_run.conclusion }}
      trigger_class: ${{ github.event.workflow_run.conclusion == 'failure' && needs.context.outputs.trivial_failure == 'true' && 'trivial-failure' || github.event.workflow_run.conclusion }}
      trigger_reason: ${{ github.event.workflow_run.conclusion == 'failure' && needs.context.outputs.trivial_failure == 'true' && 'trivial-failure' || github.event.workflow_run.conclusion }}
      trigger_head: ${{ needs.context.outputs.head_sha }}
      dry_run: ${{ needs.context.outputs.same_repo != 'true' }}
      allowed_file_globs: |
        src/**
        tests/**
    secrets: inherit

  fix-failing-checks:
    name: Fix failing checks
    needs: context
    if: |
      needs.context.outputs.found == 'true' &&
      needs.context.outputs.loop_skip != 'true' &&
      needs.context.outputs.trivial_failure == 'true' &&
      (needs.context.outputs.same_repo != 'true' || needs.context.outputs.pat_available == 'true')
    runs-on: ubuntu-latest
    env:
      APPLIED_LABEL: ${{ vars.AUTOFIX_APPLIED_LABEL || 'autofix:applied' }}
      AUTOFIX_TRIGGER_CONCLUSION: ${{ github.event.workflow_run.conclusion }}
      AUTOFIX_TRIGGER_CLASS: ${{ github.event.workflow_run.conclusion == 'failure' && needs.context.outputs.trivial_failure == 'true' && 'trivial-failure' || github.event.workflow_run.conclusion }}
      AUTOFIX_TRIGGER_PR_HEAD: ${{ needs.context.outputs.head_sha }}
      AUTOFIX_TRIGGER_REASON: ${{ github.event.workflow_run.conclusion == 'failure' && needs.context.outputs.trivial_failure == 'true' && 'trivial-failure' || github.event.workflow_run.conclusion }}
    outputs:
      ran: ${{ steps.capture.outputs.ran }}
      changed: ${{ steps.capture.outputs.changed }}
      remaining: ${{ steps.capture.outputs.remaining }}
      new: ${{ steps.capture.outputs.new }}
      patch_available: ${{ steps.capture.outputs.patch_available }}
      skip_reason: ${{ steps.capture.outputs.skip_reason }}
      trigger_conclusion: ${{ steps.capture.outputs.trigger_conclusion }}
      trigger_class: ${{ steps.capture.outputs.trigger_class }}
      trigger_reason: ${{ steps.capture.outputs.trigger_reason }}
      trigger_head: ${{ steps.capture.outputs.trigger_head }}
    steps:
      - name: Checkout workflow repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Load formatter pins
        run: |
          set -euo pipefail
          pin_file=".github/workflows/autofix-versions.env"
          if [ ! -f "$pin_file" ]; then
            echo "::error::Missing $pin_file" >&2
            exit 1
          fi
          # shellcheck source=/dev/null
          source "$pin_file"
          for var in BLACK_VERSION RUFF_VERSION ISORT_VERSION DOCFORMATTER_VERSION MYPY_VERSION; do
            if [ -z "${!var:-}" ]; then
              echo "::error::Missing ${var} in $pin_file" >&2
              exit 1
            fi
          done
          cat "$pin_file" >> "$GITHUB_ENV"
      - name: Autofix, commit, and push (composite)
        id: autofix
        uses: ./.github/actions/autofix-commit-push
        with:
          head_ref: ${{ needs.context.outputs.head_ref }}
          token: ${{ needs.context.outputs.same_repo == 'true' && secrets.SERVICE_BOT_PAT || github.token }}
          same_repo: ${{ needs.context.outputs.same_repo }}
          commit_message: "${COMMIT_PREFIX} fix failing checks"
          pr: ${{ needs.context.outputs.pr }}
      - name: Label PR (autofix applied)
        if: steps.autofix.outputs.changed == 'true' && needs.context.outputs.same_repo == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.SERVICE_BOT_PAT || github.token }}
          script: |
            const pr = Number('${{ needs.context.outputs.pr }}');
            const label = process.env.APPLIED_LABEL || 'autofix:applied';
            try {
              await github.rest.issues.addLabels({ owner: context.repo.owner, repo: context.repo.repo, issue_number: pr, labels: [label] });
            } catch (error) {
              core.warning(`Failed to add label: ${error.message}`);
            }

      - name: Tag PR for manual review
        if: steps.autofix.outputs.changed != 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.SERVICE_BOT_PAT || github.token }}
          script: |
            const pr = Number('${{ needs.context.outputs.pr }}');
            const label = 'needs-autofix-review';
            try {
              await github.rest.issues.addLabels({ owner: context.repo.owner, repo: context.repo.repo, issue_number: pr, labels: [label] });
            } catch (error) {
              core.warning(`Failed to add label: ${error.message}`);
            }

      - name: Update residual history (same-repo)
        if: |
          needs.context.outputs.same_repo == 'true' &&
          hashFiles('.github/actions/update-residual-history/action.yml') != ''
        uses: ./.github/actions/update-residual-history

      - name: Upload autofix history artifact (same-repo)
        if: needs.context.outputs.same_repo == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: autofix-history-pr-${{ needs.context.outputs.pr }}
          path: ci/autofix/history.json
          if-no-files-found: ignore

      - name: Generate trend sparkline (same-repo)
        if: needs.context.outputs.same_repo == 'true'
        shell: bash
        run: |
          if [ -f scripts/generate_residual_trend.py ]; then python scripts/generate_residual_trend.py || true; fi
          if [ -f ci/autofix/trend.json ]; then echo "Trend:"; cat ci/autofix/trend.json; fi

      - name: Emit JSON report
        if: always()
        shell: bash
        env:
          PR_NUMBER: ${{ needs.context.outputs.pr }}
          CHANGED: ${{ steps.autofix.outputs.changed }}
          REMAINING: ${{ steps.autofix.outputs.remaining_issues }}
          NEW_ISSUES: ${{ steps.autofix.outputs.new_issues }}
        run: |
          set -euo pipefail
          ts=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          if [ -f autofix_report_enriched.json ]; then
            if python scripts/merge_autofix_report.py \
              --input autofix_report_enriched.json \
              --output autofix_report.json \
              --pr-number "${PR_NUMBER}" \
              --timestamp "${ts}"; then
              :
            else
              printf '{\n  "changed": "%s",\n  "remaining_issues": "%s",\n  "new_issues": "%s",\n  "pull_request": "%s",\n  "timestamp_utc": "%s"\n}\n' \
                "${CHANGED}" \
                "${REMAINING}" \
                "${NEW_ISSUES}" \
                "${PR_NUMBER}" \
                "${ts}" > autofix_report.json
            fi
          else
            printf '{\n  "changed": "%s",\n  "remaining_issues": "%s",\n  "new_issues": "%s",\n  "pull_request": "%s",\n  "timestamp_utc": "%s"\n}\n' \
              "${CHANGED}" \
              "${REMAINING}" \
              "${NEW_ISSUES}" \
              "${PR_NUMBER}" \
              "${ts}" > autofix_report.json
          fi
          echo "Enriched report ready."

      - name: Upload JSON report
        uses: actions/upload-artifact@v4
        with:
          name: autofix-report-pr-${{ needs.context.outputs.pr }}
          path: autofix_report.json

      - name: Summary
        if: always()
        run: |
          {
            echo "### Fix failing checks"
            echo "PR: #${{ needs.context.outputs.pr }}"
            echo "Changes applied: ${{ steps.autofix.outputs.changed }}"
            echo "Remaining ruff issues: ${{ steps.autofix.outputs.remaining_issues }}"
            echo "New ruff issues: ${{ steps.autofix.outputs.new_issues }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Capture job summary
        id: capture
        if: always()
        run: |
          set -euo pipefail
          changed="${AUTOFIX_CHANGED:-false}"
          remaining="${AUTOFIX_REMAINING:-0}"
          new_issues="${AUTOFIX_NEW:-0}"
          same_repo="${SAME_REPO:-false}"
          ran="true"
          patch="false"
          if [ "${changed}" = "true" ] && [ "${same_repo}" != "true" ]; then
            patch="true"
          fi
          {
            echo "ran=${ran}"
            echo "changed=${changed:-false}"
            echo "remaining=${remaining:-0}"
            echo "new=${new_issues:-0}"
            echo "patch_available=${patch}"
            echo "skip_reason="
            echo "trigger_conclusion=${AUTOFIX_TRIGGER_CONCLUSION:-}"
            echo "trigger_class=${AUTOFIX_TRIGGER_CLASS:-}"
            echo "trigger_reason=${AUTOFIX_TRIGGER_REASON:-}"
            echo "trigger_head=${AUTOFIX_TRIGGER_PR_HEAD:-}"
          } >> "$GITHUB_OUTPUT"
        env:
          AUTOFIX_CHANGED: ${{ steps.autofix.outputs.changed }}
          AUTOFIX_REMAINING: ${{ steps.autofix.outputs.remaining_issues }}
          AUTOFIX_NEW: ${{ steps.autofix.outputs.new_issues }}
          SAME_REPO: ${{ needs.context.outputs.same_repo }}
          AUTOFIX_TRIGGER_CONCLUSION: ${{ env.AUTOFIX_TRIGGER_CONCLUSION }}
          AUTOFIX_TRIGGER_CLASS: ${{ env.AUTOFIX_TRIGGER_CLASS }}
          AUTOFIX_TRIGGER_REASON: ${{ env.AUTOFIX_TRIGGER_REASON }}
          AUTOFIX_TRIGGER_PR_HEAD: ${{ env.AUTOFIX_TRIGGER_PR_HEAD }}

  post-comment:
    name: Publish consolidated status
    needs:
      - summarize
      - context
      - small-fixes
      - fix-failing-checks
    if: >
      always() &&
      needs.context.result == 'success' &&
      needs.context.outputs.found == 'true' &&
      needs.context.outputs.failure_tracker_skip != 'true' &&
      needs.context.outputs.failure_incomplete != 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Write summary body
        run: |
          cat <<'EOF' > summary_body.md
          ${{ needs.summarize.outputs.summary_body }}
          EOF

      - name: Locate patch artifact
        id: patch_artifact
        if: >-
          contains(toJSON(needs['small-fixes'].outputs), '"patch_available":"true"') ||
          needs.fix-failing-checks.outputs.patch_available == 'true'
        uses: actions/github-script@v7
        env:
          RUN_ID: ${{ github.run_id }}
          PR_NUMBER: ${{ needs.context.outputs.pr }}
        with:
          github-token: ${{ secrets.SERVICE_BOT_PAT || github.token }}
          result-encoding: string
          script: |
            const runId = process.env.RUN_ID;
            const prNumber = process.env.PR_NUMBER;
            if (!runId || !prNumber) {
              let missing = [];
              if (!runId) missing.push('run ID');
              if (!prNumber) missing.push('PR number');
              core.info(`Missing ${missing.join(' and ')} for patch lookup.`);
              return '';
            }
            const targetName = `autofix-patch-pr-${prNumber}`;
            const artifacts = await github.paginate(
              github.rest.actions.listWorkflowRunArtifacts,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: Number(runId),
                per_page: 100,
              },
            );
            const match = artifacts.find(artifact => artifact && artifact.name === targetName);
            if (!match) {
              core.info(`No patch artifact found for ${targetName}. This is expected if no patch was generated for this PR/run. If a patch was expected, this may indicate an error or misconfiguration.`);
              return '';
            }
            return `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${runId}/artifacts/${match.id}`;

      - name: Prepare consolidated comment
        id: prepare
        env:
          SUMMARY_PATH: summary_body.md
          HEAD_SHA: ${{ needs.summarize.outputs.head_sha }}
          PR_NUMBER: ${{ needs.context.outputs.pr }}
          PATCH_URL: ${{ steps.patch_artifact.outputs.result }}
          SMALL_RESULT: ${{ needs['small-fixes'].result }}
          SMALL_OUTPUTS_JSON: ${{ toJSON(needs['small-fixes'].outputs) }}
          SMALL_LABEL_PRESENT: ${{ needs.context.outputs.has_opt_in }}
          SMALL_SKIP_CONTEXT: ${{ needs.context.outputs.autofix_skip_reason }}
          FIX_RESULT: ${{ needs.fix-failing-checks.result }}
          FIX_OUTPUTS_JSON: ${{ toJSON(needs.fix-failing-checks.outputs) }}
          FAIL_JOB_NAMES: ${{ needs.context.outputs.failing_jobs }}
        run: |
          python <<'PY'
          from __future__ import annotations

          import json
          import os
          import pathlib
          import re
          from typing import Any, Dict, List

          summary_path = pathlib.Path(os.environ.get("SUMMARY_PATH", "summary_body.md"))
          summary_text = summary_path.read_text(encoding="utf-8") if summary_path.exists() else ""
          summary_text = summary_text.strip()

          footer = "_Updated automatically; will refresh on subsequent CI/Docker completions._"
          prefix = summary_text
          suffix = ""
          if footer and footer in summary_text:
              parts = summary_text.split(footer, 1)
              prefix = parts[0].rstrip()
              suffix = (footer + parts[1]).strip()

          def load_outputs(prefix: str) -> Dict[str, Any]:
              raw = os.environ.get(f"{prefix}_OUTPUTS_JSON") or ""
              if not raw:
                  return {}
              try:
                  parsed = json.loads(raw)
              except json.JSONDecodeError:
                  return {}
              return parsed if isinstance(parsed, dict) else {}

          outputs_cache = {key: load_outputs(key) for key in ("SMALL", "FIX")}
          env = os.environ

          def parse_bool(value: Any) -> bool:
              if isinstance(value, bool):
                  return value
              if value is None:
                  return False
              return str(value).strip().lower() == "true"

          def parse_int(value: Any) -> int:
              if value is None:
                  return 0
              if isinstance(value, (int, float)):
                  return int(value)
              text = str(value).strip()
              if not text:
                  return 0
              try:
                  return int(float(text))
              except ValueError:
                  return 0

          def clean_reason(reason: str | None) -> str:
              if not reason:
                  return ""
              value = reason.strip()
              if not value:
                  return ""
              mapping = {
                  "duplicate-patch": "duplicate patch",
                  "not-applicable": "not applicable",
              }
              return mapping.get(value.lower(), re.sub(r"[-_]+", " ", value))

          server = os.environ.get("GITHUB_SERVER_URL", "https://github.com").rstrip("/")
          repository = os.environ.get("GITHUB_REPOSITORY", "").strip("/")
          run_id = os.environ.get("GITHUB_RUN_ID", "").strip()
          artifact_url = ""
          if repository and run_id:
              artifact_url = f"{server}/{repository}/actions/runs/{run_id}?check_suite_focus=true#artifacts"

          pr_number = os.environ.get("PR_NUMBER", "").strip()
          head_sha = os.environ.get("HEAD_SHA", "").strip()
          head_token = head_sha[:12] if head_sha else ""
          anchor_fields: list[str] = []
          if pr_number:
              anchor_fields.append(f"pr={pr_number}")
          if head_token:
              anchor_fields.append(f"head={head_token}")
          if not anchor_fields:
              anchor_fields.append("anchor")
          anchor_marker = f"<!-- maint-46-post-ci: {' '.join(anchor_fields)} -->"
          legacy_marker = "<!-- maint-46-post-ci: DO NOT EDIT -->"

          def build_entry(prefix_key: str, title: str, result: str | None) -> Dict[str, Any]:
              output_data = outputs_cache.get(prefix_key, {})
              ran = parse_bool(output_data.get("ran"))
              changed = parse_bool(output_data.get("changed"))
              remaining = parse_int(output_data.get("remaining"))
              new = parse_int(output_data.get("new"))
              patch = parse_bool(output_data.get("patch_available"))
              skip_raw = output_data.get("skip_reason")
              trigger_conclusion = str(output_data.get("trigger_conclusion") or "").strip()
              trigger_class = str(output_data.get("trigger_class") or "").strip()
              trigger_reason = str(output_data.get("trigger_reason") or "").strip()
              trigger_head = str(output_data.get("trigger_head") or "").strip()
              skip_reason = clean_reason(skip_raw)
              job_result = (result or "").lower()
              if job_result == "skipped" and not skip_reason and not ran:
                  skip_reason = "not applicable"
              if prefix_key == "SMALL":
                  label_present = parse_bool(env.get("SMALL_LABEL_PRESENT"))
                  if not skip_reason and not label_present:
                      skip_reason = "requires `autofix` label"
                  if not skip_reason:
                      context_skip = env.get("SMALL_SKIP_CONTEXT")
                      if context_skip:
                          skip_reason = context_skip
              status: str
              if ran:
                  status = "✅ completed" if changed else "✅ no changes"
              else:
                  status = "⏭️ skipped"
                  if skip_reason:
                      status = f"{status} ({skip_reason})"
              notes: List[str] = []
              if patch and pr_number:
                  if artifact_url:
                      notes.append(
                          f"Patch artifact: [autofix-patch-pr-{pr_number}]({artifact_url})"
                      )
                  else:
                      notes.append(f"Patch artifact: `autofix-patch-pr-{pr_number}`")
              if trigger_conclusion:
                  trigger_label = trigger_conclusion
                  if trigger_class and trigger_class != trigger_conclusion:
                      trigger_label = f"{trigger_conclusion} ({trigger_class})"
                  if trigger_reason and trigger_reason not in {trigger_conclusion, trigger_class}:
                      trigger_label = f"{trigger_label}; reason={trigger_reason}"
                  notes.append(f"Trigger: {trigger_label}")
              if trigger_head:
                  notes.append(f"Head: `{trigger_head}`")
              if not notes:
                  notes.append("—")
              return {
                  "title": title,
                  "status": status,
                  "changed": "Yes" if changed else "No",
                  "remaining": remaining,
                  "new": new,
                  "notes": "<br/>".join(notes),
                  "ran": ran,
                  "patch": patch,
              }

          entries = [
              build_entry("SMALL", "Small hygiene fixes", os.environ.get("SMALL_RESULT")),
              build_entry("FIX", "Fix failing checks", os.environ.get("FIX_RESULT")),
          ]

          autopatch_present = any(entry["patch"] for entry in entries)

          table_lines: List[str] = [
              "### Autofix Summary",
              "",
              "| Flow | Status | Changed | Remaining | New | Notes |",
              "|------|--------|---------|-----------|-----|-------|",
          ]
          for entry in entries:
              table_lines.append(
                  f"| {entry['title']} | {entry['status']} | {entry['changed']} | {entry['remaining']} | {entry['new']} | {entry['notes']} |"
              )

          if autopatch_present:
              table_lines.extend(
                  [
                      "",
                      "Fork contributors: download the patch artifact above and apply it locally:",
                      "```bash",
                      "git am < autofix.patch",
                      "```",
                  ]
              )

          small_outputs = outputs_cache.get("SMALL", {})
          small_files_raw = small_outputs.get("file_list") or ""
          if isinstance(small_files_raw, list):
              small_files_raw = "\n".join(str(item) for item in small_files_raw)
          small_files = [line.strip() for line in small_files_raw.splitlines() if line.strip()]
          small_mode = str(small_outputs.get("mode") or "").strip().lower()
          files_block: List[str] = []
          header = "### Files touched"
          if small_mode == "clean":
              header += " (clean mode)"
          files_block.append(header)
          files_block.append("")
          if small_files:
              files_block.extend(f"- `{path}`" for path in small_files)
          else:
              files_block.append("- None")

          fail_jobs_raw = os.environ.get("FAIL_JOB_NAMES") or ""
          fail_jobs = [item.strip() for item in fail_jobs_raw.split(',') if item.strip()]
          fix_outputs = outputs_cache.get("FIX", {})
          fix_ran = parse_bool(fix_outputs.get("ran"))
          checks_block: List[str] = ["### Checks re-run", ""]
          if fix_ran or fail_jobs:
              if fail_jobs:
                  checks_block.extend(f"- {job}" for job in fail_jobs)
              else:
                  checks_block.append("- Gate checks re-triggered (names unavailable)")
          else:
              checks_block.append("- None (Gate succeeded)")

          sections: List[str] = [anchor_marker, legacy_marker]
          if prefix:
              sections.append(prefix.strip())
          sections.append("")
          sections.extend(table_lines)
          if files_block:
              sections.append("")
              sections.extend(files_block)
          if checks_block:
              sections.append("")
              sections.extend(checks_block)
          if suffix:
              sections.append("")
              sections.append(suffix)

          comment_body = "\n".join(part for part in sections if part is not None)
          pathlib.Path("maint_post_ci_comment.md").write_text(comment_body.strip() + "\n", encoding="utf-8")
          PY

      - name: Upsert consolidated PR comment
        uses: actions/github-script@v7
        env:
          COMMENT_PATH: maint_post_ci_comment.md
          PR_NUMBER: ${{ needs.context.outputs.pr }}
        with:
          github-token: ${{ secrets.SERVICE_BOT_PAT || github.token }}
          script: |
            const path = require('path');
            const workspaceRoots = [
              process.env.GITHUB_WORKSPACE,
              process.cwd(),
            ].filter(Boolean);

            const anchorPattern = /<!--\s*maint-46-post-ci:([^>]*)-->/i;
            const extractAnchor = (text) => {
              if (typeof text !== 'string') {
                return null;
              }
              const match = text.match(anchorPattern);
              return match ? match[1] : null;
            };

            let helpers = null;
            for (const root of workspaceRoots) {
              try {
                helpers = require(path.join(root, '.github', 'scripts', 'comment-dedupe'));
                break;
              } catch (error) {
                if (!error || error.code !== 'MODULE_NOT_FOUND') {
                  throw error;
                }
              }
            }

            if (!helpers) {
              helpers = require('./.github/scripts/comment-dedupe');
            }

            const fs = require('fs');
            const commentPath = process.env.COMMENT_PATH;
            let commentBody = '';
            if (commentPath) {
              try {
                commentBody = fs.readFileSync(commentPath, 'utf8');
              } catch (error) {
                core.warning(`Failed to read consolidated comment body: ${error}`);
              }
            }

            let prNumber = process.env.PR_NUMBER;
            if (!prNumber) {
              const anchor = extractAnchor(commentBody);
              if (anchor) {
                const prMatch = anchor.match(/pr=([0-9]+)/i);
                if (prMatch) {
                  prNumber = prMatch[1];
                }
              }
            }

            if (!prNumber) {
              core.warning('PR number missing; skipping comment update.');
              return;
            }

            const { upsertAnchoredComment } = helpers;
            // Helper contract: github.rest.issues.updateComment / github.rest.issues.createComment invoked inside comment-dedupe utilities.
            await upsertAnchoredComment({
              github,
              context,
              core,
              prNumber,
              commentPath,
              body: commentBody,
              anchorPattern,
            });
  failure-tracker:
    name: Update failure tracker
    needs: context
    if: >
      needs.context.result == 'success' &&
      needs.context.outputs.found == 'true' &&
      needs.context.outputs.failure_incomplete != 'true' &&
      needs.context.outputs.failure_tracker_skip != 'true' &&
      github.event.workflow_run.event == 'pull_request'
    runs-on: ubuntu-latest
    env:
      PR_NUMBER: ${{ needs.context.outputs.pr }}
      RATE_LIMIT_MINUTES: 15
      STACK_TOKENS_ENABLED: 'true'
      STACK_TOKEN_MAX_LEN: 160
      AUTO_HEAL_INACTIVITY_HOURS: 24
      FAILURE_INACTIVITY_HEAL_HOURS: 0
      NEW_ISSUE_COOLDOWN_HOURS: 12
      DISABLE_FAILURE_ISSUES: 'false'
      COOLDOWN_RETRY_MS: 3000
      STACK_TOKEN_RAW: 'false'
      COOLDOWN_SCOPE: signature
      OCCURRENCE_ESCALATE_THRESHOLD: 3
      ESCALATE_LABEL: 'priority: high'
      ESCALATE_COMMENT: ''
    steps:
      - name: Derive failure signature & update tracking issue
        if: github.event.workflow_run.conclusion == 'failure'
        id: tracker
        uses: actions/github-script@v7
        with:
          script: |
            const path = require('path');
            const { updateFailureTracker } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await updateFailureTracker({ github, context, core });
      - name: Label pull request as ci-failure
        if: >
          github.event.workflow_run.conclusion == 'failure' &&
          needs.context.outputs.pr
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ needs.context.outputs.pr }}
        with:
          script: |
            const pr = Number(process.env.PR_NUMBER || 0);
            if (!pr) {
              core.info('No PR number detected; skipping label.');
              return;
            }
            try {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: pr,
                labels: ['ci-failure'],
              });
              core.info(`Applied ci-failure label to PR #${pr}.`);
            } catch (error) {
              if (error.status === 422) {
                core.info(`ci-failure label already present on PR #${pr}.`);
              } else {
                throw error;
              }
            }
      - name: Emit failure snapshot artifact
        if: github.event.workflow_run.conclusion == 'failure'
        run: |
          set -euo pipefail
          mkdir -p artifacts
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          payload = {
              "workflow": os.environ.get("WORKFLOW_NAME"),
              "run_id": os.environ.get("RUN_ID"),
              "run_url": os.environ.get("RUN_URL"),
              "pr_number": os.environ.get("PR_NUMBER"),
              "run_conclusion": os.environ.get("RUN_CONCLUSION"),
              "generated_at": os.environ.get("GENERATED_AT"),
          }

          Path("artifacts/ci_failures_snapshot.json").write_text(
              json.dumps(payload, indent=2),
              encoding="utf-8",
          )
          PY
        env:
          WORKFLOW_NAME: ${{ github.event.workflow_run.name }}
          RUN_ID: ${{ github.event.workflow_run.id }}
          RUN_URL: ${{ github.event.workflow_run.html_url }}
          PR_NUMBER: ${{ needs.context.outputs.pr }}
          RUN_CONCLUSION: ${{ github.event.workflow_run.conclusion }}
          GENERATED_AT: ${{ github.event.workflow_run.updated_at }}
      - name: Upload failure snapshot artifact
        if: github.event.workflow_run.conclusion == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: ci-failures-snapshot
          path: artifacts/ci_failures_snapshot.json
          retention-days: 7
      - name: Emit failure summary
        if: github.event.workflow_run.conclusion == 'failure'
        run: echo "Failure tracking step completed." >> "$GITHUB_STEP_SUMMARY"

      - name: Resolve failure issue for recovered PR
        if: >
          github.event.workflow_run.conclusion == 'success' &&
          needs.context.outputs.pr
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ needs.context.outputs.pr }}
          RUN_URL: ${{ github.event.workflow_run.html_url }}
        with:
          script: |
            const path = require('path');
            const { resolveFailureIssuesForRecoveredPR } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await resolveFailureIssuesForRecoveredPR({ github, context, core });

      - name: Auto-heal stale failure issues & note success
        if: github.event.workflow_run.conclusion == 'success'
        uses: actions/github-script@v7
        with:
          script: |
            const path = require('path');
            const { autoHealFailureIssues } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await autoHealFailureIssues({ github, context, core });
      - name: Remove ci-failure label from pull request
        if: >
          github.event.workflow_run.conclusion == 'success' &&
          needs.context.outputs.pr
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ needs.context.outputs.pr }}
        with:
          script: |
            const pr = Number(process.env.PR_NUMBER || 0);
            if (!pr) {
              core.info('No PR number detected; skipping label removal.');
              return;
            }
            try {
              await github.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: pr,
                name: 'ci-failure',
              });
              core.info(`Removed ci-failure label from PR #${pr}.`);
            } catch (error) {
              if (error.status === 404) {
                core.info(`ci-failure label not present on PR #${pr}.`);
              } else {
                throw error;
              }
            }
      - name: Snapshot open failure issues (JSON)
        if: github.event.workflow_run.conclusion == 'success'
        uses: actions/github-script@v7
        with:
          script: |
            const path = require('path');
            const { snapshotFailureIssues } = require(path.join(process.env.GITHUB_WORKSPACE, '.github/scripts/maint-post-ci'));
            await snapshotFailureIssues({ github, context, core });
      - name: Upload snapshot artifact
        if: github.event.workflow_run.conclusion == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: ci-failures-snapshot
          path: artifacts/ci_failures_snapshot.json
      - name: Emit success summary
        if: github.event.workflow_run.conclusion == 'success'
        run: echo "Run succeeded — failure issues scanned for auto-heal." >> "$GITHUB_STEP_SUMMARY"

