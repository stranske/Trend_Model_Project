name: Reusable Python CI

# Clean rebuilt reusable workflow with debug instrumentation retained from strict-lint branch.
# Inputs are feature flags controlling optional artifacts and gates.

on:
  workflow_call:
    inputs:
      python-versions:
        description: JSON list of Python versions
        required: false
        default: '["3.11"]'
        type: string
      coverage-min:
        description: Minimum coverage percent (hard gate)
        required: false
        default: '70'
        type: string
      run-mypy:
        description: Run mypy job
        required: false
        default: true
        type: boolean
      enable-metrics:
        description: Emit ci-metrics.json (test metrics)
        required: false
        default: false
        type: boolean
      enable-history:
        description: Append metrics history artifact
        required: false
        default: false
        type: boolean
      history-artifact-name:
        description: Metrics history artifact filename
        required: false
        default: metrics-history.ndjson
        type: string
      enable-classification:
        description: Emit failure classification
        required: false
        default: false
        type: boolean
      enable-coverage-delta:
        description: Compute coverage delta vs baseline
        required: false
        default: false
        type: boolean
      baseline-coverage:
        description: Baseline coverage percent for delta
        required: false
        default: '0'
        type: string
      coverage-alert-drop:
        description: Coverage drop alert threshold (pct pts)
        required: false
        default: '1'
        type: string
      fail-on-coverage-drop:
        description: Fail if drop >= threshold
        required: false
        default: 'false'
        type: string
      coverage-drop-label:
        description: Optional label to apply when coverage drops
        required: false
        default: coverage-drop
        type: string
      enable-soft-gate:
        description: Enable soft coverage gate (aggregate + issue update)
        required: false
        default: false
        type: boolean
      coverage-hard-fail:
        description: Fail tests job if coverage < min
        required: false
        default: true
        type: boolean
      coverage-artifact-retention-days:
        description: Retention days for coverage artifacts
        required: false
        default: '10'
        type: string
      low-coverage-threshold:
        description: Low coverage hotspot threshold (%)
        required: false
        default: '50'
        type: string
      slow-test-top:
        description: Top N slow tests to report
        required: false
        default: '15'
        type: string
      slow-test-min-seconds:
        description: Minimum seconds for a test to qualify as slow
        required: false
        default: '1'
        type: string
      artifact-prefix:
        description: Prefix applied to uploaded artifact names
        required: false
        default: ''
        type: string

jobs:
  tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ${{ fromJson(inputs.python-versions) }}
        include:
          - python-version: '3.11'
            scenario: base
          - python-version: '3.11'
            scenario: metrics
            enable-metrics: true
          - python-version: '3.11'
            scenario: metrics-history
            enable-metrics: true
            enable-history: true
          - python-version: '3.11'
            scenario: classification
            enable-classification: true
          - python-version: '3.11'
            scenario: cov-delta
            enable-coverage-delta: true
            baseline-coverage: ${{ inputs.baseline-coverage }}
            enable-soft-gate: true
    continue-on-error: false
    env:
      ENABLE_METRICS_FLAG: ${{ matrix.enable-metrics || inputs.enable-metrics }}
      ENABLE_HISTORY_FLAG: ${{ matrix.enable-history || inputs.enable-history }}
      ENABLE_CLASSIFICATION_FLAG: ${{ matrix.enable-classification || inputs.enable-classification }}
      ENABLE_COV_DELTA_FLAG: ${{ matrix.enable-coverage-delta || inputs.enable-coverage-delta }}
      ENABLE_SOFT_GATE_FLAG: ${{ matrix.enable-soft-gate || inputs.enable-soft-gate }}
      COVERAGE_HARD_FAIL_FLAG: ${{ inputs.coverage-hard-fail }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install pytest pytest-cov jq
      - name: Run tests with coverage
        run: |
          pytest --junitxml=pytest-junit.xml \
            --cov=src --cov-branch \
            --cov-report=xml:coverage.xml \
            --cov-report=json:coverage.json \
            --cov-report=html:htmlcov \
            --cov-report=term-missing
      - name: Prepare coverage artifacts
        run: |
          cp -f pytest-junit.xml pytest-report.xml || true
          mv coverage.json coverage-${{ matrix.python-version }}.json
          test -f coverage-${{ matrix.python-version }}.json
          test -f coverage.xml
      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}coverage-${{ matrix.python-version }}
          retention-days: ${{ inputs.coverage-artifact-retention-days }}
          path: |
            coverage.xml
            coverage-${{ matrix.python-version }}.json
            htmlcov/**
            pytest-junit.xml
            pytest-report.xml
      - name: Extract test metrics
        if: ${{ env.ENABLE_METRICS_FLAG == 'true' }}
        run: python scripts/ci_metrics.py
        env:
          JUNIT_PATH: pytest-junit.xml
          OUTPUT_PATH: ci-metrics.json
          TOP_N: ${{ inputs.slow-test-top }}
          MIN_SECONDS: ${{ inputs.slow-test-min-seconds }}
      - name: Upload metrics artifact
        if: ${{ env.ENABLE_METRICS_FLAG == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}ci-metrics
          path: ci-metrics.json
      - name: Enforce coverage minimum (hard gate)
        if: ${{ env.COVERAGE_HARD_FAIL_FLAG == 'true' }}
        run: |
          RAW=$(grep -Eo 'line-rate="[0-9.]+"' coverage.xml | head -1 | sed -E 's/.*"([0-9.]+)"/\1/')
          PCT=$(python -c "print(float('$RAW')*100.0)")
          echo "Coverage: ${PCT}% (min ${{ inputs.coverage-min }}%)"
          python -c "import sys; cur=float('$PCT'); m=float('${{ inputs.coverage-min }}'); sys.exit(0 if cur>=m else 1)" || { echo 'Coverage below minimum' >&2; exit 1; }
      - name: Coverage delta
        if: ${{ env.ENABLE_COV_DELTA_FLAG == 'true' }}
        run: python scripts/ci_coverage_delta.py
        env:
          BASELINE_COVERAGE: ${{ inputs.baseline-coverage }}
          ALERT_DROP: ${{ inputs.coverage-alert-drop }}
          FAIL_ON_DROP: ${{ inputs.fail-on-coverage-drop }}
      - name: Upload coverage delta
        if: ${{ env.ENABLE_COV_DELTA_FLAG == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}coverage-delta
          path: coverage-delta.json
      - name: History & classification
        if: ${{ env.ENABLE_HISTORY_FLAG == 'true' || env.ENABLE_CLASSIFICATION_FLAG == 'true' }}
        run: python scripts/ci_history.py
        env:
          JUNIT_PATH: pytest-junit.xml
          METRICS_PATH: ci-metrics.json
          HISTORY_PATH: ${{ inputs.history-artifact-name }}
          CLASSIFICATION_OUT: classification.json
      - name: Upload history artifact
        if: ${{ env.ENABLE_HISTORY_FLAG == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}metrics-history
          path: ${{ inputs.history-artifact-name }}
      - name: Upload classification artifact
        if: ${{ env.ENABLE_CLASSIFICATION_FLAG == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}classification
          path: classification.json
      - name: CI summary
        run: |
          echo "## CI Summary" >> $GITHUB_STEP_SUMMARY
          if [ -f ci-metrics.json ]; then echo "- Metrics: present" >> $GITHUB_STEP_SUMMARY; else echo "- Metrics: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
          if [ -f coverage-delta.json ]; then
            CUR=$(jq -r .current coverage-delta.json 2>/dev/null || echo '?')
            BASE=$(jq -r .baseline coverage-delta.json 2>/dev/null || echo '?')
            DELTA=$(jq -r .delta coverage-delta.json 2>/dev/null || echo '?')
            echo "- Coverage delta: current=$CUR baseline=$BASE delta=$DELTA" >> $GITHUB_STEP_SUMMARY
          else
            echo "- Coverage delta: (disabled)" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f classification.json ]; then echo "- Classification: present" >> $GITHUB_STEP_SUMMARY; else echo "- Classification: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
          if [ -f ${{ inputs.history-artifact-name }} ]; then echo "- History: appended" >> $GITHUB_STEP_SUMMARY; else echo "- History: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
          if [ "$ENABLE_SOFT_GATE_FLAG" = "true" ]; then echo "- Soft gate: enabled (see coverage_soft_gate job)" >> $GITHUB_STEP_SUMMARY; else echo "- Soft gate: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
      - name: Assert feature outputs
        run: python scripts/ci_feature_assert.py
        env:
          EXPECT_METRICS: ${{ env.ENABLE_METRICS_FLAG }}
          EXPECT_HISTORY: ${{ env.ENABLE_HISTORY_FLAG }}
          EXPECT_CLASSIFICATION: ${{ env.ENABLE_CLASSIFICATION_FLAG }}
          EXPECT_COV_DELTA: ${{ env.ENABLE_COV_DELTA_FLAG }}
          HISTORY_ARTIFACT_NAME: ${{ inputs.history-artifact-name }}

  mypy:
    if: ${{ inputs.run-mypy }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install mypy
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install mypy
      - name: Run mypy
        run: mypy src || (echo 'mypy failed' && exit 1)

  coverage_soft_gate:
    if: ${{ inputs.enable-soft-gate }}
    needs: tests
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      actions: read
    steps:
      - name: Download coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ${{ inputs.artifact-prefix }}coverage-*
          merge-multiple: true
      - name: Debug coverage artifact contents (Issue #1386)
        run: |
          echo '== Top-level listing =='
          ls -al . || true
          echo ''
          echo '== Find coverage json candidates =='
          find . -maxdepth 2 -type f -name 'coverage*.json' -print || true
          echo -e '\n== Show first 40 lines of each coverage json =='
          for f in $(find . -maxdepth 2 -type f -name 'coverage*.json' | head -5); do
            echo "--- $f ---";
            head -40 "$f" || true;
          done
      - name: Compute coverage summary & hotspots
        id: cov
        shell: python
        env:
          LOW_COVERAGE_THRESHOLD: ${{ inputs.low-coverage-threshold }}
        run: |
          import glob, json, os, re, sys

          HOTSPOT_LIMIT = 15
          try:
              LOW_COVERAGE_THRESHOLD = float(os.environ.get('LOW_COVERAGE_THRESHOLD', '50.0'))
          except ValueError:
              LOW_COVERAGE_THRESHOLD = 50.0

          candidates = sorted(set(glob.glob('coverage-*.json') + glob.glob('**/coverage.json', recursive=True)))
          seen=set(); ordered=[]
          for c in candidates:
              p=os.path.relpath(c)
              if p not in seen:
                  seen.add(p)
                  ordered.append(p)

          if not ordered:
              msg = 'No coverage JSON files found (Issue #1386 diagnostics)'
              print('[warn]', msg)
              with open('coverage_summary.md','w') as w:
                  w.write('**Coverage data unavailable – see debug step output.**\n')
              print('::notice:: '+msg)
              sys.exit(0)

          totals=[]; hotspots=[]
          for jf in ordered:
              try:
                  with open(jf,'r') as fh:
                      data=json.load(fh)
              except Exception as e:
                  print(f'[warn] Failed to parse {jf}: {e}')
                  continue
              t=data.get('totals', {}) or {}
              pct = t.get('percent_covered')
              if pct is None:
                  disp = t.get('percent_covered_display')
                  try:
                      pct = float(disp) if disp is not None else 0.0
                  except Exception:
                      pct = 0.0
              totals.append(float(pct))
              for fpath, meta in (data.get('files') or {}).items():
                  s=meta.get('summary', {}) or {}
                  fpct = s.get('percent_covered')
                  if fpct is None:
                      disp=s.get('percent_covered_display')
                      try:
                          fpct=float(disp) if disp is not None else 0.0
                      except Exception:
                          fpct=0.0
                  hotspots.append((float(fpct), fpath))

          hotspots.sort(key=lambda x: x[0])
          avg = round(sum(totals)/len(totals), 2) if totals else 0.0
          worst = round(min(totals), 2) if totals else 0.0
          lines=[f"**Coverage (avg across jobs): {avg}% | worst job: {worst}%**", "", "| File | % covered |", "|---|---:|"]
          for fpct,f in hotspots[:HOTSPOT_LIMIT]:
              lines.append(f"| `{f}` | {fpct:.1f}% |")
          if len(lines) == 4:
              lines.append('| *(no files parsed)* | *(n/a)* |')
          low_cov=[(p,f) for p,f in hotspots if p < LOW_COVERAGE_THRESHOLD]
          if low_cov:
              lines += ['', f"#### Low Coverage (<{LOW_COVERAGE_THRESHOLD:.0f}% )", "| File | % covered |", "|---|---:|"]
              for p,f in low_cov[:HOTSPOT_LIMIT]:
                  lines.append(f"| `{f}` | {p:.1f}% |")
              if len(low_cov) > HOTSPOT_LIMIT:
                  lines.append(f"| *(+{len(low_cov)-HOTSPOT_LIMIT} more below {LOW_COVERAGE_THRESHOLD:.0f}% – truncated)* | *(n/a)* |")
          with open('coverage_summary.md','w') as w:
              w.write('\n'.join(lines)+'\n')
          first_line = lines[0]
          match = re.search(r'avg across jobs\):\s*([0-9.]+)% \| worst job: ([0-9.]+)%', first_line)
          if match:
              print(first_line)
          else:
              print('[warn] Unable to parse coverage headline from summary header:', first_line)
      - name: Upload coverage summary artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}coverage-summary
          retention-days: ${{ inputs.coverage-artifact-retention-days }}
          path: coverage_summary.md
      - name: Build job log links table
        id: jobs
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const run_id = context.runId;
            const { data } = await github.rest.actions.listJobsForWorkflowRun({ owner, repo, run_id, per_page: 100 });
            const rows = data.jobs.map(j => `| ${j.name} | ${j.conclusion || j.status} | [logs](${j.html_url}) |`);
            const md = ["### Logs for this run","| Job | Result | Logs |","|---|---|---|",...rows].join("\n");
            core.setOutput('table', md);
            const failed = data.jobs.filter(j => !['success','skipped'].includes((j.conclusion || '').toLowerCase())).map(j => j.name);
            core.setOutput('failed', failed.join(', '));
      - name: Create / update soft coverage issue
        uses: actions/github-script@v7
        env:
          TABLE: ${{ steps.jobs.outputs.table }}
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const title = 'Increase test coverage (soft gate)';
            const label = 'tech:coverage';
            const bodyBlock = fs.readFileSync('coverage_summary.md','utf8');
            const jobTable = process.env.TABLE || '';
            const runUrl = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
            try { await github.rest.issues.getLabel({owner, repo, name: label}); } catch { await github.rest.issues.createLabel({owner, repo, name: label, color: '0e8a16'}); }
            const q = `repo:${owner}/${repo} is:issue is:open in:title "${title}" label:"${label}"`;
            const search = await github.rest.search.issuesAndPullRequests({ q, per_page: 1 });
            const compositeBody = `CI run: ${runUrl}\n\n${bodyBlock}\n\n#### Job logs\n${jobTable}`;
            if (search.data.items.length) {
              const num = search.data.items[0].number;
              await github.rest.issues.update({owner, repo, issue_number: num, title});
              await github.rest.issues.createComment({owner, repo, issue_number: num, body: compositeBody});
            } else {
              await github.rest.issues.create({owner, repo, title, body: compositeBody, labels:[label]});
            }
      - name: Append coverage summary to run summary
        run: |
          echo "## Soft Coverage Gate" >> $GITHUB_STEP_SUMMARY
          cat coverage_summary.md >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "${{ steps.jobs.outputs.table }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      - name: Emit coverage trend record
        shell: python
        run: |
          import datetime, json, os, re
          summary_path='coverage_summary.md'
          avg=worst=None
          try:
            with open(summary_path,'r') as fh:
              first=fh.readline().strip()
            m=re.search(r'avg across jobs\):\s*([0-9.]+)% \| worst job: ([0-9.]+)%', first)
            if m:
              avg=float(m.group(1))
              worst=float(m.group(2))
          except Exception:
            pass
          rec={
            'run_id': int(os.environ.get('GITHUB_RUN_ID','0')),
            'run_number': int(os.environ.get('GITHUB_RUN_NUMBER','0')),
            'repo': os.environ.get('GITHUB_REPOSITORY'),
            'sha': os.environ.get('GITHUB_SHA'),
            'ref': os.environ.get('GITHUB_REF'),
            'avg_coverage': avg,
            'worst_job_coverage': worst,
            'timestamp_utc': datetime.datetime.utcnow().isoformat()+'Z'
          }
          with open('coverage-trend.json','w') as w:
            json.dump(rec,w,indent=2,sort_keys=True)
          print('Wrote coverage-trend.json')
      - name: Upload coverage trend artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}coverage-trend
          retention-days: ${{ inputs.coverage-artifact-retention-days }}
          path: coverage-trend.json
      - name: Download existing coverage trend history (if any)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: ${{ inputs.artifact-prefix }}coverage-trend-history
          path: coverage-history-pre
      - name: Merge coverage trend history
        shell: bash
        run: |
          set -euo pipefail
          HIST=coverage-trend-history.ndjson
          if [ -d coverage-history-pre ]; then
            if [ -f coverage-history-pre/coverage-trend-history.ndjson ]; then
              cp coverage-history-pre/coverage-trend-history.ndjson "$HIST"
            fi
          fi
          python scripts/coverage_history_append.py || echo "[history] append failed" >&2
          ls -l "$HIST" || true
      - name: Upload coverage trend history artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact-prefix }}coverage-trend-history
          retention-days: ${{ inputs.coverage-artifact-retention-days }}
          path: coverage-trend-history.ndjson

  logs_summary:
    if: ${{ always() }}
    needs: [tests]
    runs-on: ubuntu-latest
    permissions:
      actions: read
    steps:
      - name: Enumerate jobs
        id: jobs
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const run_id = context.runId;
            const { data } = await github.rest.actions.listJobsForWorkflowRun({ owner, repo, run_id, per_page: 100 });
            const rows = data.jobs.map(j => `| ${j.name} | ${j.conclusion || j.status} | [logs](${j.html_url}) |`);
            const failed = data.jobs.filter(j => !['success','skipped'].includes((j.conclusion || '').toLowerCase())).map(j => j.name);
            const failingTestJobs = failed.filter(n => /test/i.test(n));
            let explanation = '';
            if (failed.length) {
              explanation = `\n> ❗ ${failed.length} job(s) did not succeed: ${failed.join(', ')}.`;
              if (failingTestJobs.length) {
                explanation += ` Failing test jobs: ${failingTestJobs.length}.`;
              }
            } else {
              explanation = `\n> ✅ All jobs succeeded.`;
            }
            const md = ["### Logs for this run","| Job | Result | Logs |","|---|---|---|",...rows, explanation].join("\n");
            core.setOutput('table', md);
      - name: Append logs table to summary
        run: |
          echo "${{ steps.jobs.outputs.table }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

# End of workflow

