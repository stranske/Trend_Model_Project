name: Reusable Python CI

on:
  workflow_call:
    inputs:
      python-versions: { description: 'JSON list Python versions', required: false, default: '["3.11"]', type: string }
      coverage-min: { description: 'Minimum coverage percent', required: false, default: '70', type: string }
      run-mypy: { description: 'Run mypy job', required: false, default: 'true', type: string }
      # Phase 1 – Metrics extraction inputs
      enable-metrics: { description: 'Enable metrics extraction (ci-metrics.json)', required: false, default: 'false', type: string }
      slow-test-top: { description: 'Count of slow tests to report', required: false, default: '15', type: string }
      slow-test-min-seconds: { description: 'Min seconds for slow test list', required: false, default: '1', type: string }
      # Phase 2 – Classification & history logging
      enable-classification: { description: 'Enable failure classification', required: false, default: 'false', type: string }
      enable-history: { description: 'Enable metrics history append', required: false, default: 'false', type: string }
      history-artifact-name: { description: 'Artifact name for metrics history', required: false, default: 'metrics-history.ndjson', type: string }
      # Phase 3 – Coverage delta
      enable-coverage-delta: { description: 'Enable coverage delta evaluation', required: false, default: 'false', type: string }
      baseline-coverage: { description: 'Baseline coverage percent', required: false, default: '0', type: string }
      coverage-alert-drop: { description: 'Coverage drop alert threshold (pct pts)', required: false, default: '1', type: string }
      fail-on-coverage-drop: { description: 'Fail if drop >= threshold', required: false, default: 'false', type: string }
      coverage-drop-label: { description: 'Label to add on drop (future)', required: false, default: 'coverage-drop', type: string }
      # Phase 4 – Soft coverage gate (Issue #1342)
      enable-soft-gate: { description: 'Enable soft coverage gate (aggregate + issue update)', required: false, default: 'false', type: string }
      coverage-hard-fail: { description: 'Still fail build on coverage shortfall (true/false)', required: false, default: 'true', type: string }
      coverage-artifact-retention-days: { description: 'Retention days for coverage artifacts', required: false, default: '10', type: string }

jobs:
  tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ${{ fromJson(inputs.python-versions) }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install pytest pytest-cov
      - name: Run tests with coverage
        run: |
          pytest --junitxml=pytest-junit.xml \
            --cov=src --cov-branch \
            --cov-report=xml:coverage.xml \
            --cov-report=json:coverage.json \
            --cov-report=html:htmlcov \
            --cov-report=term-missing
      - name: Prepare coverage ancillary files
        run: |
          # Create a second JUnit filename expected by soft gate snippet if needed
          cp -f pytest-junit.xml pytest-report.xml || true
          # Basic sanity checks
          test -f coverage.xml || { echo 'coverage.xml missing'; exit 1; }
          test -f coverage.json || { echo 'coverage.json missing'; exit 1; }
          mv coverage.json coverage-${{ matrix.python-version }}.json
        shell: bash
      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}
          retention-days: ${{ inputs.coverage-artifact-retention-days }}
          path: |
            coverage.xml
            coverage-${{ matrix.python-version }}.json
            htmlcov/**
            pytest-junit.xml
            pytest-report.xml
      - name: Extract test metrics
        if: ${{ inputs.enable-metrics == 'true' }}
        run: |
          python scripts/ci_metrics.py || exit 1
        env:
          JUNIT_PATH: pytest-junit.xml
          OUTPUT_PATH: ci-metrics.json
          TOP_N: ${{ inputs.slow-test-top }}
          MIN_SECONDS: ${{ inputs.slow-test-min-seconds }}
      - name: Upload metrics artifact
        if: ${{ inputs.enable-metrics == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: ci-metrics
          path: ci-metrics.json
      - name: Enforce coverage minimum (hard gate)
        if: ${{ inputs.coverage-hard-fail == 'true' }}
        run: |
          if [ ! -f coverage.xml ]; then echo 'coverage.xml missing'; exit 1; fi
          RAW=$(grep -Eo 'line-rate="[0-9.]+' coverage.xml | head -1 | sed -E 's/.*"([0-9.]+)$/\1/')
          PCT=$(python -c "print('{:.2f}'.format(float('$RAW')*100.0))")
          echo "Current coverage: $PCT% (hard gate)"
          MIN=${{ inputs.coverage-min }}
          python -c "import sys; c=float('$PCT'); m=float('$MIN'); sys.exit(0 if c>=m else 1)" || { echo "Coverage $PCT% < min $MIN%" >&2; exit 1; }
      - name: Coverage delta
        if: ${{ inputs.enable-coverage-delta == 'true' }}
        run: |
          python scripts/ci_coverage_delta.py || exit 1
        env:
          BASELINE_COVERAGE: ${{ inputs.baseline-coverage }}
          ALERT_DROP: ${{ inputs.coverage-alert-drop }}
          FAIL_ON_DROP: ${{ inputs.fail-on-coverage-drop }}
      - name: Upload coverage delta artifact
        if: ${{ inputs.enable-coverage-delta == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: coverage-delta
          path: coverage-delta.json
      - name: History & classification
        if: ${{ inputs.enable-history == 'true' || inputs.enable-classification == 'true' }}
        run: |
          python scripts/ci_history.py || exit 1
        env:
          JUNIT_PATH: pytest-junit.xml
          METRICS_PATH: ci-metrics.json
          HISTORY_PATH: ${{ inputs.history-artifact-name }}
          ENABLE_CLASSIFICATION: ${{ inputs.enable-classification }}
          CLASSIFICATION_OUT: classification.json
      - name: Upload history artifact
        if: ${{ inputs.enable-history == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: metrics-history
          path: ${{ inputs.history-artifact-name }}
      - name: Upload classification artifact
        if: ${{ inputs.enable-classification == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: classification
          path: classification.json
      - name: CI summary
        run: |
          echo "## CI Summary" >> $GITHUB_STEP_SUMMARY
          if [ -f ci-metrics.json ]; then echo "- Metrics: present" >> $GITHUB_STEP_SUMMARY; else echo "- Metrics: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
          if [ -f coverage-delta.json ]; then
            CUR=$(jq -r .current coverage-delta.json 2>/dev/null || echo '?')
            BASE=$(jq -r .baseline coverage-delta.json 2>/dev/null || echo '?')
            DELTA=$(jq -r .delta coverage-delta.json 2>/dev/null || echo '?')
            echo "- Coverage delta: current=$CUR baseline=$BASE delta=$DELTA" >> $GITHUB_STEP_SUMMARY
          else
            echo "- Coverage delta: (disabled)" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f classification.json ]; then echo "- Classification: present" >> $GITHUB_STEP_SUMMARY; else echo "- Classification: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
          if [ -f ${{ inputs.history-artifact-name }} ]; then echo "- History: appended" >> $GITHUB_STEP_SUMMARY; else echo "- History: (disabled)" >> $GITHUB_STEP_SUMMARY; fi
          if [ "${{ inputs.enable-soft-gate }}" = "true" ]; then echo "- Soft gate: enabled (see coverage_soft_gate job)" >> $GITHUB_STEP_SUMMARY; else echo "- Soft gate: (disabled)" >> $GITHUB_STEP_SUMMARY; fi

  mypy:
    if: ${{ inputs.run-mypy == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install mypy
      - name: Run mypy
        run: mypy src || (echo 'mypy failed' && exit 1)

  coverage_soft_gate:
    # Soft coverage gate aggregates artifacts and updates a canonical issue (Issue #1342 design).
    if: ${{ inputs.enable-soft-gate == 'true' }}
    needs: tests
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      actions: read
    steps:
      - name: Download coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-*
          merge-multiple: true
      - name: Debug coverage artifact contents (Issue #1386)
        run: |
          echo '== Top-level listing =='
          ls -al . || true
          echo ''
          echo '== Find coverage json candidates =='
          find . -maxdepth 2 -type f -name 'coverage*.json' -printf '%p\n' || true
          echo -e '\n== Show first 40 lines of each coverage json =='
          for f in $(find . -maxdepth 2 -type f -name 'coverage*.json' | head -5); do
            echo "--- $f ---";
            head -40 "$f" || true;
          done
      - name: Compute coverage summary & hotspots
        id: cov
        shell: python
        run: |
          import glob, json, os, sys

          HOTSPOT_LIMIT = 15
          candidates = sorted(set(glob.glob('coverage-*.json') + glob.glob('**/coverage.json', recursive=True)))
          # Filter out duplicate same-path entries
          seen=set(); ordered=[]
          for c in candidates:
              p=os.path.relpath(c)
              if p not in seen:
                  seen.add(p); ordered.append(p)
          if not ordered:
              msg = 'No coverage JSON files found (Issue #1386 diagnostics)'
              print('[warn]', msg)
              with open('coverage_summary.md','w') as w:
                  w.write('**Coverage data unavailable – see debug step output.**\n')
              # Continue (non-blocking) but set output flag
              print('::notice ::'+msg)
              sys.exit(0)
          totals=[]; hotspots=[]
          for jf in ordered:
              try:
                  with open(jf,'r') as fh:
                      data=json.load(fh)
              except Exception as e:
                  print(f'[warn] Failed to parse {jf}: {e}')
                  continue
              t=data.get('totals', {}) or {}
              pct = t.get('percent_covered')
              if pct is None:
                  disp = t.get('percent_covered_display')
                  try: pct=float(disp) if disp is not None else 0.0
                  except Exception: pct=0.0
              totals.append(float(pct))
              files=(data.get('files') or {})
              for fpath, meta in files.items():
                  s=meta.get('summary', {}) or {}
                  fpct = s.get('percent_covered')
                  if fpct is None:
                      disp=s.get('percent_covered_display')
                      try: fpct=float(disp) if disp is not None else 0.0
                      except Exception: fpct=0.0
                  hotspots.append((float(fpct), fpath))
          hotspots.sort(key=lambda x: x[0])
          if not totals:
              print('[warn] Coverage totals list empty after parsing candidates.')
          avg= round(sum(totals)/len(totals),2) if totals else 0.0
          worst= round(min(totals),2) if totals else 0.0
          lines=[f"**Coverage (avg across jobs): {avg}% | worst job: {worst}%**", "", "| File | % covered |", "|---|---:|"]
          for fpct,f in hotspots[:HOTSPOT_LIMIT]:
              lines.append(f"| `{f}` | {fpct:.1f}% |")
          if len(lines)==4:
              lines.append('| *(no files parsed)* | — |')
          with open('coverage_summary.md','w') as w:
              w.write("\n".join(lines)+"\n")
          print('\n'.join(lines[:6])+'\n...')
      - name: Build job log links table
        id: jobs
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const run_id = context.runId;
            const { data } = await github.rest.actions.listJobsForWorkflowRun({ owner, repo, run_id, per_page: 100 });
            const rows = data.jobs.map(j => `| ${j.name} | ${j.conclusion || j.status} | [logs](${j.html_url}) |`);
            const md = ["### Logs for this run","| Job | Result | Logs |","|---|---|---|",...rows].join("\n");
            core.setOutput('table', md);
      - name: Create / update soft coverage issue
        uses: actions/github-script@v7
        env:
          TABLE: ${{ steps.jobs.outputs.table }}
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const title = 'Increase test coverage (soft gate)';
            const label = 'tech:coverage';
            const bodyBlock = fs.readFileSync('coverage_summary.md','utf8');
            const jobTable = process.env.TABLE || '';
            const runUrl = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
            // Ensure label exists
            try { await github.rest.issues.getLabel({owner, repo, name: label}); } catch { await github.rest.issues.createLabel({owner, repo, name: label, color: '0e8a16'}); }
            const q = `repo:${owner}/${repo} is:issue is:open in:title "${title}" label:"${label}"`;
            const search = await github.rest.search.issuesAndPullRequests({ q, per_page: 1 });
            const compositeBody = `CI run: ${runUrl}\n\n${bodyBlock}\n\n#### Job logs\n${jobTable}`;
            if (search.data.items.length) {
              const num = search.data.items[0].number;
              await github.rest.issues.update({owner, repo, issue_number: num, title});
              await github.rest.issues.createComment({owner, repo, issue_number: num, body: compositeBody});
              core.info(`Updated #${num}`);
            } else {
              const created = await github.rest.issues.create({owner, repo, title, body: compositeBody, labels:[label]});
              core.info(`Created #${created.data.number}`);
            }
      - name: Append coverage summary to run summary
        run: |
          echo "## Soft Coverage Gate" >> $GITHUB_STEP_SUMMARY
          cat coverage_summary.md >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          # (Per Issue #1344) Universal logs table now emitted by logs_summary job.
          # Removed duplicate per-job logs table here to avoid redundancy.
      - name: Emit coverage trend record
        shell: python
        run: |
          import json, os, datetime
          # Simple single-run JSON line; a downstream process or future enhancement can append history.
          summary_path='coverage_summary.md'
          avg=worst=None
          try:
            with open(summary_path,'r') as fh:
              first=fh.readline().strip()
            # Parse **Coverage (avg across jobs): X% | worst job: Y%**
            import re
            m=re.search(r'avg across jobs\):\s*([0-9.]+)% \| worst job: ([0-9.]+)%', first)
            if m:
              avg=float(m.group(1)); worst=float(m.group(2))
          except Exception:
            pass
          rec={
            'run_id': int(os.environ.get('GITHUB_RUN_ID','0')),
            'run_number': int(os.environ.get('GITHUB_RUN_NUMBER','0')),
            'repo': os.environ.get('GITHUB_REPOSITORY'),
            'sha': os.environ.get('GITHUB_SHA'),
            'ref': os.environ.get('GITHUB_REF'),
            'avg_coverage': avg,
            'worst_job_coverage': worst,
            'timestamp_utc': datetime.datetime.utcnow().isoformat()+'Z'
          }
          with open('coverage-trend.json','w') as w: json.dump(rec,w,indent=2,sort_keys=True)
          print('Wrote coverage-trend.json')
      - name: Upload coverage trend artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-trend
          path: coverage-trend.json
      - name: Download existing coverage trend history (if any)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
            name: coverage-trend-history
            path: coverage-history-pre
      - name: Merge coverage trend history
        shell: bash
        run: |
          set -euo pipefail
          HIST=coverage-trend-history.ndjson
          if [ -d coverage-history-pre ]; then
            # Rehydrate prior artifact contents if present
            if [ -f coverage-history-pre/coverage-trend-history.ndjson ]; then
              cp coverage-history-pre/coverage-trend-history.ndjson "$HIST"
            fi
          fi
          python scripts/coverage_history_append.py || echo "[history] append failed" >&2
          ls -l "$HIST" || true
      - name: Upload coverage trend history artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-trend-history
          path: coverage-trend-history.ndjson

  # Universal logs summary (Issue #1344)
  # Ensures every CI run exposes a per-job logs table in the run summary even when
  # the soft coverage gate is disabled. Placed in its own job so it can depend on
  # all earlier jobs completing (success, failure, or skip). We only require the
  # mandatory 'tests' job so optional jobs (mypy, coverage_soft_gate) don't break
  # dependency resolution when disabled or skipped. The GitHub API call enumerates
  # ALL jobs for the workflow run, so the table naturally includes mypy / soft gate
  # when present.
  logs_summary:
    if: ${{ always() }}
    needs: [tests]
    runs-on: ubuntu-latest
    permissions:
      actions: read
    steps:
      - name: Build universal job log links table
        id: jobs
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const run_id = context.runId;
            const { data } = await github.rest.actions.listJobsForWorkflowRun({ owner, repo, run_id, per_page: 100 });
            const rows = data.jobs.map(j => `| ${j.name} | ${j.conclusion || j.status} | [logs](${j.html_url}) |`);
            const failed = data.jobs.filter(j => !['success','skipped'].includes((j.conclusion || '').toLowerCase())).map(j => j.name);
            // Count failing test jobs (heuristic: name contains 'test' case-insensitive)
            const failingTestJobs = failed.filter(n => /test/i.test(n));
            let explanation = '';
            if (failed.length) {
              explanation = `\n> ❗ ${failed.length} job(s) did not succeed: ${failed.join(', ')}.`;
              if (failingTestJobs.length) {
                explanation += ` Failing test jobs: ${failingTestJobs.length}.`;
              }
            } else {
              explanation = `\n> ✅ All jobs succeeded.`;
            }
            const md = ["### Logs for this run","| Job | Result | Logs |","|---|---|---|",...rows, explanation].join("\n");
            core.setOutput('table', md);
      - name: Append logs table to summary
        run: |
          echo "${{ steps.jobs.outputs.table }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
