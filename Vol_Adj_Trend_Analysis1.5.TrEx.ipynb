{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22994893-0193-45bc-b9e3-a97b328ecaea",
      "metadata": {},
      "source": [
        "# Volatility Scaling & Portfolio Analysis\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Imports, Data Loader and Rf Detector\n",
        "2. Select fund (month period logic)\n",
        "3. Weight prep\n",
        "4. Core Stats + Run Analysis\n",
        "5. Export\n",
        "6. Widget /UI\n",
        "7. Output in-sample and out-of-sample results to Excel with formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "30ea203f",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Legacy helper and metric functions replaced by modules\n",
        "# See trend_analysis.metrics and run_analysis.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f74bd17b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import inspect\n",
        "from collections import namedtuple\n",
        "from typing import Dict, Optional, Callable\n",
        "import ipywidgets as widgets\n",
        "from ipyfilechooser import FileChooser\n",
        "from IPython.display import display, clear_output\n",
        "from trend_analysis.data import load_csv, identify_risk_free_fund\n",
        "from trend_analysis.core.rank_selection import (\n",
        "    FundSelectionConfig,\n",
        "    RiskStatsConfig,\n",
        "    select_funds,\n",
        "    register_metric,\n",
        "    METRIC_REGISTRY,\n",
        ")\n",
        "from trend_analysis.export import make_summary_formatter, export_to_excel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7a576b-aa3f-42e0-bfdc-f4a950b7d97c",
      "metadata": {},
      "source": [
        "## 2. Select Funds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ff528d69-5a52-4b75-8af4-17974826f4ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 2 · SELECT_FUNDS  (restored ≤ 3-missing-months rule)\n",
        "# ===============================================================\n",
        "\n",
        "cfg = FundSelectionConfig(\n",
        "    max_missing_months           = 3,\n",
        "    max_consecutive_month_gap    = 6,\n",
        "    outlier_threshold            = 0.5,\n",
        "    zero_return_threshold        = 0.2,\n",
        "    enforce_monotonic_index      = True,\n",
        "    allow_duplicate_dates        = False,\n",
        "    max_missing_ratio            = 0.05,\n",
        "    max_drawdown                 = 0.3,\n",
        "    min_volatility               = 0.05,\n",
        "    max_volatility               = 1.0,\n",
        "    min_avg_return               = 0.0,\n",
        "    max_skewness                 = 3.0,\n",
        "    max_kurtosis                 = 10.0,\n",
        "    expected_freq                = \"B\",\n",
        "    max_gap_days                 = 3,\n",
        "    min_aum_usd                  = 1e7,\n",
        ")\n",
        "\n",
        "def select_funds(\n",
        "    df: pd.DataFrame,\n",
        "    rf_col: str,\n",
        "    fund_columns: list[str],\n",
        "    in_sdate: str,\n",
        "    in_edate: str,\n",
        "    out_sdate: str,\n",
        "    out_edate: str,\n",
        "    cfg: FundSelectionConfig,\n",
        "    selection_mode: str = \"all\",\n",
        "    random_n: int | None = None\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Select eligible funds with additional data-validity and coverage checks driven by FundSelectionConfig.\n",
        "    \"\"\"\n",
        "    # Ensure Date is sorted\n",
        "    df = df.sort_values(\"Date\")  # guarantee monotonic index\n",
        "\n",
        "    # Prepare monthly periods within analysis window\n",
        "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
        "    span = pd.period_range(\n",
        "        pd.Period(in_sdate, \"M\"), pd.Period(out_edate, \"M\"), freq=\"M\"\n",
        "    )\n",
        "\n",
        "    eligible_funds: list[str] = []\n",
        "    for f in fund_columns:\n",
        "        try:\n",
        "            ser = df.set_index(\"Date\")[f]\n",
        "            clean = ser.dropna()\n",
        "\n",
        "            # 1. Implausible value limits\n",
        "            if not clean.between(-cfg.implausible_value_limit, cfg.implausible_value_limit).all():\n",
        "                raise ValueError(f\"Values outside ±{cfg.implausible_value_limit}\")\n",
        "\n",
        "            # 2. Extreme outlier threshold\n",
        "            if (clean.abs() > cfg.outlier_threshold).any():\n",
        "                raise ValueError(f\"Outliers beyond ±{cfg.outlier_threshold}\")\n",
        "\n",
        "            # 3. Excessive zero-return rate\n",
        "            if (clean == 0).mean() > cfg.zero_return_threshold:\n",
        "                raise ValueError(f\"Zero-return proportion > {cfg.zero_return_threshold}\")\n",
        "\n",
        "            # 4. Monotonic date index\n",
        "            if cfg.enforce_monotonic_index and not clean.index.is_monotonic_increasing:\n",
        "                raise ValueError(\"Date index not monotonically increasing\")\n",
        "\n",
        "            # 5. Duplicate dates\n",
        "            if not cfg.allow_duplicate_dates and clean.index.duplicated().any():\n",
        "                raise ValueError(\"Duplicate dates detected in index\")\n",
        "\n",
        "            # 6. Coverage checks using config thresholds\n",
        "            m_ok = df.groupby(\"Month\")[f].apply(lambda col: col.notna().any())\n",
        "            mask = m_ok.reindex(span, fill_value=False).to_numpy()\n",
        "\n",
        "            # tolerance for missing months per-cfg\n",
        "            missing_count = (~mask).sum()\n",
        "            if missing_count > cfg.max_missing_months:\n",
        "                raise ValueError(f\"Missing-month count {missing_count} exceeds {cfg.max_missing_months}\")\n",
        "\n",
        "            # maximum run of consecutive missing months per-cfg with guard\n",
        "            temp = np.flatnonzero(np.r_[True, mask, True])\n",
        "            if temp.size <= 1:\n",
        "                gap = 0\n",
        "            else:\n",
        "                gap = np.diff(temp).max() - 1\n",
        "            if gap > cfg.max_consecutive_month_gap:\n",
        "                raise ValueError(f\"Consecutive-missing gap {gap} exceeds {cfg.max_consecutive_month_gap}\")\n",
        "\n",
        "            eligible_funds.append(f)\n",
        "\n",
        "        except ValueError:\n",
        "            continue\n",
        "        except KeyError:\n",
        "            continue\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # Final selection-mode logic\n",
        "    if selection_mode == \"all\" or random_n is None:\n",
        "        return eligible_funds\n",
        "    if selection_mode == \"random\":\n",
        "        if random_n > len(eligible_funds):\n",
        "            raise ValueError(\n",
        "                f\"random_n exceeds eligible pool: {random_n} > {len(eligible_funds)}\"\n",
        "            )\n",
        "        return list(np.random.choice(eligible_funds, random_n, replace=False))\n",
        "\n",
        "    raise ValueError(f\"Unsupported selection_mode '{selection_mode}'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac53bc18",
      "metadata": {},
      "source": [
        "## 3. Weight Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "59a9bf13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "#  3 · WEIGHT PREP\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "def prepare_weights(selected: list[str],\n",
        "                    custom: Dict[str, int] | None) -> tuple[Dict[str, float], np.ndarray]:\n",
        "    if not custom:\n",
        "        w = {f: 1/len(selected) for f in selected}\n",
        "    else:\n",
        "        missing = [f for f in selected if f not in custom]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing weights for {missing}\")\n",
        "        w = {f: pct/100 for f, pct in custom.items()}\n",
        "        if abs(sum(w.values()) - 1) > 1e-6:\n",
        "            raise ValueError(\"Custom weights must sum to 100.\")\n",
        "    vec = np.array([w[f] for f in selected])\n",
        "    return w, vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3666a84",
      "metadata": {},
      "source": [
        "## 4. Analysis (In-Sample & Out-of-Sample)\n",
        "The `run_analysis` function orchestrates the entire process:\n",
        "- Function definitions\n",
        "- Validates date inputs.\n",
        "- Converts 'Date' column.\n",
        "- Identifies risk-free column.\n",
        "- Fills short gaps.\n",
        "- Selects funds.\n",
        "- Computes in-sample scaling factors and applies them in- and out-of-sample.\n",
        "- Computes individual fund stats and portfolio stats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "72976bb9-5ceb-4a2f-953d-193aca9aab44",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 4 · CORE STATS  +  RUN_ANALYSIS  (helpers included, weight fix)\n",
        "# ===============================================================\n",
        "\n",
        "M_PER_YEAR = 12           # constant used across helpers\n",
        "\n",
        "# ---------- helpers --------------------------------------------\n",
        "def _ensure_dt(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Return a copy whose Date column is datetime64[ns].\"\"\"\n",
        "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
        "        return df\n",
        "    df = df.copy()\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "    df.dropna(subset=[\"Date\"], inplace=True)\n",
        "    return df\n",
        "\n",
        "# 3. Metric function definitions\n",
        "# === Metric Function Definitions with flexible annualization ===\n",
        "@register_metric(\"AnnualReturn\")\n",
        "def compute_annual_return(\n",
        "    returns: pd.Series,\n",
        "    periods_per_year: int = 252,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Geometric annualized return based on periods_per_year.\n",
        "    \"\"\"\n",
        "    r = returns.dropna()\n",
        "    if r.empty:\n",
        "        return np.nan\n",
        "    total_growth = (1 + r).prod()\n",
        "    n_periods = len(r)\n",
        "    return total_growth ** (periods_per_year / n_periods) - 1\n",
        "\n",
        "@register_metric(\"Volatility\")\n",
        "def compute_volatility(\n",
        "    returns: pd.Series,\n",
        "    periods_per_year: int = 252,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Annualized standard deviation of returns with flexible scaling.\n",
        "    \"\"\"\n",
        "    r = returns.dropna()\n",
        "    if r.empty:\n",
        "        return 0.0\n",
        "    return r.std(ddof=0) * np.sqrt(periods_per_year)\n",
        "\n",
        "@register_metric(\"Sharpe\")\n",
        "def compute_sharpe(\n",
        "    returns: pd.Series,\n",
        "    risk_free: float = 0.0,\n",
        "    periods_per_year: int = 252,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Sharpe ratio using flexible annualized return and volatility.\n",
        "    \"\"\"\n",
        "    vol = compute_volatility(returns, periods_per_year=periods_per_year)\n",
        "    if vol == 0:\n",
        "        return np.nan\n",
        "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
        "    return (ann_ret - risk_free) / vol\n",
        "\n",
        "@register_metric(\"Sortino\")\n",
        "def compute_sortino(\n",
        "    returns: pd.Series,\n",
        "    risk_free: float = 0.0,\n",
        "    periods_per_year: int = 252,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Sortino ratio using flexible annualized return and downside deviation.\n",
        "    \"\"\"\n",
        "    r = returns.dropna()\n",
        "    if r.empty:\n",
        "        return np.nan\n",
        "    ann_ret = compute_annual_return(returns, periods_per_year=periods_per_year)\n",
        "    # Define per-period risk-free rate\n",
        "    period_rf = risk_free / periods_per_year\n",
        "    excess = r - period_rf\n",
        "    downside = excess[excess < 0]\n",
        "    if downside.empty:\n",
        "        return np.nan\n",
        "    down_dev = np.sqrt((downside ** 2).mean()) * np.sqrt(periods_per_year)\n",
        "    if down_dev == 0:\n",
        "        return np.nan\n",
        "    return (ann_ret - risk_free) / down_dev\n",
        "\n",
        "@register_metric(\"MaxDrawdown\")\n",
        "def compute_max_drawdown(\n",
        "    returns: pd.Series,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Maximum drawdown (peak-to-trough) of cumulative returns.\n",
        "    \"\"\"\n",
        "    r = returns.dropna()\n",
        "    if r.empty:\n",
        "        return 0.0\n",
        "    cum = (1 + r).cumprod()\n",
        "    peak = cum.cummax()\n",
        "    drawdown = (cum / peak) - 1\n",
        "    return float(drawdown.min())\n",
        "\n",
        "# Alias for backward compatibility\n",
        "_ann_vol = compute_volatility\n",
        "\n",
        "# === Aggregator with Centralized Error Handling ===\n",
        "\n",
        "def _stats(\n",
        "    returns: pd.Series,\n",
        "    cfg: RiskStatsConfig,\n",
        "    **metric_kwargs\n",
        ") -> namedtuple:\n",
        "    \"\"\"\n",
        "    Run each metric in cfg.metrics_to_run, returning a namedtuple of values.\n",
        "    Uses cfg.periods_per_year for annualization.\n",
        "    Centralized try/except ensures one failing metric doesn’t break the batch.\n",
        "    \"\"\"\n",
        "    Stat = namedtuple(\"Stat\", cfg.metrics_to_run)\n",
        "    values: list[float] = []\n",
        "    for name in cfg.metrics_to_run:\n",
        "        fn = METRIC_REGISTRY.get(name)\n",
        "        if fn is None:\n",
        "            logging.error(\"Metric '%s' not registered\", name)\n",
        "            values.append(np.nan)\n",
        "            continue\n",
        "        try:\n",
        "            params = {\n",
        "                \"risk_free\": cfg.risk_free,\n",
        "                \"periods_per_year\": cfg.periods_per_year,\n",
        "                **metric_kwargs\n",
        "            }\n",
        "            valid = {k: v for k, v in params.items() if k in inspect.signature(fn).parameters}\n",
        "            val = fn(returns, **valid)\n",
        "        except ZeroDivisionError:\n",
        "            logging.warning(\"%s: division by zero, setting NaN\", name)\n",
        "            val = np.nan\n",
        "        except (ValueError, TypeError) as e:\n",
        "            logging.warning(\"%s: invalid input (%s), setting NaN\", name, e)\n",
        "            val = np.nan\n",
        "        except Exception as e:\n",
        "            logging.error(\"%s: unexpected error (%s), setting NaN\", name, e)\n",
        "            val = np.nan\n",
        "        values.append(val)\n",
        "    return Stat(*values)\n",
        "\n",
        "# ---------- main ------------------------------------------------\n",
        "def run_analysis(\n",
        "    df,\n",
        "    selected,\n",
        "    w_vec,\n",
        "    w_dict,\n",
        "    rf_col,\n",
        "    in_start,\n",
        "    in_end,\n",
        "    out_start,\n",
        "    out_end,\n",
        "    target_vol,\n",
        "    monthly_cost,\n",
        "    indices_list\n",
        "):\n",
        "    \"\"\"\n",
        "    Vectorised run_analysis with correct weight re-normalisation\n",
        "    after funds are dropped.\n",
        "    Returns the same keys used by the UI and export functions.\n",
        "    \"\"\"\n",
        "    df = _ensure_dt(df)\n",
        "\n",
        "    # ---- date masks --------------------------------------------------\n",
        "    in_s = pd.to_datetime(in_start)  + pd.offsets.MonthEnd(0)\n",
        "    in_e = pd.to_datetime(in_end)    + pd.offsets.MonthEnd(0)\n",
        "    out_s= pd.to_datetime(out_start) + pd.offsets.MonthEnd(0)\n",
        "    out_e= pd.to_datetime(out_end)   + pd.offsets.MonthEnd(0)\n",
        "\n",
        "    m_in  = df[\"Date\"].between(in_s,  in_e)\n",
        "    m_out = df[\"Date\"].between(out_s, out_e)\n",
        "\n",
        "    in_df,  out_df  = df.loc[m_in,  selected], df.loc[m_out, selected]\n",
        "    in_rf,  out_rf  = df.loc[m_in,  rf_col],   df.loc[m_out, rf_col]\n",
        "\n",
        "    # ---- drop funds with any NaNs in either window ------------------\n",
        "    good = [f for f in selected\n",
        "            if in_df[f].notna().all() and out_df[f].notna().all()]\n",
        "    dropped = list(set(selected) - set(good))\n",
        "    if dropped:\n",
        "        logging.warning(\"Dropped funds: %s\", dropped)\n",
        "\n",
        "    selected = good\n",
        "    # >>>> new guard: kick out any accidental index columns\n",
        "    selected = [f for f in selected if f not in (indices_list or [])]\n",
        "    # <<<<\n",
        "\n",
        "    in_df, out_df = in_df[selected], out_df[selected]\n",
        "\n",
        "    # rebuild weights\n",
        "    if w_dict is None:                      # equal-weight path\n",
        "        w_dict = {f: 1/len(selected) for f in selected}\n",
        "    else:                                   # manual path → rescale\n",
        "        pct   = {f: w_dict[f]*100 for f in selected}\n",
        "        total = sum(pct.values())\n",
        "        w_dict = {f: p/total for f, p in pct.items()}\n",
        "    w_vec = np.array([w_dict[f] for f in selected])\n",
        "\n",
        "    # ---- scaling ----------------------------------------------------\n",
        "    vols = in_df.apply(compute_volatility)\n",
        "    scale = np.where(vols > 0, target_vol / vols, 1.0)\n",
        "    in_sc  = (in_df * scale) - monthly_cost\n",
        "    out_sc = (out_df * scale) - monthly_cost\n",
        "    in_sc.clip(lower=-1, inplace=True)\n",
        "    out_sc.clip(lower=-1, inplace=True)\n",
        "\n",
        "    # ---- stats ------------------------------------------------------\n",
        "    rf_value = in_rf.mean() if hasattr(in_rf, \"mean\") else float(in_rf)\n",
        "\n",
        "    # Create a RiskStatsConfig for in-sample stats\n",
        "    stats_cfg = RiskStatsConfig(risk_free=rf_value)\n",
        "\n",
        "    # Now compute stats for each scenario, always passing stats_cfg first\n",
        "    in_stat = {\n",
        "        f: _stats(in_sc[f], stats_cfg)\n",
        "        for f in selected\n",
        "    }\n",
        "    out_rf_value = out_rf.mean() if hasattr(out_rf, \"mean\") else float(out_rf)\n",
        "\n",
        "    # Re‐use the same config, updating only the risk_free field\n",
        "    stats_cfg.risk_free = out_rf_value\n",
        "\n",
        "    out_stat = {\n",
        "        f: _stats(out_sc[f], stats_cfg)\n",
        "        for f in selected\n",
        "    }\n",
        "\n",
        "    ew_vec = np.full(len(selected), 1/len(selected))\n",
        "\n",
        "    in_ew_stats  = _stats(in_sc.dot(ew_vec),  stats_cfg)\n",
        "    out_ew_stats = _stats(out_sc.dot(ew_vec), stats_cfg)\n",
        "    in_user_stats  = _stats(in_sc.dot(w_vec),  stats_cfg)\n",
        "    out_user_stats = _stats(out_sc.dot(w_vec), stats_cfg)\n",
        "\n",
        "    results = {\n",
        "        \"selected_funds\": selected,\n",
        "        \"indices_list\":   indices_list or [],\n",
        "        \"fund_weights\":   w_dict,\n",
        "        \"ew_weights\":     {f: 1/len(selected) for f in selected},\n",
        "        \"in_sample_stats\":  in_stat,\n",
        "        \"out_sample_stats\": out_stat,\n",
        "        \"in_ew_stats\":     in_ew_stats,\n",
        "        \"out_ew_stats\":    out_ew_stats,\n",
        "        \"in_user_stats\":   in_user_stats,\n",
        "        \"out_user_stats\":  out_user_stats,\n",
        "        \"dropped\":         dropped,\n",
        "    }\n",
        "\n",
        "    # ---- optional index stats ---------------------------------------\n",
        "    if indices_list:\n",
        "        idx_stats = {}\n",
        "        for col in indices_list:\n",
        "            idx_stats[col] = {\n",
        "                \"in_sample\":  _stats(df.loc[m_in,  col], stats_cfg),\n",
        "                \"out_sample\": _stats(df.loc[m_out, col], stats_cfg),\n",
        "            }\n",
        "        results[\"index_stats\"] = idx_stats\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183dc5df",
      "metadata": {},
      "source": [
        "## 5. Excel Export\n",
        "Creates an Excel file with In-Sample, Out-of-Sample and Equal-weight and User-weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8e2cce23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deprecated local export_to_excel; use trend_analysis.export.export_to_excel\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8c2c6d",
      "metadata": {},
      "source": [
        "## 6. Run Parameters, Widgets & User Inputs\n",
        "Here we define some IPython widgets for in-sample/out-of-sample dates, target volatility, monthly cost, etc. Also lets us use custom weights."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86794206",
      "metadata": {},
      "source": [
        "### Using This Notebook\n",
        "1. Run all cells.\n",
        "2. Call `demo_run()` in a new cell to see a quick example with dummy data.\n",
        "3. To use your own data, load it into a DataFrame (make sure it has a 'Date' column and decimal returns in other columns), then call `run_analysis()` and `export_to_excel()`.\n",
        "4. For interactive selection, do:\n",
        "   ```python\n",
        "   display(ui_inputs)\n",
        "   ```\n",
        "   Then wire the `apply_button` to a callback function that reads the widget values and runs `run_analysis()`.\n",
        "5. For custom weights, call:\n",
        "   ```python\n",
        "   my_weights = get_custom_weights(selected_funds)\n",
        "   ```\n",
        "   Then pass `my_weights` into your logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687e0d59-d17a-41c8-b991-1d91d29a22d1",
      "metadata": {
        "outputId": "795bb6da-96a0-42e2-c760-7d516fd82610"
      },
      "outputs": [],
      "source": [
        "from trend_analysis.core.rank_selection import build_ui",
        "display(build_ui())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (base)",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
